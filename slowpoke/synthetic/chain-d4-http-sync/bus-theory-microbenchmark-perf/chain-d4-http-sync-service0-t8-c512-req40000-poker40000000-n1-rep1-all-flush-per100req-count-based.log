[config.py] Random numbers for execution time: [395.60913465643097, 538.4926419819171, 620.7982495129224, 698.1320409217916, 823.4080191969051, 972.8167577794558]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service0
request_type                     : chain-d4-http-sync
repetitions                      : 1
target_num_exp                   : 1
pre_run                          : False
num_req                          : 40000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 31122
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 1, 'service3': 1, 'service4': 1, 'service5': 1}
baseline_service_processing_time : {'service0': 972.82, 'service1': 823.41, 'service2': 698.13, 'service3': 620.8, 'service4': 538.49, 'service5': 395.61}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2, 'service4': 2, 'service5': 2}
target_processing_time_range     : [0, 972.82]
baseline_throughputs             : []
poker_batch                      : 40000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d4-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '40000000', 'PROCESSING_TIME_SERVICE0': '0.00097282', 'PROCESSING_TIME_SERVICE1': '0.00082341', 'PROCESSING_TIME_SERVICE2': '0.00069813', 'PROCESSING_TIME_SERVICE3': '0.0006208', 'PROCESSING_TIME_SERVICE4': '0.00053849', 'PROCESSING_TIME_SERVICE5': '0.00039561', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE5': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d4-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request chain-d4-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        configmap/config-service5 created
        deployment.apps/service5 created
        service/service5 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   544.69ms  150.25ms   1.82s    83.48%
        Req/Sec   117.26     41.96   262.00     71.76%
        Latency Distribution
        50%  492.55ms
        75%  605.81ms
        90%  744.78ms
        99%    1.09s
        2560 requests in 3.03s, 62.46MB read
        Requests/sec:    844.44
        Transfer/sec:     20.60MB
        [run.sh] Speed is 844.44, duration is 94
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d94s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5c4bd886cd-5gz4q        1937m        52Mi
        service1-6cf58b9cfc-qzh2t        1369m        17Mi
        service2-6d55fcf7d8-7jv72        1222m        18Mi
        service3-7d984466f9-cnhm2        1143m        13Mi
        service4-596795d86-drf8g         1083m        15Mi
        service5-79d76f68df-ffq68        611m         10Mi
        ubuntu-client-76886f6bbd-kbxrf   106m         30Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   529.49ms  156.72ms   1.97s    83.46%
        Req/Sec   120.79     35.63   343.00     69.17%
        Latency Distribution
        50%  474.58ms
        75%  591.93ms
        90%  738.97ms
        99%    1.07s
        40000 requests in 1.57m, 0.95GB read
        Requests/sec:    425.53
        Transfer/sec:     10.38MB
        ------------------------------
        stop time: 41.378222
        stop time: 41.358245
        stop time: 41.508668
        stop time: 41.415539
        stop time: 41.848058
        stop time: 41.769040
        stop time: 41.708562
        stop time: 41.989920
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [41.378222, 41.358245, 41.508668, 41.415539, 41.848058, 41.76904, 41.708562, 41.98992]
    [exp] Throughput: 961.0294913102122
[test.py] Baseline throughput: 961.0294913102122
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d4-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '40000000', 'PROCESSING_TIME_SERVICE0': '0.0', 'PROCESSING_TIME_SERVICE1': '0.00082341', 'PROCESSING_TIME_SERVICE2': '0.00069813', 'PROCESSING_TIME_SERVICE3': '0.0006208', 'PROCESSING_TIME_SERVICE4': '0.00053849', 'PROCESSING_TIME_SERVICE5': '0.00039561', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE5': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d4-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request chain-d4-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        configmap "config-service5" deleted
        deployment.apps "service5" deleted
        service "service5" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        configmap/config-service5 created
        deployment.apps/service5 created
        service/service5 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   369.26ms   62.53ms 591.45ms   72.25%
        Req/Sec   169.04     52.13   290.00     71.12%
        Latency Distribution
        50%  365.23ms
        75%  408.60ms
        90%  449.91ms
        99%  523.57ms
        3931 requests in 3.04s, 95.87MB read
        Requests/sec:   1294.82
        Transfer/sec:     31.58MB
        [run.sh] Speed is 1294.82, duration is 61
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d61s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service2-6d55fcf7d8-fbdsk        168m         18Mi
        service4-596795d86-tvxmh         189m         15Mi
        ubuntu-client-76886f6bbd-mdv7g   23m          10Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   367.42ms   55.39ms 753.67ms   74.83%
        Req/Sec   173.71     45.36   383.00     68.82%
        Latency Distribution
        50%  360.03ms
        75%  396.36ms
        90%  438.15ms
        99%  528.25ms
        40000 requests in 1.02m, 0.95GB read
        Requests/sec:    655.74
        Transfer/sec:     15.99MB
        ------------------------------
        stop time: 28.608314
        stop time: 28.998194
        stop time: 28.745397
        stop time: 28.872301
        stop time: 29.046844
        stop time: 28.983884
        stop time: 29.083415
        stop time: 29.040419
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [28.608314, 28.998194, 28.745397, 28.872301, 29.046844, 28.983884, 29.083415, 29.040419]
    [exp] Throughput: 1383.0136739253448
[test.py] Running slowdown experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d4-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '40000000', 'PROCESSING_TIME_SERVICE0': '0.00097282', 'PROCESSING_TIME_SERVICE1': '0.00082341', 'PROCESSING_TIME_SERVICE2': '0.00069813', 'PROCESSING_TIME_SERVICE3': '0.0006208', 'PROCESSING_TIME_SERVICE4': '0.00053849', 'PROCESSING_TIME_SERVICE5': '0.00039561', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE5': '486.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d4-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request chain-d4-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        configmap "config-service5" deleted
        deployment.apps "service5" deleted
        service "service5" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        configmap/config-service5 created
        deployment.apps/service5 created
        service/service5 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   616.23ms  162.13ms   1.25s    80.93%
        Req/Sec    96.06     40.38   191.00     67.10%
        Latency Distribution
        50%  597.10ms
        75%  659.97ms
        90%  809.40ms
        99%    1.15s
        2234 requests in 3.03s, 54.49MB read
        Requests/sec:    737.89
        Transfer/sec:     18.00MB
        [run.sh] Speed is 737.89, duration is 108
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d108s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   605.10ms   73.23ms   1.26s    75.26%
        Req/Sec   105.56     36.71   262.00     72.33%
        Latency Distribution
        50%  598.11ms
        75%  642.86ms
        90%  691.96ms
        99%  812.82ms
        40000 requests in 1.80m, 0.95GB read
        Requests/sec:    370.37
        Transfer/sec:      9.03MB
        ------------------------------
        stop time: 47.316111
        stop time: 47.519384
        stop time: 47.537206
        stop time: 47.581007
        stop time: 47.815786
        stop time: 47.554805
        stop time: 47.588821
        stop time: 47.823626
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [47.316111, 47.519384, 47.537206, 47.581007, 47.815786, 47.554805, 47.588821, 47.823626]
    [exp] Throughput: 840.4757443611708
[test.py] Baseline throughput:  961.0294913102122
[test.py] Groundtruth:  [1383.0136739253448]
[test.py] Slowdown:  [840.4757443611708]
[test.py] Predicted:  [1421.6816925241394]
[test.py] Error percentage:  [2.7959245326219286]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 961.0294913102122
    Groundtruth: [1383.0136739253448]
    Slowdown:    [840.4757443611708]
    Predicted:   [1421.6816925241394]
    Error Perc:  [2.7959245326219286]
