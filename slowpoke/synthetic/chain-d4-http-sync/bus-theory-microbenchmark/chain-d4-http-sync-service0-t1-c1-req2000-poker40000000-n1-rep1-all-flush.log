[config.py] Random numbers for execution time: [395.60913465643097, 538.4926419819171, 620.7982495129224, 698.1320409217916, 823.4080191969051, 972.8167577794558]
benchmark                        : synthetic
num_threads                      : 1
num_conns                        : 1
target_service                   : service0
request_type                     : chain-d4-http-sync
repetitions                      : 1
target_num_exp                   : 1
pre_run                          : False
num_req                          : 2000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 31122
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 1, 'service3': 1, 'service4': 1, 'service5': 1}
baseline_service_processing_time : {'service0': 972.82, 'service1': 823.41, 'service2': 698.13, 'service3': 620.8, 'service4': 538.49, 'service5': 395.61}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2, 'service4': 2, 'service5': 2}
target_processing_time_range     : [0, 972.82]
baseline_throughputs             : []
poker_batch                      : 40000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d4-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '40000000', 'PROCESSING_TIME_SERVICE0': '0.00097282', 'PROCESSING_TIME_SERVICE1': '0.00082341', 'PROCESSING_TIME_SERVICE2': '0.00069813', 'PROCESSING_TIME_SERVICE3': '0.0006208', 'PROCESSING_TIME_SERVICE4': '0.00053849', 'PROCESSING_TIME_SERVICE5': '0.00039561', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE5': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d4-http-sync 1 1 2000`:
        [run.sh] Running benchmark synthetic with request chain-d4-http-sync, thread 1, conn 1, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        configmap "config-service5" deleted
        deployment.apps "service5" deleted
        service "service5" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        configmap/config-service5 created
        deployment.apps/service5 created
        service/service5 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t1 -c1 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        1 threads and 1 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency     7.76ms    4.70ms  63.09ms   98.37%
        Req/Sec   136.65     16.54   150.00     96.77%
        Latency Distribution
        50%    7.16ms
        75%    7.27ms
        90%    7.49ms
        99%   33.71ms
        422 requests in 3.10s, 739.74KB read
        Requests/sec:    136.14
        Transfer/sec:    238.64KB
        [run.sh] Speed is 136.14, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t1 -c1 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        1 threads and 1 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency     7.09ms  303.51us  13.51ms   92.15%
        Req/Sec   141.40      4.90   151.00     78.01%
        Latency Distribution
        50%    7.03ms
        75%    7.12ms
        90%    7.29ms
        99%    8.28ms
        2000 requests in 22.00s, 3.42MB read
        Requests/sec:     90.91
        Transfer/sec:    159.36KB
        ------------------------------
        stop time: 14.190627
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5c4bd886cd-4xd9p        65m          7Mi
        service1-6cf58b9cfc-gttjc        58m          7Mi
        service2-6d55fcf7d8-ssnft        53m          6Mi
        service3-7d984466f9-448qf        51m          6Mi
        service4-596795d86-jpgds         45m          6Mi
        service5-79d76f68df-f6glx        27m          4Mi
        ubuntu-client-76886f6bbd-wpglt   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.190627]
    [exp] Throughput: 140.93809949341914
[test.py] Baseline throughput: 140.93809949341914
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d4-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '40000000', 'PROCESSING_TIME_SERVICE0': '0.0', 'PROCESSING_TIME_SERVICE1': '0.00082341', 'PROCESSING_TIME_SERVICE2': '0.00069813', 'PROCESSING_TIME_SERVICE3': '0.0006208', 'PROCESSING_TIME_SERVICE4': '0.00053849', 'PROCESSING_TIME_SERVICE5': '0.00039561', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE5': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d4-http-sync 1 1 2000`:
        [run.sh] Running benchmark synthetic with request chain-d4-http-sync, thread 1, conn 1, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        configmap "config-service5" deleted
        deployment.apps "service5" deleted
        service "service5" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        configmap/config-service5 created
        deployment.apps/service5 created
        service/service5 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t1 -c1 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        1 threads and 1 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency     6.58ms    4.04ms  56.28ms   98.37%
        Req/Sec   160.93     17.86   171.00     96.67%
        Latency Distribution
        50%    6.09ms
        75%    6.17ms
        90%    6.32ms
        99%   31.34ms
        482 requests in 3.00s, 844.91KB read
        Requests/sec:    160.42
        Transfer/sec:    281.21KB
        [run.sh] Speed is 160.42, duration is 18
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t1 -c1 -d18s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 18s test @ http://service0:80/endpoint1
        1 threads and 1 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency     6.17ms  244.22us   8.53ms   85.90%
        Req/Sec   162.33      4.83   171.00     73.17%
        Latency Distribution
        50%    6.14ms
        75%    6.24ms
        90%    6.38ms
        99%    7.14ms
        2000 requests in 18.00s, 3.42MB read
        Requests/sec:    111.11
        Transfer/sec:    194.77KB
        ------------------------------
        stop time: 12.358949
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5c4bd886cd-lkpfr        1m           7Mi
        service1-6cf58b9cfc-shbft        1m           7Mi
        service2-6d55fcf7d8-xzf4j        1m           7Mi
        service3-7d984466f9-6jpjw        1m           7Mi
        service4-596795d86-rqqkg         1m           7Mi
        service5-79d76f68df-rgsbh        1m           7Mi
        ubuntu-client-76886f6bbd-pvbs7   1m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.358949]
    [exp] Throughput: 161.82605818666295
[test.py] Running slowdown experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d4-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '40000000', 'PROCESSING_TIME_SERVICE0': '0.00097282', 'PROCESSING_TIME_SERVICE1': '0.00082341', 'PROCESSING_TIME_SERVICE2': '0.00069813', 'PROCESSING_TIME_SERVICE3': '0.0006208', 'PROCESSING_TIME_SERVICE4': '0.00053849', 'PROCESSING_TIME_SERVICE5': '0.00039561', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE5': '486.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d4-http-sync 1 1 2000`:
        [run.sh] Running benchmark synthetic with request chain-d4-http-sync, thread 1, conn 1, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        configmap "config-service5" deleted
        deployment.apps "service5" deleted
        service "service5" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        configmap/config-service5 created
        deployment.apps/service5 created
        service/service5 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t1 -c1 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        1 threads and 1 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency    25.44ms   46.31ms 210.31ms   88.49%
        Req/Sec   117.15     39.68   141.00     85.19%
        Latency Distribution
        50%    7.23ms
        75%    7.54ms
        90%   89.43ms
        99%  201.01ms
        323 requests in 3.00s, 566.20KB read
        Requests/sec:    107.54
        Transfer/sec:    188.51KB
        [run.sh] Speed is 107.54, duration is 27
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t1 -c1 -d27s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 27s test @ http://service0:80/endpoint1
        1 threads and 1 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency    24.53ms   46.00ms 211.95ms   88.30%
        Req/Sec   115.23     43.47   151.00     79.14%
        Latency Distribution
        50%    7.23ms
        75%    7.50ms
        90%   88.47ms
        99%  209.68ms
        2000 requests in 27.00s, 3.42MB read
        Requests/sec:     74.07
        Transfer/sec:    129.85KB
        ------------------------------
        stop time: 19.584588
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5c4bd886cd-nn8fm        51m          7Mi
        service1-7d47b66d67-wjj5r        46m          6Mi
        service2-6dff5c796b-qs4wj        41m          6Mi
        service3-5dbc559b49-9v2hz        39m          6Mi
        service4-64d6cd5984-47b2z        35m          6Mi
        service5-98c6b585f-b4l72         22m          4Mi
        ubuntu-client-76886f6bbd-vzbtw   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.584588]
    [exp] Throughput: 102.1211168700613
[test.py] Baseline throughput:  140.93809949341914
[test.py] Groundtruth:  [161.82605818666295]
[test.py] Slowdown:  [102.1211168700613]
[test.py] Predicted:  [107.45889374937406]
[test.py] Error percentage:  [-33.59605062775336]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 140.93809949341914
    Groundtruth: [161.82605818666295]
    Slowdown:    [102.1211168700613]
    Predicted:   [107.45889374937406]
    Error Perc:  [-33.59605062775336]
