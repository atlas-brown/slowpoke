[config.py] Random numbers for execution time: [395.60913465643097, 538.4926419819171, 620.7982495129224, 698.1320409217916, 823.4080191969051, 972.8167577794558]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service0
request_type                     : chain-d4-http-sync
repetitions                      : 1
target_num_exp                   : 1
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 31122
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 1, 'service3': 1, 'service4': 1, 'service5': 1}
baseline_service_processing_time : {'service0': 972.82, 'service1': 823.41, 'service2': 698.13, 'service3': 620.8, 'service4': 538.49, 'service5': 395.61}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2, 'service4': 2, 'service5': 2}
target_processing_time_range     : [0, 972.82]
baseline_throughputs             : []
poker_batch                      : 40000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d4-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '40000000', 'PROCESSING_TIME_SERVICE0': '0.00097282', 'PROCESSING_TIME_SERVICE1': '0.00082341', 'PROCESSING_TIME_SERVICE2': '0.00069813', 'PROCESSING_TIME_SERVICE3': '0.0006208', 'PROCESSING_TIME_SERVICE4': '0.00053849', 'PROCESSING_TIME_SERVICE5': '0.00039561', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE5': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d4-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request chain-d4-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        configmap "config-service5" deleted
        deployment.apps "service5" deleted
        service "service5" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        configmap/config-service5 created
        deployment.apps/service5 created
        service/service5 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   546.45ms  174.31ms   1.45s    77.74%
        Req/Sec   110.48     42.35   232.00     73.68%
        Latency Distribution
        50%  503.48ms
        75%  637.88ms
        90%  779.99ms
        99%    1.13s
        2543 requests in 3.02s, 62.08MB read
        Requests/sec:    840.75
        Transfer/sec:     20.52MB
        [run.sh] Speed is 840.75, duration is 47
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 47s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   520.44ms  154.78ms   1.54s    83.38%
        Req/Sec   122.21     37.21   373.00     67.11%
        Latency Distribution
        50%  467.45ms
        75%  588.31ms
        90%  719.86ms
        99%    1.07s
        20000 requests in 47.00s, 487.90MB read
        Requests/sec:    425.53
        Transfer/sec:     10.38MB
        ------------------------------
        stop time: 20.243727
        stop time: 20.634572
        stop time: 20.633291
        stop time: 20.528379
        stop time: 20.669189
        stop time: 20.737807
        stop time: 20.788677
        stop time: 20.667724
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [20.243727, 20.634572, 20.633291, 20.528379, 20.669189, 20.737807, 20.788677, 20.667724]
    [exp] Throughput: 970.2652158113012
[test.py] Baseline throughput: 970.2652158113012
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d4-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '40000000', 'PROCESSING_TIME_SERVICE0': '0.0', 'PROCESSING_TIME_SERVICE1': '0.00082341', 'PROCESSING_TIME_SERVICE2': '0.00069813', 'PROCESSING_TIME_SERVICE3': '0.0006208', 'PROCESSING_TIME_SERVICE4': '0.00053849', 'PROCESSING_TIME_SERVICE5': '0.00039561', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE5': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d4-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request chain-d4-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        configmap "config-service5" deleted
        deployment.apps "service5" deleted
        service "service5" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        configmap/config-service5 created
        deployment.apps/service5 created
        service/service5 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   399.79ms   70.81ms 692.53ms   71.02%
        Req/Sec   160.54     58.13   313.00     67.86%
        Latency Distribution
        50%  388.75ms
        75%  438.32ms
        90%  491.03ms
        99%  626.94ms
        3606 requests in 3.03s, 88.09MB read
        Requests/sec:   1190.24
        Transfer/sec:     29.08MB
        [run.sh] Speed is 1190.24, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   359.54ms   56.66ms 663.88ms   77.68%
        Req/Sec   176.86     49.37   383.00     70.11%
        Latency Distribution
        50%  354.82ms
        75%  389.61ms
        90%  427.66ms
        99%  509.36ms
        20000 requests in 33.00s, 487.79MB read
        Requests/sec:    606.06
        Transfer/sec:     14.78MB
        ------------------------------
        stop time: 14.057825
        stop time: 14.126576
        stop time: 14.132873
        stop time: 14.230155
        stop time: 14.328152
        stop time: 14.341944
        stop time: 14.311681
        stop time: 14.312581
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5c4bd886cd-n4vmh        185m         32Mi
        service1-6cf58b9cfc-hk2rz        560m         19Mi
        service2-6d55fcf7d8-q7x2m        477m         15Mi
        service3-7d984466f9-s4ttm        232m         13Mi
        service4-596795d86-r9n98         422m         12Mi
        service5-79d76f68df-tj5rb        252m         9Mi
        ubuntu-client-76886f6bbd-8hvng   39m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.057825, 14.126576, 14.132873, 14.230155, 14.328152, 14.341944, 14.311681, 14.312581]
    [exp] Throughput: 1405.4593152161256
[test.py] Running slowdown experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d4-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '40000000', 'PROCESSING_TIME_SERVICE0': '0.00097282', 'PROCESSING_TIME_SERVICE1': '0.00082341', 'PROCESSING_TIME_SERVICE2': '0.00069813', 'PROCESSING_TIME_SERVICE3': '0.0006208', 'PROCESSING_TIME_SERVICE4': '0.00053849', 'PROCESSING_TIME_SERVICE5': '0.00039561', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '486.0', 'SLOWPOKE_DELAY_MICROS_SERVICE5': '486.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d4-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request chain-d4-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        configmap "config-service5" deleted
        deployment.apps "service5" deleted
        service "service5" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        configmap/config-service5 created
        deployment.apps/service5 created
        service/service5 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   615.61ms  102.81ms   1.06s    77.02%
        Req/Sec   103.57     52.40   260.00     64.59%
        Latency Distribution
        50%  597.45ms
        75%  654.46ms
        90%  747.72ms
        99%  964.39ms
        2219 requests in 3.03s, 54.17MB read
        Requests/sec:    732.18
        Transfer/sec:     17.87MB
        [run.sh] Speed is 732.18, duration is 54
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d54s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5c4bd886cd-cbhq4        1683m        41Mi
        service1-7d47b66d67-6nk7z        1101m        21Mi
        service2-6dff5c796b-mclbm        933m         17Mi
        service3-5dbc559b49-4pnq9        908m         14Mi
        service4-64d6cd5984-hgjfc        855m         12Mi
        service5-98c6b585f-wfkr4         514m         10Mi
        ubuntu-client-76886f6bbd-85tjc   80m          43Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   609.71ms  101.22ms   1.58s    85.08%
        Req/Sec   104.66     39.53   272.00     69.04%
        Latency Distribution
        50%  602.33ms
        75%  649.73ms
        90%  705.30ms
        99%  895.71ms
        20000 requests in 0.90m, 487.81MB read
        Requests/sec:    370.37
        Transfer/sec:      9.03MB
        ------------------------------
        stop time: 23.698661
        stop time: 23.692818
        stop time: 23.922273
        stop time: 24.146219
        stop time: 24.154731
        stop time: 24.336774
        stop time: 24.493203
        stop time: 24.489126
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.698661, 23.692818, 23.922273, 24.146219, 24.154731, 24.336774, 24.493203, 24.489126]
    [exp] Throughput: 829.2999767459103
[test.py] Baseline throughput:  970.2652158113012
[test.py] Groundtruth:  [1405.4593152161256]
[test.py] Slowdown:  [829.2999767459103]
[test.py] Predicted:  [1389.9964820057787]
[test.py] Error percentage:  [-1.1001978529680196]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 970.2652158113012
    Groundtruth: [1405.4593152161256]
    Slowdown:    [829.2999767459103]
    Predicted:   [1389.9964820057787]
    Error Perc:  [-1.1001978529680196]
