[config.py] Random numbers for execution time: [786.0420416734107, 826.5145977008433, 958.0749646410659]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : dynamic-cache-http-sync
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 13505
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.25}
baseline_service_processing_time : {'service0': 958.07, 'service1': 826.51, 'service2': 6288.34}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2}
target_processing_time_range     : [0, 6288.34]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 628, 1256, 1884, 2512, 3140, 3768, 4396, 5024, 5652]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   328.81ms  388.60ms   2.86s    83.59%
        Req/Sec   188.73     70.20   535.00     74.14%
        Latency Distribution
        50%  127.47ms
        75%  536.18ms
        90%  877.05ms
        99%    1.66s
        4393 requests in 3.02s, 682.12KB read
        Requests/sec:   1452.24
        Transfer/sec:    225.49KB
        [run.sh] Speed is 1452.24, duration is 20
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d20s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 20s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   627.22ms  852.22ms   5.48s    83.50%
        Req/Sec   160.85     92.26   484.00     69.04%
        Latency Distribution
        50%   74.71ms
        75%    1.04s
        90%    1.95s
        99%    3.36s
        20000 requests in 20.00s, 3.03MB read
        Requests/sec:    999.99
        Transfer/sec:    155.27KB
        ------------------------------
        stop time: 14.566715
        stop time: 14.754815
        stop time: 15.477059
        stop time: 15.798013
        stop time: 15.989692
        stop time: 16.695879
        stop time: 16.852368
        stop time: 16.424391
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [14.566715, 14.754815, 15.477059, 15.798013, 15.989692, 16.695879, 16.852368, 16.424391]
    [exp] Throughput: 1264.2331716263218
[test.py] Baseline throughput: 1264.2331716263218
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   280.93ms  222.50ms   1.11s    65.15%
        Req/Sec   216.89     95.74   490.00     70.56%
        Latency Distribution
        50%  221.48ms
        75%  439.48ms
        90%  598.47ms
        99%  881.48ms
        4783 requests in 3.03s, 742.67KB read
        Requests/sec:   1577.09
        Transfer/sec:    244.88KB
        [run.sh] Speed is 1577.09, duration is 19
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d19s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 19s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   321.38ms  346.61ms   3.08s    85.06%
        Req/Sec   214.29     84.33   595.00     69.66%
        Latency Distribution
        50%  168.80ms
        75%  482.64ms
        90%  830.35ms
        99%    1.55s
        20000 requests in 19.00s, 3.03MB read
        Requests/sec:   1052.62
        Transfer/sec:    163.44KB
        ------------------------------
        stop time: 11.311081
        stop time: 11.481917
        stop time: 11.951317
        stop time: 12.105416
        stop time: 12.053955
        stop time: 11.896573
        stop time: 12.162948
        stop time: 12.140764
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-qfr92        932m         68Mi
        service1-7585bd9d88-zr75v        267m         39Mi
        service2-84cffc954f-m6sk2        35m          9Mi
        ubuntu-client-76886f6bbd-tzdb7   5m           16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.311081, 11.481917, 11.951317, 12.105416, 12.053955, 11.896573, 12.162948, 12.140764]
    [exp] Throughput: 1682.369288239289
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '786.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '786.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   690.96ms  433.91ms   2.41s    67.37%
        Req/Sec   127.59    100.18   393.00     63.57%
        Latency Distribution
        50%  601.84ms
        75%    1.02s
        90%    1.28s
        99%    1.81s
        1968 requests in 3.03s, 305.58KB read
        Requests/sec:    649.96
        Transfer/sec:    100.92KB
        [run.sh] Speed is 649.96, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-755b5b56df-7ttnr        537m         68Mi
        service1-5fb76b9f75-ztzpb        612m         49Mi
        service2-84cffc954f-g5m8g        788m         24Mi
        ubuntu-client-76886f6bbd-hdv52   25m          24Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   713.62ms  616.46ms   4.87s    69.22%
        Req/Sec   120.00     84.92   484.00     64.66%
        Latency Distribution
        50%  577.03ms
        75%    1.02s
        90%    1.55s
        99%    2.60s
        20000 requests in 46.00s, 3.03MB read
        Requests/sec:    434.78
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 27.063363
        stop time: 27.044076
        stop time: 28.211672
        stop time: 28.204083
        stop time: 28.226084
        stop time: 27.836675
        stop time: 28.145458
        stop time: 27.185557
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.063363, 27.044076, 28.211672, 28.204083, 28.226084, 27.836675, 28.145458, 27.185557]
    [exp] Throughput: 720.9903841151976
[test.py] Finished running 0th optmization experiment: groundtruth->1682.369288239289, slowdown->720.9903841151976, predicted->1664.063655094186, err->-1.0880865023553217
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.000628', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   391.07ms  386.48ms   2.61s    85.68%
        Req/Sec   195.68     87.41   404.00     68.28%
        Latency Distribution
        50%  223.31ms
        75%  525.84ms
        90%  996.25ms
        99%    1.69s
        4492 requests in 3.02s, 697.49KB read
        Requests/sec:   1485.36
        Transfer/sec:    230.64KB
        [run.sh] Speed is 1485.36, duration is 20
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d20s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 20s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   387.35ms  502.63ms   3.47s    85.07%
        Req/Sec   209.88     80.91   630.00     74.26%
        Latency Distribution
        50%  151.07ms
        75%  529.14ms
        90%    1.14s
        99%    2.23s
        20000 requests in 20.00s, 3.03MB read
        Requests/sec:    999.99
        Transfer/sec:    155.27KB
        ------------------------------
        stop time: 11.896696
        stop time: 11.867689
        stop time: 12.109727
        stop time: 12.177341
        stop time: 12.137305
        stop time: 12.274020
        stop time: 11.572268
        stop time: 12.101820
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-hc5xg   155m         56Mi
        service2-84cffc954f-77gdk   27m          9Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.896696, 11.867689, 12.109727, 12.177341, 12.137305, 12.27402, 11.572268, 12.10182]
    [exp] Throughput: 1664.2939036519042
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '707.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '707.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   700.06ms  742.94ms   2.87s    79.77%
        Req/Sec   144.63     88.04   390.00     62.81%
        Latency Distribution
        50%  350.85ms
        75%    1.31s
        90%    1.90s
        99%    2.66s
        1914 requests in 3.03s, 297.19KB read
        Requests/sec:    632.16
        Transfer/sec:     98.16KB
        [run.sh] Speed is 632.16, duration is 47
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fcdff97c-ftr22         852m         68Mi
        service1-5c8bcd55-w94jg          738m         54Mi
        service2-84cffc954f-bh7fx        1263m        27Mi
        ubuntu-client-76886f6bbd-wdhvt   26m          21Mi
        Running 47s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   670.16ms  619.53ms   4.40s    78.40%
        Req/Sec   121.44     83.28   515.00     64.60%
        Latency Distribution
        50%  515.68ms
        75%  922.82ms
        90%    1.53s
        99%    2.77s
        20000 requests in 47.00s, 3.03MB read
        Requests/sec:    425.53
        Transfer/sec:     66.07KB
        ------------------------------
        stop time: 24.834441
        stop time: 25.991306
        stop time: 25.943448
        stop time: 26.051951
        stop time: 26.344634
        stop time: 26.438249
        stop time: 26.417135
        stop time: 26.392087
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.834441, 25.991306, 25.943448, 26.051951, 26.344634, 26.438249, 26.417135, 26.392087]
    [exp] Throughput: 767.7055044834935
[test.py] Finished running 1th optmization experiment: groundtruth->1664.2939036519042, slowdown->767.7055044834935, predicted->1680.5583898931377, err->0.9772604589576926
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.001256', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   275.84ms  235.94ms   1.30s    75.39%
        Req/Sec   204.35    112.89   575.00     78.48%
        Latency Distribution
        50%  187.75ms
        75%  407.98ms
        90%  621.26ms
        99%    1.05s
        4572 requests in 3.02s, 709.91KB read
        Requests/sec:   1514.52
        Transfer/sec:    235.16KB
        [run.sh] Speed is 1514.52, duration is 19
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d19s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 19s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   329.03ms  360.14ms   2.71s    85.76%
        Req/Sec   216.61     95.07   636.00     70.39%
        Latency Distribution
        50%  171.40ms
        75%  473.28ms
        90%  842.10ms
        99%    1.62s
        20001 requests in 19.00s, 3.03MB read
        Requests/sec:   1052.68
        Transfer/sec:    163.45KB
        ------------------------------
        stop time: 11.064117
        stop time: 11.353445
        stop time: 12.073320
        stop time: 11.894088
        stop time: 11.942514
        stop time: 11.543851
        stop time: 12.076665
        stop time: 11.981959
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-z8qs4        541m         64Mi
        service1-7585bd9d88-l9nbj        1m           40Mi
        service2-84cffc954f-s86jw        183m         13Mi
        ubuntu-client-76886f6bbd-vln6l   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.064117, 11.353445, 12.07332, 11.894088, 11.942514, 11.543851, 12.076665, 11.981959]
    [exp] Throughput: 1703.3968895908918
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '629.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '629.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   687.73ms  616.20ms   2.49s    60.88%
        Req/Sec   145.02     81.61   330.00     60.16%
        Latency Distribution
        50%  563.13ms
        75%    1.13s
        90%    1.56s
        99%    2.27s
        2205 requests in 3.03s, 342.38KB read
        Requests/sec:    728.78
        Transfer/sec:    113.16KB
        [run.sh] Speed is 728.78, duration is 41
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d41s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-54bc669545-9hc28        137m         55Mi
        service1-8d87fcdc5-6ddjv         282m         43Mi
        service2-84cffc954f-x4qkd        2m           22Mi
        ubuntu-client-76886f6bbd-jnjrk   19m          0Mi
        Running 41s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   631.25ms  474.58ms   3.92s    66.70%
        Req/Sec   124.18     78.32   440.00     67.06%
        Latency Distribution
        50%  570.20ms
        75%  875.08ms
        90%    1.27s
        99%    2.13s
        20000 requests in 41.00s, 3.03MB read
        Requests/sec:    487.80
        Transfer/sec:     75.74KB
        ------------------------------
        stop time: 24.806557
        stop time: 24.093856
        stop time: 24.567292
        stop time: 24.460344
        stop time: 24.792650
        stop time: 24.801053
        stop time: 24.877764
        stop time: 24.885967
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.806557, 24.093856, 24.567292, 24.460344, 24.79265, 24.801053, 24.877764, 24.885967]
    [exp] Throughput: 811.007467792245
[test.py] Finished running 2th optmization experiment: groundtruth->1703.3968895908918, slowdown->811.007467792245, predicted->1655.6517021242935, err->-2.802939688240557
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.001884', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   322.11ms  258.56ms   1.52s    80.26%
        Req/Sec   207.51     86.52   465.00     66.07%
        Latency Distribution
        50%  213.38ms
        75%  460.62ms
        90%  703.51ms
        99%    1.14s
        4665 requests in 3.02s, 724.35KB read
        Requests/sec:   1542.64
        Transfer/sec:    239.53KB
        [run.sh] Speed is 1542.64, duration is 19
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d19s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 19s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   356.23ms  446.93ms   2.44s    85.79%
        Req/Sec   213.68     85.66   727.00     73.03%
        Latency Distribution
        50%  150.12ms
        75%  497.55ms
        90%    1.04s
        99%    1.88s
        20001 requests in 19.00s, 3.03MB read
        Requests/sec:   1052.68
        Transfer/sec:    163.45KB
        ------------------------------
        stop time: 11.484900
        stop time: 11.638938
        stop time: 12.132606
        stop time: 11.737746
        stop time: 11.821994
        stop time: 12.096179
        stop time: 12.152916
        stop time: 11.603439
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-cjcb6        1581m        65Mi
        service1-7585bd9d88-xkgqb        1161m        36Mi
        service2-84cffc954f-hw5t8        707m         12Mi
        ubuntu-client-76886f6bbd-qwmhx   55m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.4849, 11.638938, 12.132606, 11.737746, 11.821994, 12.096179, 12.152916, 11.603439]
    [exp] Throughput: 1690.104222178228
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '550.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '550.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   517.97ms  345.88ms   2.03s    62.54%
        Req/Sec   136.59     97.08   350.00     62.68%
        Latency Distribution
        50%  513.62ms
        75%  703.68ms
        90%  947.96ms
        99%    1.44s
        2292 requests in 3.02s, 355.89KB read
        Requests/sec:    758.50
        Transfer/sec:    117.77KB
        [run.sh] Speed is 758.50, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   604.00ms  558.30ms   3.89s    82.11%
        Req/Sec   126.59     83.42   480.00     70.50%
        Latency Distribution
        50%  432.06ms
        75%  807.80ms
        90%    1.39s
        99%    2.42s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 22.402812
        stop time: 22.006887
        stop time: 22.320061
        stop time: 23.466343
        stop time: 23.156683
        stop time: 22.855623
        stop time: 23.423810
        stop time: 23.276953
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [22.402812, 22.006887, 22.320061, 23.466343, 23.156683, 22.855623, 23.42381, 23.276953]
    [exp] Throughput: 874.7511032415587
[test.py] Finished running 3th optmization experiment: groundtruth->1690.104222178228, slowdown->874.7511032415587, predicted->1687.3655090594023, err->-0.16204403745563
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.002512', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   352.89ms  376.51ms   2.37s    84.81%
        Req/Sec   218.00     77.34   400.00     72.22%
        Latency Distribution
        50%  166.17ms
        75%  564.74ms
        90%  880.42ms
        99%    1.61s
        4746 requests in 3.03s, 736.93KB read
        Requests/sec:   1566.60
        Transfer/sec:    243.25KB
        [run.sh] Speed is 1566.60, duration is 19
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d19s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 19s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   354.01ms  399.21ms   2.88s    86.60%
        Req/Sec   209.19     85.28   555.00     70.88%
        Latency Distribution
        50%  188.53ms
        75%  478.87ms
        90%  894.52ms
        99%    1.95s
        20001 requests in 19.00s, 3.03MB read
        Requests/sec:   1052.68
        Transfer/sec:    163.45KB
        ------------------------------
        stop time: 12.117537
        stop time: 11.694641
        stop time: 12.054247
        stop time: 12.048495
        stop time: 12.315527
        stop time: 12.234049
        stop time: 12.141982
        stop time: 11.860131
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-gqgm7        448m         66Mi
        service1-7585bd9d88-hhvbj        733m         50Mi
        service2-84cffc954f-5skcc        347m         22Mi
        ubuntu-client-76886f6bbd-prlzl   0m           15Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.117537, 11.694641, 12.054247, 12.048495, 12.315527, 12.234049, 12.141982, 11.860131]
    [exp] Throughput: 1658.6049997880614
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '472.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '472.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   575.70ms  372.97ms   1.96s    62.56%
        Req/Sec   116.26     62.52   292.00     61.20%
        Latency Distribution
        50%  500.03ms
        75%  862.64ms
        90%    1.08s
        99%    1.64s
        2440 requests in 3.03s, 378.87KB read
        Requests/sec:    805.52
        Transfer/sec:    125.08KB
        [run.sh] Speed is 805.52, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f776f4d67-vqh2v        756m         70Mi
        service1-79d8499785-9hrdb        895m         42Mi
        service2-84cffc954f-kbh7l        1139m        18Mi
        ubuntu-client-76886f6bbd-2h48x   16m          22Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   580.50ms  602.70ms   4.62s    85.34%
        Req/Sec   128.90     74.41   545.00     69.53%
        Latency Distribution
        50%  376.76ms
        75%  784.85ms
        90%    1.42s
        99%    2.72s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 20.637430
        stop time: 21.349732
        stop time: 21.347873
        stop time: 21.357335
        stop time: 21.285999
        stop time: 21.488601
        stop time: 21.785977
        stop time: 21.457602
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.63743, 21.349732, 21.347873, 21.357335, 21.285999, 21.488601, 21.785977, 21.457602]
    [exp] Throughput: 937.2590091078671
[test.py] Finished running 4th optmization experiment: groundtruth->1658.6049997880614, slowdown->937.2590091078671, predicted->1680.959215002132, err->1.3477720865984977
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00314', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   338.47ms  254.31ms   1.43s    73.04%
        Req/Sec   199.66     90.19   424.00     67.86%
        Latency Distribution
        50%  259.42ms
        75%  480.50ms
        90%  727.04ms
        99%    1.08s
        4492 requests in 3.04s, 697.49KB read
        Requests/sec:   1480.00
        Transfer/sec:    229.80KB
        [run.sh] Speed is 1480.00, duration is 20
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d20s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 20s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   381.20ms  512.39ms   4.58s    84.71%
        Req/Sec   211.26     75.61   590.00     72.90%
        Latency Distribution
        50%  124.37ms
        75%  570.92ms
        90%    1.14s
        99%    2.16s
        20000 requests in 20.00s, 3.03MB read
        Requests/sec:    999.99
        Transfer/sec:    155.27KB
        ------------------------------
        stop time: 11.430638
        stop time: 12.050296
        stop time: 11.854756
        stop time: 11.703107
        stop time: 12.121592
        stop time: 11.893939
        stop time: 12.100161
        stop time: 11.748867
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-8r2t9        498m         64Mi
        service1-7585bd9d88-dlljq        2m           38Mi
        service2-84cffc954f-wppvk        302m         10Mi
        ubuntu-client-76886f6bbd-plclw   27m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.430638, 12.050296, 11.854756, 11.703107, 12.121592, 11.893939, 12.100161, 11.748867]
    [exp] Throughput: 1685.9256273297647
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '393.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '393.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   516.31ms  415.39ms   2.51s    68.49%
        Req/Sec   125.24     69.45   330.00     63.01%
        Latency Distribution
        50%  372.09ms
        75%  781.51ms
        90%    1.09s
        99%    1.69s
        2431 requests in 3.03s, 377.47KB read
        Requests/sec:    803.60
        Transfer/sec:    124.78KB
        [run.sh] Speed is 803.60, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-647895557b-78kks        1183m        74Mi
        service1-567df7bb86-7x6dq        980m         43Mi
        service2-84cffc954f-mmd5h        1652m        20Mi
        ubuntu-client-76886f6bbd-ngfjv   34m          21Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   510.92ms  503.39ms   3.48s    84.19%
        Req/Sec   135.37     79.01   590.00     65.71%
        Latency Distribution
        50%  346.68ms
        75%  638.64ms
        90%    1.27s
        99%    2.18s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 17.976176
        stop time: 19.393653
        stop time: 19.320670
        stop time: 19.962806
        stop time: 20.069560
        stop time: 20.008347
        stop time: 19.753937
        stop time: 19.927840
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.976176, 19.393653, 19.32067, 19.962806, 20.06956, 20.008347, 19.753937, 19.92784]
    [exp] Throughput: 1022.9329483627477
[test.py] Finished running 5th optmization experiment: groundtruth->1685.9256273297647, slowdown->1022.9329483627477, predicted->1712.2153585096985, err->1.559364823320975
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.003768', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   374.41ms  518.78ms   2.93s    83.98%
        Req/Sec   193.36     75.89   585.00     72.69%
        Latency Distribution
        50%   89.40ms
        75%  559.76ms
        90%    1.20s
        99%    2.09s
        4248 requests in 3.02s, 659.60KB read
        Requests/sec:   1405.63
        Transfer/sec:    218.26KB
        [run.sh] Speed is 1405.63, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   365.39ms  453.12ms   3.47s    85.30%
        Req/Sec   208.26     78.47   525.00     72.09%
        Latency Distribution
        50%  155.77ms
        75%  505.16ms
        90%    1.07s
        99%    1.86s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 11.462531
        stop time: 12.092122
        stop time: 12.206697
        stop time: 12.193598
        stop time: 11.898873
        stop time: 12.016112
        stop time: 12.153774
        stop time: 12.087357
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [11.462531, 12.092122, 12.206697, 12.193598, 11.898873, 12.016112, 12.153774, 12.087357]
    [exp] Throughput: 1664.7407004046902
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '315.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '315.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   473.38ms  322.88ms   1.86s    71.04%
        Req/Sec   123.35     67.32   300.00     65.17%
        Latency Distribution
        50%  386.97ms
        75%  642.32ms
        90%  947.26ms
        99%    1.56s
        2897 requests in 3.03s, 449.83KB read
        Requests/sec:    955.83
        Transfer/sec:    148.41KB
        [run.sh] Speed is 955.83, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   481.32ms  468.03ms   3.31s    84.33%
        Req/Sec   140.90     81.47   710.00     71.27%
        Latency Distribution
        50%  321.52ms
        75%  652.52ms
        90%    1.16s
        99%    2.01s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 17.166239
        stop time: 18.011139
        stop time: 18.453185
        stop time: 18.496197
        stop time: 18.103808
        stop time: 18.267645
        stop time: 18.489003
        stop time: 18.527259
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-75695c895c-p7bjw        1034m        66Mi
        service1-5c566b998c-9zqp7        495m         39Mi
        service2-84cffc954f-zs9nv        1390m        17Mi
        ubuntu-client-76886f6bbd-h7shr   40m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.166239, 18.011139, 18.453185, 18.496197, 18.103808, 18.267645, 18.489003, 18.527259]
    [exp] Throughput: 1099.5469694681576
[test.py] Finished running 6th optmization experiment: groundtruth->1664.7407004046902, slowdown->1099.5469694681576, predicted->1682.3037678084336, err->1.0550031845484342
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.004396', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
