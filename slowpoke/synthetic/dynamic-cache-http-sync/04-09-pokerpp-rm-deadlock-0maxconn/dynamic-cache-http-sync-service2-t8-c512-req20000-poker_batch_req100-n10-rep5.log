[config.py] Random numbers for execution time: [786.0420416734107, 826.5145977008433, 958.0749646410659]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : dynamic-cache-http-sync
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 13505
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.25}
baseline_service_processing_time : {'service0': 958.07, 'service1': 826.51, 'service2': 6288.34}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2}
target_processing_time_range     : [0, 6288.34]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 628, 1256, 1884, 2512, 3140, 3768, 4396, 5024, 5652]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   328.81ms  388.60ms   2.86s    83.59%
        Req/Sec   188.73     70.20   535.00     74.14%
        Latency Distribution
        50%  127.47ms
        75%  536.18ms
        90%  877.05ms
        99%    1.66s
        4393 requests in 3.02s, 682.12KB read
        Requests/sec:   1452.24
        Transfer/sec:    225.49KB
        [run.sh] Speed is 1452.24, duration is 20
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d20s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 20s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   627.22ms  852.22ms   5.48s    83.50%
        Req/Sec   160.85     92.26   484.00     69.04%
        Latency Distribution
        50%   74.71ms
        75%    1.04s
        90%    1.95s
        99%    3.36s
        20000 requests in 20.00s, 3.03MB read
        Requests/sec:    999.99
        Transfer/sec:    155.27KB
        ------------------------------
        stop time: 14.566715
        stop time: 14.754815
        stop time: 15.477059
        stop time: 15.798013
        stop time: 15.989692
        stop time: 16.695879
        stop time: 16.852368
        stop time: 16.424391
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [14.566715, 14.754815, 15.477059, 15.798013, 15.989692, 16.695879, 16.852368, 16.424391]
    [exp] Throughput: 1264.2331716263218
[test.py] Baseline throughput: 1264.2331716263218
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   280.93ms  222.50ms   1.11s    65.15%
        Req/Sec   216.89     95.74   490.00     70.56%
        Latency Distribution
        50%  221.48ms
        75%  439.48ms
        90%  598.47ms
        99%  881.48ms
        4783 requests in 3.03s, 742.67KB read
        Requests/sec:   1577.09
        Transfer/sec:    244.88KB
        [run.sh] Speed is 1577.09, duration is 19
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d19s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 19s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   321.38ms  346.61ms   3.08s    85.06%
        Req/Sec   214.29     84.33   595.00     69.66%
        Latency Distribution
        50%  168.80ms
        75%  482.64ms
        90%  830.35ms
        99%    1.55s
        20000 requests in 19.00s, 3.03MB read
        Requests/sec:   1052.62
        Transfer/sec:    163.44KB
        ------------------------------
        stop time: 11.311081
        stop time: 11.481917
        stop time: 11.951317
        stop time: 12.105416
        stop time: 12.053955
        stop time: 11.896573
        stop time: 12.162948
        stop time: 12.140764
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-qfr92        932m         68Mi
        service1-7585bd9d88-zr75v        267m         39Mi
        service2-84cffc954f-m6sk2        35m          9Mi
        ubuntu-client-76886f6bbd-tzdb7   5m           16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.311081, 11.481917, 11.951317, 12.105416, 12.053955, 11.896573, 12.162948, 12.140764]
    [exp] Throughput: 1682.369288239289
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '786.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '786.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   690.96ms  433.91ms   2.41s    67.37%
        Req/Sec   127.59    100.18   393.00     63.57%
        Latency Distribution
        50%  601.84ms
        75%    1.02s
        90%    1.28s
        99%    1.81s
        1968 requests in 3.03s, 305.58KB read
        Requests/sec:    649.96
        Transfer/sec:    100.92KB
        [run.sh] Speed is 649.96, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-755b5b56df-7ttnr        537m         68Mi
        service1-5fb76b9f75-ztzpb        612m         49Mi
        service2-84cffc954f-g5m8g        788m         24Mi
        ubuntu-client-76886f6bbd-hdv52   25m          24Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   713.62ms  616.46ms   4.87s    69.22%
        Req/Sec   120.00     84.92   484.00     64.66%
        Latency Distribution
        50%  577.03ms
        75%    1.02s
        90%    1.55s
        99%    2.60s
        20000 requests in 46.00s, 3.03MB read
        Requests/sec:    434.78
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 27.063363
        stop time: 27.044076
        stop time: 28.211672
        stop time: 28.204083
        stop time: 28.226084
        stop time: 27.836675
        stop time: 28.145458
        stop time: 27.185557
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.063363, 27.044076, 28.211672, 28.204083, 28.226084, 27.836675, 28.145458, 27.185557]
    [exp] Throughput: 720.9903841151976
[test.py] Finished running 0th optmization experiment: groundtruth->1682.369288239289, slowdown->720.9903841151976, predicted->1664.063655094186, err->-1.0880865023553217
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.000628', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   391.07ms  386.48ms   2.61s    85.68%
        Req/Sec   195.68     87.41   404.00     68.28%
        Latency Distribution
        50%  223.31ms
        75%  525.84ms
        90%  996.25ms
        99%    1.69s
        4492 requests in 3.02s, 697.49KB read
        Requests/sec:   1485.36
        Transfer/sec:    230.64KB
        [run.sh] Speed is 1485.36, duration is 20
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d20s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 20s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   387.35ms  502.63ms   3.47s    85.07%
        Req/Sec   209.88     80.91   630.00     74.26%
        Latency Distribution
        50%  151.07ms
        75%  529.14ms
        90%    1.14s
        99%    2.23s
        20000 requests in 20.00s, 3.03MB read
        Requests/sec:    999.99
        Transfer/sec:    155.27KB
        ------------------------------
        stop time: 11.896696
        stop time: 11.867689
        stop time: 12.109727
        stop time: 12.177341
        stop time: 12.137305
        stop time: 12.274020
        stop time: 11.572268
        stop time: 12.101820
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-hc5xg   155m         56Mi
        service2-84cffc954f-77gdk   27m          9Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.896696, 11.867689, 12.109727, 12.177341, 12.137305, 12.27402, 11.572268, 12.10182]
    [exp] Throughput: 1664.2939036519042
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '707.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '707.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   700.06ms  742.94ms   2.87s    79.77%
        Req/Sec   144.63     88.04   390.00     62.81%
        Latency Distribution
        50%  350.85ms
        75%    1.31s
        90%    1.90s
        99%    2.66s
        1914 requests in 3.03s, 297.19KB read
        Requests/sec:    632.16
        Transfer/sec:     98.16KB
        [run.sh] Speed is 632.16, duration is 47
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fcdff97c-ftr22         852m         68Mi
        service1-5c8bcd55-w94jg          738m         54Mi
        service2-84cffc954f-bh7fx        1263m        27Mi
        ubuntu-client-76886f6bbd-wdhvt   26m          21Mi
        Running 47s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   670.16ms  619.53ms   4.40s    78.40%
        Req/Sec   121.44     83.28   515.00     64.60%
        Latency Distribution
        50%  515.68ms
        75%  922.82ms
        90%    1.53s
        99%    2.77s
        20000 requests in 47.00s, 3.03MB read
        Requests/sec:    425.53
        Transfer/sec:     66.07KB
        ------------------------------
        stop time: 24.834441
        stop time: 25.991306
        stop time: 25.943448
        stop time: 26.051951
        stop time: 26.344634
        stop time: 26.438249
        stop time: 26.417135
        stop time: 26.392087
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.834441, 25.991306, 25.943448, 26.051951, 26.344634, 26.438249, 26.417135, 26.392087]
    [exp] Throughput: 767.7055044834935
[test.py] Finished running 1th optmization experiment: groundtruth->1664.2939036519042, slowdown->767.7055044834935, predicted->1680.5583898931377, err->0.9772604589576926
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.001256', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   275.84ms  235.94ms   1.30s    75.39%
        Req/Sec   204.35    112.89   575.00     78.48%
        Latency Distribution
        50%  187.75ms
        75%  407.98ms
        90%  621.26ms
        99%    1.05s
        4572 requests in 3.02s, 709.91KB read
        Requests/sec:   1514.52
        Transfer/sec:    235.16KB
        [run.sh] Speed is 1514.52, duration is 19
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d19s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 19s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   329.03ms  360.14ms   2.71s    85.76%
        Req/Sec   216.61     95.07   636.00     70.39%
        Latency Distribution
        50%  171.40ms
        75%  473.28ms
        90%  842.10ms
        99%    1.62s
        20001 requests in 19.00s, 3.03MB read
        Requests/sec:   1052.68
        Transfer/sec:    163.45KB
        ------------------------------
        stop time: 11.064117
        stop time: 11.353445
        stop time: 12.073320
        stop time: 11.894088
        stop time: 11.942514
        stop time: 11.543851
        stop time: 12.076665
        stop time: 11.981959
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-z8qs4        541m         64Mi
        service1-7585bd9d88-l9nbj        1m           40Mi
        service2-84cffc954f-s86jw        183m         13Mi
        ubuntu-client-76886f6bbd-vln6l   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.064117, 11.353445, 12.07332, 11.894088, 11.942514, 11.543851, 12.076665, 11.981959]
    [exp] Throughput: 1703.3968895908918
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '629.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '629.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   687.73ms  616.20ms   2.49s    60.88%
        Req/Sec   145.02     81.61   330.00     60.16%
        Latency Distribution
        50%  563.13ms
        75%    1.13s
        90%    1.56s
        99%    2.27s
        2205 requests in 3.03s, 342.38KB read
        Requests/sec:    728.78
        Transfer/sec:    113.16KB
        [run.sh] Speed is 728.78, duration is 41
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d41s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-54bc669545-9hc28        137m         55Mi
        service1-8d87fcdc5-6ddjv         282m         43Mi
        service2-84cffc954f-x4qkd        2m           22Mi
        ubuntu-client-76886f6bbd-jnjrk   19m          0Mi
        Running 41s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   631.25ms  474.58ms   3.92s    66.70%
        Req/Sec   124.18     78.32   440.00     67.06%
        Latency Distribution
        50%  570.20ms
        75%  875.08ms
        90%    1.27s
        99%    2.13s
        20000 requests in 41.00s, 3.03MB read
        Requests/sec:    487.80
        Transfer/sec:     75.74KB
        ------------------------------
        stop time: 24.806557
        stop time: 24.093856
        stop time: 24.567292
        stop time: 24.460344
        stop time: 24.792650
        stop time: 24.801053
        stop time: 24.877764
        stop time: 24.885967
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.806557, 24.093856, 24.567292, 24.460344, 24.79265, 24.801053, 24.877764, 24.885967]
    [exp] Throughput: 811.007467792245
[test.py] Finished running 2th optmization experiment: groundtruth->1703.3968895908918, slowdown->811.007467792245, predicted->1655.6517021242935, err->-2.802939688240557
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.001884', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   322.11ms  258.56ms   1.52s    80.26%
        Req/Sec   207.51     86.52   465.00     66.07%
        Latency Distribution
        50%  213.38ms
        75%  460.62ms
        90%  703.51ms
        99%    1.14s
        4665 requests in 3.02s, 724.35KB read
        Requests/sec:   1542.64
        Transfer/sec:    239.53KB
        [run.sh] Speed is 1542.64, duration is 19
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d19s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 19s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   356.23ms  446.93ms   2.44s    85.79%
        Req/Sec   213.68     85.66   727.00     73.03%
        Latency Distribution
        50%  150.12ms
        75%  497.55ms
        90%    1.04s
        99%    1.88s
        20001 requests in 19.00s, 3.03MB read
        Requests/sec:   1052.68
        Transfer/sec:    163.45KB
        ------------------------------
        stop time: 11.484900
        stop time: 11.638938
        stop time: 12.132606
        stop time: 11.737746
        stop time: 11.821994
        stop time: 12.096179
        stop time: 12.152916
        stop time: 11.603439
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-cjcb6        1581m        65Mi
        service1-7585bd9d88-xkgqb        1161m        36Mi
        service2-84cffc954f-hw5t8        707m         12Mi
        ubuntu-client-76886f6bbd-qwmhx   55m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.4849, 11.638938, 12.132606, 11.737746, 11.821994, 12.096179, 12.152916, 11.603439]
    [exp] Throughput: 1690.104222178228
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '550.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '550.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   517.97ms  345.88ms   2.03s    62.54%
        Req/Sec   136.59     97.08   350.00     62.68%
        Latency Distribution
        50%  513.62ms
        75%  703.68ms
        90%  947.96ms
        99%    1.44s
        2292 requests in 3.02s, 355.89KB read
        Requests/sec:    758.50
        Transfer/sec:    117.77KB
        [run.sh] Speed is 758.50, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
