[config.py] Random numbers for execution time: [386.33758138448223, 630.0371054585657, 749.3901128626006, 763.4512536815579, 862.3153336716528]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : dynamic-cycle-http-sync
repetitions                      : 1
target_num_exp                   : 2
pre_run                          : False
num_req                          : 40000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 30622
request_ratio                    : {'service0': 1, 'service1': 1.34, 'service2': 0.34, 'service3': 0.5, 'service4': 0.5}
baseline_service_processing_time : {'service0': 1155.5, 'service1': 763.45, 'service2': 2953.48, 'service3': 1688.5, 'service4': 1035.38}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2, 'service4': 2}
target_processing_time_range     : [0, 2953.48]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 1476]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0011555', 'PROCESSING_TIME_SERVICE1': '0.00076345', 'PROCESSING_TIME_SERVICE2': '0.00295348', 'PROCESSING_TIME_SERVICE3': '0.0016885', 'PROCESSING_TIME_SERVICE4': '0.00103538', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-8cbfd77d6-sdld2 cannot connect to service4
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   420.85ms  202.26ms   1.52s    91.83%
        Req/Sec   155.51     51.86   303.00     72.20%
        Latency Distribution
        50%  366.13ms
        75%  417.13ms
        90%  564.96ms
        99%    1.37s
        3502 requests in 3.03s, 1.97MB read
        Requests/sec:   1156.47
        Transfer/sec:    666.74KB
        [run.sh] Speed is 1156.47, duration is 69
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d69s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-5c544b6b9c-9lzvw   9m           16Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   380.97ms   75.11ms   1.60s    87.34%
        Req/Sec   167.90     39.36   313.00     69.13%
        Latency Distribution
        50%  369.41ms
        75%  405.38ms
        90%  449.14ms
        99%  622.05ms
        40000 requests in 1.15m, 22.67MB read
        Requests/sec:    579.71
        Transfer/sec:    336.38KB
        ------------------------------
        stop time: 30.133004
        stop time: 29.792988
        stop time: 29.792646
        stop time: 29.731714
        stop time: 30.084990
        stop time: 30.062842
        stop time: 30.055946
        stop time: 30.116221
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [30.133004, 29.792988, 29.792646, 29.731714, 30.08499, 30.062842, 30.055946, 30.116221]
    [exp] Throughput: 1334.6103830827692
[test.py] Baseline throughput: 1334.6103830827692
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0011555', 'PROCESSING_TIME_SERVICE1': '0.00076345', 'PROCESSING_TIME_SERVICE2': '0.0', 'PROCESSING_TIME_SERVICE3': '0.0016885', 'PROCESSING_TIME_SERVICE4': '0.00103538', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   405.00ms  118.54ms   1.35s    88.27%
        Req/Sec   157.23     48.54   300.00     75.00%
        Latency Distribution
        50%  373.99ms
        75%  420.13ms
        90%  516.42ms
        99%  894.65ms
        3544 requests in 3.03s, 2.01MB read
        Requests/sec:   1171.45
        Transfer/sec:    681.81KB
        [run.sh] Speed is 1171.45, duration is 68
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d68s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   380.66ms  105.96ms   2.06s    91.68%
        Req/Sec   168.25     41.73   430.00     69.53%
        Latency Distribution
        50%  369.52ms
        75%  404.91ms
        90%  447.13ms
        99%  674.91ms
        40001 requests in 1.13m, 22.66MB read
        Requests/sec:    588.25
        Transfer/sec:    341.22KB
        ------------------------------
        stop time: 29.337481
        stop time: 29.239551
        stop time: 29.681749
        stop time: 30.034384
        stop time: 29.994232
        stop time: 30.214274
        stop time: 30.144844
        stop time: 30.260147
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [29.337481, 29.239551, 29.681749, 30.034384, 29.994232, 30.214274, 30.144844, 30.260147]
    [exp] Throughput: 1339.4352309857313
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0011555', 'PROCESSING_TIME_SERVICE1': '0.00076345', 'PROCESSING_TIME_SERVICE2': '0.001476', 'PROCESSING_TIME_SERVICE3': '0.0016885', 'PROCESSING_TIME_SERVICE4': '0.00103538', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   429.01ms  109.92ms 928.81ms   82.57%
        Req/Sec   157.59     55.02   373.00     69.86%
        Latency Distribution
        50%  398.36ms
        75%  454.42ms
        90%  571.47ms
        99%  806.44ms
        3368 requests in 3.03s, 1.90MB read
        Requests/sec:   1110.14
        Transfer/sec:    642.08KB
        [run.sh] Speed is 1110.14, duration is 72
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d72s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-4k6dj         1941m        49Mi
        service1-5c544b6b9c-tg8cn        1889m        22Mi
        service2-66888cb84d-lv9dc        994m         13Mi
        service3-67b8d48975-k8dfq        1210m        11Mi
        service4-dcdcc9fc4-94dnt         832m         10Mi
        ubuntu-client-76886f6bbd-llrcl   65m          13Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   381.44ms   76.23ms   1.22s    87.03%
        Req/Sec   168.15     43.17   444.00     70.64%
        Latency Distribution
        50%  371.38ms
        75%  407.01ms
        90%  451.69ms
        99%  622.96ms
        40000 requests in 1.20m, 22.60MB read
        Requests/sec:    555.55
        Transfer/sec:    321.48KB
        ------------------------------
        stop time: 29.482422
        stop time: 29.614067
        stop time: 29.982095
        stop time: 29.772769
        stop time: 30.221873
        stop time: 30.249710
        stop time: 30.244401
        stop time: 30.202031
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [29.482422, 29.614067, 29.982095, 29.772769, 30.221873, 30.24971, 30.244401, 30.202031]
    [exp] Throughput: 1334.615854682488
[test.py] Running slowdown experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0011555', 'PROCESSING_TIME_SERVICE1': '0.00076345', 'PROCESSING_TIME_SERVICE2': '0.00295348', 'PROCESSING_TIME_SERVICE3': '0.0016885', 'PROCESSING_TIME_SERVICE4': '0.00103538', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '502.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '50200000', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '374.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '37450000', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1004.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100400000', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1004.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100400000'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   695.99ms  130.12ms   1.12s    75.14%
        Req/Sec    89.49     41.29   220.00     70.37%
        Latency Distribution
        50%  685.94ms
        75%  763.98ms
        90%  837.45ms
        99%    1.07s
        1963 requests in 3.03s, 1.11MB read
        Requests/sec:    648.91
        Transfer/sec:    376.36KB
        [run.sh] Speed is 648.91, duration is 123
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d123s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-d86f8f887-tf8db         1102m        50Mi
        service1-8cff75774-c8gmv         1087m        24Mi
        service2-66888cb84d-5828m        908m         13Mi
        service3-55ddf66d6-f2fbz         703m         13Mi
        service4-7b866969bc-wr5zn        438m         11Mi
        ubuntu-client-76886f6bbd-k85md   38m          14Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   704.70ms   97.35ms   1.77s    74.72%
        Req/Sec    90.84     39.40   242.00     63.62%
        Latency Distribution
        50%  696.78ms
        75%  756.60ms
        90%  822.91ms
        99%  969.45ms
        40000 requests in 2.05m, 22.68MB read
        Requests/sec:    325.20
        Transfer/sec:    188.82KB
        ------------------------------
        stop time: 54.864381
        stop time: 54.980182
        stop time: 55.396369
        stop time: 55.296970
        stop time: 55.700887
        stop time: 55.695124
        stop time: 55.699557
        stop time: 55.694918
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [54.864381, 54.980182, 55.396369, 55.29697, 55.700887, 55.695124, 55.699557, 55.694918]
    [exp] Throughput: 721.8125630159285
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0011555', 'PROCESSING_TIME_SERVICE1': '0.00076345', 'PROCESSING_TIME_SERVICE2': '0.00295348', 'PROCESSING_TIME_SERVICE3': '0.0016885', 'PROCESSING_TIME_SERVICE4': '0.00103538', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '251.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '25100000', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '187.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '18700000', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '502.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '50200000', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '502.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '50200000'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   532.80ms  105.41ms   1.18s    84.12%
        Req/Sec   118.38     46.18   252.00     70.32%
        Latency Distribution
        50%  515.64ms
        75%  568.53ms
        90%  631.06ms
        99%  983.74ms
        2633 requests in 3.03s, 1.48MB read
        Requests/sec:    868.44
        Transfer/sec:    499.76KB
        [run.sh] Speed is 868.44, duration is 92
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d92s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7dd8d744cc-77kwl        1466m        50Mi
        service1-597fd56858-xkkll        1414m        22Mi
        service2-66888cb84d-8qbtt        1194m        12Mi
        service3-7dd95965d-h4lp4         937m         12Mi
        service4-665944bb99-c48fv        589m         11Mi
        ubuntu-client-76886f6bbd-86cn2   50m          13Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   520.33ms   76.21ms   1.59s    78.51%
        Req/Sec   123.06     38.14   313.00     71.88%
        Latency Distribution
        50%  511.22ms
        75%  557.68ms
        90%  605.73ms
        99%  728.73ms
        40000 requests in 1.53m, 22.63MB read
        Requests/sec:    434.78
        Transfer/sec:    251.84KB
        ------------------------------
        stop time: 40.548158
        stop time: 40.686067
        stop time: 40.846668
        stop time: 40.773168
        stop time: 40.922747
        stop time: 41.203800
        stop time: 41.182074
        stop time: 41.149822
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [40.548158, 40.686067, 40.846668, 40.773168, 40.922747, 41.2038, 41.182074, 41.149822]
    [exp] Throughput: 977.658953108617
[test.py] Baseline throughput:  1334.6103830827692
[test.py] Groundtruth:  [1339.4352309857313, 1334.615854682488]
[test.py] Slowdown:  [721.8125630159285, 977.658953108617]
[test.py] Predicted:  [1132.1058730129014, 1295.8739793656043]
[test.py] Error percentage:  [-15.478864014966213, -2.902848424957493]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1334.6103830827692
    Groundtruth: [1339.4352309857313, 1334.615854682488]
    Slowdown:    [721.8125630159285, 977.658953108617]
    Predicted:   [1132.1058730129014, 1295.8739793656043]
    Error Perc:  [-15.478864014966213, -2.902848424957493]
