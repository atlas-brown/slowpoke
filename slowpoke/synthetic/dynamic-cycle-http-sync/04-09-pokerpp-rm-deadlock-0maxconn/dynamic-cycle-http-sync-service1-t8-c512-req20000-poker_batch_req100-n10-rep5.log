[config.py] Random numbers for execution time: [536.9622541078321, 789.2346993697366, 1047.527802014133, 1063.0141286808516, 1238.2474317227257]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service1
request_type                     : dynamic-cycle-http-sync
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 12843
request_ratio                    : {'service0': 1, 'service1': 1.34, 'service2': 0.34, 'service3': 0.5, 'service4': 0.5}
baseline_service_processing_time : {'service0': 1659.25, 'service1': 1063.01, 'service2': 4128.49, 'service3': 2115.15, 'service4': 1439.06}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2, 'service4': 2}
target_processing_time_range     : [0, 1063.01]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 106, 212, 318, 424, 530, 636, 742, 848, 954]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        configmap "config-service1" deleted
        configmap "config-service2" deleted
        configmap "config-service3" deleted
        configmap "config-service4" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   705.15ms  682.72ms   2.96s    78.97%
        Req/Sec   112.24     67.45   280.00     61.11%
        Latency Distribution
        50%  581.41ms
        75%    1.04s
        90%    1.71s
        99%    2.79s
        2057 requests in 3.03s, 319.40KB read
        Requests/sec:    678.25
        Transfer/sec:    105.31KB
        [run.sh] Speed is 678.25, duration is 44
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d44s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 44s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   516.34ms  567.41ms   5.09s    86.44%
        Req/Sec   129.74     61.05   575.00     72.57%
        Latency Distribution
        50%  307.82ms
        75%  614.67ms
        90%    1.29s
        99%    2.65s
        20000 requests in 44.00s, 3.03MB read
        Requests/sec:    454.54
        Transfer/sec:     70.58KB
        ------------------------------
        stop time: 19.057868
        stop time: 20.059066
        stop time: 19.519283
        stop time: 19.645627
        stop time: 19.637810
        stop time: 19.904306
        stop time: 19.353450
        stop time: 19.910726
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.057868, 20.059066, 19.519283, 19.645627, 19.63781, 19.904306, 19.35345, 19.910726]
    [exp] Throughput: 1018.5364985169853
[test.py] Baseline throughput: 1018.5364985169853
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   447.95ms  363.00ms   2.08s    64.22%
        Req/Sec   127.92     59.06   280.00     71.36%
        Latency Distribution
        50%  389.62ms
        75%  724.43ms
        90%  933.11ms
        99%    1.42s
        2739 requests in 3.03s, 425.29KB read
        Requests/sec:    902.76
        Transfer/sec:    140.17KB
        [run.sh] Speed is 902.76, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   579.75ms  731.56ms   6.16s    90.94%
        Req/Sec   132.64     72.30   505.00     71.07%
        Latency Distribution
        50%  334.78ms
        75%  722.58ms
        90%    1.24s
        99%    4.08s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.350311
        stop time: 18.766757
        stop time: 19.473383
        stop time: 19.357286
        stop time: 19.809241
        stop time: 19.573875
        stop time: 19.950660
        stop time: 19.729183
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-ztk6l        647m         47Mi
        service1-7755b7b4b5-5xh5t        120m         50Mi
        service2-958786d58-z4g7r         518m         29Mi
        service3-6ddd8b8f64-j9hgl        381m         11Mi
        service4-9bb5bd9fd-hwcm6         260m         10Mi
        ubuntu-client-76886f6bbd-nz67h   16m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.350311, 18.766757, 19.473383, 19.357286, 19.809241, 19.573875, 19.95066, 19.729183]
    [exp] Throughput: 1025.5707083057944
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '712.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '2094.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   974.27ms  449.88ms   2.81s    68.29%
        Req/Sec    75.89     62.77   262.00     67.89%
        Latency Distribution
        50%    1.05s
        75%    1.19s
        90%    1.43s
        99%    2.24s
        1337 requests in 3.04s, 207.60KB read
        Requests/sec:    440.46
        Transfer/sec:     68.39KB
        [run.sh] Speed is 440.46, duration is 68
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d68s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-85bdf5784-5pwgc         1165m        68Mi
        service1-7755b7b4b5-z92mm        1049m        57Mi
        service2-9bc5fc9b-rthdj          906m         26Mi
        service3-689fcdc4df-8tl92        687m         16Mi
        service4-5f56f879dc-xvm5t        473m         15Mi
        ubuntu-client-76886f6bbd-rgrkd   24m          24Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   875.30ms  759.38ms   7.31s    82.23%
        Req/Sec    78.93     49.98   350.00     70.78%
        Latency Distribution
        50%  700.28ms
        75%    1.13s
        90%    1.79s
        99%    3.71s
        20000 requests in 1.13m, 3.03MB read
        Requests/sec:    294.12
        Transfer/sec:     45.67KB
        ------------------------------
        stop time: 33.697278
        stop time: 32.130715
        stop time: 33.852686
        stop time: 33.572818
        stop time: 34.511038
        stop time: 34.404737
        stop time: 34.411543
        stop time: 34.002705
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [33.697278, 32.130715, 33.852686, 33.572818, 34.511038, 34.404737, 34.411543, 34.002705]
    [exp] Throughput: 591.3146521266336
[test.py] Finished running 0th optmization experiment: groundtruth->1025.5707083057944, slowdown->591.3146521266336, predicted->1021.5231870951386, err->-0.39466037571822987
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000106', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   526.31ms  395.21ms   2.11s    69.56%
        Req/Sec   138.45     77.19   363.00     63.96%
        Latency Distribution
        50%  447.10ms
        75%  780.89ms
        90%    1.05s
        99%    1.61s
        2767 requests in 3.03s, 429.64KB read
        Requests/sec:    913.37
        Transfer/sec:    141.82KB
        [run.sh] Speed is 913.37, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   574.96ms  681.55ms   6.37s    86.79%
        Req/Sec   129.51     59.34   464.00     68.57%
        Latency Distribution
        50%  320.92ms
        75%  741.42ms
        90%    1.50s
        99%    3.17s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.894053
        stop time: 19.512682
        stop time: 18.548735
        stop time: 18.760961
        stop time: 19.971403
        stop time: 19.409218
        stop time: 19.916678
        stop time: 20.018015
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-n7rpr        1765m        67Mi
        service1-7755b7b4b5-8wsjd        241m         57Mi
        service2-958786d58-qjrxd         248m         34Mi
        service3-6ddd8b8f64-w4wxs        1160m        15Mi
        service4-9bb5bd9fd-6nqnw         607m         11Mi
        ubuntu-client-76886f6bbd-2zjn4   18m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.894053, 19.512682, 18.548735, 18.760961, 19.971403, 19.409218, 19.916678, 20.018015]
    [exp] Throughput: 1025.4323567297156
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '641.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1885.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   618.39ms  453.07ms   2.70s    60.40%
        Req/Sec    72.43     44.70   212.00     61.35%
        Latency Distribution
        50%  473.55ms
        75%    1.08s
        90%    1.26s
        99%    1.64s
        1505 requests in 3.03s, 233.69KB read
        Requests/sec:    497.12
        Transfer/sec:     77.19KB
        [run.sh] Speed is 497.12, duration is 60
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d60s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   832.48ms  713.96ms   6.21s    79.30%
        Req/Sec    81.38     51.50   434.00     73.57%
        Latency Distribution
        50%  647.28ms
        75%    1.14s
        90%    1.74s
        99%    3.34s
        20000 requests in 1.00m, 3.03MB read
        Requests/sec:    333.33
        Transfer/sec:     51.76KB
        ------------------------------
        stop time: 32.383928
        stop time: 31.428093
        stop time: 31.385776
        stop time: 32.219711
        stop time: 33.096633
        stop time: 32.766953
        stop time: 32.509983
        stop time: 32.866378
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [32.383928, 31.428093, 31.385776, 32.219711, 33.096633, 32.766953, 32.509983, 32.866378]
    [exp] Throughput: 618.578729926806
[test.py] Finished running 1th optmization experiment: groundtruth->1025.4323567297156, slowdown->618.578729926806, predicted->1025.2073957718253, err->-0.02193815676030833
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000212', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   535.49ms  431.82ms   2.49s    69.82%
        Req/Sec   143.39     76.13   430.00     73.96%
        Latency Distribution
        50%  431.34ms
        75%  773.41ms
        90%    1.12s
        99%    1.94s
        2825 requests in 3.03s, 438.65KB read
        Requests/sec:    932.62
        Transfer/sec:    144.81KB
        [run.sh] Speed is 932.62, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   526.02ms  562.69ms   4.53s    87.14%
        Req/Sec   129.26     62.71   530.00     70.89%
        Latency Distribution
        50%  318.10ms
        75%  720.70ms
        90%    1.25s
        99%    2.56s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.716253
        stop time: 19.355920
        stop time: 19.489087
        stop time: 19.950634
        stop time: 19.589521
        stop time: 19.860219
        stop time: 19.454383
        stop time: 19.643839
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-c85jg        3m           67Mi
        service1-7755b7b4b5-hcppg        176m         62Mi
        service2-958786d58-r6pgd         783m         44Mi
        service3-6ddd8b8f64-2fns2        659m         12Mi
        service4-9bb5bd9fd-8pvrf         1m           12Mi
        ubuntu-client-76886f6bbd-8ktvk   15m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.716253, 19.35592, 19.489087, 19.950634, 19.589521, 19.860219, 19.454383, 19.643839]
    [exp] Throughput: 1018.7198949170053
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '570.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1676.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   783.12ms  485.76ms   2.92s    70.58%
        Req/Sec    77.91     48.31   210.00     68.07%
        Latency Distribution
        50%  709.13ms
        75%    1.04s
        90%    1.45s
        99%    2.07s
        1526 requests in 3.03s, 236.95KB read
        Requests/sec:    503.33
        Transfer/sec:     78.15KB
        [run.sh] Speed is 503.33, duration is 59
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-d98b4cfdb-p5bqp         304m         57Mi
        service1-7755b7b4b5-vzw8b        399m         51Mi
        service2-5569d86cb9-lmgq7        271m         28Mi
        service3-84456c486d-9rmpf        159m         14Mi
        service4-79fb8b8978-hjm9n        166m         10Mi
        ubuntu-client-76886f6bbd-sqrrm   19m          0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   801.27ms  747.97ms   6.48s    84.36%
        Req/Sec    86.66     46.58   373.00     67.10%
        Latency Distribution
        50%  579.81ms
        75%    1.08s
        90%    1.83s
        99%    3.55s
        20000 requests in 0.98m, 3.03MB read
        Requests/sec:    338.98
        Transfer/sec:     52.63KB
        ------------------------------
        stop time: 30.810317
        stop time: 30.963450
        stop time: 30.790965
        stop time: 29.686474
        stop time: 30.968025
        stop time: 31.422442
        stop time: 30.661499
        stop time: 31.576635
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [30.810317, 30.96345, 30.790965, 29.686474, 30.968025, 31.422442, 30.661499, 31.576635]
    [exp] Throughput: 648.088646634433
[test.py] Finished running 2th optmization experiment: groundtruth->1018.7198949170053, slowdown->648.088646634433, predicted->1027.93718031756, err->0.9047909485762663
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000318', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   491.15ms  408.48ms   2.06s    76.63%
        Req/Sec   116.13     65.07   370.00     69.68%
        Latency Distribution
        50%  328.87ms
        75%  771.12ms
        90%    1.08s
        99%    1.67s
        2586 requests in 3.03s, 401.54KB read
        Requests/sec:    852.18
        Transfer/sec:    132.32KB
        [run.sh] Speed is 852.18, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-hbrs2        20m          63Mi
        service1-7755b7b4b5-6l9gx        281m         36Mi
        service2-958786d58-99dmx         384m         13Mi
        service3-6ddd8b8f64-sl5pd        191m         9Mi
        service4-9bb5bd9fd-md5hn         247m         8Mi
        ubuntu-client-76886f6bbd-hs45v   18m          0Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   514.18ms  465.65ms   3.70s    83.50%
        Req/Sec   130.09     67.32   380.00     68.25%
        Latency Distribution
        50%  382.63ms
        75%  695.88ms
        90%    1.13s
        99%    2.36s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 19.803401
        stop time: 19.773491
        stop time: 19.277917
        stop time: 19.797756
        stop time: 19.597878
        stop time: 20.071456
        stop time: 19.903196
        stop time: 18.974024
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.803401, 19.773491, 19.277917, 19.797756, 19.597878, 20.071456, 19.903196, 18.974024]
    [exp] Throughput: 1017.8174090148686
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '499.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1468.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   778.79ms  499.94ms   2.49s    65.78%
        Req/Sec    86.76     48.29   272.00     70.24%
        Latency Distribution
        50%  725.25ms
        75%    1.08s
        90%    1.46s
        99%    2.23s
        1719 requests in 3.03s, 266.92KB read
        Requests/sec:    567.46
        Transfer/sec:     88.11KB
        [run.sh] Speed is 567.46, duration is 52
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d52s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-766754b87b-685k4        1356m        74Mi
        service1-7755b7b4b5-m7l7s        1234m        50Mi
        service2-b6f7bd475-wsdvh         1056m        26Mi
        service3-84f6c86b-9vknf          783m         13Mi
        service4-68bd74b5d4-fhsrh        553m         11Mi
        ubuntu-client-76886f6bbd-dnw4t   28m          22Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   753.41ms  619.80ms   5.17s    73.94%
        Req/Sec    89.88     51.73   430.00     70.57%
        Latency Distribution
        50%  604.06ms
        75%    1.07s
        90%    1.59s
        99%    2.65s
        20000 requests in 0.87m, 3.03MB read
        Requests/sec:    384.61
        Transfer/sec:     59.72KB
        ------------------------------
        stop time: 29.094770
        stop time: 28.995296
        stop time: 29.104897
        stop time: 29.191712
        stop time: 30.020679
        stop time: 29.425638
        stop time: 29.724132
        stop time: 29.891500
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [29.09477, 28.995296, 29.104897, 29.191712, 30.020679, 29.425638, 29.724132, 29.8915]
    [exp] Throughput: 679.5537696580465
[test.py] Finished running 3th optmization experiment: groundtruth->1017.8174090148686, slowdown->679.5537696580465, predicted->1028.3863425357456, err->1.0383918989071408
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000424', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   576.75ms  454.19ms   2.62s    75.05%
        Req/Sec   121.64     77.51   370.00     63.94%
        Latency Distribution
        50%  420.99ms
        75%  819.45ms
        90%    1.23s
        99%    1.88s
        2576 requests in 3.03s, 399.98KB read
        Requests/sec:    848.78
        Transfer/sec:    131.79KB
        [run.sh] Speed is 848.78, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-tswlk        1939m        71Mi
        service1-7755b7b4b5-6g8j7        702m         53Mi
        service2-958786d58-zd25f         1500m        23Mi
        service3-6ddd8b8f64-8wr6f        1183m        15Mi
        service4-9bb5bd9fd-chd59         825m         11Mi
        ubuntu-client-76886f6bbd-lbfl7   38m          21Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   561.76ms  649.82ms   5.01s    85.81%
        Req/Sec   128.24     59.74   460.00     73.07%
        Latency Distribution
        50%  327.67ms
        75%  629.28ms
        90%    1.51s
        99%    2.96s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 19.022066
        stop time: 19.698254
        stop time: 19.649324
        stop time: 19.944445
        stop time: 19.633815
        stop time: 19.123162
        stop time: 19.847011
        stop time: 19.975550
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.022066, 19.698254, 19.649324, 19.944445, 19.633815, 19.123162, 19.847011, 19.97555]
    [exp] Throughput: 1019.7992299585246
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '428.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1259.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   724.64ms  445.19ms   2.67s    67.76%
        Req/Sec    89.12     52.41   292.00     68.94%
        Latency Distribution
        50%  645.71ms
        75%  954.77ms
        90%    1.33s
        99%    2.01s
        1751 requests in 3.03s, 271.88KB read
        Requests/sec:    577.70
        Transfer/sec:     89.70KB
        [run.sh] Speed is 577.70, duration is 51
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d51s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-75578d5c44-kg96h        3m           56Mi
        service1-7755b7b4b5-t2vj6        32m          45Mi
        service2-6ddcd79dbf-zcqzs        3m           23Mi
        service3-899d5fdcf-6pbbf         3m           11Mi
        ubuntu-client-76886f6bbd-5zp6m   6m           10Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   762.18ms  751.06ms   6.98s    87.49%
        Req/Sec    93.98     52.01   303.00     67.59%
        Latency Distribution
        50%  534.15ms
        75%  986.57ms
        90%    1.68s
        99%    3.63s
        20001 requests in 0.85m, 3.03MB read
        Requests/sec:    392.18
        Transfer/sec:     60.89KB
        ------------------------------
        stop time: 28.669736
        stop time: 28.085056
        stop time: 27.662337
        stop time: 28.538374
        stop time: 28.494988
        stop time: 28.333882
        stop time: 27.161222
        stop time: 27.839134
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [28.669736, 28.085056, 27.662337, 28.538374, 28.494988, 28.333882, 27.161222, 27.839134]
    [exp] Throughput: 711.7921253449562
[test.py] Finished running 4th optmization experiment: groundtruth->1019.7992299585246, slowdown->711.7921253449562, predicted->1023.7847136362499, err->0.39081061846725906
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00053', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   471.83ms  404.40ms   2.34s    70.41%
        Req/Sec   137.91     68.68   330.00     74.21%
        Latency Distribution
        50%  325.05ms
        75%  799.44ms
        90%  967.04ms
        99%    1.70s
        2668 requests in 3.03s, 414.27KB read
        Requests/sec:    881.01
        Transfer/sec:    136.80KB
        [run.sh] Speed is 881.01, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   585.10ms  733.52ms   5.38s    89.66%
        Req/Sec   129.99     60.38   440.00     73.12%
        Latency Distribution
        50%  350.29ms
        75%  661.13ms
        90%    1.34s
        99%    4.05s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.315183
        stop time: 19.836587
        stop time: 19.543925
        stop time: 19.027661
        stop time: 19.524512
        stop time: 19.183867
        stop time: 19.521850
        stop time: 19.906516
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-x8sjs        545m         67Mi
        service1-7755b7b4b5-dllfv        369m         49Mi
        service2-958786d58-pgr2r         504m         26Mi
        service3-6ddd8b8f64-8xgxp        371m         12Mi
        service4-9bb5bd9fd-68b5m         3m           11Mi
        ubuntu-client-76886f6bbd-pl6mk   23m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.315183, 19.836587, 19.543925, 19.027661, 19.524512, 19.183867, 19.52185, 19.906516]
    [exp] Throughput: 1026.5616342696967
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '357.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1050.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   585.20ms  526.21ms   2.87s    76.45%
        Req/Sec   103.88     43.68   212.00     61.93%
        Latency Distribution
        50%  400.96ms
        75%  967.19ms
        90%    1.19s
        99%    2.05s
        1966 requests in 3.03s, 305.27KB read
        Requests/sec:    649.41
        Transfer/sec:    100.84KB
        [run.sh] Speed is 649.41, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-76cf478f75-zm4nj        1497m        70Mi
        service1-7755b7b4b5-zxtlj        1265m        60Mi
        service2-6fc48d9cd4-dxpxm        1149m        35Mi
        service3-769fd8d48-vj999         899m         13Mi
        service4-7bfcf7775d-txsmc        586m         12Mi
        ubuntu-client-76886f6bbd-nbs26   31m          23Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   736.57ms  806.55ms   5.65s    85.47%
        Req/Sec   101.03     48.32   343.00     65.38%
        Latency Distribution
        50%  415.94ms
        75%  939.87ms
        90%    1.94s
        99%    3.60s
        20000 requests in 46.00s, 3.03MB read
        Requests/sec:    434.78
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 27.091140
        stop time: 27.204501
        stop time: 26.961922
        stop time: 26.631975
        stop time: 26.997732
        stop time: 26.620595
        stop time: 25.306046
        stop time: 25.885617
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.09114, 27.204501, 26.961922, 26.631975, 26.997732, 26.620595, 25.306046, 25.885617]
    [exp] Throughput: 752.234861564902
[test.py] Finished running 5th optmization experiment: groundtruth->1026.5616342696967, slowdown->752.234861564902, predicted->1028.536381928883, err->0.1923652310064293
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000636', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   539.49ms  389.52ms   1.89s    66.91%
        Req/Sec   137.46     67.65   310.00     65.59%
        Latency Distribution
        50%  430.14ms
        75%  825.68ms
        90%    1.09s
        99%    1.76s
        2565 requests in 3.03s, 398.28KB read
        Requests/sec:    847.28
        Transfer/sec:    131.56KB
        [run.sh] Speed is 847.28, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-8wh7v        516m         71Mi
        service1-7755b7b4b5-nmcpt        1004m        55Mi
        service2-958786d58-cshpq         61m          28Mi
        service3-6ddd8b8f64-nvl7r        180m         16Mi
        service4-9bb5bd9fd-8gj85         479m         10Mi
        ubuntu-client-76886f6bbd-h59jm   10m          20Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   533.52ms  536.51ms   4.11s    88.59%
        Req/Sec   130.40     64.93   484.00     70.35%
        Latency Distribution
        50%  357.26ms
        75%  636.04ms
        90%    1.16s
        99%    2.81s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 19.831465
        stop time: 19.669387
        stop time: 19.788082
        stop time: 19.414929
        stop time: 18.965620
        stop time: 19.425125
        stop time: 19.796213
        stop time: 19.446858
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.831465, 19.669387, 19.788082, 19.414929, 18.96562, 19.425125, 19.796213, 19.446858]
    [exp] Throughput: 1023.4257091663745
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '286.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '841.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   645.33ms  393.13ms   1.98s    71.01%
        Req/Sec   102.55     61.15   272.00     62.83%
        Latency Distribution
        50%  570.85ms
        75%  886.07ms
        90%    1.18s
        99%    1.75s
        2061 requests in 3.03s, 320.02KB read
        Requests/sec:    680.21
        Transfer/sec:    105.62KB
        [run.sh] Speed is 680.21, duration is 44
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d44s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f758f58-bl4mp          515m         59Mi
        service1-7755b7b4b5-lqq4f        3m           43Mi
        service2-df5dc84c7-bjcgs         412m         22Mi
        service3-ff5f5bd54-bpvmh         301m         9Mi
        service4-69f57699c6-dn696        11m          10Mi
        ubuntu-client-76886f6bbd-9h6xv   21m          0Mi
        Running 44s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   659.10ms  521.11ms   4.61s    82.22%
        Req/Sec   101.87     56.46   333.00     65.63%
        Latency Distribution
        50%  560.85ms
        75%  862.13ms
        90%    1.23s
        99%    2.81s
        20001 requests in 44.00s, 3.03MB read
        Requests/sec:    454.57
        Transfer/sec:     70.58KB
        ------------------------------
        stop time: 25.310763
        stop time: 25.664473
        stop time: 24.824535
        stop time: 25.147582
        stop time: 25.450428
        stop time: 25.125810
        stop time: 25.606370
        stop time: 25.131783
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [25.310763, 25.664473, 24.824535, 25.147582, 25.450428, 25.12581, 25.60637, 25.131783]
    [exp] Throughput: 791.0541896642599
[test.py] Finished running 6th optmization experiment: groundtruth->1023.4257091663745, slowdown->791.0541896642599, predicted->1022.4539057330215, err->-0.09495593325914838
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000742', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   424.90ms  432.05ms   2.99s    88.13%
        Req/Sec   117.68     48.12   260.00     73.78%
        Latency Distribution
        50%  271.68ms
        75%  452.96ms
        90%  955.65ms
        99%    2.25s
        2683 requests in 3.03s, 416.60KB read
        Requests/sec:    886.92
        Transfer/sec:    137.71KB
        [run.sh] Speed is 886.92, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   564.24ms  644.84ms   5.34s    87.53%
        Req/Sec   129.30     60.97   640.00     73.59%
        Latency Distribution
        50%  321.39ms
        75%  713.40ms
        90%    1.40s
        99%    3.02s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.953737
        stop time: 19.602068
        stop time: 19.540020
        stop time: 19.729386
        stop time: 20.046271
        stop time: 19.169655
        stop time: 19.800796
        stop time: 19.744218
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-hrvgf        947m         67Mi
        service1-7755b7b4b5-rtwf8        60m          51Mi
        service2-958786d58-f96vq         1129m        28Mi
        service3-6ddd8b8f64-66pth        698m         12Mi
        service4-9bb5bd9fd-rmmgh         122m         10Mi
        ubuntu-client-76886f6bbd-6zs6g   20m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.953737, 19.602068, 19.54002, 19.729386, 20.046271, 19.169655, 19.800796, 19.744218]
    [exp] Throughput: 1015.3176467899139
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '215.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '632.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   668.16ms  522.45ms   2.83s    77.52%
        Req/Sec   109.14     47.68   330.00     70.53%
        Latency Distribution
        50%  548.55ms
        75%  885.31ms
        90%    1.40s
        99%    2.26s
        2225 requests in 3.03s, 345.48KB read
        Requests/sec:    733.95
        Transfer/sec:    113.96KB
        [run.sh] Speed is 733.95, duration is 40
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d40s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-57b7884898-6ptmc        842m         70Mi
        service1-7755b7b4b5-89rrz        1483m        44Mi
        service2-76ccc647cd-d8bkt        1296m        23Mi
        service3-77cbbdbbc5-kxcsn        431m         11Mi
        service4-57dc9b8757-xprqh        587m         10Mi
        ubuntu-client-76886f6bbd-5ftdm   21m          22Mi
        Running 40s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   616.73ms  533.35ms   4.13s    80.67%
        Req/Sec   108.15     53.21   525.00     68.14%
        Latency Distribution
        50%  491.66ms
        75%  822.77ms
        90%    1.31s
        99%    2.43s
        20000 requests in 40.00s, 3.03MB read
        Requests/sec:    500.00
        Transfer/sec:     77.64KB
        ------------------------------
        stop time: 23.298210
        stop time: 23.294393
        stop time: 23.986430
        stop time: 23.240382
        stop time: 23.750263
        stop time: 23.934029
        stop time: 24.087672
        stop time: 23.954788
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.29821, 23.294393, 23.98643, 23.240382, 23.750263, 23.934029, 24.087672, 23.954788]
    [exp] Throughput: 844.1215273954867
[test.py] Finished running 7th optmization experiment: groundtruth->1015.3176467899139, slowdown->844.1215273954867, predicted->1031.367129665635, err->1.5807351449533213
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000848', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   592.80ms  555.47ms   2.83s    86.05%
        Req/Sec   118.97     66.52   300.00     60.62%
        Latency Distribution
        50%  357.59ms
        75%  837.86ms
        90%    1.40s
        99%    2.42s
        2737 requests in 3.03s, 424.98KB read
        Requests/sec:    904.11
        Transfer/sec:    140.39KB
        [run.sh] Speed is 904.11, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   552.99ms  617.49ms   5.14s    87.48%
        Req/Sec   131.33     62.28   420.00     73.96%
        Latency Distribution
        50%  327.59ms
        75%  697.26ms
        90%    1.39s
        99%    2.89s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.139646
        stop time: 18.648057
        stop time: 19.387177
        stop time: 19.578458
        stop time: 19.748413
        stop time: 19.459960
        stop time: 19.957409
        stop time: 19.959455
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-7pl5c        77m          56Mi
        service3-6ddd8b8f64-h9w8j        137m         8Mi
        service4-9bb5bd9fd-bspg4         3m           7Mi
        ubuntu-client-76886f6bbd-97knx   6m           10Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.139646, 18.648057, 19.387177, 19.578458, 19.748413, 19.45996, 19.957409, 19.959455]
    [exp] Throughput: 1026.439970983825
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '144.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '423.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   549.11ms  554.86ms   2.93s    83.26%
        Req/Sec   124.85     48.47   290.00     72.25%
        Latency Distribution
        50%  372.93ms
        75%  871.13ms
        90%    1.33s
        99%    2.32s
        2402 requests in 3.03s, 372.97KB read
        Requests/sec:    792.54
        Transfer/sec:    123.06KB
        [run.sh] Speed is 792.54, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-859d87f949-mrl9h        1712m        70Mi
        service1-7755b7b4b5-zd65t        1108m        54Mi
        service2-5458f69958-5rk4c        601m         31Mi
        service3-7cd879df74-dhf2s        301m         10Mi
        service4-55f47fc56d-mdpj8        632m         10Mi
        ubuntu-client-76886f6bbd-62zn2   35m          20Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   648.89ms  738.29ms   6.71s    85.67%
        Req/Sec   116.35     60.43   400.00     70.09%
        Latency Distribution
        50%  367.71ms
        75%  821.95ms
        90%    1.72s
        99%    3.22s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 22.271240
        stop time: 22.643388
        stop time: 22.809236
        stop time: 21.728900
        stop time: 21.402245
        stop time: 22.613382
        stop time: 21.909709
        stop time: 22.213982
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.27124, 22.643388, 22.809236, 21.7289, 21.402245, 22.613382, 21.909709, 22.213982]
    [exp] Throughput: 900.9410678568428
[test.py] Finished running 8th optmization experiment: groundtruth->1026.439970983825, slowdown->900.9410678568428, predicted->1035.3104938230463, err->0.8642027873017184
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000954', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   678.41ms  642.31ms   2.89s    79.90%
        Req/Sec   119.97     70.08   323.00     68.97%
        Latency Distribution
        50%  482.51ms
        75%    1.03s
        90%    1.69s
        99%    2.48s
        2195 requests in 3.03s, 340.83KB read
        Requests/sec:    724.68
        Transfer/sec:    112.52KB
        [run.sh] Speed is 724.68, duration is 41
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d41s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 41s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   521.22ms  640.44ms   4.69s    86.24%
        Req/Sec   129.37     55.17   474.00     73.01%
        Latency Distribution
        50%  248.97ms
        75%  647.70ms
        90%    1.48s
        99%    2.86s
        20000 requests in 41.00s, 3.03MB read
        Requests/sec:    487.80
        Transfer/sec:     75.74KB
        ------------------------------
        stop time: 19.932401
        stop time: 19.591038
        stop time: 18.941826
        stop time: 19.727110
        stop time: 19.891462
        stop time: 19.793991
        stop time: 19.564265
        stop time: 19.362113
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.932401, 19.591038, 18.941826, 19.72711, 19.891462, 19.793991, 19.564265, 19.362113]
    [exp] Throughput: 1020.3807925917498
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '73.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '214.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   608.45ms  433.25ms   2.45s    69.89%
        Req/Sec   135.71     61.99   303.00     69.14%
        Latency Distribution
        50%  502.69ms
        75%  909.47ms
        90%    1.18s
        99%    1.94s
        2390 requests in 3.02s, 371.10KB read
        Requests/sec:    791.10
        Transfer/sec:    122.84KB
        [run.sh] Speed is 791.10, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service1-7755b7b4b5-h4fvz        3m           64Mi
        service2-74457b7b66-h5z72        3m           29Mi
        service3-657f66b697-kvmtq        3m           13Mi
        service4-648ccfbd5f-hbgxb        43m          13Mi
        ubuntu-client-76886f6bbd-ktxcq   17m          0Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   588.52ms  611.10ms   6.19s    88.36%
        Req/Sec   121.01     54.26   343.00     69.96%
        Latency Distribution
        50%  379.93ms
        75%  691.07ms
        90%    1.32s
        99%    2.99s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 20.547719
        stop time: 20.744991
        stop time: 21.108133
        stop time: 21.358228
        stop time: 21.370542
        stop time: 21.317316
        stop time: 20.801238
        stop time: 21.019081
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.547719, 20.744991, 21.108133, 21.358228, 21.370542, 21.317316, 20.801238, 21.019081]
    [exp] Throughput: 950.8683472377227
[test.py] Finished running 9th optmization experiment: groundtruth->1020.3807925917498, slowdown->950.8683472377227, predicted->1021.8328902665921, err->0.14230938933631018
[test.py] Baseline throughput:  1018.5364985169853
[test.py] Groundtruth:  [1025.5707083057944, 1025.4323567297156, 1018.7198949170053, 1017.8174090148686, 1019.7992299585246, 1026.5616342696967, 1023.4257091663745, 1015.3176467899139, 1026.439970983825, 1020.3807925917498]
[test.py] Slowdown:  [591.3146521266336, 618.578729926806, 648.088646634433, 679.5537696580465, 711.7921253449562, 752.234861564902, 791.0541896642599, 844.1215273954867, 900.9410678568428, 950.8683472377227]
[test.py] Predicted:  [1021.5231870951386, 1025.2073957718253, 1027.93718031756, 1028.3863425357456, 1023.7847136362499, 1028.536381928883, 1022.4539057330215, 1031.367129665635, 1035.3104938230463, 1021.8328902665921]
[test.py] Error percentage:  [-0.39466037571822987, -0.02193815676030833, 0.9047909485762663, 1.0383918989071408, 0.39081061846725906, 0.1923652310064293, -0.09495593325914838, 1.5807351449533213, 0.8642027873017184, 0.14230938933631018]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 1...
[test.py] Actual processing time range: [0, 106, 212, 318, 424, 530, 636, 742, 848, 954]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   564.75ms  414.07ms   2.20s    68.92%
        Req/Sec   127.31     58.37   282.00     72.92%
        Latency Distribution
        50%  452.68ms
        75%  803.02ms
        90%    1.13s
        99%    1.88s
        2462 requests in 3.02s, 382.28KB read
        Requests/sec:    814.14
        Transfer/sec:    126.41KB
        [run.sh] Speed is 814.14, duration is 36
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d36s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-zvz66        650m         72Mi
        service1-7755b7b4b5-rtzh8        1434m        56Mi
        service2-958786d58-th2jx         834m         25Mi
        service3-6ddd8b8f64-lzr4k        464m         17Mi
        service4-9bb5bd9fd-qk6x5         759m         11Mi
        ubuntu-client-76886f6bbd-8mbn9   39m          20Mi
        Running 36s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   527.09ms  508.19ms   5.02s    87.95%
        Req/Sec   128.62     62.73   490.00     70.21%
        Latency Distribution
        50%  379.42ms
        75%  703.47ms
        90%    1.12s
        99%    2.41s
        20000 requests in 36.00s, 3.03MB read
        Requests/sec:    555.55
        Transfer/sec:     86.26KB
        ------------------------------
        stop time: 19.188042
        stop time: 19.351265
        stop time: 19.881180
        stop time: 19.335762
        stop time: 20.148779
        stop time: 20.111054
        stop time: 19.832723
        stop time: 19.658518
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.188042, 19.351265, 19.88118, 19.335762, 20.148779, 20.111054, 19.832723, 19.658518]
    [exp] Throughput: 1015.8257848112879
[test.py] Baseline throughput: 1015.8257848112879
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   508.20ms  319.94ms   1.52s    64.04%
        Req/Sec   139.48     73.42   323.00     69.27%
        Latency Distribution
        50%  465.59ms
        75%  732.58ms
        90%  943.02ms
        99%    1.35s
        2715 requests in 3.03s, 421.57KB read
        Requests/sec:    896.46
        Transfer/sec:    139.20KB
        [run.sh] Speed is 896.46, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   553.55ms  631.79ms   4.67s    89.15%
        Req/Sec   129.96     69.27   500.00     69.14%
        Latency Distribution
        50%  330.93ms
        75%  694.27ms
        90%    1.25s
        99%    3.24s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.189682
        stop time: 19.089791
        stop time: 19.832005
        stop time: 19.485690
        stop time: 19.171673
        stop time: 19.865757
        stop time: 19.866792
        stop time: 19.959176
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.189682, 19.089791, 19.832005, 19.48569, 19.171673, 19.865757, 19.866792, 19.959176]
    [exp] Throughput: 1022.6218918318368
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '712.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '2094.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   815.40ms  491.51ms   2.97s    69.27%
        Req/Sec    83.65     65.06   272.00     71.92%
        Latency Distribution
        50%  806.03ms
        75%    1.03s
        90%    1.41s
        99%    2.35s
        1435 requests in 3.03s, 222.82KB read
        Requests/sec:    473.58
        Transfer/sec:     73.54KB
        [run.sh] Speed is 473.58, duration is 63
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d63s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-85bdf5784-8hntn         392m         58Mi
        service1-7755b7b4b5-ktjb4        384m         52Mi
        service2-9bc5fc9b-f8cjg          328m         29Mi
        service3-689fcdc4df-xc7sg        231m         12Mi
        service4-5f56f879dc-pdhgc        157m         12Mi
        ubuntu-client-76886f6bbd-787vk   9m           0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   850.42ms  616.50ms   4.68s    75.38%
        Req/Sec    77.91     50.41   410.00     69.47%
        Latency Distribution
        50%  734.12ms
        75%    1.13s
        90%    1.58s
        99%    3.11s
        20000 requests in 1.05m, 3.03MB read
        Requests/sec:    317.46
        Transfer/sec:     49.29KB
        ------------------------------
        stop time: 33.217203
        stop time: 33.238032
        stop time: 33.208973
        stop time: 33.794128
        stop time: 34.077655
        stop time: 33.540142
        stop time: 33.881606
        stop time: 33.982952
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [33.217203, 33.238032, 33.208973, 33.794128, 34.077655, 33.540142, 33.881606, 33.982952]
    [exp] Throughput: 594.9267082086884
[test.py] Finished running 0th optmization experiment: groundtruth->1022.6218918318368, slowdown->594.9267082086884, predicted->1032.3511825927994, err->0.9514064620242384
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000106', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   471.12ms  400.65ms   2.19s    81.66%
        Req/Sec   116.95     57.70   343.00     78.24%
        Latency Distribution
        50%  343.24ms
        75%  745.59ms
        90%    1.03s
        99%    2.03s
        2557 requests in 3.03s, 397.03KB read
        Requests/sec:    843.87
        Transfer/sec:    131.03KB
        [run.sh] Speed is 843.87, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-zhtz5        111m         58Mi
        service1-7755b7b4b5-b7w66        199m         41Mi
        service2-958786d58-f849f         372m         20Mi
        service3-6ddd8b8f64-76kh6        106m         10Mi
        service4-9bb5bd9fd-pd7mr         245m         8Mi
        ubuntu-client-76886f6bbd-mbljt   17m          0Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   508.59ms  520.04ms   3.77s    86.90%
        Req/Sec   130.45     65.21   440.00     68.44%
        Latency Distribution
        50%  332.67ms
        75%  675.84ms
        90%    1.20s
        99%    2.46s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 18.919767
        stop time: 19.325939
        stop time: 19.430503
        stop time: 19.128939
        stop time: 20.019689
        stop time: 20.013596
        stop time: 19.753080
        stop time: 19.970206
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.919767, 19.325939, 19.430503, 19.128939, 20.019689, 20.013596, 19.75308, 19.970206]
    [exp] Throughput: 1021.9611857991927
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '641.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1885.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   734.48ms  606.30ms   3.00s    84.63%
        Req/Sec    80.51     38.55   202.00     64.90%
        Latency Distribution
        50%  533.05ms
        75%    1.08s
        90%    1.86s
        99%    2.44s
        1530 requests in 3.03s, 237.57KB read
        Socket errors: connect 0, read 0, write 0, timeout 1
        Requests/sec:    505.04
        Transfer/sec:     78.42KB
        [run.sh] Speed is 505.04, duration is 59
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f574d6759-7462m         1207m        74Mi
        service1-7755b7b4b5-dlp5w        1082m        53Mi
        service2-768b85b46f-pp5kf        950m         25Mi
        service3-f58957f9-mn9w9          711m         14Mi
        service4-7c96f6d57-q59x6         359m         11Mi
        ubuntu-client-76886f6bbd-zr9cx   26m          22Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   838.24ms  677.66ms   6.08s    78.89%
        Req/Sec    81.73     47.15   313.00     65.68%
        Latency Distribution
        50%  685.24ms
        75%    1.11s
        90%    1.68s
        99%    3.26s
        20000 requests in 0.98m, 3.03MB read
        Requests/sec:    338.98
        Transfer/sec:     52.63KB
        ------------------------------
        stop time: 32.485846
        stop time: 32.324331
        stop time: 32.266443
        stop time: 32.316981
        stop time: 32.904108
        stop time: 32.756859
        stop time: 32.308042
        stop time: 33.062516
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [32.485846, 32.324331, 32.266443, 32.316981, 32.904108, 32.756859, 32.308042, 33.062516]
    [exp] Throughput: 614.3800425769977
[test.py] Finished running 1th optmization experiment: groundtruth->1021.9611857991927, slowdown->614.3800425769977, predicted->1013.7255011532584, err->-0.8058705908183599
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000212', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   507.63ms  381.07ms   1.72s    66.50%
        Req/Sec   144.58     66.11   292.00     71.05%
        Latency Distribution
        50%  454.07ms
        75%  760.66ms
        90%    1.02s
        99%    1.50s
        2815 requests in 3.03s, 437.09KB read
        Requests/sec:    928.27
        Transfer/sec:    144.14KB
        [run.sh] Speed is 928.27, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   556.29ms  604.92ms   4.95s    86.68%
        Req/Sec   127.94     63.80   420.00     73.33%
        Latency Distribution
        50%  310.39ms
        75%  733.17ms
        90%    1.40s
        99%    2.82s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.487314
        stop time: 19.902512
        stop time: 19.934331
        stop time: 19.599397
        stop time: 19.443721
        stop time: 20.092325
        stop time: 19.562148
        stop time: 19.947803
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-kx5f7        1936m        69Mi
        service1-7755b7b4b5-8tzm9        702m         53Mi
        service2-958786d58-9n7q8         1534m        25Mi
        service3-6ddd8b8f64-tpdz5        1169m        15Mi
        service4-9bb5bd9fd-4sq64         556m         12Mi
        ubuntu-client-76886f6bbd-wjmtd   39m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.487314, 19.902512, 19.934331, 19.599397, 19.443721, 20.092325, 19.562148, 19.947803]
    [exp] Throughput: 1012.8534200872673
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '570.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1676.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   752.83ms  542.64ms   2.98s    66.32%
        Req/Sec    83.04     48.50   222.00     64.10%
        Latency Distribution
        50%  753.63ms
        75%    1.05s
        90%    1.37s
        99%    2.49s
        1523 requests in 3.02s, 236.48KB read
        Requests/sec:    503.61
        Transfer/sec:     78.20KB
        [run.sh] Speed is 503.61, duration is 59
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   780.86ms  551.21ms   4.88s    75.13%
        Req/Sec    85.22     51.92   360.00     65.78%
        Latency Distribution
        50%  684.44ms
        75%    1.04s
        90%    1.45s
        99%    2.73s
        20000 requests in 0.98m, 3.03MB read
        Requests/sec:    338.98
        Transfer/sec:     52.63KB
        ------------------------------
        stop time: 29.950857
        stop time: 30.878425
        stop time: 30.570806
        stop time: 31.559939
        stop time: 30.608763
        stop time: 31.285614
        stop time: 31.184268
        stop time: 31.166739
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [29.950857, 30.878425, 30.570806, 31.559939, 30.608763, 31.285614, 31.184268, 31.166739]
    [exp] Throughput: 647.2350235084457
[test.py] Finished running 2th optmization experiment: groundtruth->1012.8534200872673, slowdown->647.2350235084457, predicted->1025.7913501029145, err->1.2773743721507596
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000318', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   576.24ms  481.73ms   2.54s    76.41%
        Req/Sec   129.71     73.62   373.00     69.90%
        Latency Distribution
        50%  414.04ms
        75%  787.99ms
        90%    1.27s
        99%    1.91s
        2637 requests in 3.03s, 409.46KB read
        Requests/sec:    870.80
        Transfer/sec:    135.21KB
        [run.sh] Speed is 870.80, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   551.88ms  596.67ms   5.17s    87.73%
        Req/Sec   132.71     72.89   560.00     75.03%
        Latency Distribution
        50%  328.83ms
        75%  710.52ms
        90%    1.29s
        99%    2.88s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 18.625116
        stop time: 19.436344
        stop time: 18.790419
        stop time: 19.809770
        stop time: 19.899789
        stop time: 19.411676
        stop time: 20.046290
        stop time: 19.897995
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.625116, 19.436344, 18.790419, 19.80977, 19.899789, 19.411676, 20.04629, 19.897995]
    [exp] Throughput: 1026.1843836940866
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '499.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1468.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   739.61ms  448.65ms   2.75s    67.90%
        Req/Sec    83.05     54.08   250.00     68.72%
        Latency Distribution
        50%  652.09ms
        75%    1.01s
        90%    1.32s
        99%    2.17s
        1830 requests in 3.02s, 284.15KB read
        Requests/sec:    605.64
        Transfer/sec:     94.04KB
        [run.sh] Speed is 605.64, duration is 49
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-766754b87b-zp758        85m          61Mi
        service1-7755b7b4b5-d4wdr        431m         39Mi
        service2-b6f7bd475-89tf6         278m         19Mi
        service3-84f6c86b-xzpw8          35m          10Mi
        service4-68bd74b5d4-kk5gz        192m         10Mi
        ubuntu-client-76886f6bbd-hzx9s   15m          13Mi
        Running 49s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   780.86ms  717.53ms   5.66s    86.12%
        Req/Sec    89.77     49.73   380.00     64.59%
        Latency Distribution
        50%  572.72ms
        75%    1.02s
        90%    1.71s
        99%    3.41s
        20000 requests in 49.00s, 3.03MB read
        Requests/sec:    408.16
        Transfer/sec:     63.38KB
        ------------------------------
        stop time: 29.574563
        stop time: 29.482037
        stop time: 29.481697
        stop time: 29.633665
        stop time: 30.072541
        stop time: 29.131416
        stop time: 29.610549
        stop time: 29.474854
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [29.574563, 29.482037, 29.481697, 29.633665, 30.072541, 29.131416, 29.610549, 29.474854]
    [exp] Throughput: 676.6434300828276
[test.py] Finished running 3th optmization experiment: groundtruth->1026.1843836940866, slowdown->676.6434300828276, predicted->1021.7358333932007, err->-0.4335039951467507
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000424', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-phjv4 cannot connect to service4
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   555.48ms  468.21ms   2.12s    72.31%
        Req/Sec   130.90     54.73   280.00     69.00%
        Latency Distribution
        50%  417.45ms
        75%  806.32ms
        90%    1.32s
        99%    2.03s
        2656 requests in 3.03s, 412.41KB read
        Requests/sec:    875.91
        Transfer/sec:    136.00KB
        [run.sh] Speed is 875.91, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   531.04ms  522.50ms   4.26s    86.94%
        Req/Sec   128.74     59.53   430.00     73.32%
        Latency Distribution
        50%  351.94ms
        75%  682.55ms
        90%    1.20s
        99%    2.50s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.506526
        stop time: 19.450103
        stop time: 19.673633
        stop time: 19.854704
        stop time: 19.824169
        stop time: 19.866135
        stop time: 19.782386
        stop time: 19.640144
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-phjv4        1675m        70Mi
        service1-7755b7b4b5-gxh7g        281m         52Mi
        service2-958786d58-pgzm5         80m          29Mi
        service3-6ddd8b8f64-4cxmc        1012m        15Mi
        service4-9bb5bd9fd-phnc4         290m         10Mi
        ubuntu-client-76886f6bbd-xkg65   11m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [19.506526, 19.450103, 19.673633, 19.854704, 19.824169, 19.866135, 19.782386, 19.640144]
    [exp] Throughput: 1015.2425985641933
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '428.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1259.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   725.75ms  561.55ms   2.44s    64.45%
        Req/Sec    89.66     44.45   200.00     68.12%
        Latency Distribution
        50%  603.35ms
        75%    1.11s
        90%    1.48s
        99%    2.38s
        1796 requests in 3.03s, 278.87KB read
        Requests/sec:    593.31
        Transfer/sec:     92.13KB
        [run.sh] Speed is 593.31, duration is 50
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d50s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-75578d5c44-vl5dt        812m         68Mi
        service1-7755b7b4b5-pmvxj        1276m        47Mi
        service2-6ddcd79dbf-ftd2s        1114m        27Mi
        service3-899d5fdcf-f76fh         522m         12Mi
        service4-675dc4d5d9-hd6fq        588m         11Mi
        ubuntu-client-76886f6bbd-g66zl   28m          24Mi
        Running 50s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   732.16ms  712.51ms   5.73s    86.24%
        Req/Sec    92.56     54.47   320.00     69.60%
        Latency Distribution
        50%  510.13ms
        75%  957.18ms
        90%    1.70s
        99%    3.25s
        20000 requests in 50.00s, 3.03MB read
        Requests/sec:    400.00
        Transfer/sec:     62.11KB
        ------------------------------
        stop time: 27.506825
        stop time: 27.670662
        stop time: 26.862834
        stop time: 28.079265
        stop time: 27.581420
        stop time: 28.245872
        stop time: 28.388171
        stop time: 28.483822
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.506825, 27.670662, 26.862834, 28.079265, 27.58142, 28.245872, 28.388171, 28.483822]
    [exp] Throughput: 718.0720343924551
[test.py] Finished running 4th optmization experiment: groundtruth->1015.2425985641933, slowdown->718.0720343924551, predicted->1036.8267983231065, err->2.1260139979782817
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00053', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   572.34ms  486.20ms   2.90s    79.30%
        Req/Sec   136.55     62.55   303.00     69.59%
        Latency Distribution
        50%  368.16ms
        75%  829.75ms
        90%    1.26s
        99%    2.23s
        2704 requests in 3.03s, 419.86KB read
        Requests/sec:    892.75
        Transfer/sec:    138.62KB
        [run.sh] Speed is 892.75, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   583.03ms  707.97ms   6.09s    87.45%
        Req/Sec   130.66     59.63   440.00     69.20%
        Latency Distribution
        50%  318.37ms
        75%  744.10ms
        90%    1.52s
        99%    3.22s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.154122
        stop time: 19.434922
        stop time: 19.450916
        stop time: 18.330116
        stop time: 19.812584
        stop time: 19.890415
        stop time: 19.600432
        stop time: 19.835188
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.154122, 19.434922, 19.450916, 18.330116, 19.812584, 19.890415, 19.600432, 19.835188]
    [exp] Throughput: 1028.881375411195
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '357.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1050.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   686.80ms  354.67ms   1.79s    61.40%
        Req/Sec   102.40     62.31   260.00     62.07%
        Latency Distribution
        50%  676.57ms
        75%  948.53ms
        90%    1.16s
        99%    1.42s
        1894 requests in 3.03s, 294.09KB read
        Requests/sec:    625.09
        Transfer/sec:     97.06KB
        [run.sh] Speed is 625.09, duration is 47
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-76cf478f75-d6cfq        480m         66Mi
        service1-7755b7b4b5-dgkjq        175m         52Mi
        service2-6fc48d9cd4-b7dkj        392m         25Mi
        service3-769fd8d48-hdr48         279m         13Mi
        service4-7bfcf7775d-s7shk        47m          12Mi
        ubuntu-client-76886f6bbd-j9h29   12m          14Mi
        Running 47s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   751.48ms  808.41ms   6.55s    87.36%
        Req/Sec   100.23     47.69   310.00     64.22%
        Latency Distribution
        50%  470.84ms
        75%  957.72ms
        90%    1.73s
        99%    3.75s
        20000 requests in 47.00s, 3.03MB read
        Requests/sec:    425.53
        Transfer/sec:     66.07KB
        ------------------------------
        stop time: 27.063384
        stop time: 26.656769
        stop time: 26.352837
        stop time: 26.178600
        stop time: 27.049379
        stop time: 27.074369
        stop time: 26.672620
        stop time: 27.007091
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.063384, 26.656769, 26.352837, 26.1786, 27.049379, 27.074369, 26.67262, 27.007091]
    [exp] Throughput: 747.4712731489926
[test.py] Finished running 5th optmization experiment: groundtruth->1028.881375411195, slowdown->747.4712731489926, predicted->1019.651377752623, err->-0.8970905567109881
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000636', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   537.04ms  449.56ms   2.59s    71.68%
        Req/Sec   132.58     61.41   303.00     70.50%
        Latency Distribution
        50%  394.77ms
        75%  832.39ms
        90%    1.14s
        99%    1.70s
        2679 requests in 3.02s, 415.98KB read
        Requests/sec:    885.95
        Transfer/sec:    137.56KB
        [run.sh] Speed is 885.95, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   594.25ms  732.50ms   6.22s    88.69%
        Req/Sec   129.10     59.07   424.00     66.78%
        Latency Distribution
        50%  336.40ms
        75%  681.88ms
        90%    1.49s
        99%    3.65s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.690615
        stop time: 18.520758
        stop time: 18.733834
        stop time: 19.794089
        stop time: 20.082761
        stop time: 19.963673
        stop time: 19.619143
        stop time: 19.838796
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-298vn        1223m        72Mi
        service1-7755b7b4b5-g5qvz        1228m        56Mi
        service2-958786d58-hlx87         1260m        38Mi
        service3-6ddd8b8f64-vtpfd        702m         12Mi
        service4-9bb5bd9fd-n6f89         821m         9Mi
        ubuntu-client-76886f6bbd-7l9fm   35m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.690615, 18.520758, 18.733834, 19.794089, 20.082761, 19.963673, 19.619143, 19.838796]
    [exp] Throughput: 1024.0414925228106
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '286.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '841.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   592.34ms  434.63ms   1.90s    68.73%
        Req/Sec   110.45     54.74   260.00     68.07%
        Latency Distribution
        50%  475.61ms
        75%  912.88ms
        90%    1.18s
        99%    1.74s
        2034 requests in 3.03s, 315.83KB read
        Requests/sec:    672.08
        Transfer/sec:    104.36KB
        [run.sh] Speed is 672.08, duration is 44
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d44s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 44s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   647.39ms  567.15ms   4.00s    78.79%
        Req/Sec   102.27     50.49   310.00     68.67%
        Latency Distribution
        50%  481.86ms
        75%  906.16ms
        90%    1.49s
        99%    2.48s
        20000 requests in 44.00s, 3.03MB read
        Requests/sec:    454.54
        Transfer/sec:     70.58KB
        ------------------------------
        stop time: 25.156373
        stop time: 25.031985
        stop time: 24.726979
        stop time: 25.371229
        stop time: 25.337603
        stop time: 24.986431
        stop time: 25.649163
        stop time: 25.280144
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [25.156373, 25.031985, 24.726979, 25.371229, 25.337603, 24.986431, 25.649163, 25.280144]
    [exp] Throughput: 793.8874359012182
[test.py] Finished running 6th optmization experiment: groundtruth->1024.0414925228106, slowdown->793.8874359012182, predicted->1027.1921186630311, err->0.3076658673721034
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000742', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   571.98ms  540.34ms   2.97s    85.90%
        Req/Sec   129.75     70.64   320.00     70.26%
        Latency Distribution
        50%  387.16ms
        75%  804.09ms
        90%    1.30s
        99%    2.49s
        2558 requests in 3.03s, 397.19KB read
        Requests/sec:    843.88
        Transfer/sec:    131.03KB
        [run.sh] Speed is 843.88, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-2m7lx        3m           64Mi
        service1-7755b7b4b5-777wh        381m         60Mi
        service2-958786d58-vpzpm         3m           33Mi
        service3-6ddd8b8f64-mcb7j        3m           11Mi
        service4-9bb5bd9fd-hnw5p         248m         12Mi
        ubuntu-client-76886f6bbd-4lxx8   5m           0Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   516.14ms  474.88ms   3.57s    86.10%
        Req/Sec   130.02     62.63   440.00     72.73%
        Latency Distribution
        50%  365.68ms
        75%  652.35ms
        90%    1.15s
        99%    2.45s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 18.943450
        stop time: 19.066625
        stop time: 19.595590
        stop time: 19.772064
        stop time: 19.421126
        stop time: 19.682551
        stop time: 19.818146
        stop time: 19.968954
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.94345, 19.066625, 19.59559, 19.772064, 19.421126, 19.682551, 19.818146, 19.968954]
    [exp] Throughput: 1023.8787334410172
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '215.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '632.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   601.27ms  329.77ms   2.15s    65.64%
        Req/Sec   111.19     70.65   300.00     56.22%
        Latency Distribution
        50%  584.53ms
        75%  802.52ms
        90%    1.03s
        99%    1.47s
        2196 requests in 3.03s, 340.98KB read
        Requests/sec:    725.18
        Transfer/sec:    112.60KB
        [run.sh] Speed is 725.18, duration is 41
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d41s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-57b7884898-wm6fs        1475m        71Mi
        service1-7755b7b4b5-mvptd        1468m        50Mi
        service2-76ccc647cd-2t4b9        1314m        25Mi
        service3-77cbbdbbc5-q25mw        824m         11Mi
        service4-57dc9b8757-99bjd        678m         11Mi
        ubuntu-client-76886f6bbd-qdrzm   36m          20Mi
        Running 41s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   631.62ms  548.87ms   4.00s    84.61%
        Req/Sec   107.65     58.25   400.00     72.30%
        Latency Distribution
        50%  471.23ms
        75%  823.24ms
        90%    1.33s
        99%    2.73s
        20000 requests in 41.00s, 3.03MB read
        Requests/sec:    487.80
        Transfer/sec:     75.74KB
        ------------------------------
        stop time: 23.343825
        stop time: 23.622438
        stop time: 24.074002
        stop time: 24.243923
        stop time: 23.954230
        stop time: 24.104270
        stop time: 24.230173
        stop time: 24.059996
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.343825, 23.622438, 24.074002, 24.243923, 23.95423, 24.10427, 24.230173, 24.059996]
    [exp] Throughput: 834.9298888759978
[test.py] Finished running 7th optmization experiment: groundtruth->1023.8787334410172, slowdown->834.9298888759978, predicted->1017.6784420437054, err->-0.6055689208890979
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000848', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   537.16ms  409.35ms   2.21s    76.08%
        Req/Sec   126.50     59.80   343.00     74.30%
        Latency Distribution
        50%  393.94ms
        75%  768.23ms
        90%    1.18s
        99%    1.71s
        2744 requests in 3.03s, 426.07KB read
        Requests/sec:    905.50
        Transfer/sec:    140.60KB
        [run.sh] Speed is 905.50, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   530.52ms  523.44ms   3.42s    88.06%
        Req/Sec   129.43     61.34   490.00     72.12%
        Latency Distribution
        50%  348.39ms
        75%  681.49ms
        90%    1.16s
        99%    2.58s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 18.721340
        stop time: 19.038605
        stop time: 19.391656
        stop time: 19.880229
        stop time: 19.703416
        stop time: 19.936809
        stop time: 19.757956
        stop time: 19.807222
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-dllhz        424m         69Mi
        service1-7755b7b4b5-wt9jj        1m           45Mi
        service2-958786d58-9z28b         156m         24Mi
        service3-6ddd8b8f64-qdtsw        360m         11Mi
        service4-9bb5bd9fd-6rd8d         1m           9Mi
        ubuntu-client-76886f6bbd-j562s   9m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.72134, 19.038605, 19.391656, 19.880229, 19.703416, 19.936809, 19.757956, 19.807222]
    [exp] Throughput: 1024.0836766483185
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '144.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '423.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   543.67ms  313.73ms   1.74s    67.68%
        Req/Sec   106.61     61.58   290.00     61.95%
        Latency Distribution
        50%  511.32ms
        75%  727.33ms
        90%  935.43ms
        99%    1.40s
        2428 requests in 3.03s, 377.00KB read
        Requests/sec:    801.17
        Transfer/sec:    124.40KB
        [run.sh] Speed is 801.17, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-859d87f949-kd5xc        582m         55Mi
        service1-7755b7b4b5-n7r6m        528m         37Mi
        service2-5458f69958-gh7px        467m         18Mi
        service3-7cd879df74-wjk2k        338m         8Mi
        service4-55f47fc56d-phrsq        243m         9Mi
        ubuntu-client-76886f6bbd-5zmrc   22m          0Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   583.37ms  505.47ms   4.66s    82.84%
        Req/Sec   114.93     61.99   383.00     66.92%
        Latency Distribution
        50%  443.64ms
        75%  742.85ms
        90%    1.25s
        99%    2.37s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 22.332296
        stop time: 21.323904
        stop time: 22.105186
        stop time: 22.642536
        stop time: 22.626173
        stop time: 22.674833
        stop time: 22.540235
        stop time: 22.527426
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.332296, 21.323904, 22.105186, 22.642536, 22.626173, 22.674833, 22.540235, 22.527426]
    [exp] Throughput: 894.9917931769731
[test.py] Finished running 8th optmization experiment: groundtruth->1024.0836766483185, slowdown->894.9917931769731, predicted->1027.4620242490414, err->0.329889800780711
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000954', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   555.76ms  485.24ms   2.90s    79.14%
        Req/Sec   137.90     63.24   320.00     64.89%
        Latency Distribution
        50%  406.02ms
        75%  858.11ms
        90%    1.19s
        99%    2.20s
        2624 requests in 3.04s, 407.44KB read
        Requests/sec:    864.39
        Transfer/sec:    134.22KB
        [run.sh] Speed is 864.39, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   524.56ms  502.70ms   4.08s    87.83%
        Req/Sec   129.68     61.24   540.00     71.29%
        Latency Distribution
        50%  369.67ms
        75%  690.76ms
        90%    1.11s
        99%    2.65s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.263703
        stop time: 19.212659
        stop time: 19.552606
        stop time: 19.890051
        stop time: 19.745823
        stop time: 19.322357
        stop time: 19.605648
        stop time: 19.939778
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-vkgk9        1939m        70Mi
        service1-7755b7b4b5-8rrz9        1623m        53Mi
        service2-958786d58-7pcnq         1580m        28Mi
        service3-6ddd8b8f64-5wspf        1160m        10Mi
        service4-9bb5bd9fd-lr8wd         842m         16Mi
        ubuntu-client-76886f6bbd-kgvv6   38m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.263703, 19.212659, 19.552606, 19.890051, 19.745823, 19.322357, 19.605648, 19.939778]
    [exp] Throughput: 1022.1511330305746
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '73.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '214.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   608.17ms  587.99ms   2.62s    82.61%
        Req/Sec   114.64     67.36   280.00     66.50%
        Latency Distribution
        50%  375.59ms
        75%  901.59ms
        90%    1.48s
        99%    2.33s
        2303 requests in 3.03s, 357.59KB read
        Requests/sec:    759.18
        Transfer/sec:    117.88KB
        [run.sh] Speed is 759.18, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   558.06ms  561.63ms   3.66s    87.32%
        Req/Sec   122.14     52.16   320.00     72.85%
        Latency Distribution
        50%  365.56ms
        75%  721.57ms
        90%    1.29s
        99%    2.67s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 20.602761
        stop time: 21.036780
        stop time: 20.377147
        stop time: 20.579770
        stop time: 21.197963
        stop time: 21.331815
        stop time: 21.130229
        stop time: 21.339141
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [20.602761, 21.03678, 20.377147, 20.57977, 21.197963, 21.331815, 21.130229, 21.339141]
    [exp] Throughput: 954.6789669414126
[test.py] Finished running 9th optmization experiment: groundtruth->1022.1511330305746, slowdown->954.6789669414126, predicted->1026.2348340610984, err->0.3995202762644344
[test.py] Baseline throughput:  1015.8257848112879
[test.py] Groundtruth:  [1022.6218918318368, 1021.9611857991927, 1012.8534200872673, 1026.1843836940866, 1015.2425985641933, 1028.881375411195, 1024.0414925228106, 1023.8787334410172, 1024.0836766483185, 1022.1511330305746]
[test.py] Slowdown:  [594.9267082086884, 614.3800425769977, 647.2350235084457, 676.6434300828276, 718.0720343924551, 747.4712731489926, 793.8874359012182, 834.9298888759978, 894.9917931769731, 954.6789669414126]
[test.py] Predicted:  [1032.3511825927994, 1013.7255011532584, 1025.7913501029145, 1021.7358333932007, 1036.8267983231065, 1019.651377752623, 1027.1921186630311, 1017.6784420437054, 1027.4620242490414, 1026.2348340610984]
[test.py] Error percentage:  [0.9514064620242384, -0.8058705908183599, 1.2773743721507596, -0.4335039951467507, 2.1260139979782817, -0.8970905567109881, 0.3076658673721034, -0.6055689208890979, 0.329889800780711, 0.3995202762644344]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 2...
[test.py] Actual processing time range: [0, 106, 212, 318, 424, 530, 636, 742, 848, 954]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   515.54ms  345.47ms   1.98s    72.77%
        Req/Sec   118.95     58.59   303.00     63.43%
        Latency Distribution
        50%  436.64ms
        75%  698.83ms
        90%    1.00s
        99%    1.66s
        2584 requests in 3.03s, 401.23KB read
        Requests/sec:    853.91
        Transfer/sec:    132.59KB
        [run.sh] Speed is 853.91, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-x99tx        528m         59Mi
        service1-7755b7b4b5-hhjh8        551m         41Mi
        service2-958786d58-v7br4         255m         18Mi
        service3-6ddd8b8f64-9lh55        365m         10Mi
        service4-9bb5bd9fd-jjwpb         250m         11Mi
        ubuntu-client-76886f6bbd-jgms5   18m          6Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   554.67ms  635.05ms   4.77s    85.92%
        Req/Sec   128.40     51.60   323.00     69.67%
        Latency Distribution
        50%  295.72ms
        75%  729.76ms
        90%    1.50s
        99%    2.71s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 19.886179
        stop time: 19.586163
        stop time: 19.503542
        stop time: 19.878772
        stop time: 19.475346
        stop time: 19.486300
        stop time: 20.015154
        stop time: 19.475838
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.886179, 19.586163, 19.503542, 19.878772, 19.475346, 19.4863, 20.015154, 19.475838]
    [exp] Throughput: 1017.1174897967541
[test.py] Baseline throughput: 1017.1174897967541
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   505.11ms  288.22ms   1.80s    68.81%
        Req/Sec   134.68     96.15   424.00     68.75%
        Latency Distribution
        50%  460.46ms
        75%  674.87ms
        90%  922.21ms
        99%    1.33s
        2726 requests in 3.03s, 423.28KB read
        Requests/sec:    898.51
        Transfer/sec:    139.51KB
        [run.sh] Speed is 898.51, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   567.39ms  672.27ms   5.83s    87.24%
        Req/Sec   130.84     65.77   450.00     70.00%
        Latency Distribution
        50%  293.15ms
        75%  733.25ms
        90%    1.47s
        99%    3.16s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 18.393822
        stop time: 18.190855
        stop time: 19.753333
        stop time: 19.376461
        stop time: 19.674549
        stop time: 19.848055
        stop time: 19.974449
        stop time: 19.215805
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-wnxz8        1788m        68Mi
        service1-7755b7b4b5-k9nn7        425m         41Mi
        service2-958786d58-bm4xg         1294m        22Mi
        service3-6ddd8b8f64-tnv92        1188m        12Mi
        service4-9bb5bd9fd-fs8tw         833m         11Mi
        ubuntu-client-76886f6bbd-hlnt8   38m          22Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.393822, 18.190855, 19.753333, 19.376461, 19.674549, 19.848055, 19.974449, 19.215805]
    [exp] Throughput: 1036.0860414803913
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '712.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '2094.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   873.54ms  563.92ms   2.96s    69.25%
        Req/Sec    69.32     47.71   220.00     61.54%
        Latency Distribution
        50%  862.80ms
        75%    1.13s
        90%    1.55s
        99%    2.64s
        1395 requests in 3.04s, 216.61KB read
        Requests/sec:    459.58
        Transfer/sec:     71.36KB
        [run.sh] Speed is 459.58, duration is 65
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d65s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-85bdf5784-d48kb    3m           3Mi
        service2-9bc5fc9b-x72lq     3m           3Mi
        service3-689fcdc4df-kjmpz   3m           2Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   854.92ms  532.45ms   3.98s    68.11%
        Req/Sec    79.15     52.60   343.00     70.64%
        Latency Distribution
        50%  783.66ms
        75%    1.16s
        90%    1.57s
        99%    2.52s
        20000 requests in 1.08m, 3.03MB read
        Requests/sec:    307.69
        Transfer/sec:     47.78KB
        ------------------------------
        stop time: 32.994804
        stop time: 33.746864
        stop time: 34.071347
        stop time: 34.233101
        stop time: 34.063871
        stop time: 34.324931
        stop time: 33.730769
        stop time: 33.938230
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [32.994804, 33.746864, 34.071347, 34.233101, 34.063871, 34.324931, 33.730769, 33.93823]
    [exp] Throughput: 590.1795952287919
[test.py] Finished running 0th optmization experiment: groundtruth->1036.0860414803913, slowdown->590.1795952287919, predicted->1018.1404307733071, err->-1.7320579554805031
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000106', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   522.97ms  455.18ms   2.05s    64.84%
        Req/Sec   141.99     77.97   373.00     68.31%
        Latency Distribution
        50%  435.16ms
        75%  825.36ms
        90%    1.18s
        99%    1.75s
        2699 requests in 3.03s, 419.08KB read
        Requests/sec:    890.61
        Transfer/sec:    138.29KB
        [run.sh] Speed is 890.61, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   556.13ms  629.00ms   4.66s    88.02%
        Req/Sec   131.43     67.07   474.00     69.27%
        Latency Distribution
        50%  348.46ms
        75%  730.78ms
        90%    1.31s
        99%    3.07s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 18.622388
        stop time: 18.561447
        stop time: 19.611644
        stop time: 18.864999
        stop time: 19.671549
        stop time: 19.813460
        stop time: 19.586674
        stop time: 19.987206
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.622388, 18.561447, 19.611644, 18.864999, 19.671549, 19.81346, 19.586674, 19.987206]
    [exp] Throughput: 1034.1303942899406
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '641.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1885.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   857.52ms  537.55ms   2.68s    74.57%
        Req/Sec    87.81     59.43   250.00     62.68%
        Latency Distribution
        50%  762.17ms
        75%    1.10s
        90%    1.69s
        99%    2.47s
        1459 requests in 3.03s, 226.54KB read
        Requests/sec:    481.23
        Transfer/sec:     74.72KB
        [run.sh] Speed is 481.23, duration is 62
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d62s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f574d6759-968gg         401m         63Mi
        service1-7755b7b4b5-rsfl8        379m         58Mi
        service2-768b85b46f-pxz9t        296m         28Mi
        service3-f58957f9-vlbqz          80m          14Mi
        service4-7c96f6d57-wsnwc         160m         12Mi
        ubuntu-client-76886f6bbd-lsncq   4m           11Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   833.71ms  656.71ms   4.94s    80.30%
        Req/Sec    80.56     49.16   280.00     64.68%
        Latency Distribution
        50%  673.70ms
        75%    1.11s
        90%    1.60s
        99%    3.31s
        20001 requests in 1.03m, 3.03MB read
        Requests/sec:    322.60
        Transfer/sec:     50.09KB
        ------------------------------
        stop time: 31.835431
        stop time: 32.668885
        stop time: 32.668192
        stop time: 32.409646
        stop time: 32.050716
        stop time: 32.469162
        stop time: 32.652325
        stop time: 32.819694
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [31.835431, 32.668885, 32.668192, 32.409646, 32.050716, 32.469162, 32.652325, 32.819694]
    [exp] Throughput: 616.3944330475468
[test.py] Finished running 1th optmization experiment: groundtruth->1034.1303942899406, slowdown->616.3944330475468, predicted->1019.2213748762531, err->-1.441696278922773
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000212', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   543.34ms  387.77ms   1.87s    71.78%
        Req/Sec   133.63     95.73   474.00     67.20%
        Latency Distribution
        50%  479.26ms
        75%  784.59ms
        90%  980.12ms
        99%    1.63s
        2660 requests in 3.03s, 413.03KB read
        Requests/sec:    877.68
        Transfer/sec:    136.28KB
        [run.sh] Speed is 877.68, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   506.47ms  429.93ms   3.67s    79.11%
        Req/Sec   132.14     72.83   414.00     70.16%
        Latency Distribution
        50%  387.39ms
        75%  715.77ms
        90%    1.08s
        99%    1.94s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.542313
        stop time: 19.157763
        stop time: 18.882176
        stop time: 19.625132
        stop time: 19.929695
        stop time: 19.582251
        stop time: 19.842397
        stop time: 19.584426
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-qcpq5        550m         63Mi
        service1-7755b7b4b5-crx24        271m         79Mi
        service2-958786d58-276zd         495m         43Mi
        service3-6ddd8b8f64-wfjbr        284m         17Mi
        service4-9bb5bd9fd-r5dps         258m         13Mi
        ubuntu-client-76886f6bbd-tkhtt   18m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.542313, 19.157763, 18.882176, 19.625132, 19.929695, 19.582251, 19.842397, 19.584426]
    [exp] Throughput: 1024.6810243221298
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '570.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1676.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   798.24ms  436.50ms   2.66s    71.59%
        Req/Sec    80.78     58.48   252.00     64.71%
        Latency Distribution
        50%  714.45ms
        75%    1.08s
        90%    1.34s
        99%    1.92s
        1655 requests in 3.03s, 256.98KB read
        Requests/sec:    546.41
        Transfer/sec:     84.84KB
        [run.sh] Speed is 546.41, duration is 54
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d54s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-d98b4cfdb-5tmqr         1243m        69Mi
        service1-7755b7b4b5-bqj65        1173m        60Mi
        service2-5569d86cb9-cmk9h        1014m        29Mi
        service3-84456c486d-49mvx        741m         16Mi
        service4-79fb8b8978-l4bfr        530m         12Mi
        ubuntu-client-76886f6bbd-8bl2r   26m          24Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   821.89ms  787.83ms   6.16s    84.96%
        Req/Sec    87.30     49.84   313.00     68.23%
        Latency Distribution
        50%  577.88ms
        75%    1.14s
        90%    1.89s
        99%    3.69s
        20000 requests in 0.90m, 3.03MB read
        Requests/sec:    370.37
        Transfer/sec:     57.51KB
        ------------------------------
        stop time: 30.649447
        stop time: 31.157528
        stop time: 31.063057
        stop time: 31.532789
        stop time: 30.631092
        stop time: 31.141380
        stop time: 29.561561
        stop time: 31.558267
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [30.649447, 31.157528, 31.063057, 31.532789, 30.631092, 31.14138, 29.561561, 31.558267]
    [exp] Throughput: 647.000229333275
[test.py] Finished running 2th optmization experiment: groundtruth->1024.6810243221298, slowdown->647.000229333275, predicted->1025.2017069941612, err->0.05081412260716472
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000318', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   453.52ms  285.57ms   1.51s    64.75%
        Req/Sec   131.41     80.16   414.00     67.66%
        Latency Distribution
        50%  441.16ms
        75%  634.99ms
        90%  857.11ms
        99%    1.16s
        2818 requests in 3.02s, 437.56KB read
        Requests/sec:    932.28
        Transfer/sec:    144.76KB
        [run.sh] Speed is 932.28, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   564.85ms  626.80ms   5.30s    87.14%
        Req/Sec   132.40     66.43   434.00     71.38%
        Latency Distribution
        50%  330.45ms
        75%  739.12ms
        90%    1.44s
        99%    2.76s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.978876
        stop time: 18.603218
        stop time: 19.849050
        stop time: 19.217576
        stop time: 19.728803
        stop time: 19.952514
        stop time: 19.783274
        stop time: 19.975560
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-vrc4q        1941m        65Mi
        service1-7755b7b4b5-dr9x2        750m         37Mi
        service2-958786d58-d9gjr         1610m        20Mi
        service3-6ddd8b8f64-hwrgd        1192m        12Mi
        service4-9bb5bd9fd-brthk         777m         10Mi
        ubuntu-client-76886f6bbd-v9989   25m          22Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.978876, 18.603218, 19.84905, 19.217576, 19.728803, 19.952514, 19.783274, 19.97556]
    [exp] Throughput: 1025.0570650869786
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '499.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1468.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   779.20ms  474.81ms   2.36s    68.19%
        Req/Sec    88.31     49.32   250.00     66.04%
        Latency Distribution
        50%  776.85ms
        75%    1.05s
        90%    1.35s
        99%    2.27s
        1646 requests in 3.03s, 255.58KB read
        Requests/sec:    543.57
        Transfer/sec:     84.40KB
        [run.sh] Speed is 543.57, duration is 55
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-766754b87b-hddgl        3m           60Mi
        service1-7755b7b4b5-fc99g        3m           47Mi
        service2-b6f7bd475-rhmxc         3m           21Mi
        service4-68bd74b5d4-6zjv9        3m           11Mi
        ubuntu-client-76886f6bbd-2jhsz   11m          3Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   768.14ms  705.75ms   5.45s    84.89%
        Req/Sec    90.01     51.26   343.00     72.06%
        Latency Distribution
        50%  575.94ms
        75%    1.04s
        90%    1.68s
        99%    3.51s
        20000 requests in 0.92m, 3.03MB read
        Requests/sec:    363.64
        Transfer/sec:     56.46KB
        ------------------------------
        stop time: 29.466461
        stop time: 29.353714
        stop time: 29.189157
        stop time: 29.995540
        stop time: 29.982392
        stop time: 29.991017
        stop time: 28.946589
        stop time: 29.085126
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [29.466461, 29.353714, 29.189157, 29.99554, 29.982392, 29.991017, 28.946589, 29.085126]
    [exp] Throughput: 677.9373870249123
[test.py] Finished running 3th optmization experiment: groundtruth->1025.0570650869786, slowdown->677.9373870249123, predicted->1024.6890894769015, err->-0.035898060957795214
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000424', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   587.14ms  643.98ms   2.91s    83.75%
        Req/Sec   120.89     50.10   282.00     62.96%
        Latency Distribution
        50%  355.16ms
        75%  762.13ms
        90%    1.63s
        99%    2.56s
        2690 requests in 3.04s, 417.69KB read
        Requests/sec:    886.18
        Transfer/sec:    137.60KB
        [run.sh] Speed is 886.18, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   570.94ms  646.24ms   5.25s    86.07%
        Req/Sec   129.12     68.75   565.00     71.15%
        Latency Distribution
        50%  320.97ms
        75%  689.17ms
        90%    1.46s
        99%    2.98s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.371738
        stop time: 19.547215
        stop time: 19.757316
        stop time: 19.406125
        stop time: 20.036434
        stop time: 19.300988
        stop time: 19.732925
        stop time: 19.293373
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-bq6tc        3m           65Mi
        service1-7755b7b4b5-qs8f9        262m         34Mi
        service2-958786d58-cmd5f         58m          15Mi
        service3-6ddd8b8f64-vcwjz        3m           8Mi
        service4-9bb5bd9fd-blzkt         144m         8Mi
        ubuntu-client-76886f6bbd-zbrzk   24m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.371738, 19.547215, 19.757316, 19.406125, 20.036434, 19.300988, 19.732925, 19.293373]
    [exp] Throughput: 1022.716358426135
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '428.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1259.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   684.87ms  387.22ms   2.10s    63.93%
        Req/Sec   100.54     64.74   260.00     62.57%
        Latency Distribution
        50%  741.42ms
        75%  936.65ms
        90%    1.12s
        99%    1.64s
        1837 requests in 3.03s, 285.24KB read
        Requests/sec:    606.81
        Transfer/sec:     94.22KB
        [run.sh] Speed is 606.81, duration is 49
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-75578d5c44-mx864        1391m        69Mi
        service1-7755b7b4b5-7kp9b        1271m        54Mi
        service2-6ddcd79dbf-d88xp        1098m        28Mi
        service3-899d5fdcf-rxdcs         734m         15Mi
        service4-675dc4d5d9-69pdz        567m         12Mi
        ubuntu-client-76886f6bbd-6h256   29m          22Mi
        Running 49s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   745.13ms  700.96ms   5.49s    85.04%
        Req/Sec    91.65     51.91   424.00     70.41%
        Latency Distribution
        50%  537.77ms
        75%  970.37ms
        90%    1.70s
        99%    3.16s
        20000 requests in 49.00s, 3.03MB read
        Requests/sec:    408.16
        Transfer/sec:     63.38KB
        ------------------------------
        stop time: 26.854718
        stop time: 28.290097
        stop time: 28.445662
        stop time: 28.039071
        stop time: 27.918495
        stop time: 28.162826
        stop time: 28.415105
        stop time: 28.071728
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.854718, 28.290097, 28.445662, 28.039071, 27.918495, 28.162826, 28.415105, 28.071728]
    [exp] Throughput: 713.6558429131445
[test.py] Finished running 4th optmization experiment: groundtruth->1022.716358426135, slowdown->713.6558429131445, predicted->1027.6447352507769, err->0.48189087658930035
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00053', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   527.81ms  495.16ms   2.46s    75.78%
        Req/Sec   133.64     59.38   323.00     68.21%
        Latency Distribution
        50%  354.25ms
        75%  850.61ms
        90%    1.25s
        99%    1.95s
        2668 requests in 3.03s, 414.27KB read
        Requests/sec:    881.21
        Transfer/sec:    136.83KB
        [run.sh] Speed is 881.21, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   569.81ms  661.47ms   5.58s    87.25%
        Req/Sec   128.26     64.76   424.00     72.01%
        Latency Distribution
        50%  320.03ms
        75%  705.97ms
        90%    1.44s
        99%    3.08s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.640112
        stop time: 19.849454
        stop time: 19.855216
        stop time: 20.023743
        stop time: 19.798541
        stop time: 19.348692
        stop time: 19.922673
        stop time: 19.387840
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-rwhww        1780m        70Mi
        service1-7755b7b4b5-c4hkc        695m         51Mi
        service2-958786d58-nfmbn         1317m        27Mi
        service3-6ddd8b8f64-l49nb        1188m        15Mi
        service4-9bb5bd9fd-nrhbf         591m         11Mi
        ubuntu-client-76886f6bbd-l88x9   22m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.640112, 19.849454, 19.855216, 20.023743, 19.798541, 19.348692, 19.922673, 19.38784]
    [exp] Throughput: 1013.772922506672
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '357.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1050.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   684.68ms  553.91ms   2.98s    82.25%
        Req/Sec   102.93     57.09   300.00     68.97%
        Latency Distribution
        50%  556.31ms
        75%  953.02ms
        90%    1.38s
        99%    2.75s
        1985 requests in 3.02s, 308.22KB read
        Requests/sec:    656.26
        Transfer/sec:    101.90KB
        [run.sh] Speed is 656.26, duration is 45
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d45s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-76cf478f75-l87dp        3m           56Mi
        service1-7755b7b4b5-47shh        279m         47Mi
        service2-6fc48d9cd4-bxnzv        3m           23Mi
        service3-769fd8d48-bmvkg         3m           11Mi
        service4-7bfcf7775d-7svpk        43m          9Mi
        ubuntu-client-76886f6bbd-fv8vd   15m          10Mi
        Running 45s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   688.11ms  552.04ms   4.60s    79.76%
        Req/Sec    99.62     53.22   330.00     68.70%
        Latency Distribution
        50%  573.01ms
        75%  894.16ms
        90%    1.35s
        99%    2.87s
        20000 requests in 45.00s, 3.03MB read
        Requests/sec:    444.44
        Transfer/sec:     69.01KB
        ------------------------------
        stop time: 25.388354
        stop time: 26.529604
        stop time: 26.306880
        stop time: 26.273975
        stop time: 27.113399
        stop time: 27.018905
        stop time: 27.111380
        stop time: 26.550117
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [25.388354, 26.529604, 26.30688, 26.273975, 27.113399, 27.018905, 27.11138, 26.550117]
    [exp] Throughput: 753.6767152907166
[test.py] Finished running 5th optmization experiment: groundtruth->1013.772922506672, slowdown->753.6767152907166, predicted->1031.2338696492805, err->1.722372609778749
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000636', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   415.73ms  392.87ms   1.99s    77.86%
        Req/Sec   141.68     57.31   292.00     67.50%
        Latency Distribution
        50%  231.43ms
        75%  737.84ms
        90%    1.01s
        99%    1.35s
        2855 requests in 3.04s, 443.31KB read
        Requests/sec:    940.59
        Transfer/sec:    146.05KB
        [run.sh] Speed is 940.59, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   535.48ms  529.10ms   4.14s    85.68%
        Req/Sec   129.92     64.42   363.00     69.56%
        Latency Distribution
        50%  351.35ms
        75%  749.60ms
        90%    1.26s
        99%    2.38s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 19.701592
        stop time: 19.563669
        stop time: 19.701248
        stop time: 19.714460
        stop time: 19.894908
        stop time: 19.894236
        stop time: 19.351933
        stop time: 19.673355
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-r6bst        54m          70Mi
        service1-7755b7b4b5-p24zf        375m         54Mi
        service2-958786d58-7ph7z         142m         27Mi
        service3-6ddd8b8f64-xstw7        301m         11Mi
        service4-9bb5bd9fd-7swmn         158m         14Mi
        ubuntu-client-76886f6bbd-kk6k8   16m          14Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.701592, 19.563669, 19.701248, 19.71446, 19.894908, 19.894236, 19.351933, 19.673355]
    [exp] Throughput: 1015.9026802312785
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '286.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '841.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   623.64ms  378.88ms   2.40s    65.87%
        Req/Sec    94.85     61.46   270.00     65.60%
        Latency Distribution
        50%  554.95ms
        75%  856.90ms
        90%    1.21s
        99%    1.58s
        2155 requests in 3.03s, 334.61KB read
        Requests/sec:    711.45
        Transfer/sec:    110.47KB
        [run.sh] Speed is 711.45, duration is 42
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f758f58-8l8tn          1523m        66Mi
        service1-7755b7b4b5-xrkhv        1427m        33Mi
        service2-df5dc84c7-wtzb6         1184m        20Mi
        service3-ff5f5bd54-rprbc         917m         11Mi
        service4-69f57699c6-frnt5        565m         10Mi
        ubuntu-client-76886f6bbd-2vqmn   30m          22Mi
        Running 42s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   650.27ms  545.34ms   3.90s    82.41%
        Req/Sec   102.74     52.68   330.00     65.00%
        Latency Distribution
        50%  493.83ms
        75%  857.43ms
        90%    1.39s
        99%    2.76s
        20000 requests in 42.00s, 3.03MB read
        Requests/sec:    476.19
        Transfer/sec:     73.94KB
        ------------------------------
        stop time: 24.408568
        stop time: 24.960519
        stop time: 25.375427
        stop time: 25.492596
        stop time: 25.466396
        stop time: 25.071322
        stop time: 24.997436
        stop time: 25.589722
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.408568, 24.960519, 25.375427, 25.492596, 25.466396, 25.071322, 24.997436, 25.589722]
    [exp] Throughput: 794.5889051769682
[test.py] Finished running 6th optmization experiment: groundtruth->1015.9026802312785, slowdown->794.5889051769682, predicted->1028.366764487056, err->1.2268974674759032
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000742', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   517.46ms  351.57ms   1.85s    62.14%
        Req/Sec   141.84     84.72   353.00     68.48%
        Latency Distribution
        50%  450.42ms
        75%  781.53ms
        90%  972.51ms
        99%    1.37s
        2678 requests in 3.04s, 415.82KB read
        Requests/sec:    881.27
        Transfer/sec:    136.84KB
        [run.sh] Speed is 881.27, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   557.30ms  605.24ms   4.24s    87.62%
        Req/Sec   128.86     62.28   414.00     72.92%
        Latency Distribution
        50%  338.45ms
        75%  674.25ms
        90%    1.38s
        99%    2.85s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 18.933275
        stop time: 19.006029
        stop time: 19.458151
        stop time: 19.971658
        stop time: 20.067928
        stop time: 19.866224
        stop time: 19.702432
        stop time: 19.734311
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.933275, 19.006029, 19.458151, 19.971658, 20.067928, 19.866224, 19.702432, 19.734311]
    [exp] Throughput: 1020.7987229399657
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '215.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '632.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   643.13ms  498.00ms   2.71s    67.13%
        Req/Sec   107.74     48.81   210.00     67.05%
        Latency Distribution
        50%  554.40ms
        75%  967.22ms
        90%    1.37s
        99%    2.04s
        1967 requests in 3.03s, 305.42KB read
        Requests/sec:    648.90
        Transfer/sec:    100.76KB
        [run.sh] Speed is 648.90, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-57b7884898-ml8tz        1057m        69Mi
        service1-7755b7b4b5-tg4z7        120m         56Mi
        service2-76ccc647cd-4f8sf        913m         29Mi
        service3-77cbbdbbc5-lzmgw        374m         14Mi
        service4-57dc9b8757-nkzcd        147m         11Mi
        ubuntu-client-76886f6bbd-jtkpk   9m           17Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   634.46ms  637.44ms   8.00s    87.01%
        Req/Sec   107.26     52.30   340.00     64.84%
        Latency Distribution
        50%  417.65ms
        75%  790.46ms
        90%    1.45s
        99%    2.91s
        20000 requests in 46.00s, 3.03MB read
        Requests/sec:    434.78
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 23.866231
        stop time: 23.878466
        stop time: 23.721698
        stop time: 24.037004
        stop time: 24.237873
        stop time: 23.405786
        stop time: 23.870945
        stop time: 23.924742
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.866231, 23.878466, 23.721698, 24.037004, 24.237873, 23.405786, 23.870945, 23.924742]
    [exp] Throughput: 837.9475219129167
[test.py] Finished running 7th optmization experiment: groundtruth->1020.7987229399657, slowdown->837.9475219129167, predicted->1022.1651856887954, err->0.13386211386454225
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000848', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   558.87ms  372.97ms   1.68s    63.50%
        Req/Sec   144.12     80.11   363.00     67.05%
        Latency Distribution
        50%  433.80ms
        75%  893.56ms
        90%    1.11s
        99%    1.38s
        2562 requests in 3.02s, 397.81KB read
        Requests/sec:    847.88
        Transfer/sec:    131.65KB
        [run.sh] Speed is 847.88, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-rsp45        1937m        69Mi
        service1-7755b7b4b5-skmx5        1495m        54Mi
        service2-958786d58-tfwjl         1536m        25Mi
        service3-6ddd8b8f64-gxpss        1156m        14Mi
        service4-9bb5bd9fd-md7cb         825m         14Mi
        ubuntu-client-76886f6bbd-zllg4   38m          20Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   545.90ms  578.48ms   4.75s    88.03%
        Req/Sec   129.33     61.94   550.00     72.60%
        Latency Distribution
        50%  352.22ms
        75%  671.77ms
        90%    1.26s
        99%    2.81s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 19.539705
        stop time: 19.888273
        stop time: 19.654346
        stop time: 19.591852
        stop time: 19.661179
        stop time: 19.953560
        stop time: 19.105432
        stop time: 19.500273
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.539705, 19.888273, 19.654346, 19.591852, 19.661179, 19.95356, 19.105432, 19.500273]
    [exp] Throughput: 1019.7927755585246
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '144.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '423.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   588.80ms  614.50ms   2.98s    82.61%
        Req/Sec   106.63     49.92   252.00     67.44%
        Latency Distribution
        50%  321.77ms
        75%  804.09ms
        90%    1.61s
        99%    2.59s
        2348 requests in 3.03s, 364.58KB read
        Requests/sec:    774.58
        Transfer/sec:    120.27KB
        [run.sh] Speed is 774.58, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   578.06ms  452.17ms   4.32s    82.67%
        Req/Sec   114.91     57.72   353.00     70.17%
        Latency Distribution
        50%  467.51ms
        75%  713.14ms
        90%    1.15s
        99%    2.28s
        20000 requests in 38.00s, 3.03MB read
        Requests/sec:    526.31
        Transfer/sec:     81.72KB
        ------------------------------
        stop time: 21.749014
        stop time: 22.138588
        stop time: 21.491682
        stop time: 22.249694
        stop time: 22.786034
        stop time: 22.228170
        stop time: 22.582508
        stop time: 22.625134
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [21.749014, 22.138588, 21.491682, 22.249694, 22.786034, 22.22817, 22.582508, 22.625134]
    [exp] Throughput: 899.6303553814291
[test.py] Finished running 8th optmization experiment: groundtruth->1019.7927755585246, slowdown->899.6303553814291, predicted->1033.5800333836016, err->1.3519666108171826
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000954', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   497.30ms  324.35ms   1.75s    66.09%
        Req/Sec   135.22     56.77   303.00     72.73%
        Latency Distribution
        50%  471.39ms
        75%  713.38ms
        90%  895.96ms
        99%    1.45s
        2848 requests in 3.03s, 442.22KB read
        Requests/sec:    941.44
        Transfer/sec:    146.18KB
        [run.sh] Speed is 941.44, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   594.00ms  722.12ms   5.99s    86.92%
        Req/Sec   129.83     59.72   700.00     67.58%
        Latency Distribution
        50%  306.29ms
        75%  726.78ms
        90%    1.60s
        99%    3.32s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 19.133695
        stop time: 19.528704
        stop time: 19.035124
        stop time: 19.120018
        stop time: 19.622619
        stop time: 19.203978
        stop time: 19.760407
        stop time: 20.068498
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-lmcfq        666m         65Mi
        service1-7755b7b4b5-8whzb        559m         48Mi
        service2-958786d58-bhsfz         528m         24Mi
        service3-6ddd8b8f64-r6gqk        125m         11Mi
        service4-9bb5bd9fd-wjqr8         269m         10Mi
        ubuntu-client-76886f6bbd-g9b29   18m          11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.133695, 19.528704, 19.035124, 19.120018, 19.622619, 19.203978, 19.760407, 20.068498]
    [exp] Throughput: 1029.1173113528112
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '73.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '214.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   521.82ms  310.99ms   1.74s    67.82%
        Req/Sec   117.35     65.80   330.00     65.73%
        Latency Distribution
        50%  470.83ms
        75%  699.38ms
        90%  952.61ms
        99%    1.45s
        2551 requests in 3.03s, 396.10KB read
        Requests/sec:    841.70
        Transfer/sec:    130.69KB
        [run.sh] Speed is 841.70, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-765df4d958-f9qsq        1814m        73Mi
        service1-7755b7b4b5-f6zgh        1663m        51Mi
        service2-74457b7b66-fxqk9        1471m        19Mi
        service3-657f66b697-sznff        614m         14Mi
        service4-648ccfbd5f-mdfvg        777m         11Mi
        ubuntu-client-76886f6bbd-mwlcz   36m          21Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   582.99ms  608.67ms   4.84s    86.90%
        Req/Sec   121.54     59.09   434.00     69.17%
        Latency Distribution
        50%  391.48ms
        75%  724.25ms
        90%    1.37s
        99%    3.13s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 21.214696
        stop time: 20.923984
        stop time: 21.419005
        stop time: 20.585216
        stop time: 21.389540
        stop time: 20.911000
        stop time: 21.224684
        stop time: 20.943697
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.214696, 20.923984, 21.419005, 20.585216, 21.38954, 20.911, 21.224684, 20.943697]
    [exp] Throughput: 948.9251589962653
[test.py] Finished running 9th optmization experiment: groundtruth->1029.1173113528112, slowdown->948.9251589962653, predicted->1019.589175658965, err->-0.9258551565244847
[test.py] Baseline throughput:  1017.1174897967541
[test.py] Groundtruth:  [1036.0860414803913, 1034.1303942899406, 1024.6810243221298, 1025.0570650869786, 1022.716358426135, 1013.772922506672, 1015.9026802312785, 1020.7987229399657, 1019.7927755585246, 1029.1173113528112]
[test.py] Slowdown:  [590.1795952287919, 616.3944330475468, 647.000229333275, 677.9373870249123, 713.6558429131445, 753.6767152907166, 794.5889051769682, 837.9475219129167, 899.6303553814291, 948.9251589962653]
[test.py] Predicted:  [1018.1404307733071, 1019.2213748762531, 1025.2017069941612, 1024.6890894769015, 1027.6447352507769, 1031.2338696492805, 1028.366764487056, 1022.1651856887954, 1033.5800333836016, 1019.589175658965]
[test.py] Error percentage:  [-1.7320579554805031, -1.441696278922773, 0.05081412260716472, -0.035898060957795214, 0.48189087658930035, 1.722372609778749, 1.2268974674759032, 0.13386211386454225, 1.3519666108171826, -0.9258551565244847]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 3...
[test.py] Actual processing time range: [0, 106, 212, 318, 424, 530, 636, 742, 848, 954]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   577.93ms  445.74ms   2.55s    74.25%
        Req/Sec   119.04     64.02   290.00     68.02%
        Latency Distribution
        50%  462.75ms
        75%  768.51ms
        90%    1.21s
        99%    2.01s
        2666 requests in 3.02s, 413.96KB read
        Requests/sec:    881.64
        Transfer/sec:    136.89KB
        [run.sh] Speed is 881.64, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   552.89ms  600.03ms   4.76s    86.42%
        Req/Sec   128.04     57.29   630.00     70.64%
        Latency Distribution
        50%  339.23ms
        75%  663.58ms
        90%    1.42s
        99%    2.82s
        20001 requests in 34.00s, 3.03MB read
        Requests/sec:    588.26
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.224618
        stop time: 19.015728
        stop time: 20.039095
        stop time: 19.718653
        stop time: 19.853595
        stop time: 19.694175
        stop time: 20.169020
        stop time: 19.700068
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-sznrh   3m           63Mi
        service1-7755b7b4b5-r9kqt   3m           62Mi
        service2-958786d58-46v2l    3m           32Mi
        service3-6ddd8b8f64-92knz   238m         10Mi
        service4-9bb5bd9fd-qhhw8    3m           12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.224618, 19.015728, 20.039095, 19.718653, 19.853595, 19.694175, 20.16902, 19.700068]
    [exp] Throughput: 1016.4218707762905
[test.py] Baseline throughput: 1016.4218707762905
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   584.98ms  575.43ms   2.95s    85.74%
        Req/Sec   124.23     72.71   390.00     68.88%
        Latency Distribution
        50%  331.64ms
        75%  722.62ms
        90%    1.53s
        99%    2.44s
        2566 requests in 3.04s, 398.43KB read
        Requests/sec:    842.84
        Transfer/sec:    130.87KB
        [run.sh] Speed is 842.84, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-mtbmf        1389m        64Mi
        service1-7755b7b4b5-jqqb8        411m         39Mi
        service2-958786d58-qvvg6         1124m        22Mi
        service3-6ddd8b8f64-jc4vd        481m         14Mi
        service4-9bb5bd9fd-ngxfp         645m         9Mi
        ubuntu-client-76886f6bbd-r5zth   29m          21Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   580.08ms  744.95ms   5.00s    84.88%
        Req/Sec   129.07     57.08   370.00     68.48%
        Latency Distribution
        50%  237.99ms
        75%  788.28ms
        90%    1.71s
        99%    3.21s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 18.896686
        stop time: 19.678075
        stop time: 19.032129
        stop time: 19.749334
        stop time: 19.645623
        stop time: 18.981742
        stop time: 19.877283
        stop time: 19.982093
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.896686, 19.678075, 19.032129, 19.749334, 19.645623, 18.981742, 19.877283, 19.982093]
    [exp] Throughput: 1026.6745117432795
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '712.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '2094.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   791.50ms  417.15ms   2.09s    64.97%
        Req/Sec    77.31     48.91   210.00     62.77%
        Latency Distribution
        50%  869.59ms
        75%    1.02s
        90%    1.36s
        99%    1.87s
        1493 requests in 3.03s, 231.82KB read
        Requests/sec:    492.79
        Transfer/sec:     76.52KB
        [run.sh] Speed is 492.79, duration is 60
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d60s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   886.89ms  737.97ms   6.53s    80.28%
        Req/Sec    80.44     55.62   610.00     72.87%
        Latency Distribution
        50%  717.63ms
        75%    1.16s
        90%    1.79s
        99%    3.55s
        20000 requests in 1.00m, 3.03MB read
        Requests/sec:    333.33
        Transfer/sec:     51.76KB
        ------------------------------
        stop time: 33.180380
        stop time: 34.074544
        stop time: 34.374628
        stop time: 33.581503
        stop time: 33.929189
        stop time: 34.344043
        stop time: 34.526736
        stop time: 34.335314
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [33.18038, 34.074544, 34.374628, 33.581503, 33.929189, 34.344043, 34.526736, 34.335314]
    [exp] Throughput: 587.4872479008227
[test.py] Finished running 0th optmization experiment: groundtruth->1026.6745117432795, slowdown->587.4872479008227, predicted->1010.1541643621212, err->-1.6091124491935622
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000106', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   401.14ms  371.34ms   2.03s    82.64%
        Req/Sec   128.08     61.30   300.00     66.51%
        Latency Distribution
        50%  266.76ms
        75%  592.76ms
        90%  920.85ms
        99%    1.69s
        2779 requests in 3.03s, 431.50KB read
        Requests/sec:    917.20
        Transfer/sec:    142.42KB
        [run.sh] Speed is 917.20, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   575.89ms  649.79ms   4.79s    87.34%
        Req/Sec   130.96     74.56   525.00     73.15%
        Latency Distribution
        50%  344.18ms
        75%  658.38ms
        90%    1.48s
        99%    3.10s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.869601
        stop time: 18.914335
        stop time: 19.307582
        stop time: 19.715685
        stop time: 19.998345
        stop time: 19.507363
        stop time: 19.726824
        stop time: 19.889311
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-96w9x        129m         63Mi
        service1-7755b7b4b5-gcptc        1m           44Mi
        service2-958786d58-zb97s         73m          27Mi
        service3-6ddd8b8f64-fwhc2        484m         11Mi
        service4-9bb5bd9fd-9zrpc         24m          12Mi
        ubuntu-client-76886f6bbd-xh726   9m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.869601, 18.914335, 19.307582, 19.715685, 19.998345, 19.507363, 19.726824, 19.889311]
    [exp] Throughput: 1026.1077336418773
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '641.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1885.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   822.62ms  626.76ms   2.93s    76.72%
        Req/Sec    76.30     55.28   222.00     61.54%
        Latency Distribution
        50%  624.65ms
        75%    1.18s
        90%    1.68s
        99%    2.81s
        1499 requests in 3.03s, 232.75KB read
        Requests/sec:    494.73
        Transfer/sec:     76.82KB
        [run.sh] Speed is 494.73, duration is 60
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d60s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f574d6759-pp56w         408m         44Mi
        service1-7755b7b4b5-26bwv        402m         59Mi
        service2-768b85b46f-2662r        334m         32Mi
        service3-f58957f9-fvqrb          242m         15Mi
        service4-7c96f6d57-74cv7         160m         12Mi
        ubuntu-client-76886f6bbd-rd9kz   15m          0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   833.07ms  663.81ms   4.77s    76.00%
        Req/Sec    80.04     49.37   363.00     63.97%
        Latency Distribution
        50%  702.59ms
        75%    1.13s
        90%    1.65s
        99%    3.15s
        20000 requests in 1.00m, 3.03MB read
        Requests/sec:    333.33
        Transfer/sec:     51.76KB
        ------------------------------
        stop time: 32.775600
        stop time: 32.195508
        stop time: 32.442366
        stop time: 32.350767
        stop time: 32.987065
        stop time: 32.826149
        stop time: 32.591999
        stop time: 31.714291
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [32.7756, 32.195508, 32.442366, 32.350767, 32.987065, 32.826149, 32.591999, 31.714291]
    [exp] Throughput: 615.6598982364211
[test.py] Finished running 1th optmization experiment: groundtruth->1026.1077336418773, slowdown->615.6598982364211, predicted->1017.2146218524036, err->-0.8666840233149882
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000212', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   485.28ms  307.11ms   1.61s    68.69%
        Req/Sec   130.87     84.08   380.00     68.88%
        Latency Distribution
        50%  430.14ms
        75%  650.38ms
        90%  978.87ms
        99%    1.34s
        2746 requests in 3.03s, 426.38KB read
        Requests/sec:    905.70
        Transfer/sec:    140.63KB
        [run.sh] Speed is 905.70, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   549.20ms  577.24ms   4.92s    86.26%
        Req/Sec   128.85     69.66   464.00     71.59%
        Latency Distribution
        50%  346.79ms
        75%  663.17ms
        90%    1.34s
        99%    2.72s
        20001 requests in 33.00s, 3.03MB read
        Requests/sec:    606.09
        Transfer/sec:     94.11KB
        ------------------------------
        stop time: 19.565834
        stop time: 19.400886
        stop time: 19.101068
        stop time: 19.789205
        stop time: 19.833196
        stop time: 19.740287
        stop time: 19.726989
        stop time: 19.756552
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-gm8jn        641m         64Mi
        service1-7755b7b4b5-w2c8f        245m         41Mi
        service2-958786d58-qrzvc         493m         23Mi
        service3-6ddd8b8f64-fv2gx        241m         10Mi
        service4-9bb5bd9fd-sccwd         266m         8Mi
        ubuntu-client-76886f6bbd-2l6jq   22m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.565834, 19.400886, 19.101068, 19.789205, 19.833196, 19.740287, 19.726989, 19.756552]
    [exp] Throughput: 1019.6667133950183
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '570.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1676.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   789.82ms  479.20ms   2.60s    69.23%
        Req/Sec    75.20     55.57   260.00     72.30%
        Latency Distribution
        50%  776.47ms
        75%    1.02s
        90%    1.45s
        99%    2.20s
        1635 requests in 3.03s, 253.87KB read
        Requests/sec:    539.55
        Transfer/sec:     83.78KB
        [run.sh] Speed is 539.55, duration is 55
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-d98b4cfdb-8d4hk         1090m        71Mi
        service1-7755b7b4b5-47vbp        1051m        73Mi
        service2-5569d86cb9-rbns9        867m         56Mi
        service3-84456c486d-5sq7s        650m         13Mi
        service4-79fb8b8978-k6hds        462m         11Mi
        ubuntu-client-76886f6bbd-b6hwj   23m          23Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency     1.01s     1.29s    9.91s    87.57%
        Req/Sec    81.69     48.69   410.00     68.91%
        Latency Distribution
        50%  564.06ms
        75%    1.31s
        90%    2.67s
        99%    6.21s
        20000 requests in 0.92m, 3.03MB read
        Requests/sec:    363.64
        Transfer/sec:     56.46KB
        ------------------------------
        stop time: 33.398112
        stop time: 30.871205
        stop time: 31.458879
        stop time: 32.880884
        stop time: 33.278467
        stop time: 33.017822
        stop time: 33.477974
        stop time: 33.158009
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [33.398112, 30.871205, 31.458879, 32.880884, 33.278467, 33.017822, 33.477974, 33.158009]
    [exp] Throughput: 611.7579448774892
[test.py] Finished running 2th optmization experiment: groundtruth->1019.6667133950183, slowdown->611.7579448774892, predicted->939.4463419955765, err->-7.867312950948949
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000318', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   504.28ms  411.51ms   2.12s    70.68%
        Req/Sec   139.99     65.64   350.00     70.31%
        Latency Distribution
        50%  435.36ms
        75%  751.19ms
        90%    1.09s
        99%    1.70s
        2733 requests in 3.03s, 424.36KB read
        Requests/sec:    901.88
        Transfer/sec:    140.04KB
        [run.sh] Speed is 901.88, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   513.18ms  491.18ms   4.14s    86.87%
        Req/Sec   131.56     73.65   434.00     70.72%
        Latency Distribution
        50%  346.66ms
        75%  646.02ms
        90%    1.18s
        99%    2.31s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 18.729419
        stop time: 18.933969
        stop time: 19.397664
        stop time: 18.947733
        stop time: 19.906401
        stop time: 19.860156
        stop time: 19.964374
        stop time: 19.554632
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-mwlkp        1715m        71Mi
        service1-7755b7b4b5-44r4l        840m         57Mi
        service2-958786d58-dxgsm         1357m        33Mi
        service3-6ddd8b8f64-cc5s8        1186m        14Mi
        service4-9bb5bd9fd-dzqql         739m         12Mi
        ubuntu-client-76886f6bbd-5f259   39m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.729419, 18.933969, 19.397664, 18.947733, 19.906401, 19.860156, 19.964374, 19.554632]
    [exp] Throughput: 1030.301502022469
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '499.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1468.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   772.22ms  570.26ms   2.90s    66.84%
        Req/Sec    82.00     51.52   242.00     59.90%
        Latency Distribution
        50%  649.86ms
        75%    1.07s
        90%    1.66s
        99%    2.54s
        1722 requests in 3.03s, 267.38KB read
        Requests/sec:    568.61
        Transfer/sec:     88.29KB
        [run.sh] Speed is 568.61, duration is 52
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d52s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-766754b87b-nsvjh   3m           18Mi
        service2-b6f7bd475-x8rm9    3m           3Mi
        service4-68bd74b5d4-cq4rv   3m           3Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   777.56ms  711.45ms   6.10s    83.15%
        Req/Sec    91.31     52.93   353.00     69.94%
        Latency Distribution
        50%  591.85ms
        75%    1.01s
        90%    1.77s
        99%    3.37s
        20000 requests in 0.87m, 3.03MB read
        Requests/sec:    384.61
        Transfer/sec:     59.72KB
        ------------------------------
        stop time: 28.405066
        stop time: 28.550291
        stop time: 28.960519
        stop time: 29.846419
        stop time: 30.062895
        stop time: 29.700682
        stop time: 29.783117
        stop time: 29.513042
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [28.405066, 28.550291, 28.960519, 29.846419, 30.062895, 29.700682, 29.783117, 29.513042]
    [exp] Throughput: 681.367073262389
[test.py] Finished running 3th optmization experiment: groundtruth->1030.301502022469, slowdown->681.367073262389, predicted->1032.5447855491277, err->0.2177307829072439
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000424', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   532.11ms  546.51ms   2.30s    85.54%
        Req/Sec   138.70     78.35   380.00     72.92%
        Latency Distribution
        50%  288.91ms
        75%  835.15ms
        90%    1.34s
        99%    2.12s
        2667 requests in 3.03s, 414.11KB read
        Requests/sec:    879.21
        Transfer/sec:    136.52KB
        [run.sh] Speed is 879.21, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   534.38ms  584.46ms   4.74s    85.20%
        Req/Sec   130.53     66.19   525.00     71.35%
        Latency Distribution
        50%  302.57ms
        75%  741.27ms
        90%    1.36s
        99%    2.66s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.276858
        stop time: 18.605264
        stop time: 18.772803
        stop time: 19.459463
        stop time: 19.690360
        stop time: 19.882473
        stop time: 19.846735
        stop time: 20.027074
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-2sbmn        626m         60Mi
        service1-7755b7b4b5-wtztd        3m           76Mi
        service2-958786d58-9vtbk         519m         42Mi
        service3-6ddd8b8f64-lrsrx        157m         17Mi
        service4-9bb5bd9fd-gf6t2         256m         12Mi
        ubuntu-client-76886f6bbd-l2cw4   13m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.276858, 18.605264, 18.772803, 19.459463, 19.69036, 19.882473, 19.846735, 20.027074]
    [exp] Throughput: 1028.535231477961
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '428.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1259.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   742.14ms  525.03ms   2.91s    73.05%
        Req/Sec    81.30     58.23   303.00     71.14%
        Latency Distribution
        50%  585.00ms
        75%  984.84ms
        90%    1.58s
        99%    2.64s
        1840 requests in 3.03s, 285.70KB read
        Requests/sec:    607.43
        Transfer/sec:     94.32KB
        [run.sh] Speed is 607.43, duration is 49
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-75578d5c44-wl4dx        987m         67Mi
        service1-7755b7b4b5-4xtdz        1173m        40Mi
        service2-6ddcd79dbf-9mnv5        809m         21Mi
        service3-899d5fdcf-pxsvp         837m         13Mi
        service4-675dc4d5d9-cq96p        396m         13Mi
        ubuntu-client-76886f6bbd-xxh2v   30m          22Mi
        Running 49s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   743.35ms  697.05ms   5.21s    85.25%
        Req/Sec    95.95     56.29   474.00     72.53%
        Latency Distribution
        50%  534.87ms
        75%  986.84ms
        90%    1.65s
        99%    3.28s
        20000 requests in 49.00s, 3.03MB read
        Requests/sec:    408.16
        Transfer/sec:     63.38KB
        ------------------------------
        stop time: 25.417803
        stop time: 28.314496
        stop time: 27.840456
        stop time: 28.070910
        stop time: 28.183646
        stop time: 28.626429
        stop time: 28.312704
        stop time: 28.447208
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [25.417803, 28.314496, 27.840456, 28.07091, 28.183646, 28.626429, 28.312704, 28.447208]
    [exp] Throughput: 716.8020350296496
[test.py] Finished running 4th optmization experiment: groundtruth->1028.535231477961, slowdown->716.8020350296496, predicted->1034.1811076053807, err->0.5489239410211467
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00053', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-4qq4k cannot connect to service4
        [run.sh] service0-7b65886d58-4qq4k cannot connect to service4
        [run.sh] service2-958786d58-dkk6r cannot connect to service4
        [run.sh] service2-958786d58-dkk6r cannot connect to service4
        [run.sh] service3-6ddd8b8f64-rq4x6 cannot connect to service4
        [run.sh] service3-6ddd8b8f64-rq4x6 cannot connect to service4
        [run.sh] ubuntu-client-76886f6bbd-9jd9b cannot connect to service4
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   515.04ms  436.01ms   2.65s    76.88%
        Req/Sec   120.91     65.73   310.00     68.89%
        Latency Distribution
        50%  380.07ms
        75%  771.76ms
        90%    1.17s
        99%    1.74s
        2801 requests in 3.03s, 434.92KB read
        Requests/sec:    924.94
        Transfer/sec:    143.62KB
        [run.sh] Speed is 924.94, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   539.93ms  522.80ms   4.94s    89.35%
        Req/Sec   129.39     62.54   434.00     73.17%
        Latency Distribution
        50%  395.24ms
        75%  671.96ms
        90%    1.09s
        99%    2.68s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.011107
        stop time: 19.650842
        stop time: 20.048973
        stop time: 19.283897
        stop time: 19.675245
        stop time: 19.872533
        stop time: 20.018591
        stop time: 19.645559
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-4qq4k        655m         68Mi
        service1-7755b7b4b5-8tzpp        308m         31Mi
        service2-958786d58-dkk6r         520m         17Mi
        service3-6ddd8b8f64-rq4x6        174m         10Mi
        service4-9bb5bd9fd-dgk59         270m         9Mi
        ubuntu-client-76886f6bbd-9jd9b   6m           14Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > curl: (28) Connection timed out after 1002 milliseconds
        > command terminated with exit code 28
    [exp] Times: [19.011107, 19.650842, 20.048973, 19.283897, 19.675245, 19.872533, 20.018591, 19.645559]
    [exp] Throughput: 1017.7680223864692
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '357.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1050.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   658.27ms  354.58ms   2.03s    68.95%
        Req/Sec    95.13     50.51   262.00     63.54%
        Latency Distribution
        50%  623.16ms
        75%  864.87ms
        90%    1.10s
        99%    1.86s
        1950 requests in 3.03s, 302.78KB read
        Requests/sec:    642.51
        Transfer/sec:     99.76KB
        [run.sh] Speed is 642.51, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-76cf478f75-wn2hn        1463m        68Mi
        service1-7755b7b4b5-rprrq        1347m        47Mi
        service2-6fc48d9cd4-rsdcs        1143m        25Mi
        service3-769fd8d48-b6c5p         828m         11Mi
        service4-7bfcf7775d-dv7ph        614m         10Mi
        ubuntu-client-76886f6bbd-tcnk2   30m          23Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   722.76ms  712.58ms   5.69s    88.26%
        Req/Sec    97.72     51.51   370.00     68.67%
        Latency Distribution
        50%  517.81ms
        75%  965.99ms
        90%    1.54s
        99%    3.48s
        20000 requests in 46.00s, 3.03MB read
        Requests/sec:    434.78
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 26.617537
        stop time: 26.214755
        stop time: 26.801513
        stop time: 26.605472
        stop time: 26.218060
        stop time: 26.980121
        stop time: 26.142056
        stop time: 27.050005
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.617537, 26.214755, 26.801513, 26.605472, 26.21806, 26.980121, 26.142056, 27.050005]
    [exp] Throughput: 752.4825374787214
[test.py] Finished running 5th optmization experiment: groundtruth->1017.7680223864692, slowdown->752.4825374787214, predicted->1028.9994754482236, err->1.1035376249510045
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000636', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   506.50ms  443.21ms   2.61s    80.79%
        Req/Sec   134.18     56.06   320.00     75.52%
        Latency Distribution
        50%  326.17ms
        75%  802.69ms
        90%    1.06s
        99%    1.92s
        2589 requests in 3.03s, 402.00KB read
        Requests/sec:    854.23
        Transfer/sec:    132.64KB
        [run.sh] Speed is 854.23, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   542.09ms  657.11ms   5.05s    86.59%
        Req/Sec   130.08     63.84   666.00     75.31%
        Latency Distribution
        50%  248.61ms
        75%  774.87ms
        90%    1.43s
        99%    3.02s
        20001 requests in 35.00s, 3.03MB read
        Requests/sec:    571.45
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 19.457868
        stop time: 18.999067
        stop time: 19.234909
        stop time: 19.567549
        stop time: 18.974253
        stop time: 19.992049
        stop time: 20.114847
        stop time: 19.726762
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.457868, 18.999067, 19.234909, 19.567549, 18.974253, 19.992049, 20.114847, 19.726762]
    [exp] Throughput: 1025.1987181120269
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '286.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '841.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   721.88ms  623.44ms   2.98s    78.86%
        Req/Sec   112.54     59.55   270.00     64.67%
        Latency Distribution
        50%  518.00ms
        75%    1.06s
        90%    1.63s
        99%    2.70s
        1981 requests in 3.02s, 307.60KB read
        Socket errors: connect 0, read 0, write 0, timeout 1
        Requests/sec:    655.09
        Transfer/sec:    101.72KB
        [run.sh] Speed is 655.09, duration is 45
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d45s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f758f58-gnhvl          422m         63Mi
        service1-7755b7b4b5-xzxw8        170m         54Mi
        service2-df5dc84c7-dxw65         388m         26Mi
        service3-ff5f5bd54-zdlgq         277m         14Mi
        service4-69f57699c6-zrcs5        203m         10Mi
        ubuntu-client-76886f6bbd-n44br   8m           13Mi
        Running 45s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   687.85ms  733.90ms   6.12s    87.89%
        Req/Sec   105.65     53.03   340.00     68.53%
        Latency Distribution
        50%  446.29ms
        75%  905.16ms
        90%    1.63s
        99%    3.47s
        20000 requests in 45.00s, 3.03MB read
        Requests/sec:    444.44
        Transfer/sec:     69.01KB
        ------------------------------
        stop time: 24.242528
        stop time: 24.595252
        stop time: 24.884209
        stop time: 25.540784
        stop time: 25.227601
        stop time: 25.318843
        stop time: 25.143881
        stop time: 25.517529
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.242528, 24.595252, 24.884209, 25.540784, 25.227601, 25.318843, 25.143881, 25.517529]
    [exp] Throughput: 798.1219113960271
[test.py] Finished running 6th optmization experiment: groundtruth->1025.1987181120269, slowdown->798.1219113960271, predicted->1034.2922504586522, err->0.8870019232341326
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000742', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   480.62ms  428.93ms   2.59s    74.61%
        Req/Sec   143.33     58.49   292.00     70.31%
        Latency Distribution
        50%  325.58ms
        75%  773.02ms
        90%    1.06s
        99%    1.61s
        2799 requests in 3.02s, 434.61KB read
        Requests/sec:    925.53
        Transfer/sec:    143.71KB
        [run.sh] Speed is 925.53, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   508.68ms  391.56ms   2.98s    73.78%
        Req/Sec   129.77     67.17   454.00     66.71%
        Latency Distribution
        50%  409.75ms
        75%  727.47ms
        90%    1.00s
        99%    1.89s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.381419
        stop time: 19.693635
        stop time: 19.722905
        stop time: 19.994450
        stop time: 19.605312
        stop time: 19.788485
        stop time: 19.366903
        stop time: 19.833976
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-dmr8f        1940m        73Mi
        service1-7755b7b4b5-kkng2        1369m        54Mi
        service2-958786d58-8wl4d         1566m        23Mi
        service3-6ddd8b8f64-8chgw        760m         15Mi
        service4-9bb5bd9fd-hqjnn         810m         13Mi
        ubuntu-client-76886f6bbd-5tflz   38m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.381419, 19.693635, 19.722905, 19.99445, 19.605312, 19.788485, 19.366903, 19.833976]
    [exp] Throughput: 1016.6018387086843
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '215.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '632.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   667.99ms  583.10ms   2.99s    81.81%
        Req/Sec   107.45     54.75   252.00     68.66%
        Latency Distribution
        50%  534.40ms
        75%  887.59ms
        90%    1.50s
        99%    2.85s
        2219 requests in 3.03s, 344.55KB read
        Requests/sec:    732.36
        Transfer/sec:    113.72KB
        [run.sh] Speed is 732.36, duration is 40
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d40s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 40s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   604.62ms  493.61ms   3.79s    77.93%
        Req/Sec   107.40     55.13   323.00     67.34%
        Latency Distribution
        50%  508.03ms
        75%  797.02ms
        90%    1.23s
        99%    2.36s
        20000 requests in 40.00s, 3.03MB read
        Requests/sec:    500.00
        Transfer/sec:     77.64KB
        ------------------------------
        stop time: 23.139190
        stop time: 24.039335
        stop time: 24.065736
        stop time: 23.581719
        stop time: 24.031520
        stop time: 23.433137
        stop time: 22.859197
        stop time: 23.934238
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [23.13919, 24.039335, 24.065736, 23.581719, 24.03152, 23.433137, 22.859197, 23.934238]
    [exp] Throughput: 846.184442230544
[test.py] Finished running 7th optmization experiment: groundtruth->1016.6018387086843, slowdown->846.184442230544, predicted->1034.4484256341495, err->1.7555139333738006
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000848', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   458.03ms  434.91ms   2.28s    82.55%
        Req/Sec   124.53     59.29   292.00     65.00%
        Latency Distribution
        50%  268.31ms
        75%  712.26ms
        90%    1.11s
        99%    1.70s
        2787 requests in 3.03s, 432.75KB read
        Requests/sec:    920.50
        Transfer/sec:    142.93KB
        [run.sh] Speed is 920.50, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   559.77ms  648.14ms   5.15s    86.84%
        Req/Sec   130.74     60.50   490.00     70.49%
        Latency Distribution
        50%  302.97ms
        75%  701.50ms
        90%    1.47s
        99%    2.94s
        20001 requests in 32.00s, 3.03MB read
        Requests/sec:    625.03
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.266007
        stop time: 18.546429
        stop time: 18.653775
        stop time: 19.193060
        stop time: 19.597361
        stop time: 19.826548
        stop time: 19.839647
        stop time: 19.899027
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-h88md        663m         59Mi
        service1-7755b7b4b5-5jl9h        481m         40Mi
        service2-958786d58-9vr6n         506m         13Mi
        service3-6ddd8b8f64-nx7ww        377m         8Mi
        service4-9bb5bd9fd-m9vpp         272m         8Mi
        ubuntu-client-76886f6bbd-8bqg2   12m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.266007, 18.546429, 18.653775, 19.19306, 19.597361, 19.826548, 19.839647, 19.899027]
    [exp] Throughput: 1033.4458338162003
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '144.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '423.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   584.43ms  407.12ms   2.28s    75.59%
        Req/Sec   106.03     52.57   282.00     67.92%
        Latency Distribution
        50%  472.10ms
        75%  697.16ms
        90%    1.26s
        99%    1.72s
        2402 requests in 3.03s, 372.97KB read
        Requests/sec:    793.25
        Transfer/sec:    123.17KB
        [run.sh] Speed is 793.25, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-859d87f949-zgqtr        1714m        56Mi
        service1-7755b7b4b5-6bzcn        1579m        31Mi
        service2-5458f69958-gwtmb        1359m        18Mi
        service3-7cd879df74-l6sqh        1039m        10Mi
        service4-55f47fc56d-khvhp        679m         10Mi
        ubuntu-client-76886f6bbd-7mlqm   35m          22Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   713.79ms  948.63ms   6.71s    88.38%
        Req/Sec   116.78     53.40   400.00     68.37%
        Latency Distribution
        50%  345.25ms
        75%  784.53ms
        90%    1.86s
        99%    4.84s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 21.509357
        stop time: 22.451499
        stop time: 21.709538
        stop time: 22.675729
        stop time: 22.383800
        stop time: 22.712436
        stop time: 22.170499
        stop time: 22.026014
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.509357, 22.451499, 21.709538, 22.675729, 22.3838, 22.712436, 22.170499, 22.026014]
    [exp] Throughput: 900.7037603796538
[test.py] Finished running 8th optmization experiment: groundtruth->1033.4458338162003, slowdown->900.7037603796538, predicted->1034.9971343516843, err->0.1501095156342622
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000954', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   469.92ms  285.86ms   1.92s    70.12%
        Req/Sec   125.92     64.46   340.00     70.83%
        Latency Distribution
        50%  430.36ms
        75%  630.53ms
        90%  820.81ms
        99%    1.45s
        2737 requests in 3.03s, 424.98KB read
        Requests/sec:    902.21
        Transfer/sec:    140.09KB
        [run.sh] Speed is 902.21, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   502.32ms  462.23ms   3.81s    82.99%
        Req/Sec   130.25     62.50   383.00     69.39%
        Latency Distribution
        50%  348.21ms
        75%  705.83ms
        90%    1.14s
        99%    2.10s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 18.629734
        stop time: 20.061092
        stop time: 19.047215
        stop time: 20.009719
        stop time: 19.638015
        stop time: 19.503700
        stop time: 19.866984
        stop time: 19.477078
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-zcwml        3m           3Mi
        service1-7755b7b4b5-bq5ft        3m           3Mi
        ubuntu-client-76886f6bbd-6z4j9   6m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.629734, 20.061092, 19.047215, 20.009719, 19.638015, 19.5037, 19.866984, 19.477078]
    [exp] Throughput: 1024.1079032858356
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '73.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '214.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   569.53ms  346.36ms   2.03s    69.71%
        Req/Sec   110.39     61.83   313.00     68.84%
        Latency Distribution
        50%  521.27ms
        75%  729.68ms
        90%    1.03s
        99%    1.49s
        2388 requests in 3.03s, 370.79KB read
        Requests/sec:    789.30
        Transfer/sec:    122.56KB
        [run.sh] Speed is 789.30, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-765df4d958-8qpcr        1322m        74Mi
        service1-7755b7b4b5-nw9h9        125m         49Mi
        service2-74457b7b66-tm7pt        980m         20Mi
        service3-657f66b697-j5gbg        309m         10Mi
        service4-648ccfbd5f-985x9        454m         10Mi
        ubuntu-client-76886f6bbd-zcq4v   36m          18Mi
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   553.19ms  475.48ms   3.70s    84.94%
        Req/Sec   121.71     57.83   333.00     65.34%
        Latency Distribution
        50%  429.90ms
        75%  728.45ms
        90%    1.09s
        99%    2.47s
        20000 requests in 38.00s, 3.03MB read
        Requests/sec:    526.31
        Transfer/sec:     81.72KB
        ------------------------------
        stop time: 20.869957
        stop time: 21.000987
        stop time: 21.308050
        stop time: 21.192012
        stop time: 20.537489
        stop time: 21.300795
        stop time: 21.040534
        stop time: 21.142054
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.869957, 21.000987, 21.30805, 21.192012, 20.537489, 21.300795, 21.040534, 21.142054]
    [exp] Throughput: 950.1645916675388
[test.py] Finished running 9th optmization experiment: groundtruth->1024.1079032858356, slowdown->950.1645916675388, predicted->1021.0202153962115, err->-0.3015002500925276
[test.py] Baseline throughput:  1016.4218707762905
[test.py] Groundtruth:  [1026.6745117432795, 1026.1077336418773, 1019.6667133950183, 1030.301502022469, 1028.535231477961, 1017.7680223864692, 1025.1987181120269, 1016.6018387086843, 1033.4458338162003, 1024.1079032858356]
[test.py] Slowdown:  [587.4872479008227, 615.6598982364211, 611.7579448774892, 681.367073262389, 716.8020350296496, 752.4825374787214, 798.1219113960271, 846.184442230544, 900.7037603796538, 950.1645916675388]
[test.py] Predicted:  [1010.1541643621212, 1017.2146218524036, 939.4463419955765, 1032.5447855491277, 1034.1811076053807, 1028.9994754482236, 1034.2922504586522, 1034.4484256341495, 1034.9971343516843, 1021.0202153962115]
[test.py] Error percentage:  [-1.6091124491935622, -0.8666840233149882, -7.867312950948949, 0.2177307829072439, 0.5489239410211467, 1.1035376249510045, 0.8870019232341326, 1.7555139333738006, 0.1501095156342622, -0.3015002500925276]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 4...
[test.py] Actual processing time range: [0, 106, 212, 318, 424, 530, 636, 742, 848, 954]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   541.00ms  341.75ms   2.07s    67.75%
        Req/Sec   114.86     67.63   363.00     68.78%
        Latency Distribution
        50%  491.78ms
        75%  742.46ms
        90%  992.31ms
        99%    1.63s
        2569 requests in 3.03s, 398.90KB read
        Requests/sec:    847.65
        Transfer/sec:    131.62KB
        [run.sh] Speed is 847.65, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-bsm67        223m         68Mi
        service1-7755b7b4b5-zh267        1622m        55Mi
        service2-958786d58-mchff         251m         26Mi
        service3-6ddd8b8f64-5lb4s        693m         14Mi
        service4-9bb5bd9fd-jzvzk         221m         11Mi
        ubuntu-client-76886f6bbd-qlt85   1m           21Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   543.22ms  554.95ms   4.60s    87.80%
        Req/Sec   128.87     56.80   440.00     69.42%
        Latency Distribution
        50%  351.51ms
        75%  658.16ms
        90%    1.26s
        99%    2.66s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 19.176671
        stop time: 19.147539
        stop time: 19.192193
        stop time: 19.957547
        stop time: 20.042983
        stop time: 19.935305
        stop time: 19.661203
        stop time: 20.010874
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.176671, 19.147539, 19.192193, 19.957547, 20.042983, 19.935305, 19.661203, 20.010874]
    [exp] Throughput: 1018.3019731860088
[test.py] Baseline throughput: 1018.3019731860088
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   505.25ms  462.17ms   2.35s    79.76%
        Req/Sec   121.50     67.26   353.00     67.67%
        Latency Distribution
        50%  338.45ms
        75%  830.88ms
        90%    1.08s
        99%    1.95s
        2845 requests in 3.03s, 441.75KB read
        Requests/sec:    939.09
        Transfer/sec:    145.82KB
        [run.sh] Speed is 939.09, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   563.42ms  637.18ms   4.53s    87.10%
        Req/Sec   129.69     57.90   400.00     69.96%
        Latency Distribution
        50%  300.81ms
        75%  785.97ms
        90%    1.44s
        99%    2.86s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 19.377234
        stop time: 19.011820
        stop time: 19.731093
        stop time: 19.188296
        stop time: 19.949271
        stop time: 19.809117
        stop time: 19.941521
        stop time: 19.750754
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-89ptr        660m         59Mi
        service1-7755b7b4b5-zr9f5        3m           27Mi
        service2-958786d58-vjmbx         520m         15Mi
        service3-6ddd8b8f64-8xfnl        68m          9Mi
        service4-9bb5bd9fd-vn2sz         279m         9Mi
        ubuntu-client-76886f6bbd-2tbhb   19m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.377234, 19.01182, 19.731093, 19.188296, 19.949271, 19.809117, 19.941521, 19.750754]
    [exp] Throughput: 1020.6743587833423
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '712.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '2094.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1424.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   613.50ms  509.77ms   2.68s    70.56%
        Req/Sec    84.19     43.06   191.00     62.82%
        Latency Distribution
        50%  516.44ms
        75%  925.52ms
        90%    1.30s
        99%    2.32s
        1532 requests in 3.03s, 237.88KB read
        Requests/sec:    504.92
        Transfer/sec:     78.40KB
        [run.sh] Speed is 504.92, duration is 59
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-85bdf5784-cmk82         828m         73Mi
        service1-7755b7b4b5-x5mhq        944m         65Mi
        service2-9bc5fc9b-n7rv6          931m         34Mi
        service3-689fcdc4df-sz5kw        696m         19Mi
        service4-5f56f879dc-m9d7k        482m         11Mi
        ubuntu-client-76886f6bbd-s9xqc   22m          22Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   858.97ms  617.57ms   4.44s    70.86%
        Req/Sec    78.81     51.48   363.00     71.38%
        Latency Distribution
        50%  724.95ms
        75%    1.19s
        90%    1.72s
        99%    2.78s
        20000 requests in 0.98m, 3.03MB read
        Requests/sec:    338.98
        Transfer/sec:     52.63KB
        ------------------------------
        stop time: 33.651580
        stop time: 33.490142
        stop time: 33.252239
        stop time: 33.650610
        stop time: 34.155432
        stop time: 34.386720
        stop time: 33.934502
        stop time: 34.457402
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [33.65158, 33.490142, 33.252239, 33.65061, 34.155432, 34.38672, 33.934502, 34.457402]
    [exp] Throughput: 590.4524713677879
[test.py] Finished running 0th optmization experiment: groundtruth->1020.6743587833423, slowdown->590.4524713677879, predicted->1018.9528088246151, err->-0.16866789529026027
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000106', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   493.95ms  296.05ms   1.80s    63.57%
        Req/Sec   138.93     73.14   350.00     72.38%
        Latency Distribution
        50%  483.90ms
        75%  641.08ms
        90%  879.92ms
        99%    1.30s
        2791 requests in 3.03s, 433.37KB read
        Requests/sec:    920.88
        Transfer/sec:    142.99KB
        [run.sh] Speed is 920.88, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   544.11ms  555.41ms   3.60s    87.23%
        Req/Sec   128.96     65.98   470.00     68.34%
        Latency Distribution
        50%  352.15ms
        75%  730.65ms
        90%    1.28s
        99%    2.64s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.880749
        stop time: 19.813570
        stop time: 19.553094
        stop time: 19.224111
        stop time: 19.915039
        stop time: 19.541555
        stop time: 19.874066
        stop time: 19.870407
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pnlzl        1478m        67Mi
        service1-7755b7b4b5-nqxf7        568m         39Mi
        service2-958786d58-hmjvk         1099m        22Mi
        service3-6ddd8b8f64-6vhx6        1180m        12Mi
        service4-9bb5bd9fd-8lr2x         831m         11Mi
        ubuntu-client-76886f6bbd-2xzkg   34m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.880749, 19.81357, 19.553094, 19.224111, 19.915039, 19.541555, 19.874066, 19.870407]
    [exp] Throughput: 1014.761024634903
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '641.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1885.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1282.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   867.85ms  537.00ms   2.67s    72.46%
        Req/Sec    73.59     55.97   270.00     68.09%
        Latency Distribution
        50%  788.65ms
        75%    1.09s
        90%    1.55s
        99%    2.42s
        1387 requests in 3.02s, 215.36KB read
        Requests/sec:    458.91
        Transfer/sec:     71.26KB
        [run.sh] Speed is 458.91, duration is 65
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d65s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   867.20ms  870.12ms   8.74s    88.40%
        Req/Sec    80.74     46.90   410.00     66.61%
        Latency Distribution
        50%  613.30ms
        75%    1.06s
        90%    1.90s
        99%    4.29s
        20000 requests in 1.08m, 3.03MB read
        Requests/sec:    307.69
        Transfer/sec:     47.78KB
        ------------------------------
        stop time: 32.238701
        stop time: 31.877094
        stop time: 32.535656
        stop time: 32.339923
        stop time: 32.976997
        stop time: 32.216990
        stop time: 32.317389
        stop time: 32.656453
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [32.238701, 31.877094, 32.535656, 32.339923, 32.976997, 32.21699, 32.317389, 32.656453]
    [exp] Throughput: 617.381123833754
[test.py] Finished running 1th optmization experiment: groundtruth->1014.761024634903, slowdown->617.381123833754, predicted->1021.921943800795, err->0.7056754242673424
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000212', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   535.96ms  382.35ms   1.81s    64.02%
        Req/Sec   138.05     80.21   393.00     67.02%
        Latency Distribution
        50%  471.51ms
        75%  797.47ms
        90%    1.04s
        99%    1.63s
        2649 requests in 3.03s, 411.32KB read
        Requests/sec:    873.14
        Transfer/sec:    135.58KB
        [run.sh] Speed is 873.14, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   512.06ms  490.17ms   3.37s    86.13%
        Req/Sec   128.93     67.31   616.00     68.76%
        Latency Distribution
        50%  357.69ms
        75%  699.61ms
        90%    1.15s
        99%    2.31s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.868337
        stop time: 19.585221
        stop time: 19.554353
        stop time: 19.912719
        stop time: 19.605805
        stop time: 19.747583
        stop time: 19.294933
        stop time: 20.075423
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.868337, 19.585221, 19.554353, 19.912719, 19.605805, 19.747583, 19.294933, 20.075423]
    [exp] Throughput: 1014.9426582137335
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '570.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1676.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   776.79ms  559.89ms   2.84s    71.76%
        Req/Sec    71.65     52.64   240.00     70.47%
        Latency Distribution
        50%  610.76ms
        75%    1.06s
        90%    1.65s
        99%    2.35s
        1537 requests in 3.03s, 238.66KB read
        Requests/sec:    507.60
        Transfer/sec:     78.82KB
        [run.sh] Speed is 507.60, duration is 59
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-d98b4cfdb-hv2mj         417m         49Mi
        service1-7755b7b4b5-58zds        399m         45Mi
        service2-5569d86cb9-js2sw        336m         26Mi
        service3-84456c486d-tlxn9        215m         9Mi
        service4-79fb8b8978-7vkt8        169m         11Mi
        ubuntu-client-76886f6bbd-nftqz   20m          0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   808.90ms  747.41ms   7.17s    85.34%
        Req/Sec    87.31     49.74   515.00     71.41%
        Latency Distribution
        50%  588.56ms
        75%    1.12s
        90%    1.70s
        99%    3.42s
        20001 requests in 0.98m, 3.03MB read
        Requests/sec:    339.00
        Transfer/sec:     52.64KB
        ------------------------------
        stop time: 29.546938
        stop time: 30.508269
        stop time: 30.804564
        stop time: 31.297064
        stop time: 30.789819
        stop time: 31.115204
        stop time: 31.390781
        stop time: 31.480346
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [29.546938, 30.508269, 30.804564, 31.297064, 30.789819, 31.115204, 31.390781, 31.480346]
    [exp] Throughput: 647.9490781679086
[test.py] Finished running 2th optmization experiment: groundtruth->1014.9426582137335, slowdown->647.9490781679086, predicted->1027.586107814219, err->1.2457304359181902
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000318', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   503.12ms  438.17ms   2.30s    78.12%
        Req/Sec   124.52     48.84   272.00     68.42%
        Latency Distribution
        50%  350.58ms
        75%  724.98ms
        90%    1.21s
        99%    1.79s
        2663 requests in 3.03s, 413.49KB read
        Requests/sec:    879.61
        Transfer/sec:    136.58KB
        [run.sh] Speed is 879.61, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   602.13ms  778.78ms   6.51s    86.96%
        Req/Sec   129.99     62.21   410.00     72.54%
        Latency Distribution
        50%  284.85ms
        75%  711.17ms
        90%    1.67s
        99%    3.61s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.615339
        stop time: 19.533517
        stop time: 18.330434
        stop time: 19.731495
        stop time: 19.729793
        stop time: 19.382662
        stop time: 19.899690
        stop time: 19.366863
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-ldmmb        632m         55Mi
        service1-7755b7b4b5-x7jbb        299m         57Mi
        service2-958786d58-q5jnf         478m         27Mi
        service3-6ddd8b8f64-q8787        289m         10Mi
        service4-9bb5bd9fd-lcsxv         264m         9Mi
        ubuntu-client-76886f6bbd-r56bx   23m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.615339, 19.533517, 18.330434, 19.731495, 19.729793, 19.382662, 19.89969, 19.366863]
    [exp] Throughput: 1028.3450920202715
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '499.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1468.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '998.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   865.18ms  553.25ms   2.55s    69.27%
        Req/Sec    84.68     46.10   230.00     69.59%
        Latency Distribution
        50%  887.80ms
        75%    1.17s
        90%    1.52s
        99%    2.37s
        1548 requests in 3.03s, 240.36KB read
        Requests/sec:    510.64
        Transfer/sec:     79.29KB
        [run.sh] Speed is 510.64, duration is 58
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d58s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-766754b87b-pstjh        1345m        73Mi
        service1-7755b7b4b5-bs2md        1212m        65Mi
        service2-b6f7bd475-pnlk5         1031m        39Mi
        service3-84f6c86b-sdtgw          796m         15Mi
        service4-68bd74b5d4-cmw4s        551m         13Mi
        ubuntu-client-76886f6bbd-cg46l   28m          22Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   755.48ms  581.40ms   6.18s    78.32%
        Req/Sec    89.24     52.90   373.00     68.11%
        Latency Distribution
        50%  628.31ms
        75%  987.69ms
        90%    1.42s
        99%    2.79s
        20000 requests in 0.97m, 3.03MB read
        Requests/sec:    344.83
        Transfer/sec:     53.54KB
        ------------------------------
        stop time: 30.021239
        stop time: 29.290835
        stop time: 30.017709
        stop time: 28.998543
        stop time: 29.628871
        stop time: 29.913982
        stop time: 29.619635
        stop time: 29.616064
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [30.021239, 29.290835, 30.017709, 28.998543, 29.628871, 29.913982, 29.619635, 29.616064]
    [exp] Throughput: 674.8011755272659
[test.py] Finished running 3th optmization experiment: groundtruth->1028.3450920202715, slowdown->674.8011755272659, predicted->1017.5410984531684, err->-1.0506194516743177
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000424', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   488.83ms  279.04ms   1.75s    63.66%
        Req/Sec   127.80     69.34   310.00     66.30%
        Latency Distribution
        50%  491.78ms
        75%  663.45ms
        90%  836.51ms
        99%    1.21s
        2546 requests in 3.03s, 395.33KB read
        Requests/sec:    839.06
        Transfer/sec:    130.28KB
        [run.sh] Speed is 839.06, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-69sgg        1940m        71Mi
        service1-7755b7b4b5-ptr48        892m         43Mi
        service2-958786d58-6t95p         1533m        18Mi
        service3-6ddd8b8f64-59gqp        1196m        12Mi
        service4-9bb5bd9fd-s2t79         823m         12Mi
        ubuntu-client-76886f6bbd-h6g8j   39m          21Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   530.18ms  573.36ms   4.96s    85.62%
        Req/Sec   128.60     60.32   424.00     73.47%
        Latency Distribution
        50%  320.64ms
        75%  577.31ms
        90%    1.38s
        99%    2.60s
        20001 requests in 35.00s, 3.03MB read
        Requests/sec:    571.45
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 19.180691
        stop time: 20.075694
        stop time: 19.874862
        stop time: 18.913429
        stop time: 19.844900
        stop time: 19.859544
        stop time: 19.728496
        stop time: 19.966821
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.180691, 20.075694, 19.874862, 18.913429, 19.8449, 19.859544, 19.728496, 19.966821]
    [exp] Throughput: 1016.2315229975385
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '428.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1259.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '856.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   640.14ms  486.23ms   2.10s    63.10%
        Req/Sec   106.65     45.22   232.00     63.10%
        Latency Distribution
        50%  510.59ms
        75%    1.01s
        90%    1.31s
        99%    1.75s
        1964 requests in 3.03s, 304.96KB read
        Requests/sec:    649.11
        Transfer/sec:    100.79KB
        [run.sh] Speed is 649.11, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-75578d5c44-8khx8   3m           3Mi
        service1-7755b7b4b5-kx86g   3m           3Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   751.08ms  666.26ms   4.95s    82.40%
        Req/Sec    93.48     52.48   340.00     63.92%
        Latency Distribution
        50%  583.71ms
        75%  987.95ms
        90%    1.62s
        99%    3.06s
        20001 requests in 46.00s, 3.03MB read
        Requests/sec:    434.80
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 28.131884
        stop time: 28.174938
        stop time: 28.369611
        stop time: 28.290076
        stop time: 28.418816
        stop time: 28.185427
        stop time: 28.103278
        stop time: 27.706057
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [28.131884, 28.174938, 28.369611, 28.290076, 28.418816, 28.185427, 28.103278, 27.706057]
    [exp] Throughput: 709.911874335198
[test.py] Finished running 4th optmization experiment: groundtruth->1016.2315229975385, slowdown->709.911874335198, predicted->1019.8994168820701, err->0.3609309297661402
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00053', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   529.01ms  410.96ms   2.14s    70.09%
        Req/Sec   137.01     63.64   310.00     67.02%
        Latency Distribution
        50%  422.43ms
        75%  809.83ms
        90%    1.07s
        99%    1.95s
        2635 requests in 3.03s, 409.15KB read
        Requests/sec:    868.31
        Transfer/sec:    134.82KB
        [run.sh] Speed is 868.31, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   569.61ms  675.05ms   6.78s    87.61%
        Req/Sec   129.38     61.62   420.00     73.68%
        Latency Distribution
        50%  296.41ms
        75%  755.59ms
        90%    1.44s
        99%    3.01s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 18.672966
        stop time: 19.006258
        stop time: 19.732714
        stop time: 19.797605
        stop time: 19.306144
        stop time: 19.908171
        stop time: 19.872805
        stop time: 19.937862
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-9cjwh        621m         66Mi
        service1-7755b7b4b5-h8vpz        369m         59Mi
        service2-958786d58-kbnds         487m         28Mi
        service3-6ddd8b8f64-qfqw6        303m         15Mi
        service4-9bb5bd9fd-9qtj9         247m         12Mi
        ubuntu-client-76886f6bbd-cd89j   21m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.672966, 19.006258, 19.732714, 19.797605, 19.306144, 19.908171, 19.872805, 19.937862]
    [exp] Throughput: 1024.1014270053306
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '357.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1050.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '714.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   633.34ms  399.56ms   2.40s    65.68%
        Req/Sec    87.57     55.06   282.00     62.26%
        Latency Distribution
        50%  553.25ms
        75%  888.02ms
        90%    1.20s
        99%    1.68s
        1974 requests in 3.03s, 306.51KB read
        Requests/sec:    651.65
        Transfer/sec:    101.18KB
        [run.sh] Speed is 651.65, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-76cf478f75-72qvm        1456m        70Mi
        service1-7755b7b4b5-9x8cq        1326m        48Mi
        service2-6fc48d9cd4-5xq54        1122m        21Mi
        service3-769fd8d48-qsr4x         880m         15Mi
        service4-7bfcf7775d-n7z47        606m         10Mi
        ubuntu-client-76886f6bbd-jph6g   29m          23Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   728.67ms  734.82ms   6.37s    88.51%
        Req/Sec    97.13     53.00   414.00     69.30%
        Latency Distribution
        50%  513.51ms
        75%  943.56ms
        90%    1.56s
        99%    3.56s
        20000 requests in 46.00s, 3.03MB read
        Requests/sec:    434.78
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 26.410494
        stop time: 26.497083
        stop time: 26.407283
        stop time: 26.784011
        stop time: 27.137727
        stop time: 26.982979
        stop time: 26.718006
        stop time: 26.032976
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.410494, 26.497083, 26.407283, 26.784011, 27.137727, 26.982979, 26.718006, 26.032976]
    [exp] Throughput: 751.2775509970841
[test.py] Finished running 5th optmization experiment: groundtruth->1024.1014270053306, slowdown->751.2775509970841, predicted->1026.7474974489658, err->0.2583797242986734
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000636', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   451.84ms  396.06ms   2.06s    79.09%
        Req/Sec   118.28     61.04   270.00     64.19%
        Latency Distribution
        50%  292.83ms
        75%  695.17ms
        90%    1.01s
        99%    1.71s
        2725 requests in 3.03s, 423.12KB read
        Requests/sec:    898.44
        Transfer/sec:    139.50KB
        [run.sh] Speed is 898.44, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   546.58ms  577.55ms   3.97s    86.27%
        Req/Sec   129.92     61.35   440.00     74.79%
        Latency Distribution
        50%  332.45ms
        75%  677.20ms
        90%    1.35s
        99%    2.62s
        20001 requests in 33.00s, 3.03MB read
        Requests/sec:    606.09
        Transfer/sec:     94.11KB
        ------------------------------
        stop time: 18.868432
        stop time: 19.527622
        stop time: 19.278327
        stop time: 19.785425
        stop time: 19.907928
        stop time: 19.736224
        stop time: 19.985378
        stop time: 19.363226
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-mcp5c        1m           72Mi
        service1-7755b7b4b5-q84l2        759m         39Mi
        service2-958786d58-z9nb9         1m           19Mi
        service3-6ddd8b8f64-jg8mx        389m         10Mi
        service4-9bb5bd9fd-wfmlv         45m          10Mi
        ubuntu-client-76886f6bbd-xpqs5   8m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.868432, 19.527622, 19.278327, 19.785425, 19.907928, 19.736224, 19.985378, 19.363226]
    [exp] Throughput: 1022.6742084287504
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '286.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '841.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '572.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   682.53ms  428.70ms   2.49s    67.08%
        Req/Sec   111.03     56.29   242.00     63.95%
        Latency Distribution
        50%  645.20ms
        75%  942.38ms
        90%    1.27s
        99%    1.84s
        2001 requests in 3.02s, 310.70KB read
        Requests/sec:    661.96
        Transfer/sec:    102.78KB
        [run.sh] Speed is 661.96, duration is 45
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d45s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f758f58-4vmh9          415m         56Mi
        service1-7755b7b4b5-6h5tr        270m         59Mi
        service2-df5dc84c7-68bvp         392m         31Mi
        service3-ff5f5bd54-w5rfl         300m         15Mi
        service4-69f57699c6-xzvqr        200m         12Mi
        ubuntu-client-76886f6bbd-gltkz   16m          0Mi
        Running 45s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   670.27ms  655.05ms   5.13s    87.10%
        Req/Sec   104.13     56.33   444.00     70.80%
        Latency Distribution
        50%  464.68ms
        75%  846.36ms
        90%    1.52s
        99%    3.18s
        20000 requests in 45.00s, 3.03MB read
        Requests/sec:    444.44
        Transfer/sec:     69.01KB
        ------------------------------
        stop time: 24.456838
        stop time: 25.572067
        stop time: 25.479023
        stop time: 25.688006
        stop time: 24.327138
        stop time: 24.984689
        stop time: 25.417964
        stop time: 24.250646
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.456838, 25.572067, 25.479023, 25.688006, 24.327138, 24.984689, 25.417964, 24.250646]
    [exp] Throughput: 799.2951375864436
[test.py] Finished running 6th optmization experiment: groundtruth->1022.6742084287504, slowdown->799.2951375864436, predicted->1036.2633963679186, err->1.3287895428639835
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000742', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   446.00ms  325.16ms   1.65s    65.60%
        Req/Sec   126.12     71.55   350.00     69.16%
        Latency Distribution
        50%  381.94ms
        75%  635.62ms
        90%  897.11ms
        99%    1.36s
        2798 requests in 3.03s, 434.46KB read
        Requests/sec:    922.12
        Transfer/sec:    143.18KB
        [run.sh] Speed is 922.12, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   554.19ms  607.29ms   4.83s    87.80%
        Req/Sec   128.13     61.75   686.00     68.81%
        Latency Distribution
        50%  329.14ms
        75%  713.43ms
        90%    1.34s
        99%    2.86s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.286144
        stop time: 19.998828
        stop time: 19.729392
        stop time: 20.141000
        stop time: 19.711418
        stop time: 19.956125
        stop time: 19.649591
        stop time: 19.307291
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-sncff        123m         71Mi
        service1-7755b7b4b5-82phl        308m         43Mi
        service2-958786d58-szxz5         1454m        16Mi
        service3-6ddd8b8f64-rz65v        584m         10Mi
        service4-9bb5bd9fd-kkx9d         618m         12Mi
        ubuntu-client-76886f6bbd-hscxm   27m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.286144, 19.998828, 19.729392, 20.141, 19.711418, 19.956125, 19.649591, 19.307291]
    [exp] Throughput: 1014.0715804861422
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '215.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '632.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '430.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   628.56ms  504.72ms   2.99s    76.25%
        Req/Sec   102.57     53.61   262.00     67.34%
        Latency Distribution
        50%  399.74ms
        75%  888.27ms
        90%    1.40s
        99%    2.26s
        2124 requests in 3.03s, 329.80KB read
        Requests/sec:    700.60
        Transfer/sec:    108.78KB
        [run.sh] Speed is 700.60, duration is 42
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 42s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   619.06ms  579.39ms   5.22s    85.13%
        Req/Sec   107.52     52.24   380.00     67.49%
        Latency Distribution
        50%  443.85ms
        75%  856.22ms
        90%    1.36s
        99%    2.74s
        20000 requests in 42.00s, 3.03MB read
        Requests/sec:    476.19
        Transfer/sec:     73.94KB
        ------------------------------
        stop time: 23.291857
        stop time: 22.505736
        stop time: 24.083876
        stop time: 23.363008
        stop time: 23.769973
        stop time: 24.103690
        stop time: 24.030036
        stop time: 23.427459
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [23.291857, 22.505736, 24.083876, 23.363008, 23.769973, 24.10369, 24.030036, 23.427459]
    [exp] Throughput: 848.465921909795
[test.py] Finished running 7th optmization experiment: groundtruth->1014.0715804861422, slowdown->848.465921909795, predicted->1037.8600783378085, err->2.345840107289289
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000848', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   505.84ms  317.01ms   2.24s    62.84%
        Req/Sec   124.51     72.07   303.00     61.54%
        Latency Distribution
        50%  470.30ms
        75%  725.10ms
        90%  940.35ms
        99%    1.35s
        2804 requests in 3.03s, 435.39KB read
        Requests/sec:    925.87
        Transfer/sec:    143.76KB
        [run.sh] Speed is 925.87, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   559.13ms  622.61ms   6.13s    86.32%
        Req/Sec   129.68     59.56   490.00     67.08%
        Latency Distribution
        50%  340.34ms
        75%  722.85ms
        90%    1.47s
        99%    2.63s
        20002 requests in 32.00s, 3.03MB read
        Requests/sec:    625.06
        Transfer/sec:     97.06KB
        ------------------------------
        stop time: 19.484017
        stop time: 18.761699
        stop time: 18.974508
        stop time: 19.934897
        stop time: 19.727026
        stop time: 19.818338
        stop time: 19.942651
        stop time: 19.730253
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service1-7755b7b4b5-h7qd9        3m           38Mi
        service3-6ddd8b8f64-vfjm5        3m           8Mi
        service4-9bb5bd9fd-nq25b         153m         8Mi
        ubuntu-client-76886f6bbd-mkpgj   6m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.484017, 18.761699, 18.974508, 19.934897, 19.727026, 19.818338, 19.942651, 19.730253]
    [exp] Throughput: 1023.1919959220171
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '144.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '423.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '288.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   547.77ms  336.22ms   2.03s    62.49%
        Req/Sec   109.75     65.34   323.00     71.57%
        Latency Distribution
        50%  488.99ms
        75%  811.72ms
        90%    1.03s
        99%    1.40s
        2280 requests in 3.04s, 354.02KB read
        Requests/sec:    750.90
        Transfer/sec:    116.59KB
        [run.sh] Speed is 750.90, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-859d87f949-pb26m        1181m        69Mi
        service1-7755b7b4b5-npgjj        1334m        50Mi
        service2-5458f69958-hksbz        751m         26Mi
        service3-7cd879df74-5qtg9        1028m        18Mi
        service4-55f47fc56d-zpbj5        729m         11Mi
        ubuntu-client-76886f6bbd-4qb4w   36m          20Mi
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   590.21ms  529.69ms   3.98s    83.99%
        Req/Sec   115.85     58.75   500.00     73.05%
        Latency Distribution
        50%  420.80ms
        75%  740.96ms
        90%    1.30s
        99%    2.47s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 22.259536
        stop time: 21.600527
        stop time: 22.258734
        stop time: 21.898527
        stop time: 22.857656
        stop time: 22.026396
        stop time: 22.752399
        stop time: 22.452011
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.259536, 21.600527, 22.258734, 21.898527, 22.857656, 22.026396, 22.752399, 22.452011]
    [exp] Throughput: 898.3425165087001
[test.py] Finished running 8th optmization experiment: groundtruth->1023.1919959220171, slowdown->898.3425165087001, predicted->1031.8805027688127, err->0.8491570381144551
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.000954', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   584.44ms  441.80ms   2.23s    73.50%
        Req/Sec   137.66     63.25   310.00     68.18%
        Latency Distribution
        50%  425.42ms
        75%  924.73ms
        90%    1.17s
        99%    2.01s
        2439 requests in 3.04s, 378.71KB read
        Requests/sec:    803.01
        Transfer/sec:    124.69KB
        [run.sh] Speed is 803.01, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-mmkwg        522m         69Mi
        service1-7755b7b4b5-xppp4        161m         56Mi
        service2-958786d58-2xchk         620m         26Mi
        service3-6ddd8b8f64-nwbdq        1m           12Mi
        service4-9bb5bd9fd-tjt67         1m           14Mi
        ubuntu-client-76886f6bbd-m5slv   0m           21Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   504.32ms  470.84ms   3.80s    86.16%
        Req/Sec   128.94     63.53   474.00     70.88%
        Latency Distribution
        50%  345.20ms
        75%  614.24ms
        90%    1.13s
        99%    2.23s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 19.238942
        stop time: 19.365139
        stop time: 19.676895
        stop time: 19.884611
        stop time: 19.330904
        stop time: 19.687607
        stop time: 19.646793
        stop time: 19.897735
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.238942, 19.365139, 19.676895, 19.884611, 19.330904, 19.687607, 19.646793, 19.897735]
    [exp] Throughput: 1020.8728557347272
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00165925', 'PROCESSING_TIME_SERVICE1': '0.00106301', 'PROCESSING_TIME_SERVICE2': '0.00412849', 'PROCESSING_TIME_SERVICE3': '0.00211515', 'PROCESSING_TIME_SERVICE4': '0.00143906', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '73.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '214.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '146.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   532.95ms  330.03ms   2.04s    69.78%
        Req/Sec   115.07     57.19   280.00     69.23%
        Latency Distribution
        50%  488.28ms
        75%  715.82ms
        90%  968.60ms
        99%    1.57s
        2430 requests in 3.03s, 377.31KB read
        Requests/sec:    802.38
        Transfer/sec:    124.59KB
        [run.sh] Speed is 802.38, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-765df4d958-v852k        317m         62Mi
        service1-7755b7b4b5-5xpg6        524m         43Mi
        service2-74457b7b66-xxsrh        23m          18Mi
        service3-657f66b697-xs5dh        353m         8Mi
        service4-648ccfbd5f-trwml        3m           8Mi
        ubuntu-client-76886f6bbd-4s8wq   19m          0Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   564.60ms  594.22ms   4.43s    88.33%
        Req/Sec   122.25     54.97   363.00     70.02%
        Latency Distribution
        50%  372.96ms
        75%  657.27ms
        90%    1.30s
        99%    2.93s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 20.128855
        stop time: 20.404907
        stop time: 21.064257
        stop time: 20.890101
        stop time: 21.183998
        stop time: 20.719578
        stop time: 20.374806
        stop time: 19.882960
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.128855, 20.404907, 21.064257, 20.890101, 21.183998, 20.719578, 20.374806, 19.88296]
    [exp] Throughput: 971.7614503957504
[test.py] Finished running 9th optmization experiment: groundtruth->1020.8728557347272, slowdown->971.7614503957504, predicted->1046.0005547725443, err->2.461393590461626
[test.py] Baseline throughput:  1018.3019731860088
[test.py] Groundtruth:  [1020.6743587833423, 1014.761024634903, 1014.9426582137335, 1028.3450920202715, 1016.2315229975385, 1024.1014270053306, 1022.6742084287504, 1014.0715804861422, 1023.1919959220171, 1020.8728557347272]
[test.py] Slowdown:  [590.4524713677879, 617.381123833754, 647.9490781679086, 674.8011755272659, 709.911874335198, 751.2775509970841, 799.2951375864436, 848.465921909795, 898.3425165087001, 971.7614503957504]
[test.py] Predicted:  [1018.9528088246151, 1021.921943800795, 1027.586107814219, 1017.5410984531684, 1019.8994168820701, 1026.7474974489658, 1036.2633963679186, 1037.8600783378085, 1031.8805027688127, 1046.0005547725443]
[test.py] Error percentage:  [-0.16866789529026027, 0.7056754242673424, 1.2457304359181902, -1.0506194516743177, 0.3609309297661402, 0.2583797242986734, 1.3287895428639835, 2.345840107289289, 0.8491570381144551, 2.461393590461626]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1018.5364985169853
    Groundtruth: [1025.5707083057944, 1025.4323567297156, 1018.7198949170053, 1017.8174090148686, 1019.7992299585246, 1026.5616342696967, 1023.4257091663745, 1015.3176467899139, 1026.439970983825, 1020.3807925917498]
    Slowdown:    [591.3146521266336, 618.578729926806, 648.088646634433, 679.5537696580465, 711.7921253449562, 752.234861564902, 791.0541896642599, 844.1215273954867, 900.9410678568428, 950.8683472377227]
    Predicted:   [1021.5231870951386, 1025.2073957718253, 1027.93718031756, 1028.3863425357456, 1023.7847136362499, 1028.536381928883, 1022.4539057330215, 1031.367129665635, 1035.3104938230463, 1021.8328902665921]
    Error Perc:  [-0.39466037571822987, -0.02193815676030833, 0.9047909485762663, 1.0383918989071408, 0.39081061846725906, 0.1923652310064293, -0.09495593325914838, 1.5807351449533213, 0.8642027873017184, 0.14230938933631018]
[test.py] Result for the experiment 1: 
    Baseline throughput: 1015.8257848112879
    Groundtruth: [1022.6218918318368, 1021.9611857991927, 1012.8534200872673, 1026.1843836940866, 1015.2425985641933, 1028.881375411195, 1024.0414925228106, 1023.8787334410172, 1024.0836766483185, 1022.1511330305746]
    Slowdown:    [594.9267082086884, 614.3800425769977, 647.2350235084457, 676.6434300828276, 718.0720343924551, 747.4712731489926, 793.8874359012182, 834.9298888759978, 894.9917931769731, 954.6789669414126]
    Predicted:   [1032.3511825927994, 1013.7255011532584, 1025.7913501029145, 1021.7358333932007, 1036.8267983231065, 1019.651377752623, 1027.1921186630311, 1017.6784420437054, 1027.4620242490414, 1026.2348340610984]
    Error Perc:  [0.9514064620242384, -0.8058705908183599, 1.2773743721507596, -0.4335039951467507, 2.1260139979782817, -0.8970905567109881, 0.3076658673721034, -0.6055689208890979, 0.329889800780711, 0.3995202762644344]
[test.py] Result for the experiment 2: 
    Baseline throughput: 1017.1174897967541
    Groundtruth: [1036.0860414803913, 1034.1303942899406, 1024.6810243221298, 1025.0570650869786, 1022.716358426135, 1013.772922506672, 1015.9026802312785, 1020.7987229399657, 1019.7927755585246, 1029.1173113528112]
    Slowdown:    [590.1795952287919, 616.3944330475468, 647.000229333275, 677.9373870249123, 713.6558429131445, 753.6767152907166, 794.5889051769682, 837.9475219129167, 899.6303553814291, 948.9251589962653]
    Predicted:   [1018.1404307733071, 1019.2213748762531, 1025.2017069941612, 1024.6890894769015, 1027.6447352507769, 1031.2338696492805, 1028.366764487056, 1022.1651856887954, 1033.5800333836016, 1019.589175658965]
    Error Perc:  [-1.7320579554805031, -1.441696278922773, 0.05081412260716472, -0.035898060957795214, 0.48189087658930035, 1.722372609778749, 1.2268974674759032, 0.13386211386454225, 1.3519666108171826, -0.9258551565244847]
[test.py] Result for the experiment 3: 
    Baseline throughput: 1016.4218707762905
    Groundtruth: [1026.6745117432795, 1026.1077336418773, 1019.6667133950183, 1030.301502022469, 1028.535231477961, 1017.7680223864692, 1025.1987181120269, 1016.6018387086843, 1033.4458338162003, 1024.1079032858356]
    Slowdown:    [587.4872479008227, 615.6598982364211, 611.7579448774892, 681.367073262389, 716.8020350296496, 752.4825374787214, 798.1219113960271, 846.184442230544, 900.7037603796538, 950.1645916675388]
    Predicted:   [1010.1541643621212, 1017.2146218524036, 939.4463419955765, 1032.5447855491277, 1034.1811076053807, 1028.9994754482236, 1034.2922504586522, 1034.4484256341495, 1034.9971343516843, 1021.0202153962115]
    Error Perc:  [-1.6091124491935622, -0.8666840233149882, -7.867312950948949, 0.2177307829072439, 0.5489239410211467, 1.1035376249510045, 0.8870019232341326, 1.7555139333738006, 0.1501095156342622, -0.3015002500925276]
[test.py] Result for the experiment 4: 
    Baseline throughput: 1018.3019731860088
    Groundtruth: [1020.6743587833423, 1014.761024634903, 1014.9426582137335, 1028.3450920202715, 1016.2315229975385, 1024.1014270053306, 1022.6742084287504, 1014.0715804861422, 1023.1919959220171, 1020.8728557347272]
    Slowdown:    [590.4524713677879, 617.381123833754, 647.9490781679086, 674.8011755272659, 709.911874335198, 751.2775509970841, 799.2951375864436, 848.465921909795, 898.3425165087001, 971.7614503957504]
    Predicted:   [1018.9528088246151, 1021.921943800795, 1027.586107814219, 1017.5410984531684, 1019.8994168820701, 1026.7474974489658, 1036.2633963679186, 1037.8600783378085, 1031.8805027688127, 1046.0005547725443]
    Error Perc:  [-0.16866789529026027, 0.7056754242673424, 1.2457304359181902, -1.0506194516743177, 0.3609309297661402, 0.2583797242986734, 1.3287895428639835, 2.345840107289289, 0.8491570381144551, 2.461393590461626]
