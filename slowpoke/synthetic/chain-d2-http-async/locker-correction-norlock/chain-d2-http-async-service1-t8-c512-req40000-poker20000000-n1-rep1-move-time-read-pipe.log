[config.py] Random numbers for execution time: [205.7194555714941, 410.8569070954639, 488.69351628976347]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service1
request_type                     : chain-d2-http-async
repetitions                      : 1
target_num_exp                   : 1
pre_run                          : False
num_req                          : 40000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 9944
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 1}
baseline_service_processing_time : {'service0': 488.69, 'service1': 410.86, 'service2': 205.72}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2}
target_processing_time_range     : [0, 410.86]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d2-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00048869', 'PROCESSING_TIME_SERVICE1': '0.00041086', 'PROCESSING_TIME_SERVICE2': '0.00020572', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d2-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request chain-d2-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   204.72ms   49.77ms 478.29ms   78.15%
        Req/Sec   315.91     75.23   464.00     75.66%
        Latency Distribution
        50%  191.92ms
        75%  224.36ms
        90%  269.24ms
        99%  374.54ms
        7243 requests in 3.03s, 4.34MB read
        Requests/sec:   2388.82
        Transfer/sec:      1.43MB
        [run.sh] Speed is 2388.82, duration is 25
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d25s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 25s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   194.69ms   59.73ms 872.39ms   86.02%
        Req/Sec   331.21     80.78     1.30k    81.88%
        Latency Distribution
        50%  186.49ms
        75%  213.80ms
        90%  250.63ms
        99%  387.86ms
        40000 requests in 25.00s, 23.99MB read
        Requests/sec:   1599.99
        Transfer/sec:      0.96MB
        ------------------------------
        stop time: 14.647969
        stop time: 15.007775
        stop time: 15.138764
        stop time: 15.422354
        stop time: 15.407143
        stop time: 15.436986
        stop time: 15.481781
        stop time: 15.505731
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [14.647969, 15.007775, 15.138764, 15.422354, 15.407143, 15.436986, 15.481781, 15.505731]
    [exp] Throughput: 2621.908439139151
[test.py] Baseline throughput: 2621.908439139151
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/chain-d2-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00048869', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00020572', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic chain-d2-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request chain-d2-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
