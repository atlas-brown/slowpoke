[config.py] Random numbers for execution time: [364.086631410527, 550.777026900204, 835.712170765861, 968.6408719576834, 1133.5811454513716]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service1
request_type                     : dynamic-cycle-http-async
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 21827
request_ratio                    : {'service0': 1, 'service1': 1.34, 'service2': 0.34, 'service3': 0.5, 'service4': 0.5}
baseline_service_processing_time : {'service0': 1519.0, 'service1': 968.64, 'service2': 3293.69, 'service3': 1476.08, 'service4': 975.75}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2, 'service4': 2}
target_processing_time_range     : [0, 968.64]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 96, 192, 288, 384, 480, 576, 672, 768, 864]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   491.20ms  342.63ms   1.97s    74.39%
        Req/Sec   127.17     75.32   350.00     63.91%
        Latency Distribution
        50%  422.40ms
        75%  649.69ms
        90%  962.65ms
        99%    1.63s
        2942 requests in 3.03s, 456.81KB read
        Requests/sec:    972.00
        Transfer/sec:    150.93KB
        [run.sh] Speed is 972.00, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   484.73ms  390.24ms   3.26s    77.20%
        Req/Sec   137.37     63.04   430.00     67.93%
        Latency Distribution
        50%  374.81ms
        75%  663.62ms
        90%    1.02s
        99%    1.75s
        20001 requests in 30.00s, 3.03MB read
        Requests/sec:    666.70
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.549881
        stop time: 18.234699
        stop time: 18.796747
        stop time: 18.994541
        stop time: 18.587252
        stop time: 19.035960
        stop time: 18.664914
        stop time: 18.656395
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-qrlgk        1942m        72Mi
        service1-7755b7b4b5-9qnwq        1739m        60Mi
        service2-958786d58-4tthx         1336m        29Mi
        service3-6ddd8b8f64-2lnwv        902m         14Mi
        service4-9bb5bd9fd-sqpj8         645m         10Mi
        ubuntu-client-76886f6bbd-zjhqf   43m          36Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.549881, 18.234699, 18.796747, 18.994541, 18.587252, 19.03596, 18.664914, 18.656395]
    [exp] Throughput: 1070.0881737272634
[test.py] Baseline throughput: 1070.0881737272634
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   497.99ms  439.72ms   2.35s    77.16%
        Req/Sec   140.37     75.97   383.00     72.22%
        Latency Distribution
        50%  410.95ms
        75%  717.19ms
        90%    1.08s
        99%    2.05s
        2957 requests in 3.02s, 459.14KB read
        Requests/sec:    977.57
        Transfer/sec:    151.79KB
        [run.sh] Speed is 977.57, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   484.26ms  447.03ms   3.28s    84.11%
        Req/Sec   140.84     83.26   494.00     67.70%
        Latency Distribution
        50%  353.85ms
        75%  679.20ms
        90%    1.03s
        99%    2.30s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 17.977933
        stop time: 18.445858
        stop time: 18.678446
        stop time: 18.222345
        stop time: 18.582592
        stop time: 18.789733
        stop time: 18.673683
        stop time: 18.169390
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [17.977933, 18.445858, 18.678446, 18.222345, 18.582592, 18.789733, 18.673683, 18.16939]
    [exp] Throughput: 1084.451821126721
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '648.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1908.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   777.60ms  408.88ms   2.73s    66.99%
        Req/Sec    84.57     53.61   220.00     59.09%
        Latency Distribution
        50%  747.24ms
        75%    1.00s
        90%    1.32s
        99%    2.04s
        1712 requests in 3.02s, 265.83KB read
        Requests/sec:    566.20
        Transfer/sec:     87.92KB
        [run.sh] Speed is 566.20, duration is 52
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d52s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-689ff9485f-hw2hm        422m         65Mi
        service1-7755b7b4b5-2rwrc        407m         52Mi
        service2-59f85f9ccc-rpz78        283m         22Mi
        service3-f478494d6-vcdw4         191m         14Mi
        service4-57b78cdf48-xh89l        169m         12Mi
        ubuntu-client-76886f6bbd-5n28s   9m           15Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   795.13ms  528.99ms   4.83s    69.71%
        Req/Sec    87.33     58.15   410.00     69.44%
        Latency Distribution
        50%  701.64ms
        75%    1.09s
        90%    1.51s
        99%    2.47s
        20001 requests in 0.87m, 3.03MB read
        Requests/sec:    384.63
        Transfer/sec:     59.72KB
        ------------------------------
        stop time: 30.967473
        stop time: 31.168449
        stop time: 31.168629
        stop time: 31.380231
        stop time: 31.457173
        stop time: 31.656190
        stop time: 31.837214
        stop time: 31.786208
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [30.967473, 31.168449, 31.168629, 31.380231, 31.457173, 31.65619, 31.837214, 31.786208]
    [exp] Throughput: 636.3813650083567
[test.py] Finished running 0th optmization experiment: groundtruth->1084.451821126721, slowdown->636.3813650083567, predicted->1084.1330695014203, err->-0.029392880263635564
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '9.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   473.25ms  327.71ms   1.78s    70.33%
        Req/Sec   139.10     85.33   400.00     67.00%
        Latency Distribution
        50%  392.91ms
        75%  699.04ms
        90%  898.98ms
        99%    1.41s
        2796 requests in 3.04s, 434.14KB read
        Requests/sec:    921.16
        Transfer/sec:    143.03KB
        [run.sh] Speed is 921.16, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   505.96ms  496.33ms   4.41s    87.95%
        Req/Sec   138.55     72.77   434.00     69.62%
        Latency Distribution
        50%  343.74ms
        75%  644.09ms
        90%    1.11s
        99%    2.46s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.441917
        stop time: 18.605317
        stop time: 18.535743
        stop time: 18.526907
        stop time: 18.266824
        stop time: 18.740240
        stop time: 18.391158
        stop time: 18.789711
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pjbhw        462m         69Mi
        service1-7755b7b4b5-fk29s        140m         52Mi
        service2-958786d58-lx4cz         321m         27Mi
        service3-6ddd8b8f64-zwlhq        205m         13Mi
        service4-9bb5bd9fd-92djx         76m          13Mi
        ubuntu-client-76886f6bbd-vbpxm   20m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.441917, 18.605317, 18.535743, 18.526907, 18.266824, 18.74024, 18.391158, 18.789711]
    [exp] Throughput: 1078.910015243178
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1719.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   773.46ms  437.89ms   2.41s    67.45%
        Req/Sec   101.69     67.32   272.00     62.65%
        Latency Distribution
        50%  719.16ms
        75%    1.07s
        90%    1.38s
        99%    1.83s
        1771 requests in 3.03s, 274.99KB read
        Requests/sec:    584.12
        Transfer/sec:     90.70KB
        [run.sh] Speed is 584.12, duration is 51
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d51s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   786.34ms  639.32ms   5.81s    82.75%
        Req/Sec    86.64     53.79   340.00     66.39%
        Latency Distribution
        50%  640.80ms
        75%  970.76ms
        90%    1.54s
        99%    3.31s
        20000 requests in 0.85m, 3.03MB read
        Requests/sec:    392.16
        Transfer/sec:     60.89KB
        ------------------------------
        stop time: 29.297197
        stop time: 29.044493
        stop time: 30.244211
        stop time: 29.760187
        stop time: 30.471380
        stop time: 30.153396
        stop time: 30.218240
        stop time: 30.159384
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [29.297197, 29.044493, 30.244211, 29.760187, 30.47138, 30.153396, 30.21824, 30.159384]
    [exp] Throughput: 668.4813484177932
[test.py] Finished running 1th optmization experiment: groundtruth->1078.910015243178, slowdown->668.4813484177932, predicted->1097.3825505749326, err->1.7121479150966177
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000192', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   529.68ms  541.38ms   2.97s    81.69%
        Req/Sec   126.73     57.04   333.00     72.09%
        Latency Distribution
        50%  251.73ms
        75%  828.69ms
        90%    1.43s
        99%    1.96s
        2878 requests in 3.03s, 446.88KB read
        Requests/sec:    949.09
        Transfer/sec:    147.37KB
        [run.sh] Speed is 949.09, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   513.20ms  552.69ms   3.92s    87.79%
        Req/Sec   142.38     79.99   540.00     70.66%
        Latency Distribution
        50%  310.91ms
        75%  648.71ms
        90%    1.22s
        99%    2.84s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.215450
        stop time: 17.352227
        stop time: 18.254545
        stop time: 18.355804
        stop time: 18.765913
        stop time: 18.785309
        stop time: 18.533912
        stop time: 18.533297
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.21545, 17.352227, 18.254545, 18.355804, 18.765913, 18.785309, 18.533912, 18.533297]
    [exp] Throughput: 1089.944561809145
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '520.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1530.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   734.59ms  402.16ms   1.95s    71.65%
        Req/Sec    91.89     75.70   340.00     72.55%
        Latency Distribution
        50%  708.67ms
        75%  916.84ms
        90%    1.36s
        99%    1.90s
        1633 requests in 3.03s, 253.56KB read
        Requests/sec:    538.87
        Transfer/sec:     83.67KB
        [run.sh] Speed is 538.87, duration is 55
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-656fc596d7-bjfxv        63m          71Mi
        service1-7755b7b4b5-phxvd        108m         63Mi
        service2-959db6589-kf5kb         67m          28Mi
        service3-84cb9dcd88-f8vd8        57m          14Mi
        service4-875c49d6-n279v          91m          13Mi
        ubuntu-client-76886f6bbd-phl4s   1m           16Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   735.94ms  503.79ms   3.68s    74.27%
        Req/Sec    95.86     60.35   424.00     67.50%
        Latency Distribution
        50%  647.44ms
        75%  970.26ms
        90%    1.35s
        99%    2.63s
        20000 requests in 0.92m, 3.03MB read
        Requests/sec:    363.64
        Transfer/sec:     56.46KB
        ------------------------------
        stop time: 28.686427
        stop time: 28.245162
        stop time: 28.955492
        stop time: 29.124844
        stop time: 28.941872
        stop time: 28.625203
        stop time: 29.114633
        stop time: 29.197707
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [28.686427, 28.245162, 28.955492, 29.124844, 28.941872, 28.625203, 29.114633, 29.197707]
    [exp] Throughput: 692.9666569564714
[test.py] Finished running 2th optmization experiment: groundtruth->1089.944561809145, slowdown->692.9666569564714, predicted->1083.749947133323, err->-0.5683421793067837
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000288', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   463.60ms  425.57ms   2.24s    85.10%
        Req/Sec   123.76     73.98   350.00     74.31%
        Latency Distribution
        50%  309.32ms
        75%  621.24ms
        90%    1.05s
        99%    1.98s
        2813 requests in 3.03s, 436.78KB read
        Requests/sec:    928.82
        Transfer/sec:    144.22KB
        [run.sh] Speed is 928.82, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   504.31ms  531.06ms   4.44s    87.68%
        Req/Sec   142.15     76.76   580.00     67.94%
        Latency Distribution
        50%  333.39ms
        75%  648.09ms
        90%    1.15s
        99%    2.82s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 17.053950
        stop time: 18.037205
        stop time: 18.078370
        stop time: 18.453885
        stop time: 18.691362
        stop time: 18.570211
        stop time: 18.477966
        stop time: 18.811296
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-5sgg9        602m         69Mi
        service1-7755b7b4b5-4rr6f        233m         42Mi
        service2-958786d58-vgpcw         372m         20Mi
        service3-6ddd8b8f64-pf7wv        226m         12Mi
        service4-9bb5bd9fd-qbmwf         89m          9Mi
        ubuntu-client-76886f6bbd-fd477   17m          17Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.05395, 18.037205, 18.07837, 18.453885, 18.691362, 18.570211, 18.477966, 18.811296]
    [exp] Throughput: 1094.58406985444
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '456.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1341.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   762.79ms  364.90ms   1.67s    65.59%
        Req/Sec   105.30     87.16   494.00     82.00%
        Latency Distribution
        50%  805.98ms
        75%  982.69ms
        90%    1.24s
        99%    1.58s
        1709 requests in 3.03s, 265.36KB read
        Requests/sec:    564.64
        Transfer/sec:     87.67KB
        [run.sh] Speed is 564.64, duration is 53
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d53s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d557f68bf-bg29m        1223m        72Mi
        service1-7755b7b4b5-czrq5        1234m        59Mi
        service2-54c8b5d4f9-2z27s        922m         28Mi
        service3-697b6c488d-svfmw        622m         14Mi
        service4-6cfd9c977d-4z66c        422m         14Mi
        ubuntu-client-76886f6bbd-zsd44   28m          23Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   685.80ms  606.54ms   3.86s    81.29%
        Req/Sec   102.78     59.20   430.00     70.76%
        Latency Distribution
        50%  538.36ms
        75%  907.32ms
        90%    1.49s
        99%    2.78s
        20000 requests in 0.88m, 3.03MB read
        Requests/sec:    377.36
        Transfer/sec:     58.59KB
        ------------------------------
        stop time: 26.725096
        stop time: 26.497901
        stop time: 26.033868
        stop time: 26.586033
        stop time: 26.854260
        stop time: 27.080628
        stop time: 27.056102
        stop time: 27.966764
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.725096, 26.497901, 26.033868, 26.586033, 26.85426, 27.080628, 27.056102, 27.966764]
    [exp] Throughput: 744.87669618433
[test.py] Finished running 3th optmization experiment: groundtruth->1094.58406985444, slowdown->744.87669618433, predicted->1128.0630472180965, err->3.0586026496903562
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000384', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   537.63ms  474.83ms   2.65s    80.03%
        Req/Sec   142.11     77.87   380.00     69.38%
        Latency Distribution
        50%  369.30ms
        75%  731.69ms
        90%    1.30s
        99%    1.94s
        3090 requests in 3.03s, 479.79KB read
        Requests/sec:   1019.37
        Transfer/sec:    158.28KB
        [run.sh] Speed is 1019.37, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   535.97ms  595.78ms   4.53s    86.43%
        Req/Sec   137.56     71.60   454.00     70.33%
        Latency Distribution
        50%  311.17ms
        75%  688.52ms
        90%    1.40s
        99%    2.69s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 18.636161
        stop time: 17.638491
        stop time: 18.710437
        stop time: 17.989779
        stop time: 18.738055
        stop time: 17.992519
        stop time: 18.609383
        stop time: 18.722745
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.636161, 17.638491, 18.710437, 17.989779, 18.738055, 17.992519, 18.609383, 18.722745]
    [exp] Throughput: 1088.1572648405438
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '391.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1152.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   671.20ms  322.55ms   1.86s    67.53%
        Req/Sec   105.58     72.66   300.00     62.58%
        Latency Distribution
        50%  634.30ms
        75%  871.44ms
        90%    1.08s
        99%    1.53s
        1925 requests in 3.03s, 298.90KB read
        Requests/sec:    635.84
        Transfer/sec:     98.73KB
        [run.sh] Speed is 635.84, duration is 47
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f5498d4b-x8ps4         227m         61Mi
        service1-7755b7b4b5-phc4z        290m         49Mi
        service2-77dd47bf4f-wvj4c        215m         20Mi
        service3-74947cdd48-9wvdz        174m         12Mi
        service4-789d8dbcdb-hzbwm        138m         10Mi
        ubuntu-client-76886f6bbd-hktkd   10m          9Mi
        Running 47s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   675.69ms  544.29ms   4.76s    80.36%
        Req/Sec   100.28     61.42   373.00     71.14%
        Latency Distribution
        50%  540.83ms
        75%  855.38ms
        90%    1.36s
        99%    2.70s
        20001 requests in 47.00s, 3.03MB read
        Requests/sec:    425.55
        Transfer/sec:     66.08KB
        ------------------------------
        stop time: 25.159034
        stop time: 25.571738
        stop time: 25.802120
        stop time: 26.674053
        stop time: 26.275678
        stop time: 25.986901
        stop time: 26.667810
        stop time: 26.606616
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [25.159034, 25.571738, 25.80212, 26.674053, 26.275678, 25.986901, 26.66781, 26.606616]
    [exp] Throughput: 766.4892802881234
[test.py] Finished running 4th optmization experiment: groundtruth->1088.1572648405438, slowdown->766.4892802881234, predicted->1095.3611714537215, err->0.6620280768178574
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   578.87ms  582.09ms   2.70s    82.96%
        Req/Sec   137.79     65.43   363.00     73.42%
        Latency Distribution
        50%  313.05ms
        75%  863.32ms
        90%    1.62s
        99%    2.19s
        3091 requests in 3.03s, 479.95KB read
        Requests/sec:   1019.19
        Transfer/sec:    158.25KB
        [run.sh] Speed is 1019.19, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   525.23ms  552.33ms   4.61s    87.14%
        Req/Sec   140.17     71.42   430.00     71.12%
        Latency Distribution
        50%  320.30ms
        75%  683.60ms
        90%    1.28s
        99%    2.48s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 17.613343
        stop time: 18.384509
        stop time: 18.712939
        stop time: 18.704028
        stop time: 18.256712
        stop time: 18.214691
        stop time: 18.615113
        stop time: 18.849754
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-x5k6s        1941m        67Mi
        service1-7755b7b4b5-52pfx        1136m        42Mi
        service2-958786d58-zxn42         1385m        20Mi
        service3-6ddd8b8f64-h25hk        917m         13Mi
        service4-9bb5bd9fd-xzk9d         558m         10Mi
        ubuntu-client-76886f6bbd-ntcxv   42m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.613343, 18.384509, 18.712939, 18.704028, 18.256712, 18.214691, 18.615113, 18.849754]
    [exp] Throughput: 1085.8419919787632
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '327.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '962.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   674.28ms  516.11ms   2.56s    62.43%
        Req/Sec   110.64     62.98   280.00     66.67%
        Latency Distribution
        50%  624.95ms
        75%  985.25ms
        90%    1.37s
        99%    2.06s
        1997 requests in 3.03s, 310.08KB read
        Requests/sec:    659.66
        Transfer/sec:    102.43KB
        [run.sh] Speed is 659.66, duration is 45
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d45s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 45s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   643.53ms  527.54ms   4.55s    80.48%
        Req/Sec   105.01     57.65   404.00     69.44%
        Latency Distribution
        50%  520.73ms
        75%  830.83ms
        90%    1.29s
        99%    2.56s
        20000 requests in 45.00s, 3.03MB read
        Requests/sec:    444.44
        Transfer/sec:     69.01KB
        ------------------------------
        stop time: 24.707988
        stop time: 24.238221
        stop time: 24.900455
        stop time: 25.277847
        stop time: 25.278276
        stop time: 25.267603
        stop time: 25.145485
        stop time: 25.299915
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [24.707988, 24.238221, 24.900455, 25.277847, 25.278276, 25.267603, 25.145485, 25.299915]
    [exp] Throughput: 799.5371079913283
[test.py] Finished running 5th optmization experiment: groundtruth->1085.8419919787632, slowdown->799.5371079913283, predicted->1083.0306680034332, err->-0.2589072808104251
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000576', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   516.12ms  516.60ms   2.94s    85.58%
        Req/Sec   126.83     61.21   340.00     71.43%
        Latency Distribution
        50%  277.24ms
        75%  747.27ms
        90%    1.33s
        99%    2.20s
        2848 requests in 3.01s, 442.22KB read
        Requests/sec:    945.24
        Transfer/sec:    146.77KB
        [run.sh] Speed is 945.24, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   513.97ms  533.56ms   5.92s    87.13%
        Req/Sec   137.87     75.83   525.00     69.14%
        Latency Distribution
        50%  322.74ms
        75%  657.68ms
        90%    1.24s
        99%    2.48s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.940450
        stop time: 18.748153
        stop time: 18.730206
        stop time: 18.722435
        stop time: 18.875623
        stop time: 18.897430
        stop time: 18.418136
        stop time: 18.774220
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-kzt7j        629m         61Mi
        service1-7755b7b4b5-bmnqp        359m         43Mi
        service2-958786d58-zkjq4         373m         17Mi
        service3-6ddd8b8f64-9b44n        223m         9Mi
        service4-9bb5bd9fd-qc9pt         62m          8Mi
        ubuntu-client-76886f6bbd-hxxns   13m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.94045, 18.748153, 18.730206, 18.722435, 18.875623, 18.89743, 18.418136, 18.77422]
    [exp] Throughput: 1065.9087842029228
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '263.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '773.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   641.60ms  560.90ms   2.92s    78.88%
        Req/Sec   120.31     63.12   282.00     69.27%
        Latency Distribution
        50%  452.93ms
        75%  898.00ms
        90%    1.52s
        99%    2.38s
        2359 requests in 3.03s, 366.29KB read
        Requests/sec:    777.84
        Transfer/sec:    120.78KB
        [run.sh] Speed is 777.84, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6dd6844b8c-tsm24        1510m        75Mi
        service1-7755b7b4b5-gmxz4        1412m        63Mi
        service2-cf56db458-d4tv9         1078m        38Mi
        service3-767df97779-rrxr4        728m         11Mi
        service4-75dbf88985-8nqqk        485m         10Mi
        ubuntu-client-76886f6bbd-lzkx2   33m          20Mi
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   620.54ms  524.09ms   3.87s    83.90%
        Req/Sec   112.43     61.04   380.00     66.92%
        Latency Distribution
        50%  487.19ms
        75%  792.74ms
        90%    1.25s
        99%    2.63s
        20000 requests in 38.00s, 3.03MB read
        Requests/sec:    526.31
        Transfer/sec:     81.72KB
        ------------------------------
        stop time: 23.547292
        stop time: 22.704113
        stop time: 22.839155
        stop time: 23.534960
        stop time: 23.594906
        stop time: 24.119019
        stop time: 23.905840
        stop time: 23.914965
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.547292, 22.704113, 22.839155, 23.53496, 23.594906, 24.119019, 23.90584, 23.914965]
    [exp] Throughput: 850.3390062460056
[test.py] Finished running 6th optmization experiment: groundtruth->1065.9087842029228, slowdown->850.3390062460056, predicted->1095.3709200462613, err->2.7640391260467965
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000672', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   510.31ms  350.28ms   1.64s    64.32%
        Req/Sec   147.46     88.11   393.00     68.51%
        Latency Distribution
        50%  431.32ms
        75%  792.07ms
        90%  990.05ms
        99%    1.48s
        2739 requests in 3.03s, 425.29KB read
        Requests/sec:    905.09
        Transfer/sec:    140.54KB
        [run.sh] Speed is 905.09, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   505.07ms  539.84ms   3.42s    86.41%
        Req/Sec   139.04     65.89   450.00     69.63%
        Latency Distribution
        50%  311.36ms
        75%  683.37ms
        90%    1.22s
        99%    2.62s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 17.920958
        stop time: 17.867743
        stop time: 17.899807
        stop time: 18.476747
        stop time: 18.509415
        stop time: 18.667384
        stop time: 18.829717
        stop time: 18.622791
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [17.920958, 17.867743, 17.899807, 18.476747, 18.509415, 18.667384, 18.829717, 18.622791]
    [exp] Throughput: 1089.958632118811
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '198.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   575.01ms  378.18ms   2.48s    74.68%
        Req/Sec   118.84     73.09   310.00     63.92%
        Latency Distribution
        50%  491.59ms
        75%  759.88ms
        90%    1.07s
        99%    1.80s
        2436 requests in 3.03s, 378.25KB read
        Requests/sec:    803.32
        Transfer/sec:    124.73KB
        [run.sh] Speed is 803.32, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6b6b7b9f5-wxbbj         557m         69Mi
        service1-7755b7b4b5-6vttq        503m         57Mi
        service2-7cf4598c6b-vh26b        354m         27Mi
        service3-55998c8697-cvtfc        11m          9Mi
        service4-6866646d59-s9lh5        72m          11Mi
        ubuntu-client-76886f6bbd-cwrhb   10m          7Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   570.52ms  417.49ms   3.29s    76.44%
        Req/Sec   115.33     64.41   400.00     67.62%
        Latency Distribution
        50%  467.88ms
        75%  748.02ms
        90%    1.09s
        99%    2.04s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 22.226847
        stop time: 21.781180
        stop time: 22.385878
        stop time: 22.532500
        stop time: 22.608230
        stop time: 22.482498
        stop time: 22.365777
        stop time: 22.208267
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.226847, 21.78118, 22.385878, 22.5325, 22.60823, 22.482498, 22.365777, 22.208267]
    [exp] Throughput: 895.9009212420386
[test.py] Finished running 7th optmization experiment: groundtruth->1089.958632118811, slowdown->895.9009212420386, predicted->1089.9823408554762, err->0.002175196008961975
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000768', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   466.47ms  384.37ms   2.72s    69.49%
        Req/Sec   127.96     62.39   290.00     67.43%
        Latency Distribution
        50%  384.89ms
        75%  655.43ms
        90%    1.01s
        99%    1.72s
        2836 requests in 3.03s, 440.36KB read
        Requests/sec:    935.62
        Transfer/sec:    145.28KB
        [run.sh] Speed is 935.62, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   470.98ms  411.74ms   3.24s    83.09%
        Req/Sec   137.91     71.47   510.00     67.49%
        Latency Distribution
        50%  346.53ms
        75%  617.95ms
        90%    1.00s
        99%    2.04s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.694162
        stop time: 18.688764
        stop time: 18.594058
        stop time: 18.403094
        stop time: 18.438810
        stop time: 18.746844
        stop time: 18.200460
        stop time: 18.369629
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-p8zhz        1933m        75Mi
        service1-7755b7b4b5-7vffz        1503m        58Mi
        service2-958786d58-f7r2t         1357m        22Mi
        service3-6ddd8b8f64-5wpzp        911m         13Mi
        service4-9bb5bd9fd-cdpbw         479m         13Mi
        ubuntu-client-76886f6bbd-98c6f   35m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.694162, 18.688764, 18.594058, 18.403094, 18.43881, 18.746844, 18.20046, 18.369629]
    [exp] Throughput: 1080.0898723881241
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '134.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '395.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   693.34ms  729.15ms   2.96s    82.39%
        Req/Sec   103.91     68.41   353.00     73.48%
        Latency Distribution
        50%  297.78ms
        75%    1.12s
        90%    1.89s
        99%    2.90s
        1982 requests in 3.03s, 307.75KB read
        Socket errors: connect 0, read 0, write 0, timeout 1
        Requests/sec:    654.39
        Transfer/sec:    101.61KB
        [run.sh] Speed is 654.39, duration is 45
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d45s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service4-5df98d9dbf-qrdmw        3m           3Mi
        ubuntu-client-76886f6bbd-fhp2r   5m           0Mi
        Running 45s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   528.57ms  404.17ms   2.96s    76.69%
        Req/Sec   122.33     67.07   404.00     66.31%
        Latency Distribution
        50%  443.38ms
        75%  711.34ms
        90%    1.04s
        99%    2.01s
        20001 requests in 45.00s, 3.03MB read
        Requests/sec:    444.47
        Transfer/sec:     69.01KB
        ------------------------------
        stop time: 20.698177
        stop time: 20.083669
        stop time: 20.574857
        stop time: 20.825715
        stop time: 21.039163
        stop time: 21.210209
        stop time: 21.321641
        stop time: 21.266054
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.698177, 20.083669, 20.574857, 20.825715, 21.039163, 21.210209, 21.321641, 21.266054]
    [exp] Throughput: 957.9720593678037
[test.py] Finished running 8th optmization experiment: groundtruth->1080.0898723881241, slowdown->957.9720593678037, predicted->1099.5741576074759, err->1.8039503672292687
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   532.99ms  401.77ms   2.03s    69.43%
        Req/Sec   148.46     69.31   323.00     69.57%
        Latency Distribution
        50%  417.83ms
        75%  832.89ms
        90%    1.02s
        99%    1.57s
        2760 requests in 3.03s, 428.55KB read
        Requests/sec:    912.11
        Transfer/sec:    141.63KB
        [run.sh] Speed is 912.11, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   478.67ms  388.01ms   2.98s    79.25%
        Req/Sec   140.30     68.21   373.00     66.47%
        Latency Distribution
        50%  376.25ms
        75%  637.29ms
        90%    1.02s
        99%    1.89s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.332797
        stop time: 18.402550
        stop time: 18.662025
        stop time: 18.780929
        stop time: 18.097802
        stop time: 19.001785
        stop time: 18.389856
        stop time: 18.883143
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-q7ttq        611m         58Mi
        service1-7755b7b4b5-srwh8        524m         65Mi
        service2-958786d58-bpsb7         412m         34Mi
        service3-6ddd8b8f64-wrld9        274m         9Mi
        service4-9bb5bd9fd-kf9pv         197m         11Mi
        ubuntu-client-76886f6bbd-58rmz   9m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.332797, 18.40255, 18.662025, 18.780929, 18.097802, 19.001785, 18.389856, 18.883143]
    [exp] Throughput: 1077.0719935182885
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '70.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '206.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   577.05ms  389.55ms   2.19s    68.34%
        Req/Sec   127.60     64.37   270.00     66.67%
        Latency Distribution
        50%  482.86ms
        75%  796.58ms
        90%    1.13s
        99%    1.78s
        2469 requests in 3.03s, 383.37KB read
        Requests/sec:    814.62
        Transfer/sec:    126.49KB
        [run.sh] Speed is 814.62, duration is 36
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d36s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f78d8d955-mpds4         1835m        74Mi
        service1-7755b7b4b5-lj7rx        1678m        57Mi
        service2-c67776854-62p74         1291m        30Mi
        service3-6649d96499-qgrvb        862m         12Mi
        service4-6b5bfdd577-zqbtf        604m         12Mi
        ubuntu-client-76886f6bbd-cflkq   31m          19Mi
        Running 36s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   497.27ms  378.99ms   2.86s    72.47%
        Req/Sec   132.02     66.12   370.00     66.08%
        Latency Distribution
        50%  411.38ms
        75%  684.55ms
        90%    1.01s
        99%    1.75s
        20000 requests in 36.00s, 3.03MB read
        Requests/sec:    555.55
        Transfer/sec:     86.26KB
        ------------------------------
        stop time: 19.226340
        stop time: 19.467869
        stop time: 19.807036
        stop time: 19.905686
        stop time: 19.946066
        stop time: 20.043765
        stop time: 20.021440
        stop time: 20.086563
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.22634, 19.467869, 19.807036, 19.905686, 19.946066, 20.043765, 20.02144, 20.086563]
    [exp] Throughput: 1009.4333757095566
[test.py] Finished running 9th optmization experiment: groundtruth->1077.0719935182885, slowdown->1009.4333757095566, predicted->1086.311841416232, err->0.8578672506153694
[test.py] Baseline throughput:  1070.0881737272634
[test.py] Groundtruth:  [1084.451821126721, 1078.910015243178, 1089.944561809145, 1094.58406985444, 1088.1572648405438, 1085.8419919787632, 1065.9087842029228, 1089.958632118811, 1080.0898723881241, 1077.0719935182885]
[test.py] Slowdown:  [636.3813650083567, 668.4813484177932, 692.9666569564714, 744.87669618433, 766.4892802881234, 799.5371079913283, 850.3390062460056, 895.9009212420386, 957.9720593678037, 1009.4333757095566]
[test.py] Predicted:  [1084.1330695014203, 1097.3825505749326, 1083.749947133323, 1128.0630472180965, 1095.3611714537215, 1083.0306680034332, 1095.3709200462613, 1089.9823408554762, 1099.5741576074759, 1086.311841416232]
[test.py] Error percentage:  [-0.029392880263635564, 1.7121479150966177, -0.5683421793067837, 3.0586026496903562, 0.6620280768178574, -0.2589072808104251, 2.7640391260467965, 0.002175196008961975, 1.8039503672292687, 0.8578672506153694]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 1...
[test.py] Actual processing time range: [0, 96, 192, 288, 384, 480, 576, 672, 768, 864]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   523.01ms  343.16ms   1.65s    66.64%
        Req/Sec   139.43     64.69   300.00     69.66%
        Latency Distribution
        50%  446.94ms
        75%  768.32ms
        90%  983.24ms
        99%    1.48s
        2593 requests in 3.04s, 402.62KB read
        Requests/sec:    853.34
        Transfer/sec:    132.50KB
        [run.sh] Speed is 853.34, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        ubuntu-client-76886f6bbd-fv8vk   5m           0Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   474.26ms  420.54ms   3.47s    85.68%
        Req/Sec   138.37     64.27   420.00     71.12%
        Latency Distribution
        50%  349.38ms
        75%  601.39ms
        90%    1.00s
        99%    2.09s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 17.828972
        stop time: 18.574008
        stop time: 18.768456
        stop time: 18.424921
        stop time: 18.322763
        stop time: 18.845652
        stop time: 18.649426
        stop time: 18.499193
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.828972, 18.574008, 18.768456, 18.424921, 18.322763, 18.845652, 18.649426, 18.499193]
    [exp] Throughput: 1081.7140957846068
[test.py] Baseline throughput: 1081.7140957846068
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   392.73ms  374.33ms   1.65s    83.35%
        Req/Sec   124.80     61.43   292.00     67.09%
        Latency Distribution
        50%  237.34ms
        75%  574.64ms
        90%  990.76ms
        99%    1.50s
        2964 requests in 3.03s, 460.23KB read
        Requests/sec:    977.41
        Transfer/sec:    151.77KB
        [run.sh] Speed is 977.41, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   501.16ms  487.99ms   3.44s    86.51%
        Req/Sec   139.34     78.93   530.00     68.15%
        Latency Distribution
        50%  331.84ms
        75%  625.02ms
        90%    1.16s
        99%    2.35s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.314856
        stop time: 18.222476
        stop time: 18.481956
        stop time: 18.727498
        stop time: 18.287950
        stop time: 18.195099
        stop time: 18.793260
        stop time: 18.515332
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-gmz5v        717m         63Mi
        service1-7755b7b4b5-627wq        151m         38Mi
        service2-958786d58-w2cmh         374m         20Mi
        service3-6ddd8b8f64-l2vdf        180m         12Mi
        service4-9bb5bd9fd-92vth         32m          10Mi
        ubuntu-client-76886f6bbd-5mpph   36m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.314856, 18.222476, 18.481956, 18.727498, 18.28795, 18.195099, 18.79326, 18.515332]
    [exp] Throughput: 1084.4632361438964
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '648.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1908.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   683.95ms  480.47ms   2.53s    62.69%
        Req/Sec    86.27     50.93   250.00     64.46%
        Latency Distribution
        50%  714.90ms
        75%  912.42ms
        90%    1.38s
        99%    1.95s
        1579 requests in 3.03s, 245.18KB read
        Requests/sec:    521.72
        Transfer/sec:     81.01KB
        [run.sh] Speed is 521.72, duration is 57
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d57s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-689ff9485f-4wzzc        1170m        68Mi
        service1-7755b7b4b5-xg94v        1091m        56Mi
        service2-59f85f9ccc-dx4j5        793m         27Mi
        service3-f478494d6-t2hwv         535m         15Mi
        service4-57b78cdf48-hvqcn        372m         12Mi
        ubuntu-client-76886f6bbd-bkh9g   24m          23Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   795.41ms  582.79ms   5.52s    75.28%
        Req/Sec    85.08     51.66   303.00     63.86%
        Latency Distribution
        50%  692.85ms
        75%    1.05s
        90%    1.50s
        99%    2.86s
        20000 requests in 0.95m, 3.03MB read
        Requests/sec:    350.88
        Transfer/sec:     54.48KB
        ------------------------------
        stop time: 30.956354
        stop time: 30.436977
        stop time: 31.774190
        stop time: 31.781823
        stop time: 31.369904
        stop time: 31.878302
        stop time: 31.130712
        stop time: 31.576492
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [30.956354, 30.436977, 31.77419, 31.781823, 31.369904, 31.878302, 31.130712, 31.576492]
    [exp] Throughput: 637.6921817910234
[test.py] Finished running 0th optmization experiment: groundtruth->1084.4632361438964, slowdown->637.6921817910234, predicted->1087.942869073705, err->0.320862230625845
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '9.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   529.89ms  610.26ms   2.99s    85.18%
        Req/Sec   131.53     63.69   330.00     65.95%
        Latency Distribution
        50%  246.82ms
        75%  750.38ms
        90%    1.52s
        99%    2.71s
        3070 requests in 3.03s, 476.69KB read
        Requests/sec:   1012.14
        Transfer/sec:    157.16KB
        [run.sh] Speed is 1012.14, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   486.93ms  418.90ms   3.18s    80.81%
        Req/Sec   139.21     79.11   505.00     67.14%
        Latency Distribution
        50%  363.34ms
        75%  634.82ms
        90%    1.07s
        99%    1.92s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 18.194480
        stop time: 18.635984
        stop time: 18.775336
        stop time: 18.404240
        stop time: 17.957278
        stop time: 18.227579
        stop time: 18.557818
        stop time: 18.798675
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-4jwwv        3m           71Mi
        service1-7755b7b4b5-gxgnk        1m           42Mi
        service2-958786d58-7qlss         1m           21Mi
        service3-6ddd8b8f64-vpmw9        56m          12Mi
        service4-9bb5bd9fd-gggk4         141m         11Mi
        ubuntu-client-76886f6bbd-28jx7   21m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.19448, 18.635984, 18.775336, 18.40424, 17.957278, 18.227579, 18.557818, 18.798675]
    [exp] Throughput: 1084.367961562409
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1719.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   739.38ms  449.10ms   2.68s    68.51%
        Req/Sec    84.70     51.02   240.00     66.27%
        Latency Distribution
        50%  705.93ms
        75%  942.10ms
        90%    1.33s
        99%    1.92s
        1707 requests in 3.03s, 265.05KB read
        Requests/sec:    562.92
        Transfer/sec:     87.41KB
        [run.sh] Speed is 562.92, duration is 53
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d53s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6979b6d9d6-fdhhs        418m         56Mi
        service1-7755b7b4b5-797w2        398m         54Mi
        service2-667bd658d5-znqkz        283m         23Mi
        service3-67579fdbfc-4dxdh        192m         11Mi
        service4-6b47687759-gg477        126m         14Mi
        ubuntu-client-76886f6bbd-bj4zz   10m          0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   763.73ms  497.49ms   3.98s    71.82%
        Req/Sec    89.12     59.39   414.00     70.12%
        Latency Distribution
        50%  678.77ms
        75%    1.02s
        90%    1.42s
        99%    2.34s
        20000 requests in 0.88m, 3.03MB read
        Requests/sec:    377.36
        Transfer/sec:     58.59KB
        ------------------------------
        stop time: 29.035672
        stop time: 29.661718
        stop time: 30.402473
        stop time: 29.709689
        stop time: 30.467967
        stop time: 30.324682
        stop time: 30.352182
        stop time: 30.351579
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [29.035672, 29.661718, 30.402473, 29.709689, 30.467967, 30.324682, 30.352182, 30.351579]
    [exp] Throughput: 665.8178543235645
[test.py] Finished running 1th optmization experiment: groundtruth->1084.367961562409, slowdown->665.8178543235645, predicted->1090.2230878532976, err->0.5399575142788501
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000192', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   464.20ms  323.81ms   1.56s    65.84%
        Req/Sec   147.85     93.29   390.00     64.74%
        Latency Distribution
        50%  390.68ms
        75%  650.05ms
        90%  964.04ms
        99%    1.37s
        3049 requests in 3.03s, 473.43KB read
        Requests/sec:   1006.16
        Transfer/sec:    156.23KB
        [run.sh] Speed is 1006.16, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   522.45ms  577.89ms   6.32s    86.22%
        Req/Sec   139.21     71.41   464.00     70.27%
        Latency Distribution
        50%  296.51ms
        75%  709.11ms
        90%    1.26s
        99%    2.69s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 18.511408
        stop time: 18.658779
        stop time: 18.710933
        stop time: 18.254470
        stop time: 18.603398
        stop time: 18.512459
        stop time: 18.700335
        stop time: 18.042401
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-5z8mq        65m          66Mi
        service1-7755b7b4b5-xdxf2        40m          42Mi
        service2-958786d58-tp2g6         102m         18Mi
        service3-6ddd8b8f64-l5657        177m         11Mi
        service4-9bb5bd9fd-44bjw         203m         10Mi
        ubuntu-client-76886f6bbd-ptmqh   19m          11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.511408, 18.658779, 18.710933, 18.25447, 18.603398, 18.512459, 18.700335, 18.042401]
    [exp] Throughput: 1081.1235736204578
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '520.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1530.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   657.75ms  417.60ms   2.52s    69.63%
        Req/Sec    86.96     48.77   210.00     66.85%
        Latency Distribution
        50%  590.79ms
        75%  941.73ms
        90%    1.17s
        99%    1.81s
        1784 requests in 3.04s, 277.01KB read
        Requests/sec:    587.59
        Transfer/sec:     91.24KB
        [run.sh] Speed is 587.59, duration is 51
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d51s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-656fc596d7-kvshz        1248m        73Mi
        service1-7755b7b4b5-x2btf        1183m        44Mi
        service2-959db6589-xksdx         875m         21Mi
        service3-84cb9dcd88-j2p5p        595m         13Mi
        service4-875c49d6-hsb7g          409m         10Mi
        ubuntu-client-76886f6bbd-8md84   27m          23Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   735.55ms  535.12ms   3.58s    73.90%
        Req/Sec    95.12     60.82   414.00     69.32%
        Latency Distribution
        50%  631.99ms
        75%  991.86ms
        90%    1.41s
        99%    2.87s
        20000 requests in 0.85m, 3.03MB read
        Requests/sec:    392.16
        Transfer/sec:     60.89KB
        ------------------------------
        stop time: 27.800095
        stop time: 27.154317
        stop time: 28.533183
        stop time: 29.083357
        stop time: 29.080038
        stop time: 29.209640
        stop time: 29.226544
        stop time: 28.946236
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.800095, 27.154317, 28.533183, 29.083357, 29.080038, 29.20964, 29.226544, 28.946236]
    [exp] Throughput: 698.5880356931332
[test.py] Finished running 2th optmization experiment: groundtruth->1081.1235736204578, slowdown->698.5880356931332, predicted->1097.5622990423453, err->1.5205223364834828
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000288', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   471.46ms  406.98ms   2.18s    79.82%
        Req/Sec   129.82     84.42   400.00     72.02%
        Latency Distribution
        50%  383.14ms
        75%  653.16ms
        90%  940.92ms
        99%    1.83s
        2766 requests in 3.02s, 429.49KB read
        Requests/sec:    917.16
        Transfer/sec:    142.41KB
        [run.sh] Speed is 917.16, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   529.79ms  631.76ms   4.58s    87.56%
        Req/Sec   139.51     74.04   454.00     70.77%
        Latency Distribution
        50%  307.38ms
        75%  667.34ms
        90%    1.30s
        99%    3.17s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 17.940238
        stop time: 17.417823
        stop time: 18.594212
        stop time: 17.350581
        stop time: 18.073942
        stop time: 18.688399
        stop time: 18.761920
        stop time: 18.153377
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-v54tf        3m           67Mi
        service1-7755b7b4b5-ps7j5        1m           40Mi
        service2-958786d58-vh5kj         1m           22Mi
        service3-6ddd8b8f64-dptqz        1m           12Mi
        service4-9bb5bd9fd-7gz8t         1m           9Mi
        ubuntu-client-76886f6bbd-zbb74   16m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.940238, 17.417823, 18.594212, 17.350581, 18.073942, 18.688399, 18.76192, 18.153377]
    [exp] Throughput: 1103.5967514857102
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '456.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1341.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   521.09ms  416.59ms   2.71s    70.12%
        Req/Sec    95.92     59.25   343.00     76.37%
        Latency Distribution
        50%  374.45ms
        75%  816.57ms
        90%    1.15s
        99%    1.67s
        1892 requests in 3.03s, 293.78KB read
        Requests/sec:    624.75
        Transfer/sec:     97.01KB
        [run.sh] Speed is 624.75, duration is 48
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d557f68bf-k5bsz        3m           57Mi
        service1-7755b7b4b5-ng5xx        426m         40Mi
        service2-54c8b5d4f9-q7tc8        314m         17Mi
        service3-697b6c488d-9tlns        204m         10Mi
        service4-6cfd9c977d-5b2zm        138m         8Mi
        ubuntu-client-76886f6bbd-88cbc   13m          0Mi
        Running 48s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   714.77ms  564.33ms   4.44s    79.84%
        Req/Sec    96.78     58.13   320.00     68.43%
        Latency Distribution
        50%  567.84ms
        75%  949.55ms
        90%    1.44s
        99%    2.77s
        20000 requests in 48.00s, 3.03MB read
        Requests/sec:    416.67
        Transfer/sec:     64.70KB
        ------------------------------
        stop time: 27.772797
        stop time: 27.797961
        stop time: 27.178544
        stop time: 27.919527
        stop time: 27.347876
        stop time: 27.906744
        stop time: 27.385134
        stop time: 27.895384
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.772797, 27.797961, 27.178544, 27.919527, 27.347876, 27.906744, 27.385134, 27.895384]
    [exp] Throughput: 723.3143336891421
[test.py] Finished running 3th optmization experiment: groundtruth->1103.5967514857102, slowdown->723.3143336891421, predicted->1079.3354820159468, err->-2.1983817401693
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000384', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   459.42ms  371.91ms   1.88s    68.71%
        Req/Sec   138.58     75.03   320.00     63.51%
        Latency Distribution
        50%  341.14ms
        75%  734.06ms
        90%  978.93ms
        99%    1.72s
        3000 requests in 3.02s, 465.82KB read
        Requests/sec:    991.81
        Transfer/sec:    154.00KB
        [run.sh] Speed is 991.81, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   507.46ms  492.05ms   4.61s    87.76%
        Req/Sec   139.45     76.50   464.00     68.48%
        Latency Distribution
        50%  364.41ms
        75%  675.03ms
        90%    1.09s
        99%    2.36s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.152889
        stop time: 18.013213
        stop time: 18.340697
        stop time: 18.410233
        stop time: 18.545542
        stop time: 18.642784
        stop time: 18.847317
        stop time: 18.730124
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-sgppn        645m         65Mi
        service1-7755b7b4b5-lqhfj        347m         37Mi
        service2-958786d58-x5gtf         452m         17Mi
        service3-6ddd8b8f64-q2vrx        422m         10Mi
        service4-9bb5bd9fd-sw97p         169m         9Mi
        ubuntu-client-76886f6bbd-b4kvb   11m          16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.152889, 18.013213, 18.340697, 18.410233, 18.545542, 18.642784, 18.847317, 18.730124]
    [exp] Throughput: 1083.4030847424553
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '391.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1152.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   648.29ms  353.15ms   1.93s    65.47%
        Req/Sec    94.37     60.18   250.00     63.45%
        Latency Distribution
        50%  576.72ms
        75%  888.28ms
        90%    1.08s
        99%    1.66s
        2013 requests in 3.03s, 312.57KB read
        Requests/sec:    663.55
        Transfer/sec:    103.03KB
        [run.sh] Speed is 663.55, duration is 45
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d45s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f5498d4b-bsk78         1376m        71Mi
        service1-7755b7b4b5-k7mwd        1304m        57Mi
        service2-77dd47bf4f-8qmrx        971m         29Mi
        service3-74947cdd48-69dqz        472m         15Mi
        service4-789d8dbcdb-nzkll        388m         10Mi
        ubuntu-client-76886f6bbd-tzcb8   30m          22Mi
        Running 45s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   673.48ms  499.47ms   3.74s    75.70%
        Req/Sec   102.07     58.49   393.00     65.32%
        Latency Distribution
        50%  566.60ms
        75%  875.29ms
        90%    1.29s
        99%    2.56s
        20000 requests in 45.00s, 3.03MB read
        Requests/sec:    444.44
        Transfer/sec:     69.01KB
        ------------------------------
        stop time: 25.536951
        stop time: 26.534575
        stop time: 26.210921
        stop time: 26.283238
        stop time: 26.373647
        stop time: 25.982726
        stop time: 26.267131
        stop time: 26.264809
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [25.536951, 26.534575, 26.210921, 26.283238, 26.373647, 25.982726, 26.267131, 26.264809]
    [exp] Throughput: 763.8908854821668
[test.py] Finished running 4th optmization experiment: groundtruth->1083.4030847424553, slowdown->763.8908854821668, predicted->1090.0623849515798, err->0.6146650589154916
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   459.76ms  302.73ms   2.06s    69.79%
        Req/Sec   146.50     77.49   370.00     68.50%
        Latency Distribution
        50%  413.69ms
        75%  613.92ms
        90%  875.15ms
        99%    1.33s
        3006 requests in 3.03s, 466.75KB read
        Requests/sec:    993.48
        Transfer/sec:    154.26KB
        [run.sh] Speed is 993.48, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   503.11ms  478.66ms   3.49s    87.45%
        Req/Sec   140.97     78.79   450.00     67.05%
        Latency Distribution
        50%  345.96ms
        75%  659.39ms
        90%    1.11s
        99%    2.30s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.657816
        stop time: 17.961176
        stop time: 18.353095
        stop time: 18.276367
        stop time: 18.671963
        stop time: 18.713254
        stop time: 18.840646
        stop time: 18.254315
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.657816, 17.961176, 18.353095, 18.276367, 18.671963, 18.713254, 18.840646, 18.254315]
    [exp] Throughput: 1083.0669575279082
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '327.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '962.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   612.96ms  362.16ms   1.99s    68.32%
        Req/Sec    89.39     53.65   230.00     64.76%
        Latency Distribution
        50%  541.62ms
        75%  793.68ms
        90%    1.08s
        99%    1.74s
        2087 requests in 3.03s, 324.06KB read
        Requests/sec:    689.87
        Transfer/sec:    107.12KB
        [run.sh] Speed is 689.87, duration is 43
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d43s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-59f9d8648d-lrsk6        35m          72Mi
        service1-7755b7b4b5-wsnft        140m         48Mi
        service2-745886db66-ls9dn        115m         20Mi
        service3-6fc4fcf464-g85x8        189m         10Mi
        service4-7486db89fd-wk8rb        256m         12Mi
        ubuntu-client-76886f6bbd-k6f45   2m           17Mi
        Running 43s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   641.99ms  540.38ms   4.96s    83.23%
        Req/Sec   104.83     56.44   360.00     70.68%
        Latency Distribution
        50%  500.27ms
        75%  828.53ms
        90%    1.29s
        99%    2.76s
        20000 requests in 43.00s, 3.03MB read
        Requests/sec:    465.11
        Transfer/sec:     72.22KB
        ------------------------------
        stop time: 24.543726
        stop time: 24.458586
        stop time: 24.869364
        stop time: 24.347684
        stop time: 25.264037
        stop time: 24.850768
        stop time: 25.274805
        stop time: 25.220040
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.543726, 24.458586, 24.869364, 24.347684, 25.264037, 24.850768, 25.274805, 25.22004]
    [exp] Throughput: 804.7115458654649
[test.py] Finished running 5th optmization experiment: groundtruth->1083.0669575279082, slowdown->804.7115458654649, predicted->1092.546903140978, err->0.8752871230332455
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000576', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   504.26ms  380.23ms   2.08s    71.61%
        Req/Sec   143.66     78.01   380.00     62.23%
        Latency Distribution
        50%  375.67ms
        75%  741.68ms
        90%    1.03s
        99%    1.84s
        2779 requests in 3.03s, 431.50KB read
        Requests/sec:    917.63
        Transfer/sec:    142.48KB
        [run.sh] Speed is 917.63, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   493.70ms  465.07ms   4.73s    87.70%
        Req/Sec   140.76     75.57   646.00     67.27%
        Latency Distribution
        50%  360.29ms
        75%  661.59ms
        90%    1.01s
        99%    2.41s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 17.933992
        stop time: 18.566458
        stop time: 18.648270
        stop time: 18.790435
        stop time: 17.781823
        stop time: 18.563481
        stop time: 18.547378
        stop time: 18.338626
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-78q4t        1936m        68Mi
        service1-7755b7b4b5-4jgpd        1249m        54Mi
        service2-958786d58-jc8qr         1370m        26Mi
        service3-6ddd8b8f64-zqt95        908m         16Mi
        service4-9bb5bd9fd-mptkg         439m         10Mi
        ubuntu-client-76886f6bbd-zj6p4   41m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.933992, 18.566458, 18.64827, 18.790435, 17.781823, 18.563481, 18.547378, 18.338626]
    [exp] Throughput: 1087.1746730864058
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '263.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '773.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   542.38ms  306.97ms   2.10s    65.96%
        Req/Sec   111.15     63.98   292.00     64.97%
        Latency Distribution
        50%  517.98ms
        75%  733.57ms
        90%  946.95ms
        99%    1.29s
        2238 requests in 3.03s, 347.50KB read
        Requests/sec:    737.81
        Transfer/sec:    114.56KB
        [run.sh] Speed is 737.81, duration is 40
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d40s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 40s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   605.09ms  472.38ms   3.88s    76.46%
        Req/Sec   112.63     63.83   430.00     69.02%
        Latency Distribution
        50%  505.68ms
        75%  834.85ms
        90%    1.19s
        99%    2.22s
        20000 requests in 40.00s, 3.03MB read
        Requests/sec:    500.00
        Transfer/sec:     77.64KB
        ------------------------------
        stop time: 23.699123
        stop time: 23.641891
        stop time: 23.028123
        stop time: 23.137868
        stop time: 23.967589
        stop time: 23.986893
        stop time: 24.080368
        stop time: 23.889979
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [23.699123, 23.641891, 23.028123, 23.137868, 23.967589, 23.986893, 24.080368, 23.889979]
    [exp] Throughput: 844.6310032557674
[test.py] Finished running 6th optmization experiment: groundtruth->1087.1746730864058, slowdown->844.6310032557674, predicted->1085.9176261167422, err->-0.11562511533633997
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000672', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   527.70ms  427.04ms   2.22s    74.03%
        Req/Sec   142.75     84.90   373.00     65.97%
        Latency Distribution
        50%  442.63ms
        75%  771.80ms
        90%    1.07s
        99%    1.94s
        2802 requests in 3.03s, 435.08KB read
        Requests/sec:    925.27
        Transfer/sec:    143.67KB
        [run.sh] Speed is 925.27, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   481.93ms  395.82ms   3.26s    78.75%
        Req/Sec   141.35     77.47   490.00     65.23%
        Latency Distribution
        50%  368.65ms
        75%  644.97ms
        90%  997.56ms
        99%    1.92s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 17.990503
        stop time: 18.098073
        stop time: 18.249842
        stop time: 18.471591
        stop time: 18.780161
        stop time: 18.789095
        stop time: 18.683767
        stop time: 18.580963
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-j72rs        145m         72Mi
        service1-7755b7b4b5-pqpfh        48m          64Mi
        service2-958786d58-2b7d9         61m          35Mi
        service3-6ddd8b8f64-dqrrk        219m         12Mi
        service4-9bb5bd9fd-zv277         189m         9Mi
        ubuntu-client-76886f6bbd-kwbds   4m           16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.990503, 18.098073, 18.249842, 18.471591, 18.780161, 18.789095, 18.683767, 18.580963]
    [exp] Throughput: 1083.6878262471835
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '198.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   621.25ms  391.17ms   1.78s    58.41%
        Req/Sec   121.17     69.89   333.00     66.27%
        Latency Distribution
        50%  570.14ms
        75%  944.55ms
        90%    1.15s
        99%    1.46s
        2132 requests in 3.03s, 331.04KB read
        Requests/sec:    703.49
        Transfer/sec:    109.23KB
        [run.sh] Speed is 703.49, duration is 42
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6b6b7b9f5-dwrdz         1112m        70Mi
        service1-7755b7b4b5-ttqqm        1147m        52Mi
        service2-7cf4598c6b-hqf9b        895m         26Mi
        service3-55998c8697-mlzxn        735m         16Mi
        service4-6866646d59-82vlg        528m         11Mi
        ubuntu-client-76886f6bbd-xb76h   28m          21Mi
        Running 42s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   585.43ms  543.76ms   4.62s    85.61%
        Req/Sec   115.84     61.51   343.00     64.70%
        Latency Distribution
        50%  426.45ms
        75%  812.46ms
        90%    1.22s
        99%    2.77s
        20000 requests in 42.00s, 3.03MB read
        Requests/sec:    476.19
        Transfer/sec:     73.94KB
        ------------------------------
        stop time: 22.614665
        stop time: 22.401374
        stop time: 21.784253
        stop time: 22.425052
        stop time: 21.929908
        stop time: 22.325597
        stop time: 21.731648
        stop time: 22.670527
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.614665, 22.401374, 21.784253, 22.425052, 21.929908, 22.325597, 21.731648, 22.670527]
    [exp] Throughput: 899.4675062416298
[test.py] Finished running 7th optmization experiment: groundtruth->1083.6878262471835, slowdown->899.4675062416298, predicted->1095.2661392668135, err->1.0684177434866844
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000768', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   406.01ms  443.35ms   1.87s    80.08%
        Req/Sec   153.18     61.64   370.00     76.04%
        Latency Distribution
        50%  138.10ms
        75%  737.54ms
        90%    1.11s
        99%    1.65s
        2968 requests in 3.03s, 460.85KB read
        Requests/sec:    979.33
        Transfer/sec:    152.06KB
        [run.sh] Speed is 979.33, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   485.76ms  437.58ms   3.71s    83.08%
        Req/Sec   139.11     73.31   434.00     72.48%
        Latency Distribution
        50%  358.32ms
        75%  654.31ms
        90%    1.05s
        99%    2.13s
        20001 requests in 30.00s, 3.03MB read
        Requests/sec:    666.70
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.172514
        stop time: 18.006684
        stop time: 18.250784
        stop time: 18.236286
        stop time: 18.425368
        stop time: 18.634979
        stop time: 18.543373
        stop time: 18.699509
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-zbbkt   3m           3Mi
        service1-7755b7b4b5-qj5db   3m           3Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.172514, 18.006684, 18.250784, 18.236286, 18.425368, 18.634979, 18.543373, 18.699509]
    [exp] Throughput: 1088.661275067166
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '134.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '395.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service2-8494b645-7v6rn cannot connect to service0
        [run.sh] service2-8494b645-7v6rn cannot connect to service0
        [run.sh] service3-66c8557867-cc5wr cannot connect to service0
        [run.sh] service3-66c8557867-cc5wr cannot connect to service0
        [run.sh] service4-5df98d9dbf-cgf4x cannot connect to service0
        [run.sh] ubuntu-client-76886f6bbd-69dz5 cannot connect to service0
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   509.89ms  444.92ms   2.01s    75.63%
        Req/Sec   128.54     53.74   290.00     72.11%
        Latency Distribution
        50%  375.49ms
        75%  806.36ms
        90%    1.08s
        99%    1.88s
        2467 requests in 3.03s, 383.06KB read
        Requests/sec:    813.74
        Transfer/sec:    126.35KB
        [run.sh] Speed is 813.74, duration is 36
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d36s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d8764fc6b-x5sn6        438m         64Mi
        service1-7755b7b4b5-t9k7j        234m         65Mi
        service2-8494b645-7v6rn          142m         33Mi
        service3-66c8557867-cc5wr        5m           10Mi
        service4-5df98d9dbf-cgf4x        5m           9Mi
        ubuntu-client-76886f6bbd-69dz5   11m          0Mi
        Running 36s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   543.05ms  481.50ms   3.96s    83.16%
        Req/Sec   124.85     65.92   550.00     72.72%
        Latency Distribution
        50%  411.14ms
        75%  709.66ms
        90%    1.15s
        99%    2.39s
        20000 requests in 36.00s, 3.03MB read
        Requests/sec:    555.55
        Transfer/sec:     86.26KB
        ------------------------------
        stop time: 20.167563
        stop time: 19.870941
        stop time: 19.861456
        stop time: 20.405980
        stop time: 21.008197
        stop time: 20.999903
        stop time: 21.334705
        stop time: 21.249981
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > curl: (28) Connection timed out after 1002 milliseconds
        > command terminated with exit code 28
    [exp] Times: [20.167563, 19.870941, 19.861456, 20.40598, 21.008197, 20.999903, 21.334705, 21.249981]
    [exp] Throughput: 970.2925176025919
[test.py] Finished running 8th optmization experiment: groundtruth->1088.661275067166, slowdown->970.2925176025919, predicted->1115.8370062851889, err->2.4962522173250212
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   476.17ms  413.67ms   2.93s    69.88%
        Req/Sec   141.65     57.14   310.00     70.10%
        Latency Distribution
        50%  385.92ms
        75%  750.19ms
        90%    1.06s
        99%    1.51s
        2815 requests in 3.03s, 437.09KB read
        Requests/sec:    928.81
        Transfer/sec:    144.22KB
        [run.sh] Speed is 928.81, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   485.19ms  471.95ms   4.59s    87.83%
        Req/Sec   137.35     69.63   670.00     69.32%
        Latency Distribution
        50%  347.78ms
        75%  648.40ms
        90%    1.05s
        99%    2.32s
        20001 requests in 32.00s, 3.03MB read
        Requests/sec:    625.03
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.854837
        stop time: 18.212713
        stop time: 18.438933
        stop time: 18.251748
        stop time: 18.672738
        stop time: 18.557844
        stop time: 18.573202
        stop time: 18.526808
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-x2vwg        1950m        68Mi
        service1-7755b7b4b5-wr549        1606m        57Mi
        service2-958786d58-lrmnt         1345m        28Mi
        service3-6ddd8b8f64-b2g2x        786m         12Mi
        service4-9bb5bd9fd-xlpbb         417m         11Mi
        ubuntu-client-76886f6bbd-vs265   42m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.854837, 18.212713, 18.438933, 18.251748, 18.672738, 18.557844, 18.573202, 18.526808]
    [exp] Throughput: 1080.4326535838563
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '70.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '206.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   533.66ms  352.03ms   1.83s    74.18%
        Req/Sec   129.38     77.21   320.00     68.84%
        Latency Distribution
        50%  424.91ms
        75%  688.81ms
        90%    1.12s
        99%    1.58s
        2646 requests in 3.02s, 410.85KB read
        Requests/sec:    875.03
        Transfer/sec:    135.87KB
        [run.sh] Speed is 875.03, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   516.72ms  447.57ms   4.07s    80.18%
        Req/Sec   128.91     63.08   400.00     70.16%
        Latency Distribution
        50%  407.26ms
        75%  702.94ms
        90%    1.08s
        99%    2.20s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.458093
        stop time: 18.900797
        stop time: 19.531837
        stop time: 20.018742
        stop time: 19.987376
        stop time: 19.995851
        stop time: 19.995151
        stop time: 19.945567
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.458093, 18.900797, 19.531837, 20.018742, 19.987376, 19.995851, 19.995151, 19.945567]
    [exp] Throughput: 1013.7270426146899
[test.py] Finished running 9th optmization experiment: groundtruth->1080.4326535838563, slowdown->1013.7270426146899, predicted->1091.286035987094, err->1.0045403910402364
[test.py] Baseline throughput:  1081.7140957846068
[test.py] Groundtruth:  [1084.4632361438964, 1084.367961562409, 1081.1235736204578, 1103.5967514857102, 1083.4030847424553, 1083.0669575279082, 1087.1746730864058, 1083.6878262471835, 1088.661275067166, 1080.4326535838563]
[test.py] Slowdown:  [637.6921817910234, 665.8178543235645, 698.5880356931332, 723.3143336891421, 763.8908854821668, 804.7115458654649, 844.6310032557674, 899.4675062416298, 970.2925176025919, 1013.7270426146899]
[test.py] Predicted:  [1087.942869073705, 1090.2230878532976, 1097.5622990423453, 1079.3354820159468, 1090.0623849515798, 1092.546903140978, 1085.9176261167422, 1095.2661392668135, 1115.8370062851889, 1091.286035987094]
[test.py] Error percentage:  [0.320862230625845, 0.5399575142788501, 1.5205223364834828, -2.1983817401693, 0.6146650589154916, 0.8752871230332455, -0.11562511533633997, 1.0684177434866844, 2.4962522173250212, 1.0045403910402364]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 2...
[test.py] Actual processing time range: [0, 96, 192, 288, 384, 480, 576, 672, 768, 864]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   495.80ms  365.67ms   2.45s    75.26%
        Req/Sec   132.02     69.52   343.00     66.50%
        Latency Distribution
        50%  398.09ms
        75%  696.02ms
        90%  990.37ms
        99%    1.60s
        2779 requests in 3.04s, 431.50KB read
        Requests/sec:    915.60
        Transfer/sec:    142.17KB
        [run.sh] Speed is 915.60, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   482.73ms  413.82ms   3.51s    84.87%
        Req/Sec   137.21     64.74   363.00     67.45%
        Latency Distribution
        50%  364.18ms
        75%  621.67ms
        90%  981.86ms
        99%    2.10s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.229947
        stop time: 18.295509
        stop time: 18.551878
        stop time: 18.624908
        stop time: 18.335969
        stop time: 18.749040
        stop time: 18.618351
        stop time: 18.871799
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-swbzn        329m         71Mi
        service1-7755b7b4b5-rfq24        103m         59Mi
        service2-958786d58-f96kk         64m          27Mi
        service3-6ddd8b8f64-grvqw        159m         12Mi
        service4-9bb5bd9fd-hr6tk         194m         9Mi
        ubuntu-client-76886f6bbd-wb6xh   10m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.229947, 18.295509, 18.551878, 18.624908, 18.335969, 18.74904, 18.618351, 18.871799]
    [exp] Throughput: 1079.0585680686431
[test.py] Baseline throughput: 1079.0585680686431
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   462.02ms  330.03ms   1.62s    65.84%
        Req/Sec   143.76     72.75   353.00     62.38%
        Latency Distribution
        50%  399.70ms
        75%  673.36ms
        90%  916.25ms
        99%    1.35s
        2934 requests in 3.03s, 455.57KB read
        Requests/sec:    968.25
        Transfer/sec:    150.34KB
        [run.sh] Speed is 968.25, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   546.71ms  637.08ms   5.27s    86.59%
        Req/Sec   138.94     71.05   570.00     70.52%
        Latency Distribution
        50%  282.70ms
        75%  690.04ms
        90%    1.48s
        99%    2.73s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 17.812282
        stop time: 17.233892
        stop time: 18.563615
        stop time: 18.649127
        stop time: 18.518443
        stop time: 18.508147
        stop time: 17.933836
        stop time: 18.765220
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-grjcx        1939m        72Mi
        service1-7755b7b4b5-s6g9b        216m         54Mi
        service2-958786d58-7dm4n         606m         32Mi
        service3-6ddd8b8f64-j67fs        592m         14Mi
        service4-9bb5bd9fd-mf5w8         551m         11Mi
        ubuntu-client-76886f6bbd-mfjvw   27m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.812282, 17.233892, 18.563615, 18.649127, 18.518443, 18.508147, 17.933836, 18.76522]
    [exp] Throughput: 1096.0063023650407
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '648.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1908.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   796.39ms  679.81ms   2.76s    74.42%
        Req/Sec    75.90     58.37   290.00     79.35%
        Latency Distribution
        50%  590.23ms
        75%    1.22s
        90%    1.66s
        99%    2.54s
        1517 requests in 3.03s, 235.55KB read
        Requests/sec:    501.08
        Transfer/sec:     77.80KB
        [run.sh] Speed is 501.08, duration is 59
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service1-7755b7b4b5-mxvq7        281m         36Mi
        service2-59f85f9ccc-lr95l        179m         15Mi
        service3-f478494d6-95hdc         16m          9Mi
        service4-57b78cdf48-vhbb8        3m           8Mi
        ubuntu-client-76886f6bbd-4zz5x   6m           10Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   800.68ms  570.68ms   4.70s    75.29%
        Req/Sec    84.81     56.85   333.00     71.18%
        Latency Distribution
        50%  683.45ms
        75%    1.07s
        90%    1.48s
        99%    2.81s
        20000 requests in 0.98m, 3.03MB read
        Requests/sec:    338.98
        Transfer/sec:     52.63KB
        ------------------------------
        stop time: 30.770734
        stop time: 32.052760
        stop time: 30.749497
        stop time: 31.059649
        stop time: 31.835230
        stop time: 31.366988
        stop time: 31.731526
        stop time: 31.500480
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [30.770734, 32.05276, 30.749497, 31.059649, 31.83523, 31.366988, 31.731526, 31.50048]
    [exp] Throughput: 637.2804337891439
[test.py] Finished running 0th optmization experiment: groundtruth->1096.0063023650407, slowdown->637.2804337891439, predicted->1086.7449608451223, err->-0.845008053323569
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '9.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   542.37ms  512.47ms   2.94s    84.52%
        Req/Sec   136.67     82.18   370.00     62.62%
        Latency Distribution
        50%  338.01ms
        75%  772.76ms
        90%    1.30s
        99%    2.41s
        2994 requests in 3.03s, 464.89KB read
        Requests/sec:    988.46
        Transfer/sec:    153.48KB
        [run.sh] Speed is 988.46, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   511.38ms  536.91ms   5.15s    87.77%
        Req/Sec   139.01     72.74   540.00     68.41%
        Latency Distribution
        50%  337.80ms
        75%  677.95ms
        90%    1.17s
        99%    2.64s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 17.899259
        stop time: 18.188402
        stop time: 18.371717
        stop time: 18.842945
        stop time: 18.693117
        stop time: 18.651232
        stop time: 18.367143
        stop time: 17.951522
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service3-6ddd8b8f64-7cgnp        3m           8Mi
        service4-9bb5bd9fd-lrbpw         3m           7Mi
        ubuntu-client-76886f6bbd-bh4lz   6m           9Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.899259, 18.188402, 18.371717, 18.842945, 18.693117, 18.651232, 18.367143, 17.951522]
    [exp] Throughput: 1088.692090707076
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1719.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   808.06ms  424.05ms   2.53s    77.63%
        Req/Sec    91.25     71.85   333.00     73.58%
        Latency Distribution
        50%  749.28ms
        75%    1.01s
        90%    1.24s
        99%    2.19s
        1644 requests in 3.03s, 255.27KB read
        Requests/sec:    542.79
        Transfer/sec:     84.28KB
        [run.sh] Speed is 542.79, duration is 55
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6979b6d9d6-t8xn8        567m         72Mi
        service1-7755b7b4b5-crz27        410m         51Mi
        service2-667bd658d5-pvtgr        276m         25Mi
        service3-67579fdbfc-7cz97        558m         12Mi
        service4-6b47687759-952g9        325m         13Mi
        ubuntu-client-76886f6bbd-r5c6g   30m          20Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   769.93ms  566.78ms   3.87s    74.00%
        Req/Sec    89.10     55.72   363.00     66.73%
        Latency Distribution
        50%  660.09ms
        75%    1.03s
        90%    1.49s
        99%    2.73s
        20000 requests in 0.92m, 3.03MB read
        Requests/sec:    363.64
        Transfer/sec:     56.46KB
        ------------------------------
        stop time: 29.559794
        stop time: 30.390584
        stop time: 29.846074
        stop time: 30.143688
        stop time: 30.147635
        stop time: 30.378058
        stop time: 29.940711
        stop time: 30.586671
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [29.559794, 30.390584, 29.846074, 30.143688, 30.147635, 30.378058, 29.940711, 30.586671]
    [exp] Throughput: 663.9191066022336
[test.py] Finished running 1th optmization experiment: groundtruth->1088.692090707076, slowdown->663.9191066022336, predicted->1085.1415119820613, err->-0.3261324992917601
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000192', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   494.31ms  374.67ms   2.44s    77.85%
        Req/Sec   127.36     77.60   390.00     65.18%
        Latency Distribution
        50%  362.60ms
        75%  655.94ms
        90%    1.07s
        99%    1.68s
        2902 requests in 3.03s, 450.60KB read
        Requests/sec:    956.79
        Transfer/sec:    148.56KB
        [run.sh] Speed is 956.79, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   545.61ms  629.48ms   5.38s    88.06%
        Req/Sec   142.37     79.63   510.00     70.75%
        Latency Distribution
        50%  316.72ms
        75%  648.16ms
        90%    1.29s
        99%    3.01s
        20001 requests in 31.00s, 3.03MB read
        Requests/sec:    645.19
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.144823
        stop time: 18.196056
        stop time: 18.173390
        stop time: 18.295194
        stop time: 18.938553
        stop time: 18.776029
        stop time: 18.893307
        stop time: 18.414638
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-rtkxw        1619m        72Mi
        service1-7755b7b4b5-sldqz        555m         48Mi
        service2-958786d58-pxjgj         941m         26Mi
        service3-6ddd8b8f64-97lt8        922m         13Mi
        service4-9bb5bd9fd-9xnxt         626m         9Mi
        ubuntu-client-76886f6bbd-7brj6   40m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.144823, 18.196056, 18.17339, 18.295194, 18.938553, 18.776029, 18.893307, 18.414638]
    [exp] Throughput: 1082.30972200266
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '520.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1530.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   774.46ms  625.71ms   2.98s    76.94%
        Req/Sec    91.15     67.01   280.00     65.24%
        Latency Distribution
        50%  584.53ms
        75%    1.08s
        90%    1.60s
        99%    2.84s
        1754 requests in 3.02s, 272.35KB read
        Requests/sec:    579.93
        Transfer/sec:     90.05KB
        [run.sh] Speed is 579.93, duration is 51
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d51s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   765.44ms  676.86ms   5.60s    80.57%
        Req/Sec    95.58     56.85   410.00     69.76%
        Latency Distribution
        50%  615.31ms
        75%    1.01s
        90%    1.59s
        99%    3.35s
        20000 requests in 0.85m, 3.03MB read
        Requests/sec:    392.16
        Transfer/sec:     60.89KB
        ------------------------------
        stop time: 29.410935
        stop time: 28.939564
        stop time: 29.015971
        stop time: 29.208626
        stop time: 28.709567
        stop time: 29.202957
        stop time: 28.999025
        stop time: 28.917252
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [29.410935, 28.939564, 29.015971, 29.208626, 28.709567, 29.202957, 28.999025, 28.917252]
    [exp] Throughput: 688.4566139611678
[test.py] Finished running 2th optmization experiment: groundtruth->1082.30972200266, slowdown->688.4566139611678, predicted->1072.7593030038756, err->-0.882410903702564
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000288', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   467.79ms  321.15ms   2.54s    78.26%
        Req/Sec   134.14     71.67   360.00     65.38%
        Latency Distribution
        50%  368.05ms
        75%  623.71ms
        90%  902.86ms
        99%    1.57s
        2988 requests in 3.03s, 463.96KB read
        Requests/sec:    985.47
        Transfer/sec:    153.02KB
        [run.sh] Speed is 985.47, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   469.38ms  354.17ms   2.75s    75.36%
        Req/Sec   141.32     79.85   630.00     68.80%
        Latency Distribution
        50%  391.67ms
        75%  636.84ms
        90%  922.90ms
        99%    1.72s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 17.303491
        stop time: 18.704888
        stop time: 18.544151
        stop time: 18.723079
        stop time: 18.672094
        stop time: 18.533027
        stop time: 18.384371
        stop time: 18.821412
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service4-9bb5bd9fd-9fgpj         3m           3Mi
        ubuntu-client-76886f6bbd-n62jh   5m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.303491, 18.704888, 18.544151, 18.723079, 18.672094, 18.533027, 18.384371, 18.821412]
    [exp] Throughput: 1083.3758394715433
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '456.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1341.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   690.88ms  285.71ms   1.48s    66.08%
        Req/Sec    97.87     78.65   505.00     81.40%
        Latency Distribution
        50%  737.12ms
        75%  851.71ms
        90%    1.06s
        99%    1.32s
        1937 requests in 3.03s, 300.76KB read
        Requests/sec:    639.64
        Transfer/sec:     99.32KB
        [run.sh] Speed is 639.64, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d557f68bf-9scqr        744m         66Mi
        service1-7755b7b4b5-vwzxv        545m         55Mi
        service2-54c8b5d4f9-79m8x        383m         24Mi
        service3-697b6c488d-lhxfd        106m         14Mi
        service4-6cfd9c977d-w2bmp        405m         13Mi
        ubuntu-client-76886f6bbd-9dg2w   32m          19Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   713.24ms  599.20ms   5.94s    79.65%
        Req/Sec    96.18     55.43   363.00     66.22%
        Latency Distribution
        50%  585.42ms
        75%  953.52ms
        90%    1.43s
        99%    2.80s
        20001 requests in 46.00s, 3.03MB read
        Requests/sec:    434.80
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 25.663501
        stop time: 26.535410
        stop time: 27.265770
        stop time: 27.255230
        stop time: 27.921601
        stop time: 27.816194
        stop time: 27.763523
        stop time: 27.390813
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [25.663501, 26.53541, 27.26577, 27.25523, 27.921601, 27.816194, 27.763523, 27.390813]
    [exp] Throughput: 735.2534286682536
[test.py] Finished running 3th optmization experiment: groundtruth->1083.3758394715433, slowdown->735.2534286682536, predicted->1106.137838573756, err->2.1010251726968288
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000384', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   479.18ms  345.16ms   1.75s    73.10%
        Req/Sec   144.57     75.33   370.00     67.61%
        Latency Distribution
        50%  417.85ms
        75%  679.82ms
        90%  882.93ms
        99%    1.68s
        2633 requests in 3.03s, 408.83KB read
        Requests/sec:    868.19
        Transfer/sec:    134.81KB
        [run.sh] Speed is 868.19, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   488.63ms  471.60ms   3.60s    86.91%
        Req/Sec   140.83     77.51   464.00     69.28%
        Latency Distribution
        50%  355.02ms
        75%  620.73ms
        90%    1.11s
        99%    2.33s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 17.536832
        stop time: 17.854755
        stop time: 18.208902
        stop time: 18.838475
        stop time: 18.662890
        stop time: 18.486169
        stop time: 18.818944
        stop time: 18.815407
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-dmbzp        1933m        74Mi
        service1-7755b7b4b5-9ht7z        1000m        63Mi
        service2-958786d58-pfjs2         1366m        38Mi
        service3-6ddd8b8f64-xdrnm        915m         14Mi
        service4-9bb5bd9fd-cv4z7         618m         11Mi
        ubuntu-client-76886f6bbd-77pvt   30m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.536832, 17.854755, 18.208902, 18.838475, 18.66289, 18.486169, 18.818944, 18.815407]
    [exp] Throughput: 1086.7913324098415
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '391.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1152.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   736.66ms  617.50ms   2.76s    75.93%
        Req/Sec   109.52     61.85   323.00     70.11%
        Latency Distribution
        50%  509.51ms
        75%    1.10s
        90%    1.61s
        99%    2.45s
        2056 requests in 3.03s, 319.24KB read
        Requests/sec:    678.61
        Transfer/sec:    105.37KB
        [run.sh] Speed is 678.61, duration is 44
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d44s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f5498d4b-vgj5s         3m           3Mi
        ubuntu-client-76886f6bbd-jk9fk   6m           0Mi
        Running 44s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   695.36ms  571.08ms   6.50s    82.29%
        Req/Sec    98.56     57.70   323.00     66.84%
        Latency Distribution
        50%  565.33ms
        75%  866.59ms
        90%    1.33s
        99%    3.02s
        20000 requests in 44.00s, 3.03MB read
        Requests/sec:    454.54
        Transfer/sec:     70.58KB
        ------------------------------
        stop time: 26.346290
        stop time: 26.388697
        stop time: 26.306656
        stop time: 25.996461
        stop time: 26.287681
        stop time: 26.503619
        stop time: 26.660200
        stop time: 26.513961
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.34629, 26.388697, 26.306656, 25.996461, 26.287681, 26.503619, 26.6602, 26.513961]
    [exp] Throughput: 758.2810271475745
[test.py] Finished running 4th optmization experiment: groundtruth->1086.7913324098415, slowdown->758.2810271475745, predicted->1078.6747835775566, err->-0.7468359923599474
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   560.13ms  478.22ms   2.71s    76.92%
        Req/Sec   138.94     80.86   383.00     70.31%
        Latency Distribution
        50%  338.76ms
        75%  879.03ms
        90%    1.19s
        99%    1.98s
        2710 requests in 3.04s, 420.79KB read
        Requests/sec:    892.43
        Transfer/sec:    138.57KB
        [run.sh] Speed is 892.43, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   506.37ms  539.80ms   5.45s    90.44%
        Req/Sec   140.15     71.29   380.00     67.96%
        Latency Distribution
        50%  350.65ms
        75%  662.57ms
        90%    1.02s
        99%    2.67s
        20001 requests in 33.00s, 3.03MB read
        Requests/sec:    606.09
        Transfer/sec:     94.11KB
        ------------------------------
        stop time: 17.719200
        stop time: 18.444167
        stop time: 18.790061
        stop time: 18.695098
        stop time: 18.103008
        stop time: 18.421816
        stop time: 18.694420
        stop time: 18.036758
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-kffrc        261m         62Mi
        service1-7755b7b4b5-hldsn        333m         74Mi
        service2-958786d58-qxbch         416m         41Mi
        service3-6ddd8b8f64-44twt        270m         10Mi
        service4-9bb5bd9fd-zcj8f         188m         11Mi
        ubuntu-client-76886f6bbd-d9s6r   7m           9Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.7192, 18.444167, 18.790061, 18.695098, 18.103008, 18.421816, 18.69442, 18.036758]
    [exp] Throughput: 1089.1427390175475
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '327.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '962.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   683.82ms  460.50ms   2.74s    75.87%
        Req/Sec    98.11     58.17   290.00     69.47%
        Latency Distribution
        50%  556.62ms
        75%  863.68ms
        90%    1.33s
        99%    2.18s
        2118 requests in 3.03s, 328.87KB read
        Requests/sec:    698.92
        Transfer/sec:    108.52KB
        [run.sh] Speed is 698.92, duration is 42
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-59f9d8648d-crj44        1475m        76Mi
        service1-7755b7b4b5-dtqm9        1322m        55Mi
        service2-745886db66-89qkk        991m         22Mi
        service3-6fc4fcf464-ghqjp        683m         14Mi
        service4-7486db89fd-86fd6        466m         10Mi
        ubuntu-client-76886f6bbd-g2pdp   31m          21Mi
        Running 42s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   643.25ms  482.14ms   4.88s    76.25%
        Req/Sec   104.47     60.15   400.00     66.81%
        Latency Distribution
        50%  550.79ms
        75%  856.44ms
        90%    1.23s
        99%    2.41s
        20000 requests in 42.00s, 3.03MB read
        Requests/sec:    476.19
        Transfer/sec:     73.94KB
        ------------------------------
        stop time: 24.804729
        stop time: 24.329870
        stop time: 25.199724
        stop time: 24.787314
        stop time: 25.254099
        stop time: 25.027106
        stop time: 25.064297
        stop time: 25.045684
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.804729, 24.32987, 25.199724, 24.787314, 25.254099, 25.027106, 25.064297, 25.045684]
    [exp] Throughput: 801.9534664195494
[test.py] Finished running 5th optmization experiment: groundtruth->1089.1427390175475, slowdown->801.9534664195494, predicted->1087.4691171514507, err->-0.15366414393088523
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000576', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   562.87ms  553.20ms   2.77s    84.94%
        Req/Sec   130.45     72.52   360.00     68.64%
        Latency Distribution
        50%  331.88ms
        75%  753.66ms
        90%    1.41s
        99%    2.53s
        2886 requests in 3.03s, 448.12KB read
        Requests/sec:    953.33
        Transfer/sec:    148.03KB
        [run.sh] Speed is 953.33, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   486.82ms  412.43ms   3.15s    84.79%
        Req/Sec   139.52     78.11   424.00     66.05%
        Latency Distribution
        50%  369.56ms
        75%  610.56ms
        90%  985.19ms
        99%    2.15s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.080332
        stop time: 17.958016
        stop time: 18.373913
        stop time: 18.711160
        stop time: 18.611528
        stop time: 18.615129
        stop time: 18.797350
        stop time: 18.537045
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.080332, 17.958016, 18.373913, 18.71116, 18.611528, 18.615129, 18.79735, 18.537045]
    [exp] Throughput: 1083.3908043941763
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '263.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '773.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   640.03ms  400.37ms   2.20s    74.12%
        Req/Sec   113.69     78.20   393.00     68.97%
        Latency Distribution
        50%  564.53ms
        75%  857.94ms
        90%    1.20s
        99%    1.83s
        2177 requests in 3.03s, 338.03KB read
        Requests/sec:    718.69
        Transfer/sec:    111.59KB
        [run.sh] Speed is 718.69, duration is 41
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d41s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6dd6844b8c-h4z2v        505m         68Mi
        service1-7755b7b4b5-2zslb        634m         61Mi
        service2-cf56db458-94bg7         443m         36Mi
        service3-767df97779-4hjrt        71m          11Mi
        service4-75dbf88985-4gggj        76m          11Mi
        ubuntu-client-76886f6bbd-tdtn7   12m          16Mi
        Running 41s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   602.42ms  479.59ms   3.91s    74.77%
        Req/Sec   111.98     67.01   414.00     67.21%
        Latency Distribution
        50%  486.81ms
        75%  827.38ms
        90%    1.24s
        99%    2.27s
        20000 requests in 41.00s, 3.03MB read
        Requests/sec:    487.80
        Transfer/sec:     75.74KB
        ------------------------------
        stop time: 22.519878
        stop time: 23.522777
        stop time: 23.574119
        stop time: 23.368302
        stop time: 23.761708
        stop time: 23.690880
        stop time: 23.990784
        stop time: 23.494409
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.519878, 23.522777, 23.574119, 23.368302, 23.761708, 23.69088, 23.990784, 23.494409]
    [exp] Throughput: 851.4131945109798
[test.py] Finished running 6th optmization experiment: groundtruth->1083.3908043941763, slowdown->851.4131945109798, predicted->1097.1540242899891, err->1.27038367318515
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000672', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   474.28ms  446.75ms   2.94s    85.22%
        Req/Sec   138.97     68.35   373.00     68.59%
        Latency Distribution
        50%  274.58ms
        75%  751.25ms
        90%    1.12s
        99%    2.05s
        2681 requests in 3.03s, 416.29KB read
        Requests/sec:    885.98
        Transfer/sec:    137.57KB
        [run.sh] Speed is 885.98, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   485.84ms  445.93ms   3.32s    83.80%
        Req/Sec   141.58     70.54   530.00     67.49%
        Latency Distribution
        50%  357.02ms
        75%  669.09ms
        90%    1.03s
        99%    2.20s
        20001 requests in 33.00s, 3.03MB read
        Requests/sec:    606.09
        Transfer/sec:     94.11KB
        ------------------------------
        stop time: 18.107488
        stop time: 18.071704
        stop time: 18.299273
        stop time: 18.508742
        stop time: 18.604375
        stop time: 18.558317
        stop time: 18.668478
        stop time: 18.835543
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-wf6pg        1941m        72Mi
        service1-7755b7b4b5-4btb5        785m         57Mi
        service2-958786d58-9k2j8         821m         30Mi
        service3-6ddd8b8f64-j99br        848m         14Mi
        service4-9bb5bd9fd-ml9nw         635m         11Mi
        ubuntu-client-76886f6bbd-6mqlk   41m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.107488, 18.071704, 18.299273, 18.508742, 18.604375, 18.558317, 18.668478, 18.835543]
    [exp] Throughput: 1083.614982927646
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '198.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   556.63ms  320.14ms   1.76s    68.24%
        Req/Sec   107.10     70.83   333.00     67.27%
        Latency Distribution
        50%  520.83ms
        75%  760.06ms
        90%  940.60ms
        99%    1.47s
        2385 requests in 3.04s, 370.33KB read
        Requests/sec:    785.64
        Transfer/sec:    121.99KB
        [run.sh] Speed is 785.64, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service2-7cf4598c6b-5cr9q   3m           3Mi
        service3-55998c8697-87pjl   3m           3Mi
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   588.36ms  539.88ms   4.83s    86.00%
        Req/Sec   118.10     66.30   454.00     68.03%
        Latency Distribution
        50%  427.75ms
        75%  735.81ms
        90%    1.24s
        99%    2.66s
        20001 requests in 38.00s, 3.03MB read
        Requests/sec:    526.34
        Transfer/sec:     81.73KB
        ------------------------------
        stop time: 21.278158
        stop time: 21.188784
        stop time: 21.469295
        stop time: 21.999745
        stop time: 22.176793
        stop time: 22.368555
        stop time: 22.637605
        stop time: 22.686530
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.278158, 21.188784, 21.469295, 21.999745, 22.176793, 22.368555, 22.637605, 22.68653]
    [exp] Throughput: 910.0968505159949
[test.py] Finished running 7th optmization experiment: groundtruth->1083.614982927646, slowdown->910.0968505159949, predicted->1111.0674631344514, err->2.5334164476607652
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000768', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   556.59ms  608.87ms   2.69s    80.42%
        Req/Sec   132.05     76.91   460.00     76.34%
        Latency Distribution
        50%  240.38ms
        75%  855.70ms
        90%    1.46s
        99%    2.38s
        3001 requests in 3.03s, 465.98KB read
        Requests/sec:    989.21
        Transfer/sec:    153.60KB
        [run.sh] Speed is 989.21, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   468.37ms  336.39ms   2.50s    73.26%
        Req/Sec   139.87     77.63   434.00     64.58%
        Latency Distribution
        50%  387.32ms
        75%  631.21ms
        90%  927.34ms
        99%    1.51s
        20001 requests in 30.00s, 3.03MB read
        Requests/sec:    666.70
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 17.470492
        stop time: 18.423158
        stop time: 18.632778
        stop time: 17.998781
        stop time: 18.619293
        stop time: 18.428752
        stop time: 18.890783
        stop time: 18.836716
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-wnpn4        70m          74Mi
        service1-7755b7b4b5-p8kc5        272m         42Mi
        service2-958786d58-fz6vr         283m         17Mi
        service3-6ddd8b8f64-fzfjf        419m         10Mi
        service4-9bb5bd9fd-bdsh8         129m         9Mi
        ubuntu-client-76886f6bbd-n4kcg   5m           17Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.470492, 18.423158, 18.632778, 17.998781, 18.619293, 18.428752, 18.890783, 18.836716]
    [exp] Throughput: 1086.2130487547474
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '134.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '395.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   636.63ms  498.52ms   2.33s    75.95%
        Req/Sec   128.94     86.66   390.00     67.53%
        Latency Distribution
        50%  483.00ms
        75%  930.04ms
        90%    1.29s
        99%    2.14s
        2171 requests in 3.02s, 337.10KB read
        Requests/sec:    717.75
        Transfer/sec:    111.45KB
        [run.sh] Speed is 717.75, duration is 41
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d41s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d8764fc6b-bxx9l        1279m        68Mi
        service1-7755b7b4b5-jrwsc        1418m        65Mi
        service2-8494b645-qf8hb          1141m        36Mi
        service3-66c8557867-9fgcf        233m         15Mi
        service4-5df98d9dbf-5955k        310m         12Mi
        ubuntu-client-76886f6bbd-2wps2   29m          20Mi
        Running 41s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   542.63ms  468.28ms   3.85s    84.42%
        Req/Sec   122.44     59.41   383.00     67.79%
        Latency Distribution
        50%  427.28ms
        75%  678.01ms
        90%    1.10s
        99%    2.37s
        20000 requests in 41.00s, 3.03MB read
        Requests/sec:    487.80
        Transfer/sec:     75.74KB
        ------------------------------
        stop time: 20.727255
        stop time: 20.599053
        stop time: 20.962160
        stop time: 20.859224
        stop time: 21.209560
        stop time: 21.212259
        stop time: 21.235817
        stop time: 20.650784
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.727255, 20.599053, 20.96216, 20.859224, 21.20956, 21.212259, 21.235817, 20.650784]
    [exp] Throughput: 955.4742319587593
[test.py] Finished running 8th optmization experiment: groundtruth->1086.2130487547474, slowdown->955.4742319587593, predicted->1096.2845928492204, err->0.9272162681178584
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   435.38ms  281.07ms   1.62s    66.44%
        Req/Sec   140.00     66.50   333.00     65.87%
        Latency Distribution
        50%  387.37ms
        75%  618.36ms
        90%  856.51ms
        99%    1.18s
        2922 requests in 3.03s, 453.71KB read
        Requests/sec:    964.05
        Transfer/sec:    149.69KB
        [run.sh] Speed is 964.05, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   463.77ms  330.37ms   2.71s    70.56%
        Req/Sec   138.92     69.54   430.00     68.71%
        Latency Distribution
        50%  394.28ms
        75%  644.92ms
        90%  931.99ms
        99%    1.42s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.197234
        stop time: 18.267047
        stop time: 18.598758
        stop time: 18.300502
        stop time: 18.592493
        stop time: 18.456679
        stop time: 18.814239
        stop time: 18.652107
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-zmhmn   3m           57Mi
        service3-6ddd8b8f64-ltnpv   3m           10Mi
        service4-9bb5bd9fd-ww4kf    3m           12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.197234, 18.267047, 18.598758, 18.300502, 18.592493, 18.456679, 18.814239, 18.652107]
    [exp] Throughput: 1081.9652294379289
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '70.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '206.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   524.55ms  362.08ms   1.68s    64.82%
        Req/Sec   139.40     66.90   310.00     65.88%
        Latency Distribution
        50%  423.86ms
        75%  807.08ms
        90%    1.06s
        99%    1.41s
        2422 requests in 3.03s, 376.07KB read
        Requests/sec:    798.18
        Transfer/sec:    123.94KB
        [run.sh] Speed is 798.18, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f78d8d955-bkc2z         1082m        71Mi
        service1-7755b7b4b5-8rxnb        736m         54Mi
        service2-c67776854-lrzs4         550m         25Mi
        service3-6649d96499-crf9g        871m         12Mi
        service4-6b5bfdd577-lzbdk        467m         15Mi
        ubuntu-client-76886f6bbd-cmwxj   22m          19Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   509.84ms  445.99ms   3.28s    79.17%
        Req/Sec   130.02     66.08   424.00     65.99%
        Latency Distribution
        50%  398.30ms
        75%  703.47ms
        90%    1.04s
        99%    2.14s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 19.344943
        stop time: 18.775700
        stop time: 19.684826
        stop time: 20.014927
        stop time: 19.607597
        stop time: 19.403460
        stop time: 20.008517
        stop time: 20.108195
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.344943, 18.7757, 19.684826, 20.014927, 19.607597, 19.40346, 20.008517, 20.108195]
    [exp] Throughput: 1019.44485939036
[test.py] Finished running 9th optmization experiment: groundtruth->1081.9652294379289, slowdown->1019.44485939036, predicted->1097.9151092998165, err->1.4741582657118735
[test.py] Baseline throughput:  1079.0585680686431
[test.py] Groundtruth:  [1096.0063023650407, 1088.692090707076, 1082.30972200266, 1083.3758394715433, 1086.7913324098415, 1089.1427390175475, 1083.3908043941763, 1083.614982927646, 1086.2130487547474, 1081.9652294379289]
[test.py] Slowdown:  [637.2804337891439, 663.9191066022336, 688.4566139611678, 735.2534286682536, 758.2810271475745, 801.9534664195494, 851.4131945109798, 910.0968505159949, 955.4742319587593, 1019.44485939036]
[test.py] Predicted:  [1086.7449608451223, 1085.1415119820613, 1072.7593030038756, 1106.137838573756, 1078.6747835775566, 1087.4691171514507, 1097.1540242899891, 1111.0674631344514, 1096.2845928492204, 1097.9151092998165]
[test.py] Error percentage:  [-0.845008053323569, -0.3261324992917601, -0.882410903702564, 2.1010251726968288, -0.7468359923599474, -0.15366414393088523, 1.27038367318515, 2.5334164476607652, 0.9272162681178584, 1.4741582657118735]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 3...
[test.py] Actual processing time range: [0, 96, 192, 288, 384, 480, 576, 672, 768, 864]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   503.65ms  321.19ms   1.56s    64.41%
        Req/Sec   136.66     74.32   310.00     62.16%
        Latency Distribution
        50%  464.91ms
        75%  721.67ms
        90%  905.75ms
        99%    1.40s
        2592 requests in 3.03s, 402.47KB read
        Requests/sec:    855.64
        Transfer/sec:    132.86KB
        [run.sh] Speed is 855.64, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-qxdbz        59m          68Mi
        service1-7755b7b4b5-pm5wf        318m         58Mi
        service2-958786d58-pq847         267m         29Mi
        service3-6ddd8b8f64-lrlg7        1m           12Mi
        service4-9bb5bd9fd-bfgjm         1m           13Mi
        ubuntu-client-76886f6bbd-kmqsx   9m           20Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   493.07ms  518.06ms   4.09s    87.38%
        Req/Sec   139.71     65.98   444.00     67.25%
        Latency Distribution
        50%  311.14ms
        75%  602.20ms
        90%    1.17s
        99%    2.54s
        20001 requests in 35.00s, 3.03MB read
        Requests/sec:    571.45
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 18.037926
        stop time: 17.777319
        stop time: 18.417132
        stop time: 18.337970
        stop time: 18.416242
        stop time: 18.886838
        stop time: 18.516375
        stop time: 18.236536
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.037926, 17.777319, 18.417132, 18.33797, 18.416242, 18.886838, 18.516375, 18.236536]
    [exp] Throughput: 1091.2091387019432
[test.py] Baseline throughput: 1091.2091387019432
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   446.50ms  299.17ms   2.11s    64.49%
        Req/Sec   138.37     77.39   400.00     65.70%
        Latency Distribution
        50%  402.30ms
        75%  641.80ms
        90%  842.24ms
        99%    1.29s
        2894 requests in 3.03s, 449.36KB read
        Requests/sec:    954.40
        Transfer/sec:    148.19KB
        [run.sh] Speed is 954.40, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   504.48ms  499.61ms   5.01s    88.07%
        Req/Sec   141.61     76.74   470.00     68.09%
        Latency Distribution
        50%  353.98ms
        75%  660.21ms
        90%    1.10s
        99%    2.43s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 17.332906
        stop time: 18.344969
        stop time: 18.058968
        stop time: 18.552647
        stop time: 18.688998
        stop time: 18.765810
        stop time: 18.473175
        stop time: 18.730578
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pmnvp        633m         60Mi
        service1-7755b7b4b5-qd892        180m         44Mi
        service2-958786d58-trs9x         435m         26Mi
        service3-6ddd8b8f64-sbdws        24m          10Mi
        service4-9bb5bd9fd-s9rx6         197m         9Mi
        ubuntu-client-76886f6bbd-k67vj   23m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.332906, 18.344969, 18.058968, 18.552647, 18.688998, 18.76581, 18.473175, 18.730578]
    [exp] Throughput: 1088.8201572676862
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '648.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1908.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   834.85ms  626.06ms   2.79s    63.79%
        Req/Sec    86.52     55.57   280.00     69.28%
        Latency Distribution
        50%  689.51ms
        75%    1.12s
        90%    1.68s
        99%    2.50s
        1585 requests in 3.03s, 246.11KB read
        Requests/sec:    523.61
        Transfer/sec:     81.30KB
        [run.sh] Speed is 523.61, duration is 57
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d57s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-689ff9485f-hlndx        1156m        76Mi
        service1-7755b7b4b5-89j6g        1122m        53Mi
        service2-59f85f9ccc-5wqgf        852m         26Mi
        service3-f478494d6-8lf4p         525m         15Mi
        service4-57b78cdf48-gt6q8        365m         11Mi
        ubuntu-client-76886f6bbd-fh8c2   26m          22Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   794.69ms  531.53ms   3.35s    72.03%
        Req/Sec    85.44     53.57   400.00     63.49%
        Latency Distribution
        50%  702.44ms
        75%    1.05s
        90%    1.49s
        99%    2.52s
        20000 requests in 0.95m, 3.03MB read
        Requests/sec:    350.88
        Transfer/sec:     54.48KB
        ------------------------------
        stop time: 31.233926
        stop time: 30.677894
        stop time: 31.389654
        stop time: 30.584149
        stop time: 31.526120
        stop time: 31.975441
        stop time: 31.746557
        stop time: 31.750794
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [31.233926, 30.677894, 31.389654, 30.584149, 31.52612, 31.975441, 31.746557, 31.750794]
    [exp] Throughput: 637.7435739512601
[test.py] Finished running 0th optmization experiment: groundtruth->1088.8201572676862, slowdown->637.7435739512601, predicted->1088.0924621803035, err->-0.06683335925822646
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '9.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   404.02ms  343.73ms   1.83s    77.76%
        Req/Sec   137.14     64.54   343.00     63.01%
        Latency Distribution
        50%  335.62ms
        75%  570.78ms
        90%  893.62ms
        99%    1.65s
        3048 requests in 3.04s, 473.27KB read
        Requests/sec:   1003.85
        Transfer/sec:    155.87KB
        [run.sh] Speed is 1003.85, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   525.91ms  590.36ms   4.48s    84.57%
        Req/Sec   139.02     71.89   480.00     72.35%
        Latency Distribution
        50%  266.11ms
        75%  765.12ms
        90%    1.45s
        99%    2.49s
        20001 requests in 29.00s, 3.03MB read
        Requests/sec:    689.69
        Transfer/sec:    107.09KB
        ------------------------------
        stop time: 18.739686
        stop time: 18.638197
        stop time: 18.229086
        stop time: 18.157831
        stop time: 18.308651
        stop time: 18.579362
        stop time: 17.933817
        stop time: 18.530432
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-rlbjk        1616m        66Mi
        service1-7755b7b4b5-gqqfr        638m         41Mi
        service2-958786d58-656wx         1372m        23Mi
        service3-6ddd8b8f64-td9nj        903m         13Mi
        service4-9bb5bd9fd-mbtpc         446m         10Mi
        ubuntu-client-76886f6bbd-dlgcw   41m          22Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.739686, 18.638197, 18.229086, 18.157831, 18.308651, 18.579362, 17.933817, 18.530432]
    [exp] Throughput: 1087.5692990660732
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1719.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   804.97ms  629.79ms   2.92s    65.03%
        Req/Sec    86.70     57.84   260.00     68.26%
        Latency Distribution
        50%  877.21ms
        75%    1.15s
        90%    1.68s
        99%    2.66s
        1567 requests in 3.03s, 243.31KB read
        Requests/sec:    517.40
        Transfer/sec:     80.34KB
        [run.sh] Speed is 517.40, duration is 57
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d57s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-6979b6d9d6-2469r   3m           42Mi
        service1-7755b7b4b5-l7sq2   3m           18Mi
        service2-667bd658d5-8w8cl   3m           3Mi
        service4-6b47687759-zpd4m   3m           4Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   779.61ms  633.23ms   5.26s    78.78%
        Req/Sec    89.95     56.04   360.00     67.23%
        Latency Distribution
        50%  643.11ms
        75%    1.05s
        90%    1.51s
        99%    3.24s
        20000 requests in 0.95m, 3.03MB read
        Requests/sec:    350.88
        Transfer/sec:     54.48KB
        ------------------------------
        stop time: 30.310994
        stop time: 30.206820
        stop time: 30.014802
        stop time: 29.480928
        stop time: 29.986858
        stop time: 30.257710
        stop time: 30.462645
        stop time: 30.450148
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [30.310994, 30.20682, 30.014802, 29.480928, 29.986858, 30.25771, 30.462645, 30.450148]
    [exp] Throughput: 663.4299440058908
[test.py] Finished running 1th optmization experiment: groundtruth->1087.5692990660732, slowdown->663.4299440058908, predicted->1083.8353630510107, err->-0.3433285601449849
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000192', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   508.31ms  395.49ms   2.11s    64.51%
        Req/Sec   148.80    102.82   424.00     66.48%
        Latency Distribution
        50%  465.09ms
        75%  730.50ms
        90%  997.66ms
        99%    1.68s
        2893 requests in 3.03s, 449.21KB read
        Requests/sec:    953.74
        Transfer/sec:    148.09KB
        [run.sh] Speed is 953.74, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   476.15ms  380.10ms   3.23s    77.25%
        Req/Sec   140.92     87.20   505.00     67.15%
        Latency Distribution
        50%  384.98ms
        75%  640.61ms
        90%  973.43ms
        99%    1.76s
        20001 requests in 31.00s, 3.03MB read
        Requests/sec:    645.19
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 17.795167
        stop time: 18.490764
        stop time: 17.788424
        stop time: 18.290428
        stop time: 18.672460
        stop time: 18.680122
        stop time: 18.622566
        stop time: 18.804536
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-wzscp        216m         56Mi
        service1-7755b7b4b5-wbn9p        3m           41Mi
        service2-958786d58-2nk7l         3m           19Mi
        service4-9bb5bd9fd-9ftnp         133m         8Mi
        ubuntu-client-76886f6bbd-q62kh   6m           11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.795167, 18.490764, 17.788424, 18.290428, 18.67246, 18.680122, 18.622566, 18.804536]
    [exp] Throughput: 1087.3667441399616
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '520.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1530.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   700.21ms  451.10ms   1.98s    55.18%
        Req/Sec   101.44     69.77   370.00     71.76%
        Latency Distribution
        50%  791.23ms
        75%  986.75ms
        90%    1.28s
        99%    1.80s
        1825 requests in 3.03s, 283.37KB read
        Requests/sec:    602.15
        Transfer/sec:     93.50KB
        [run.sh] Speed is 602.15, duration is 49
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-656fc596d7-76664        1248m        68Mi
        service1-7755b7b4b5-rvvbw        1151m        61Mi
        service2-959db6589-6tjfs         870m         34Mi
        service3-84cb9dcd88-cjv27        372m         12Mi
        service4-875c49d6-n7s4f          146m         14Mi
        ubuntu-client-76886f6bbd-mwrjf   28m          20Mi
        Running 49s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   731.43ms  514.15ms   4.43s    72.62%
        Req/Sec    91.42     56.51   330.00     66.12%
        Latency Distribution
        50%  654.65ms
        75%  987.94ms
        90%    1.38s
        99%    2.49s
        20000 requests in 49.00s, 3.03MB read
        Requests/sec:    408.16
        Transfer/sec:     63.38KB
        ------------------------------
        stop time: 28.431480
        stop time: 28.712841
        stop time: 28.167966
        stop time: 28.452429
        stop time: 28.842147
        stop time: 29.148930
        stop time: 29.090675
        stop time: 29.294806
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [28.43148, 28.712841, 28.167966, 28.452429, 28.842147, 29.14893, 29.090675, 29.294806]
    [exp] Throughput: 695.2251424488073
[test.py] Finished running 2th optmization experiment: groundtruth->1087.3667441399616, slowdown->695.2251424488073, predicted->1089.2840820615975, err->0.17632854158624794
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000288', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   458.75ms  302.56ms   1.61s    61.63%
        Req/Sec   147.24     77.10   360.00     65.22%
        Latency Distribution
        50%  411.83ms
        75%  692.57ms
        90%  873.86ms
        99%    1.15s
        2727 requests in 3.02s, 423.43KB read
        Requests/sec:    901.74
        Transfer/sec:    140.02KB
        [run.sh] Speed is 901.74, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   499.68ms  485.40ms   4.25s    88.92%
        Req/Sec   139.00     79.16   575.00     69.25%
        Latency Distribution
        50%  357.55ms
        75%  609.69ms
        90%    1.04s
        99%    2.55s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 18.572434
        stop time: 18.461128
        stop time: 17.736482
        stop time: 18.554856
        stop time: 18.100416
        stop time: 18.087925
        stop time: 18.690809
        stop time: 18.861905
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-rtpm5        1941m        75Mi
        service1-7755b7b4b5-wkg69        644m         55Mi
        service2-958786d58-29psd         1036m        25Mi
        service3-6ddd8b8f64-pl5c2        923m         17Mi
        service4-9bb5bd9fd-l9z6s         611m         11Mi
        ubuntu-client-76886f6bbd-j7b7p   40m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.572434, 18.461128, 17.736482, 18.554856, 18.100416, 18.087925, 18.690809, 18.861905]
    [exp] Throughput: 1087.9472410864907
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '456.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1341.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   738.05ms  537.65ms   2.55s    67.10%
        Req/Sec   100.65     65.09   280.00     66.06%
        Latency Distribution
        50%  627.72ms
        75%  965.00ms
        90%    1.62s
        99%    2.28s
        1865 requests in 3.03s, 289.58KB read
        Requests/sec:    615.58
        Transfer/sec:     95.58KB
        [run.sh] Speed is 615.58, duration is 48
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service1-7755b7b4b5-6vkq8        3m           18Mi
        service2-54c8b5d4f9-llxxb        3m           3Mi
        ubuntu-client-76886f6bbd-tltls   5m           6Mi
        Running 48s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   704.65ms  490.39ms   4.76s    73.86%
        Req/Sec    95.63     60.30   303.00     65.53%
        Latency Distribution
        50%  622.85ms
        75%  932.65ms
        90%    1.31s
        99%    2.44s
        20000 requests in 48.00s, 3.03MB read
        Requests/sec:    416.67
        Transfer/sec:     64.70KB
        ------------------------------
        stop time: 26.809053
        stop time: 27.214671
        stop time: 27.096871
        stop time: 27.676534
        stop time: 27.556999
        stop time: 27.859694
        stop time: 27.854866
        stop time: 27.654563
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.809053, 27.214671, 27.096871, 27.676534, 27.556999, 27.859694, 27.854866, 27.654563]
    [exp] Throughput: 728.1887523137003
[test.py] Finished running 3th optmization experiment: groundtruth->1087.9472410864907, slowdown->728.1887523137003, predicted->1090.2253981729718, err->0.2093995922270992
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000384', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   453.49ms  356.63ms   1.99s    71.02%
        Req/Sec   144.27     81.51   360.00     67.50%
        Latency Distribution
        50%  383.39ms
        75%  693.05ms
        90%  936.07ms
        99%    1.61s
        2995 requests in 3.03s, 465.04KB read
        Requests/sec:    990.00
        Transfer/sec:    153.72KB
        [run.sh] Speed is 990.00, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   542.05ms  616.20ms   4.19s    87.64%
        Req/Sec   139.12     72.31   464.00     71.38%
        Latency Distribution
        50%  325.36ms
        75%  663.14ms
        90%    1.33s
        99%    2.93s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 17.742262
        stop time: 18.561117
        stop time: 17.995720
        stop time: 18.093337
        stop time: 18.524610
        stop time: 18.604425
        stop time: 18.765075
        stop time: 17.936389
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-2s4cz        596m         61Mi
        service1-7755b7b4b5-ndfkt        244m         61Mi
        service2-958786d58-6hkvs         403m         32Mi
        service3-6ddd8b8f64-7xp5v        304m         14Mi
        service4-9bb5bd9fd-4zv2c         201m         10Mi
        ubuntu-client-76886f6bbd-f7n4j   19m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.742262, 18.561117, 17.99572, 18.093337, 18.52461, 18.604425, 18.765075, 17.936389]
    [exp] Throughput: 1094.2195901073933
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '391.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1152.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   718.15ms  395.99ms   2.21s    69.38%
        Req/Sec    95.15     66.10   280.00     67.27%
        Latency Distribution
        50%  702.38ms
        75%  976.10ms
        90%    1.18s
        99%    1.97s
        1811 requests in 3.03s, 281.20KB read
        Requests/sec:    596.74
        Transfer/sec:     92.66KB
        [run.sh] Speed is 596.74, duration is 50
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d50s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f5498d4b-sv42n         1413m        73Mi
        service1-7755b7b4b5-w48bg        1273m        57Mi
        service2-77dd47bf4f-wk47k        967m         26Mi
        service3-74947cdd48-w4dmj        640m         16Mi
        service4-789d8dbcdb-mvt7c        437m         12Mi
        ubuntu-client-76886f6bbd-l5qls   29m          22Mi
        Running 50s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   684.77ms  574.37ms   4.40s    81.91%
        Req/Sec   103.60     61.60   333.00     64.57%
        Latency Distribution
        50%  541.22ms
        75%  886.21ms
        90%    1.36s
        99%    3.05s
        20000 requests in 50.00s, 3.03MB read
        Requests/sec:    400.00
        Transfer/sec:     62.11KB
        ------------------------------
        stop time: 25.444813
        stop time: 26.050127
        stop time: 26.045059
        stop time: 26.268002
        stop time: 26.737893
        stop time: 26.555269
        stop time: 26.647859
        stop time: 26.641435
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [25.444813, 26.050127, 26.045059, 26.268002, 26.737893, 26.555269, 26.647859, 26.641435]
    [exp] Throughput: 760.4907669362589
[test.py] Finished running 4th optmization experiment: groundtruth->1094.2195901073933, slowdown->760.4907669362589, predicted->1083.1518845194366, err->-1.0114702467418264
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   441.33ms  250.10ms   1.41s    69.02%
        Req/Sec   149.44     86.80   390.00     67.71%
        Latency Distribution
        50%  412.16ms
        75%  573.15ms
        90%  793.22ms
        99%    1.12s
        3044 requests in 3.03s, 472.65KB read
        Requests/sec:   1003.35
        Transfer/sec:    155.79KB
        [run.sh] Speed is 1003.35, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   502.99ms  460.49ms   4.00s    88.25%
        Req/Sec   140.64     83.03   510.00     68.98%
        Latency Distribution
        50%  372.86ms
        75%  660.05ms
        90%    1.00s
        99%    2.52s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 17.745071
        stop time: 17.703941
        stop time: 18.677470
        stop time: 18.658129
        stop time: 18.589560
        stop time: 18.794324
        stop time: 18.666944
        stop time: 18.638559
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pgdr9        854m         73Mi
        service1-7755b7b4b5-vmckl        713m         43Mi
        service2-958786d58-p78xn         912m         20Mi
        service3-6ddd8b8f64-7qc8q        94m          10Mi
        service4-9bb5bd9fd-pnmts         261m         10Mi
        ubuntu-client-76886f6bbd-9j94c   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.745071, 17.703941, 18.67747, 18.658129, 18.58956, 18.794324, 18.666944, 18.638559]
    [exp] Throughput: 1084.9370205587022
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '327.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '962.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   631.60ms  287.92ms   1.62s    66.12%
        Req/Sec    96.36     57.77   313.00     68.26%
        Latency Distribution
        50%  622.85ms
        75%  776.39ms
        90%    1.03s
        99%    1.40s
        1936 requests in 3.03s, 300.61KB read
        Requests/sec:    638.73
        Transfer/sec:     99.18KB
        [run.sh] Speed is 638.73, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-59f9d8648d-dbnm4        353m         61Mi
        service1-7755b7b4b5-v2l54        69m          52Mi
        service2-745886db66-djzpb        3m           23Mi
        service3-6fc4fcf464-7lhwg        209m         13Mi
        service4-7486db89fd-dtwhx        115m         11Mi
        ubuntu-client-76886f6bbd-r8j9r   15m          0Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   643.56ms  521.91ms   5.11s    82.01%
        Req/Sec   105.39     59.58   313.00     66.61%
        Latency Distribution
        50%  516.86ms
        75%  840.41ms
        90%    1.25s
        99%    2.60s
        20000 requests in 46.00s, 3.03MB read
        Requests/sec:    434.78
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 24.439425
        stop time: 24.950752
        stop time: 25.309943
        stop time: 24.037887
        stop time: 25.063097
        stop time: 24.924068
        stop time: 24.934351
        stop time: 25.137975
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [24.439425, 24.950752, 25.309943, 24.037887, 25.063097, 24.924068, 24.934351, 25.137975]
    [exp] Throughput: 804.8391031561172
[test.py] Finished running 5th optmization experiment: groundtruth->1084.9370205587022, slowdown->804.8391031561172, predicted->1092.7820448260559, err->0.7230856831960412
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000576', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   536.15ms  606.43ms   2.98s    85.76%
        Req/Sec   131.80     56.73   280.00     65.62%
        Latency Distribution
        50%  255.18ms
        75%  791.80ms
        90%    1.38s
        99%    2.74s
        3000 requests in 3.03s, 465.82KB read
        Requests/sec:    990.65
        Transfer/sec:    153.82KB
        [run.sh] Speed is 990.65, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   532.88ms  606.20ms   5.17s    85.47%
        Req/Sec   135.91     67.36   424.00     74.04%
        Latency Distribution
        50%  288.89ms
        75%  671.34ms
        90%    1.38s
        99%    2.70s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.667019
        stop time: 17.991755
        stop time: 17.875690
        stop time: 18.711055
        stop time: 18.655895
        stop time: 18.737576
        stop time: 18.641090
        stop time: 18.806406
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-hkgcs        538m         61Mi
        service1-7755b7b4b5-2rq96        98m          38Mi
        service2-958786d58-d2ww2         41m          18Mi
        service3-6ddd8b8f64-fnncz        538m         11Mi
        service4-9bb5bd9fd-btrxl         179m         9Mi
        ubuntu-client-76886f6bbd-xnkxf   28m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.667019, 17.991755, 17.87569, 18.711055, 18.655895, 18.737576, 18.64109, 18.806406]
    [exp] Throughput: 1080.449704235672
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '263.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '773.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   653.21ms  454.64ms   2.01s    70.35%
        Req/Sec   109.02     67.19   282.00     61.11%
        Latency Distribution
        50%  584.22ms
        75%  949.36ms
        90%    1.25s
        99%    1.78s
        2142 requests in 3.03s, 332.60KB read
        Requests/sec:    708.00
        Transfer/sec:    109.93KB
        [run.sh] Speed is 708.00, duration is 42
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6dd6844b8c-mrqrq        941m         63Mi
        service1-7755b7b4b5-c4n8w        1159m        59Mi
        service2-cf56db458-t67wc         956m         34Mi
        service3-767df97779-nrtw9        225m         14Mi
        service4-75dbf88985-9lf9c        306m         11Mi
        ubuntu-client-76886f6bbd-gbhvc   12m          22Mi
        Running 42s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   617.58ms  585.38ms   5.54s    88.02%
        Req/Sec   110.87     57.70   330.00     65.83%
        Latency Distribution
        50%  450.69ms
        75%  762.91ms
        90%    1.32s
        99%    2.94s
        20001 requests in 42.00s, 3.03MB read
        Requests/sec:    476.21
        Transfer/sec:     73.94KB
        ------------------------------
        stop time: 22.880693
        stop time: 22.947808
        stop time: 22.653938
        stop time: 23.840398
        stop time: 22.955458
        stop time: 23.669367
        stop time: 23.484457
        stop time: 24.002431
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.880693, 22.947808, 22.653938, 23.840398, 22.955458, 23.669367, 23.484457, 24.002431]
    [exp] Throughput: 858.2100259849906
[test.py] Finished running 6th optmization experiment: groundtruth->1080.449704235672, slowdown->858.2100259849906, predicted->1108.4666330274756, err->2.5930803333065127
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000672', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   474.86ms  392.40ms   2.02s    76.41%
        Req/Sec   143.36     78.83   393.00     75.26%
        Latency Distribution
        50%  358.62ms
        75%  728.14ms
        90%    1.02s
        99%    1.85s
        2847 requests in 3.03s, 442.06KB read
        Requests/sec:    938.43
        Transfer/sec:    145.71KB
        [run.sh] Speed is 938.43, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   497.28ms  479.58ms   4.09s    86.63%
        Req/Sec   139.64     80.06   440.00     68.69%
        Latency Distribution
        50%  351.39ms
        75%  665.92ms
        90%    1.11s
        99%    2.24s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 17.968091
        stop time: 17.902301
        stop time: 18.676884
        stop time: 18.386907
        stop time: 18.829887
        stop time: 18.660700
        stop time: 18.585436
        stop time: 18.572330
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-9kfhb        3m           58Mi
        service1-7755b7b4b5-f9242        3m           56Mi
        service2-958786d58-nf89w         3m           26Mi
        service3-6ddd8b8f64-qp6dx        107m         9Mi
        service4-9bb5bd9fd-kp7zv         3m           10Mi
        ubuntu-client-76886f6bbd-2zr76   10m          11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.968091, 17.902301, 18.676884, 18.386907, 18.829887, 18.6607, 18.585436, 18.57233]
    [exp] Throughput: 1084.1391152134695
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '198.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   688.91ms  611.47ms   2.63s    73.50%
        Req/Sec   110.37     71.76   303.00     69.47%
        Latency Distribution
        50%  442.96ms
        75%    1.02s
        90%    1.56s
        99%    2.50s
        2142 requests in 3.04s, 332.60KB read
        Requests/sec:    705.65
        Transfer/sec:    109.57KB
        [run.sh] Speed is 705.65, duration is 42
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6b6b7b9f5-9pl2h         1622m        76Mi
        service1-7755b7b4b5-rqkgg        1149m        70Mi
        service2-7cf4598c6b-mwnvw        821m         43Mi
        service3-55998c8697-mcjtb        758m         13Mi
        service4-6866646d59-gphgw        510m         10Mi
        ubuntu-client-76886f6bbd-vv79g   35m          19Mi
        Running 42s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   574.12ms  428.17ms   3.58s    75.05%
        Req/Sec   114.95     66.14   383.00     69.24%
        Latency Distribution
        50%  488.42ms
        75%  742.64ms
        90%    1.14s
        99%    2.10s
        20000 requests in 42.00s, 3.03MB read
        Requests/sec:    476.19
        Transfer/sec:     73.94KB
        ------------------------------
        stop time: 22.467299
        stop time: 22.468342
        stop time: 22.252328
        stop time: 22.682212
        stop time: 22.050394
        stop time: 22.610026
        stop time: 22.766951
        stop time: 22.681318
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.467299, 22.468342, 22.252328, 22.682212, 22.050394, 22.610026, 22.766951, 22.681318]
    [exp] Throughput: 888.9932468183626
[test.py] Finished running 7th optmization experiment: groundtruth->1084.1391152134695, slowdown->888.9932468183626, predicted->1079.7746850361357, err->-0.40257104610365885
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000768', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   505.24ms  372.51ms   1.90s    73.74%
        Req/Sec   140.36     73.86   333.00     69.94%
        Latency Distribution
        50%  380.72ms
        75%  723.83ms
        90%    1.10s
        99%    1.56s
        2460 requests in 3.03s, 381.97KB read
        Requests/sec:    810.63
        Transfer/sec:    125.87KB
        [run.sh] Speed is 810.63, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-lng4r        199m         67Mi
        service1-7755b7b4b5-t98v2        500m         61Mi
        service2-958786d58-mplfc         538m         24Mi
        service3-6ddd8b8f64-tss7v        755m         11Mi
        service4-9bb5bd9fd-ml8sc         102m         14Mi
        ubuntu-client-76886f6bbd-fn9z5   1m           19Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   470.57ms  348.72ms   2.40s    76.27%
        Req/Sec   138.35     76.90   450.00     64.31%
        Latency Distribution
        50%  386.25ms
        75%  613.34ms
        90%  932.34ms
        99%    1.68s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 18.229160
        stop time: 18.723689
        stop time: 17.955131
        stop time: 18.910362
        stop time: 18.709820
        stop time: 18.444189
        stop time: 18.648496
        stop time: 18.892373
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.22916, 18.723689, 17.955131, 18.910362, 18.70982, 18.444189, 18.648496, 18.892373]
    [exp] Throughput: 1077.3451683291225
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '134.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '395.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   604.18ms  424.62ms   2.31s    76.24%
        Req/Sec   128.09     74.80   360.00     69.78%
        Latency Distribution
        50%  482.16ms
        75%  833.25ms
        90%    1.21s
        99%    2.12s
        2394 requests in 3.03s, 371.72KB read
        Requests/sec:    790.05
        Transfer/sec:    122.67KB
        [run.sh] Speed is 790.05, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d8764fc6b-4vpv2        201m         62Mi
        service1-7755b7b4b5-4rnnm        3m           56Mi
        service2-8494b645-qmftk          3m           26Mi
        service4-5df98d9dbf-pr75l        11m          11Mi
        ubuntu-client-76886f6bbd-vv92n   16m          11Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   553.64ms  462.49ms   3.65s    81.70%
        Req/Sec   122.65     64.96   370.00     66.71%
        Latency Distribution
        50%  426.45ms
        75%  713.54ms
        90%    1.13s
        99%    2.34s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 21.291376
        stop time: 21.125086
        stop time: 21.262722
        stop time: 20.994827
        stop time: 21.440686
        stop time: 21.154469
        stop time: 21.409777
        stop time: 20.741462
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.291376, 21.125086, 21.262722, 20.994827, 21.440686, 21.154469, 21.409777, 20.741462]
    [exp] Throughput: 944.3962785946595
[test.py] Finished running 8th optmization experiment: groundtruth->1077.3451683291225, slowdown->944.3962785946595, predicted->1081.7257530851311, err->0.4066092172485949
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   554.23ms  511.68ms   2.94s    84.70%
        Req/Sec   145.93     62.68   313.00     66.49%
        Latency Distribution
        50%  335.98ms
        75%  849.37ms
        90%    1.26s
        99%    2.01s
        2796 requests in 3.03s, 434.14KB read
        Requests/sec:    922.61
        Transfer/sec:    143.26KB
        [run.sh] Speed is 922.61, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   477.20ms  361.27ms   2.75s    79.42%
        Req/Sec   138.76     69.49   505.00     68.01%
        Latency Distribution
        50%  395.35ms
        75%  617.70ms
        90%  923.23ms
        99%    1.80s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.110738
        stop time: 18.227185
        stop time: 18.109572
        stop time: 18.651832
        stop time: 18.179060
        stop time: 18.891632
        stop time: 18.853956
        stop time: 18.935646
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-2djc2        1854m        70Mi
        service1-7755b7b4b5-q22xx        1137m        64Mi
        service2-958786d58-s8n92         875m         26Mi
        service3-6ddd8b8f64-kvc8v        188m         13Mi
        service4-9bb5bd9fd-f85rx         548m         14Mi
        ubuntu-client-76886f6bbd-gchdx   44m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.110738, 18.227185, 18.109572, 18.651832, 18.17906, 18.891632, 18.853956, 18.935646]
    [exp] Throughput: 1081.376114095345
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '70.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '206.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   525.38ms  396.14ms   2.61s    77.81%
        Req/Sec   127.33     59.53   350.00     74.04%
        Latency Distribution
        50%  435.38ms
        75%  677.63ms
        90%    1.10s
        99%    1.85s
        2745 requests in 3.03s, 426.23KB read
        Requests/sec:    905.00
        Transfer/sec:    140.52KB
        [run.sh] Speed is 905.00, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   520.79ms  461.54ms   3.50s    85.15%
        Req/Sec   131.42     68.96   710.00     69.45%
        Latency Distribution
        50%  377.26ms
        75%  687.17ms
        90%    1.10s
        99%    2.31s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.215932
        stop time: 20.229369
        stop time: 19.794858
        stop time: 20.219066
        stop time: 19.975687
        stop time: 19.890188
        stop time: 19.914812
        stop time: 19.443185
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.215932, 20.229369, 19.794858, 20.219066, 19.975687, 19.890188, 19.914812, 19.443185]
    [exp] Throughput: 1008.2989494463925
[test.py] Finished running 9th optmization experiment: groundtruth->1081.376114095345, slowdown->1008.2989494463925, predicted->1084.9981516717423, err->0.334947066907195
[test.py] Baseline throughput:  1091.2091387019432
[test.py] Groundtruth:  [1088.8201572676862, 1087.5692990660732, 1087.3667441399616, 1087.9472410864907, 1094.2195901073933, 1084.9370205587022, 1080.449704235672, 1084.1391152134695, 1077.3451683291225, 1081.376114095345]
[test.py] Slowdown:  [637.7435739512601, 663.4299440058908, 695.2251424488073, 728.1887523137003, 760.4907669362589, 804.8391031561172, 858.2100259849906, 888.9932468183626, 944.3962785946595, 1008.2989494463925]
[test.py] Predicted:  [1088.0924621803035, 1083.8353630510107, 1089.2840820615975, 1090.2253981729718, 1083.1518845194366, 1092.7820448260559, 1108.4666330274756, 1079.7746850361357, 1081.7257530851311, 1084.9981516717423]
[test.py] Error percentage:  [-0.06683335925822646, -0.3433285601449849, 0.17632854158624794, 0.2093995922270992, -1.0114702467418264, 0.7230856831960412, 2.5930803333065127, -0.40257104610365885, 0.4066092172485949, 0.334947066907195]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 4...
[test.py] Actual processing time range: [0, 96, 192, 288, 384, 480, 576, 672, 768, 864]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   541.21ms  423.44ms   2.40s    81.72%
        Req/Sec   128.75     61.62   313.00     71.22%
        Latency Distribution
        50%  406.81ms
        75%  731.65ms
        90%    1.12s
        99%    2.08s
        2659 requests in 3.03s, 412.87KB read
        Requests/sec:    876.14
        Transfer/sec:    136.04KB
        [run.sh] Speed is 876.14, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   474.15ms  374.10ms   2.44s    76.83%
        Req/Sec   138.05     69.17   393.00     68.06%
        Latency Distribution
        50%  365.02ms
        75%  655.99ms
        90%  983.89ms
        99%    1.69s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 18.552923
        stop time: 18.450174
        stop time: 18.457893
        stop time: 18.653968
        stop time: 18.885704
        stop time: 18.099741
        stop time: 18.629016
        stop time: 18.908883
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-2m6cv        480m         67Mi
        service1-7755b7b4b5-svvm4        548m         66Mi
        service2-958786d58-76l98         410m         29Mi
        service3-6ddd8b8f64-2g89q        270m         14Mi
        service4-9bb5bd9fd-p4lcq         107m         10Mi
        ubuntu-client-76886f6bbd-nwp9l   17m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.552923, 18.450174, 18.457893, 18.653968, 18.885704, 18.099741, 18.629016, 18.908883]
    [exp] Throughput: 1076.4385615761407
[test.py] Baseline throughput: 1076.4385615761407
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   487.29ms  313.85ms   2.03s    62.97%
        Req/Sec   127.05     76.60   390.00     66.18%
        Latency Distribution
        50%  433.17ms
        75%  696.33ms
        90%  936.15ms
        99%    1.33s
        2733 requests in 3.03s, 424.36KB read
        Requests/sec:    901.61
        Transfer/sec:    140.00KB
        [run.sh] Speed is 901.61, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   470.36ms  394.58ms   3.51s    80.87%
        Req/Sec   137.33     83.18   480.00     66.29%
        Latency Distribution
        50%  364.04ms
        75%  635.67ms
        90%  977.11ms
        99%    1.93s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 17.574260
        stop time: 18.590903
        stop time: 18.296676
        stop time: 18.662062
        stop time: 18.089610
        stop time: 18.609337
        stop time: 18.794571
        stop time: 18.694430
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-cc8ww        1942m        70Mi
        service1-7755b7b4b5-9rxvx        389m         40Mi
        service2-958786d58-68hdp         1147m        20Mi
        service3-6ddd8b8f64-rr55b        905m         13Mi
        service4-9bb5bd9fd-xhcdj         632m         10Mi
        ubuntu-client-76886f6bbd-bz5kl   40m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.57426, 18.590903, 18.296676, 18.662062, 18.08961, 18.609337, 18.794571, 18.69443]
    [exp] Throughput: 1086.131231711035
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '648.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1908.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1297.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   842.24ms  483.46ms   2.26s    60.11%
        Req/Sec    83.36     58.18   330.00     80.42%
        Latency Distribution
        50%  862.55ms
        75%    1.14s
        90%    1.51s
        99%    2.15s
        1597 requests in 3.03s, 247.97KB read
        Requests/sec:    526.57
        Transfer/sec:     81.76KB
        [run.sh] Speed is 526.57, duration is 56
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d56s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-7755b7b4b5-9zkdh   3m           3Mi
        service2-59f85f9ccc-cnvrh   3m           3Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   816.43ms  679.17ms   6.44s    76.62%
        Req/Sec    87.62     53.46   343.00     69.51%
        Latency Distribution
        50%  669.51ms
        75%    1.12s
        90%    1.64s
        99%    3.20s
        20000 requests in 0.93m, 3.03MB read
        Requests/sec:    357.14
        Transfer/sec:     55.45KB
        ------------------------------
        stop time: 32.032800
        stop time: 31.350671
        stop time: 30.730817
        stop time: 31.690322
        stop time: 31.337661
        stop time: 31.686672
        stop time: 31.676941
        stop time: 31.443997
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [32.0328, 31.350671, 30.730817, 31.690322, 31.337661, 31.686672, 31.676941, 31.443997]
    [exp] Throughput: 635.0469361801366
[test.py] Finished running 0th optmization experiment: groundtruth->1086.131231711035, slowdown->635.0469361801366, predicted->1080.2659693135738, err->-0.5400141554001199
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '9.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   460.54ms  321.08ms   1.82s    66.73%
        Req/Sec   141.99     89.61   370.00     62.63%
        Latency Distribution
        50%  386.31ms
        75%  607.30ms
        90%  920.45ms
        99%    1.51s
        3023 requests in 3.04s, 469.39KB read
        Requests/sec:    992.90
        Transfer/sec:    154.17KB
        [run.sh] Speed is 992.90, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   495.29ms  508.21ms   4.22s    85.93%
        Req/Sec   137.47     71.70   480.00     68.68%
        Latency Distribution
        50%  314.68ms
        75%  699.78ms
        90%    1.21s
        99%    2.25s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.592147
        stop time: 18.667473
        stop time: 17.932882
        stop time: 17.960867
        stop time: 18.375932
        stop time: 18.575689
        stop time: 18.818789
        stop time: 18.793148
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-7755b7b4b5-b4clc   79m          34Mi
        service2-958786d58-9hkcc    67m          15Mi
        service3-6ddd8b8f64-nrmqj   3m           9Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.592147, 18.667473, 17.932882, 17.960867, 18.375932, 18.575689, 18.818789, 18.793148]
    [exp] Throughput: 1083.1527790989046
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1719.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   822.67ms  523.05ms   2.64s    66.51%
        Req/Sec    81.54     63.57   310.00     72.68%
        Latency Distribution
        50%  722.84ms
        75%    1.21s
        90%    1.57s
        99%    2.35s
        1644 requests in 3.03s, 255.27KB read
        Requests/sec:    542.11
        Transfer/sec:     84.18KB
        [run.sh] Speed is 542.11, duration is 55
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6979b6d9d6-4v97x        680m         75Mi
        service1-7755b7b4b5-hcv2c        281m         56Mi
        service2-667bd658d5-jsskg        169m         35Mi
        service3-67579fdbfc-p2rgn        416m         13Mi
        service4-6b47687759-rt66j        150m         11Mi
        ubuntu-client-76886f6bbd-ckc4d   14m          20Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   774.08ms  716.60ms   4.91s    82.91%
        Req/Sec    96.71     60.25   460.00     66.70%
        Latency Distribution
        50%  588.55ms
        75%    1.04s
        90%    1.76s
        99%    3.16s
        20000 requests in 0.92m, 3.03MB read
        Requests/sec:    363.64
        Transfer/sec:     56.46KB
        ------------------------------
        stop time: 30.467957
        stop time: 29.873689
        stop time: 29.328516
        stop time: 29.353407
        stop time: 30.498820
        stop time: 30.522175
        stop time: 30.300132
        stop time: 29.844538
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [30.467957, 29.873689, 29.328516, 29.353407, 30.49882, 30.522175, 30.300132, 29.844538]
    [exp] Throughput: 666.1414308020151
[test.py] Finished running 1th optmization experiment: groundtruth->1083.1527790989046, slowdown->666.1414308020151, predicted->1091.0909112904492, err->0.7328728084092131
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000192', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   390.47ms  319.49ms   1.79s    75.75%
        Req/Sec   130.70     73.26   450.00     72.56%
        Latency Distribution
        50%  312.59ms
        75%  538.96ms
        90%  889.29ms
        99%    1.26s
        2938 requests in 3.02s, 456.19KB read
        Requests/sec:    971.58
        Transfer/sec:    150.86KB
        [run.sh] Speed is 971.58, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   491.36ms  419.53ms   3.67s    84.33%
        Req/Sec   142.59     86.22   430.00     66.25%
        Latency Distribution
        50%  383.15ms
        75%  635.71ms
        90%  966.08ms
        99%    2.24s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.189999
        stop time: 18.261642
        stop time: 18.092618
        stop time: 18.417435
        stop time: 18.609724
        stop time: 18.608812
        stop time: 18.852025
        stop time: 18.419948
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-ws9qz        1755m        67Mi
        service1-7755b7b4b5-vmfjp        463m         43Mi
        service2-958786d58-4vqpw         784m         23Mi
        service3-6ddd8b8f64-9ltgg        898m         14Mi
        service4-9bb5bd9fd-pxq76         466m         10Mi
        ubuntu-client-76886f6bbd-2hcsw   31m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.189999, 18.261642, 18.092618, 18.417435, 18.609724, 18.608812, 18.852025, 18.419948]
    [exp] Throughput: 1085.0973857609981
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '520.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1530.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '1040.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   798.13ms  443.39ms   1.92s    72.59%
        Req/Sec    89.49     58.08   250.00     60.14%
        Latency Distribution
        50%  684.48ms
        75%    1.07s
        90%    1.57s
        99%    1.87s
        1620 requests in 3.02s, 251.54KB read
        Requests/sec:    537.16
        Transfer/sec:     83.41KB
        [run.sh] Speed is 537.16, duration is 55
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   734.07ms  477.05ms   3.90s    73.79%
        Req/Sec    93.67     62.15   360.00     66.79%
        Latency Distribution
        50%  664.98ms
        75%  970.63ms
        90%    1.30s
        99%    2.37s
        20000 requests in 0.92m, 3.03MB read
        Requests/sec:    363.64
        Transfer/sec:     56.46KB
        ------------------------------
        stop time: 28.554966
        stop time: 29.185517
        stop time: 28.748489
        stop time: 27.965446
        stop time: 28.632399
        stop time: 29.034402
        stop time: 29.269465
        stop time: 29.155352
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [28.554966, 29.185517, 28.748489, 27.965446, 28.632399, 29.034402, 29.269465, 29.155352]
    [exp] Throughput: 694.0045588118462
[test.py] Finished running 2th optmization experiment: groundtruth->1085.0973857609981, slowdown->694.0045588118462, predicted->1086.2906668866044, err->0.10996995673060453
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000288', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   464.13ms  283.24ms   2.00s    68.17%
        Req/Sec   136.83     91.71   470.00     75.00%
        Latency Distribution
        50%  448.86ms
        75%  600.22ms
        90%  841.01ms
        99%    1.40s
        2783 requests in 3.03s, 432.13KB read
        Requests/sec:    918.18
        Transfer/sec:    142.57KB
        [run.sh] Speed is 918.18, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   504.97ms  543.82ms   4.36s    87.30%
        Req/Sec   138.63     74.21   400.00     70.27%
        Latency Distribution
        50%  294.66ms
        75%  642.48ms
        90%    1.26s
        99%    2.62s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.479904
        stop time: 18.249361
        stop time: 17.889619
        stop time: 18.550134
        stop time: 18.418153
        stop time: 18.568771
        stop time: 18.674715
        stop time: 18.699439
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.479904, 18.249361, 17.889619, 18.550134, 18.418153, 18.568771, 18.674715, 18.699439]
    [exp] Throughput: 1084.5244756025916
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '456.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1341.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '912.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   721.60ms  455.05ms   2.70s    68.07%
        Req/Sec   107.09     78.47   353.00     71.78%
        Latency Distribution
        50%  694.80ms
        75%  956.79ms
        90%    1.32s
        99%    1.94s
        1846 requests in 3.02s, 286.63KB read
        Requests/sec:    610.27
        Transfer/sec:     94.76KB
        [run.sh] Speed is 610.27, duration is 49
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d557f68bf-zsknh        316m         67Mi
        service1-7755b7b4b5-x827z        111m         54Mi
        service2-54c8b5d4f9-kps8h        146m         26Mi
        service3-697b6c488d-224vq        231m         13Mi
        service4-6cfd9c977d-87ffh        19m          11Mi
        ubuntu-client-76886f6bbd-92fws   6m           16Mi
        Running 49s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   706.78ms  557.61ms   5.23s    78.60%
        Req/Sec    93.41     54.92   330.00     67.03%
        Latency Distribution
        50%  591.71ms
        75%  925.47ms
        90%    1.35s
        99%    2.81s
        20000 requests in 49.00s, 3.03MB read
        Requests/sec:    408.16
        Transfer/sec:     63.38KB
        ------------------------------
        stop time: 27.303267
        stop time: 27.472654
        stop time: 27.900011
        stop time: 27.578546
        stop time: 27.484907
        stop time: 27.537696
        stop time: 27.743883
        stop time: 27.898641
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.303267, 27.472654, 27.900011, 27.578546, 27.484907, 27.537696, 27.743883, 27.898641]
    [exp] Throughput: 724.2453651861273
[test.py] Finished running 3th optmization experiment: groundtruth->1084.5244756025916, slowdown->724.2453651861273, predicted->1081.409910068803, err->-0.28718259512383304
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000384', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   486.56ms  330.15ms   1.60s    65.60%
        Req/Sec   137.38     78.18   340.00     67.15%
        Latency Distribution
        50%  416.91ms
        75%  714.57ms
        90%  989.34ms
        99%    1.33s
        2857 requests in 3.04s, 443.62KB read
        Requests/sec:    941.03
        Transfer/sec:    146.12KB
        [run.sh] Speed is 941.03, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   520.38ms  575.77ms   4.10s    88.61%
        Req/Sec   140.00     75.29   570.00     70.76%
        Latency Distribution
        50%  312.21ms
        75%  659.82ms
        90%    1.23s
        99%    2.88s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.497622
        stop time: 18.864128
        stop time: 17.811614
        stop time: 18.375216
        stop time: 18.000070
        stop time: 18.398562
        stop time: 18.780593
        stop time: 18.915180
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-6wcj7        1938m        71Mi
        service1-7755b7b4b5-vqvxm        864m         57Mi
        service2-958786d58-btn4l         1119m        29Mi
        service3-6ddd8b8f64-qxr6x        929m         18Mi
        service4-9bb5bd9fd-rzptk         607m         9Mi
        ubuntu-client-76886f6bbd-t4wcr   37m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.497622, 18.864128, 17.811614, 18.375216, 18.00007, 18.398562, 18.780593, 18.91518]
    [exp] Throughput: 1083.6952395672574
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '391.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1152.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '783.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   703.18ms  520.20ms   2.90s    67.78%
        Req/Sec    99.15     63.70   282.00     69.54%
        Latency Distribution
        50%  617.09ms
        75%  932.69ms
        90%    1.54s
        99%    1.93s
        1808 requests in 3.03s, 280.73KB read
        Requests/sec:    596.82
        Transfer/sec:     92.67KB
        [run.sh] Speed is 596.82, duration is 50
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d50s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 50s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   679.05ms  556.38ms   6.35s    82.32%
        Req/Sec   101.52     58.22   424.00     62.09%
        Latency Distribution
        50%  571.73ms
        75%  880.67ms
        90%    1.28s
        99%    2.98s
        20000 requests in 50.00s, 3.03MB read
        Requests/sec:    400.00
        Transfer/sec:     62.11KB
        ------------------------------
        stop time: 25.215107
        stop time: 26.126388
        stop time: 26.148272
        stop time: 26.360075
        stop time: 25.870373
        stop time: 26.546455
        stop time: 26.438918
        stop time: 26.153134
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [25.215107, 26.126388, 26.148272, 26.360075, 25.870373, 26.546455, 26.438918, 26.153134]
    [exp] Throughput: 766.068079263647
[test.py] Finished running 4th optmization experiment: groundtruth->1083.6952395672574, slowdown->766.068079263647, predicted->1094.501189086614, err->0.9971391517481973
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   451.46ms  349.54ms   1.48s    66.36%
        Req/Sec   146.72     71.97   410.00     70.53%
        Latency Distribution
        50%  378.26ms
        75%  707.17ms
        90%  891.06ms
        99%    1.43s
        2830 requests in 3.04s, 439.42KB read
        Requests/sec:    932.37
        Transfer/sec:    144.77KB
        [run.sh] Speed is 932.37, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   499.48ms  497.36ms   5.00s    87.17%
        Req/Sec   137.46     71.07   404.00     69.13%
        Latency Distribution
        50%  328.93ms
        75%  612.83ms
        90%    1.13s
        99%    2.51s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 18.532437
        stop time: 18.272538
        stop time: 18.712404
        stop time: 18.575806
        stop time: 18.906208
        stop time: 18.631341
        stop time: 18.800750
        stop time: 18.104025
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-kv8m6   3m           3Mi
        service4-9bb5bd9fd-7fklc    3m           3Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.532437, 18.272538, 18.712404, 18.575806, 18.906208, 18.631341, 18.80075, 18.104025]
    [exp] Throughput: 1077.18350364289
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '327.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '962.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '654.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   567.57ms  430.26ms   1.78s    62.56%
        Req/Sec   103.42     61.90   250.00     61.85%
        Latency Distribution
        50%  468.43ms
        75%  865.11ms
        90%    1.21s
        99%    1.64s
        1974 requests in 3.03s, 306.51KB read
        Requests/sec:    651.01
        Transfer/sec:    101.08KB
        [run.sh] Speed is 651.01, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-59f9d8648d-9xkjg        1436m        69Mi
        service1-7755b7b4b5-c4876        921m         54Mi
        service2-745886db66-jw4pz        657m         21Mi
        service3-6fc4fcf464-8mcfk        112m         15Mi
        service4-7486db89fd-246jl        349m         10Mi
        ubuntu-client-76886f6bbd-pgkhs   20m          19Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   659.45ms  553.22ms   4.44s    84.36%
        Req/Sec   107.14     64.85   464.00     65.48%
        Latency Distribution
        50%  537.51ms
        75%  841.25ms
        90%    1.22s
        99%    3.14s
        20000 requests in 46.00s, 3.03MB read
        Requests/sec:    434.78
        Transfer/sec:     67.51KB
        ------------------------------
        stop time: 25.072793
        stop time: 25.298170
        stop time: 24.533349
        stop time: 25.009998
        stop time: 24.717629
        stop time: 24.704894
        stop time: 25.403761
        stop time: 25.232383
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [25.072793, 25.29817, 24.533349, 25.009998, 24.717629, 24.704894, 25.403761, 25.232383]
    [exp] Throughput: 800.1081066068241
[test.py] Finished running 5th optmization experiment: groundtruth->1077.18350364289, slowdown->800.1081066068241, predicted->1084.0786390915814, err->0.6401077834345811
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000576', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   500.63ms  314.07ms   1.53s    60.69%
        Req/Sec   139.80     91.13   360.00     68.31%
        Latency Distribution
        50%  455.01ms
        75%  755.25ms
        90%  918.02ms
        99%    1.34s
        2647 requests in 3.03s, 411.01KB read
        Requests/sec:    872.85
        Transfer/sec:    135.53KB
        [run.sh] Speed is 872.85, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   500.97ms  517.25ms   3.48s    85.55%
        Req/Sec   138.85     74.00   400.00     68.69%
        Latency Distribution
        50%  327.20ms
        75%  662.14ms
        90%    1.22s
        99%    2.31s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 18.970341
        stop time: 18.723497
        stop time: 18.191663
        stop time: 18.305009
        stop time: 18.483519
        stop time: 18.276520
        stop time: 18.758218
        stop time: 18.425142
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-zztph        1933m        71Mi
        service1-7755b7b4b5-m68rh        1155m        56Mi
        service2-958786d58-7mlmh         1330m        27Mi
        service3-6ddd8b8f64-dksrx        908m         14Mi
        service4-9bb5bd9fd-nskrx         544m         13Mi
        ubuntu-client-76886f6bbd-jpjr8   40m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.970341, 18.723497, 18.191663, 18.305009, 18.483519, 18.27652, 18.758218, 18.425142]
    [exp] Throughput: 1080.103813367944
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '263.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '773.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '526.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   596.89ms  444.99ms   2.19s    65.98%
        Req/Sec   115.87     61.21   282.00     63.37%
        Latency Distribution
        50%  460.95ms
        75%  955.04ms
        90%    1.18s
        99%    1.79s
        2096 requests in 3.03s, 325.45KB read
        Requests/sec:    691.67
        Transfer/sec:    107.40KB
        [run.sh] Speed is 691.67, duration is 43
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d43s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-7755b7b4b5-s4sl2   3m           3Mi
        service2-cf56db458-2k68l    3m           3Mi
        service4-75dbf88985-95kr6   3m           3Mi
        Running 43s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   612.87ms  496.61ms   3.42s    80.09%
        Req/Sec   111.54     59.70   353.00     68.99%
        Latency Distribution
        50%  496.93ms
        75%  807.37ms
        90%    1.20s
        99%    2.46s
        20000 requests in 43.00s, 3.03MB read
        Requests/sec:    465.11
        Transfer/sec:     72.22KB
        ------------------------------
        stop time: 23.579039
        stop time: 22.954594
        stop time: 23.702252
        stop time: 23.684537
        stop time: 23.758733
        stop time: 23.939812
        stop time: 23.651528
        stop time: 23.931735
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.579039, 22.954594, 23.702252, 23.684537, 23.758733, 23.939812, 23.651528, 23.931735]
    [exp] Throughput: 845.6559946465748
[test.py] Finished running 6th optmization experiment: groundtruth->1080.103813367944, slowdown->845.6559946465748, predicted->1087.6124732347068, err->0.6951794608843755
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000672', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   434.66ms  254.20ms   1.25s    64.54%
        Req/Sec   138.94     90.78   480.00     68.60%
        Latency Distribution
        50%  396.19ms
        75%  624.46ms
        90%  838.13ms
        99%  995.95ms
        2921 requests in 3.04s, 453.55KB read
        Requests/sec:    961.38
        Transfer/sec:    149.28KB
        [run.sh] Speed is 961.38, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   481.87ms  376.66ms   3.11s    78.61%
        Req/Sec   143.13     82.29   420.00     64.04%
        Latency Distribution
        50%  375.57ms
        75%  660.10ms
        90%  962.83ms
        99%    1.80s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.561742
        stop time: 18.763716
        stop time: 18.765259
        stop time: 18.429360
        stop time: 18.656243
        stop time: 18.767971
        stop time: 18.614826
        stop time: 18.604465
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-6ppxx        638m         66Mi
        service1-7755b7b4b5-m9g9j        99m          53Mi
        service2-958786d58-pnkvp         48m          21Mi
        service3-6ddd8b8f64-whbq2        288m         11Mi
        service4-9bb5bd9fd-w5q27         71m          12Mi
        ubuntu-client-76886f6bbd-bbswn   11m          13Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.561742, 18.763716, 18.765259, 18.42936, 18.656243, 18.767971, 18.614826, 18.604465]
    [exp] Throughput: 1072.6478799630863
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '198.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '584.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '397.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   600.87ms  527.04ms   2.96s    80.82%
        Req/Sec   115.29     58.81   290.00     68.42%
        Latency Distribution
        50%  427.76ms
        75%  797.75ms
        90%    1.35s
        99%    2.67s
        2474 requests in 3.03s, 384.15KB read
        Requests/sec:    815.61
        Transfer/sec:    126.64KB
        [run.sh] Speed is 815.61, duration is 36
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d36s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6b6b7b9f5-bfbll         1627m        69Mi
        service1-7755b7b4b5-jf24f        1065m        46Mi
        service2-7cf4598c6b-9c4g2        843m         23Mi
        service3-55998c8697-gdbx8        771m         12Mi
        service4-6866646d59-k7zj5        342m         10Mi
        ubuntu-client-76886f6bbd-f2wgz   35m          22Mi
        Running 36s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   603.23ms  553.99ms   5.04s    85.90%
        Req/Sec   118.58     62.98   444.00     68.85%
        Latency Distribution
        50%  435.10ms
        75%  771.20ms
        90%    1.30s
        99%    2.85s
        20000 requests in 36.00s, 3.03MB read
        Requests/sec:    555.55
        Transfer/sec:     86.26KB
        ------------------------------
        stop time: 21.391397
        stop time: 21.976159
        stop time: 22.393744
        stop time: 22.428895
        stop time: 22.742948
        stop time: 22.525747
        stop time: 22.659227
        stop time: 22.710162
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.391397, 21.976159, 22.393744, 22.428895, 22.742948, 22.525747, 22.659227, 22.710162]
    [exp] Throughput: 894.7130783493142
[test.py] Finished running 7th optmization experiment: groundtruth->1072.6478799630863, slowdown->894.7130783493142, predicted->1088.2246065117554, err->1.452175204896234
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000768', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   443.29ms  369.07ms   2.02s    72.96%
        Req/Sec   141.50     69.20   380.00     73.76%
        Latency Distribution
        50%  333.96ms
        75%  656.06ms
        90%  992.50ms
        99%    1.61s
        2873 requests in 3.03s, 446.10KB read
        Requests/sec:    947.95
        Transfer/sec:    147.19KB
        [run.sh] Speed is 947.95, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   525.85ms  582.17ms   4.29s    86.33%
        Req/Sec   139.85     71.59   707.00     71.80%
        Latency Distribution
        50%  298.73ms
        75%  673.74ms
        90%    1.33s
        99%    2.72s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 17.816800
        stop time: 18.494277
        stop time: 18.000771
        stop time: 18.770129
        stop time: 18.046715
        stop time: 18.755289
        stop time: 18.361548
        stop time: 18.887350
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-lgx76        3m           62Mi
        service1-7755b7b4b5-tlzjd        327m         70Mi
        service2-958786d58-jw4g9         229m         30Mi
        service3-6ddd8b8f64-6h2bt        3m           16Mi
        service4-9bb5bd9fd-zmmgx         154m         10Mi
        ubuntu-client-76886f6bbd-5lgnk   6m           11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.8168, 18.494277, 18.000771, 18.770129, 18.046715, 18.755289, 18.361548, 18.88735]
    [exp] Throughput: 1087.452383773446
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '134.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '395.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '268.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   545.01ms  356.47ms   2.37s    65.01%
        Req/Sec   129.66     63.72   313.00     69.57%
        Latency Distribution
        50%  508.89ms
        75%  777.78ms
        90%  990.69ms
        99%    1.58s
        2448 requests in 3.03s, 380.11KB read
        Requests/sec:    806.99
        Transfer/sec:    125.30KB
        [run.sh] Speed is 806.99, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d8764fc6b-p465n        1258m        67Mi
        service1-7755b7b4b5-l26nv        586m         54Mi
        service2-8494b645-jmwhl          411m         28Mi
        service3-66c8557867-vg4j4        637m         12Mi
        service4-5df98d9dbf-ktd9k        235m         9Mi
        ubuntu-client-76886f6bbd-7n2xw   42m          19Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   533.43ms  370.50ms   2.95s    72.67%
        Req/Sec   122.78     70.24   363.00     65.40%
        Latency Distribution
        50%  457.35ms
        75%  720.40ms
        90%    1.03s
        99%    1.77s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 20.567161
        stop time: 21.103571
        stop time: 20.762468
        stop time: 20.932939
        stop time: 21.062600
        stop time: 21.130263
        stop time: 21.129868
        stop time: 20.997324
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.567161, 21.103571, 20.762468, 20.932939, 21.0626, 21.130263, 21.129868, 20.997324]
    [exp] Throughput: 954.1632270573211
[test.py] Finished running 8th optmization experiment: groundtruth->1087.452383773446, slowdown->954.1632270573211, predicted->1094.559052302314, err->0.6535153754694126
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.000864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   527.64ms  404.96ms   1.86s    68.52%
        Req/Sec   141.95     68.69   380.00     65.73%
        Latency Distribution
        50%  373.14ms
        75%  851.00ms
        90%    1.12s
        99%    1.49s
        2597 requests in 3.03s, 403.25KB read
        Requests/sec:    855.92
        Transfer/sec:    132.90KB
        [run.sh] Speed is 855.92, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   478.94ms  420.80ms   3.46s    81.90%
        Req/Sec   139.06     69.63   414.00     68.93%
        Latency Distribution
        50%  360.98ms
        75%  643.78ms
        90%    1.02s
        99%    1.92s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 18.422927
        stop time: 18.461095
        stop time: 18.430379
        stop time: 18.297950
        stop time: 18.620775
        stop time: 18.692387
        stop time: 18.176747
        stop time: 18.719168
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.422927, 18.461095, 18.430379, 18.29795, 18.620775, 18.692387, 18.176747, 18.719168]
    [exp] Throughput: 1082.3870541962292
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.001519', 'PROCESSING_TIME_SERVICE1': '0.00096864', 'PROCESSING_TIME_SERVICE2': '0.00329369', 'PROCESSING_TIME_SERVICE3': '0.00147608', 'PROCESSING_TIME_SERVICE4': '0.00097575', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '70.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '206.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE3': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE4': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   571.87ms  487.84ms   2.36s    75.45%
        Req/Sec   128.18     69.98   300.00     63.08%
        Latency Distribution
        50%  453.75ms
        75%  860.65ms
        90%    1.16s
        99%    2.04s
        2522 requests in 3.04s, 391.60KB read
        Requests/sec:    830.71
        Transfer/sec:    128.99KB
        [run.sh] Speed is 830.71, duration is 36
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d36s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f78d8d955-q7wrg         571m         69Mi
        service1-7755b7b4b5-hmmjr        459m         74Mi
        service2-c67776854-bhbps         297m         44Mi
        service3-6649d96499-zrbz6        250m         13Mi
        service4-6b5bfdd577-ldn2g        172m         10Mi
        ubuntu-client-76886f6bbd-79x2r   18m          0Mi
        Running 36s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   515.63ms  471.69ms   3.68s    85.82%
        Req/Sec   131.03     63.34   480.00     71.40%
        Latency Distribution
        50%  376.14ms
        75%  667.67ms
        90%    1.13s
        99%    2.36s
        20000 requests in 36.00s, 3.03MB read
        Requests/sec:    555.55
        Transfer/sec:     86.26KB
        ------------------------------
        stop time: 18.775794
        stop time: 19.632134
        stop time: 19.489689
        stop time: 19.098469
        stop time: 19.834456
        stop time: 19.959949
        stop time: 20.161324
        stop time: 19.938553
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.775794, 19.632134, 19.489689, 19.098469, 19.834456, 19.959949, 20.161324, 19.938553]
    [exp] Throughput: 1019.8204137044281
[test.py] Finished running 9th optmization experiment: groundtruth->1082.3870541962292, slowdown->1019.8204137044281, predicted->1098.3507165640071, err->1.474857104571748
[test.py] Baseline throughput:  1076.4385615761407
[test.py] Groundtruth:  [1086.131231711035, 1083.1527790989046, 1085.0973857609981, 1084.5244756025916, 1083.6952395672574, 1077.18350364289, 1080.103813367944, 1072.6478799630863, 1087.452383773446, 1082.3870541962292]
[test.py] Slowdown:  [635.0469361801366, 666.1414308020151, 694.0045588118462, 724.2453651861273, 766.068079263647, 800.1081066068241, 845.6559946465748, 894.7130783493142, 954.1632270573211, 1019.8204137044281]
[test.py] Predicted:  [1080.2659693135738, 1091.0909112904492, 1086.2906668866044, 1081.409910068803, 1094.501189086614, 1084.0786390915814, 1087.6124732347068, 1088.2246065117554, 1094.559052302314, 1098.3507165640071]
[test.py] Error percentage:  [-0.5400141554001199, 0.7328728084092131, 0.10996995673060453, -0.28718259512383304, 0.9971391517481973, 0.6401077834345811, 0.6951794608843755, 1.452175204896234, 0.6535153754694126, 1.474857104571748]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1070.0881737272634
    Groundtruth: [1084.451821126721, 1078.910015243178, 1089.944561809145, 1094.58406985444, 1088.1572648405438, 1085.8419919787632, 1065.9087842029228, 1089.958632118811, 1080.0898723881241, 1077.0719935182885]
    Slowdown:    [636.3813650083567, 668.4813484177932, 692.9666569564714, 744.87669618433, 766.4892802881234, 799.5371079913283, 850.3390062460056, 895.9009212420386, 957.9720593678037, 1009.4333757095566]
    Predicted:   [1084.1330695014203, 1097.3825505749326, 1083.749947133323, 1128.0630472180965, 1095.3611714537215, 1083.0306680034332, 1095.3709200462613, 1089.9823408554762, 1099.5741576074759, 1086.311841416232]
    Error Perc:  [-0.029392880263635564, 1.7121479150966177, -0.5683421793067837, 3.0586026496903562, 0.6620280768178574, -0.2589072808104251, 2.7640391260467965, 0.002175196008961975, 1.8039503672292687, 0.8578672506153694]
[test.py] Result for the experiment 1: 
    Baseline throughput: 1081.7140957846068
    Groundtruth: [1084.4632361438964, 1084.367961562409, 1081.1235736204578, 1103.5967514857102, 1083.4030847424553, 1083.0669575279082, 1087.1746730864058, 1083.6878262471835, 1088.661275067166, 1080.4326535838563]
    Slowdown:    [637.6921817910234, 665.8178543235645, 698.5880356931332, 723.3143336891421, 763.8908854821668, 804.7115458654649, 844.6310032557674, 899.4675062416298, 970.2925176025919, 1013.7270426146899]
    Predicted:   [1087.942869073705, 1090.2230878532976, 1097.5622990423453, 1079.3354820159468, 1090.0623849515798, 1092.546903140978, 1085.9176261167422, 1095.2661392668135, 1115.8370062851889, 1091.286035987094]
    Error Perc:  [0.320862230625845, 0.5399575142788501, 1.5205223364834828, -2.1983817401693, 0.6146650589154916, 0.8752871230332455, -0.11562511533633997, 1.0684177434866844, 2.4962522173250212, 1.0045403910402364]
[test.py] Result for the experiment 2: 
    Baseline throughput: 1079.0585680686431
    Groundtruth: [1096.0063023650407, 1088.692090707076, 1082.30972200266, 1083.3758394715433, 1086.7913324098415, 1089.1427390175475, 1083.3908043941763, 1083.614982927646, 1086.2130487547474, 1081.9652294379289]
    Slowdown:    [637.2804337891439, 663.9191066022336, 688.4566139611678, 735.2534286682536, 758.2810271475745, 801.9534664195494, 851.4131945109798, 910.0968505159949, 955.4742319587593, 1019.44485939036]
    Predicted:   [1086.7449608451223, 1085.1415119820613, 1072.7593030038756, 1106.137838573756, 1078.6747835775566, 1087.4691171514507, 1097.1540242899891, 1111.0674631344514, 1096.2845928492204, 1097.9151092998165]
    Error Perc:  [-0.845008053323569, -0.3261324992917601, -0.882410903702564, 2.1010251726968288, -0.7468359923599474, -0.15366414393088523, 1.27038367318515, 2.5334164476607652, 0.9272162681178584, 1.4741582657118735]
[test.py] Result for the experiment 3: 
    Baseline throughput: 1091.2091387019432
    Groundtruth: [1088.8201572676862, 1087.5692990660732, 1087.3667441399616, 1087.9472410864907, 1094.2195901073933, 1084.9370205587022, 1080.449704235672, 1084.1391152134695, 1077.3451683291225, 1081.376114095345]
    Slowdown:    [637.7435739512601, 663.4299440058908, 695.2251424488073, 728.1887523137003, 760.4907669362589, 804.8391031561172, 858.2100259849906, 888.9932468183626, 944.3962785946595, 1008.2989494463925]
    Predicted:   [1088.0924621803035, 1083.8353630510107, 1089.2840820615975, 1090.2253981729718, 1083.1518845194366, 1092.7820448260559, 1108.4666330274756, 1079.7746850361357, 1081.7257530851311, 1084.9981516717423]
    Error Perc:  [-0.06683335925822646, -0.3433285601449849, 0.17632854158624794, 0.2093995922270992, -1.0114702467418264, 0.7230856831960412, 2.5930803333065127, -0.40257104610365885, 0.4066092172485949, 0.334947066907195]
[test.py] Result for the experiment 4: 
    Baseline throughput: 1076.4385615761407
    Groundtruth: [1086.131231711035, 1083.1527790989046, 1085.0973857609981, 1084.5244756025916, 1083.6952395672574, 1077.18350364289, 1080.103813367944, 1072.6478799630863, 1087.452383773446, 1082.3870541962292]
    Slowdown:    [635.0469361801366, 666.1414308020151, 694.0045588118462, 724.2453651861273, 766.068079263647, 800.1081066068241, 845.6559946465748, 894.7130783493142, 954.1632270573211, 1019.8204137044281]
    Predicted:   [1080.2659693135738, 1091.0909112904492, 1086.2906668866044, 1081.409910068803, 1094.501189086614, 1084.0786390915814, 1087.6124732347068, 1088.2246065117554, 1094.559052302314, 1098.3507165640071]
    Error Perc:  [-0.5400141554001199, 0.7328728084092131, 0.10996995673060453, -0.28718259512383304, 0.9971391517481973, 0.6401077834345811, 0.6951794608843755, 1.452175204896234, 0.6535153754694126, 1.474857104571748]
