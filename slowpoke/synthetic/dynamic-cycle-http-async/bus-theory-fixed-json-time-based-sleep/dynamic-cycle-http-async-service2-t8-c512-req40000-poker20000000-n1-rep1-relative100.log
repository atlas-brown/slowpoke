[config.py] Random numbers for execution time: [332.05590072947507, 359.2955943541629, 616.1832837112506, 639.3353287057685, 681.1973146981454]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : dynamic-cycle-http-async
repetitions                      : 1
target_num_exp                   : 1
pre_run                          : False
num_req                          : 40000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 16560
request_ratio                    : {'service0': 1, 'service1': 1.34, 'service2': 0.34, 'service3': 0.5, 'service4': 0.5}
baseline_service_processing_time : {'service0': 912.8, 'service1': 639.34, 'service2': 2428.49, 'service3': 962.91, 'service4': 889.91}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2, 'service4': 2}
target_processing_time_range     : [0, 2428.49]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0009128', 'PROCESSING_TIME_SERVICE1': '0.00063934', 'PROCESSING_TIME_SERVICE2': '0.00242849', 'PROCESSING_TIME_SERVICE3': '0.00096291', 'PROCESSING_TIME_SERVICE4': '0.00088991', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   364.45ms   88.99ms 781.19ms   84.47%
        Req/Sec   183.02     55.98   313.00     75.00%
        Latency Distribution
        50%  340.55ms
        75%  383.64ms
        90%  465.84ms
        99%  714.98ms
        3979 requests in 3.02s, 2.24MB read
        Requests/sec:   1315.73
        Transfer/sec:    759.30KB
        [run.sh] Speed is 1315.73, duration is 60
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d60s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-zpxhj         587m         45Mi
        service1-5c544b6b9c-zb7wn        396m         22Mi
        service2-66888cb84d-p5mln        440m         13Mi
        service3-67b8d48975-c6h2b        265m         9Mi
        service4-dcdcc9fc4-jddqv         240m         8Mi
        ubuntu-client-76886f6bbd-wb52w   11m          0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   337.81ms   55.29ms   1.08s    77.81%
        Req/Sec   189.34     43.16   343.00     72.93%
        Latency Distribution
        50%  328.80ms
        75%  363.67ms
        90%  402.95ms
        99%  503.55ms
        40001 requests in 1.00m, 22.68MB read
        Requests/sec:    666.68
        Transfer/sec:    387.13KB
        ------------------------------
        stop time: 26.580742
        stop time: 26.630085
        stop time: 26.423797
        stop time: 26.538539
        stop time: 26.428583
        stop time: 26.594070
        stop time: 26.664884
        stop time: 26.726525
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.580742, 26.630085, 26.423797, 26.538539, 26.428583, 26.59407, 26.664884, 26.726525]
    [exp] Throughput: 1505.2644861421002
[test.py] Baseline throughput: 1505.2644861421002
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0009128', 'PROCESSING_TIME_SERVICE1': '0.00063934', 'PROCESSING_TIME_SERVICE2': '0.0', 'PROCESSING_TIME_SERVICE3': '0.00096291', 'PROCESSING_TIME_SERVICE4': '0.00088991', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   368.30ms  137.52ms   1.12s    85.04%
        Req/Sec   169.72     51.44   272.00     75.86%
        Latency Distribution
        50%  335.70ms
        75%  384.02ms
        90%  491.37ms
        99%  996.90ms
        3936 requests in 3.03s, 2.23MB read
        Requests/sec:   1299.77
        Transfer/sec:    754.52KB
        [run.sh] Speed is 1299.77, duration is 61
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d61s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-sxh2l         418m         44Mi
        service1-5c544b6b9c-zxt8n        89m          21Mi
        service2-66888cb84d-vr62h        127m         11Mi
        service3-67b8d48975-vbwll        269m         8Mi
        service4-dcdcc9fc4-mgh75         234m         9Mi
        ubuntu-client-76886f6bbd-vczkq   3m           9Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   342.10ms   72.43ms   1.54s    87.72%
        Req/Sec   186.98     42.12   640.00     69.11%
        Latency Distribution
        50%  332.37ms
        75%  367.08ms
        90%  406.62ms
        99%  528.23ms
        40000 requests in 1.02m, 22.64MB read
        Requests/sec:    655.74
        Transfer/sec:    380.13KB
        ------------------------------
        stop time: 26.509871
        stop time: 26.782790
        stop time: 26.984902
        stop time: 26.990518
        stop time: 27.069842
        stop time: 27.008770
        stop time: 26.916289
        stop time: 27.011118
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.509871, 26.78279, 26.984902, 26.990518, 27.069842, 27.00877, 26.916289, 27.011118]
    [exp] Throughput: 1486.4770076846216
[test.py] Running slowdown experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cycle-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0009128', 'PROCESSING_TIME_SERVICE1': '0.00063934', 'PROCESSING_TIME_SERVICE2': '0.00242849', 'PROCESSING_TIME_SERVICE3': '0.00096291', 'PROCESSING_TIME_SERVICE4': '0.00088991', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '412.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '41249990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '308.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '41271990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '825.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '41274990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '825.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '41274990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cycle-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-cycle-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   579.02ms  168.26ms   1.44s    80.56%
        Req/Sec   101.91     45.97   202.00     65.67%
        Latency Distribution
        50%  576.18ms
        75%  623.41ms
        90%  725.30ms
        99%    1.23s
        2387 requests in 3.03s, 1.36MB read
        Requests/sec:    787.48
        Transfer/sec:    457.82KB
        [run.sh] Speed is 787.48, duration is 101
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d101s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-679699c687-f6bvz        73m          52Mi
        service1-f76df7488-qbm7n         132m         23Mi
        service2-66888cb84d-8qhdk        306m         13Mi
        service3-594f954764-zdlcx        171m         9Mi
        service4-866948fd5c-2qbxg        158m         9Mi
        ubuntu-client-76886f6bbd-wzm57   8m           11Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   572.19ms   72.99ms   1.12s    73.83%
        Req/Sec   111.92     35.77   330.00     68.05%
        Latency Distribution
        50%  566.24ms
        75%  611.18ms
        90%  663.88ms
        99%  762.30ms
        40000 requests in 1.68m, 22.67MB read
        Requests/sec:    396.04
        Transfer/sec:    229.80KB
        ------------------------------
        stop time: 44.448123
        stop time: 44.980223
        stop time: 44.862582
        stop time: 45.100375
        stop time: 45.105419
        stop time: 45.202182
        stop time: 45.194511
        stop time: 45.196273
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [44.448123, 44.980223, 44.862582, 45.100375, 45.105419, 45.202182, 45.194511, 45.196273]
    [exp] Throughput: 888.6674921943336
[test.py] Baseline throughput:  1505.2644861421002
[test.py] Groundtruth:  [1486.4770076846216]
[test.py] Slowdown:  [888.6674921943336]
[test.py] Predicted:  [1403.6329318814485]
[test.py] Error percentage:  [-5.573182455893711]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1505.2644861421002
    Groundtruth: [1486.4770076846216]
    Slowdown:    [888.6674921943336]
    Predicted:   [1403.6329318814485]
    Error Perc:  [-5.573182455893711]
