chain-d2-http-sync[config.py] Random numbers for execution time: [816.2658925781716, 432.33282327479407, 1159.1121645128542]
[test.py] BENCHMARK:                        syncthetic
[test.py] REQUEST_TYPE:                     chain-d2-http-sync
[test.py] TARGET_SERVICE:                   service0
[test.py] NUM_THREADS:                      2
[test.py] NUM_CONN:                         128
[test.py] REPETITIONS:                      3
[test.py] NUM_REQ:                          18000
[test.py] REQUEST_RATIO:                    {'service0': 1, 'service1': 1, 'service2': 1}
[test.py] BASELINE_PROCESSING_TIME:         {'service0': 1159.11, 'service1': 816.27, 'service2': 432.33}
[test.py] TARGET_PROCESSING_TIME_RANGE:     [0, 1159.11]
[test.py] TARGET_NUM_EXP:                   10
[test.py] CPU_QUOTA:                         {'service0': 1, 'service1': 1, 'service2': 1}
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 115, 230, 345, 460, 575, 690, 805, 920, 1035]
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.0', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   189.88ms  150.67ms 996.96ms   69.60%
    Req/Sec   348.78     90.65   626.00     70.00%
    Latency Distribution
    50%  180.28ms
    75%  289.16ms
    90%  400.56ms
    99%  634.64ms
    2086 requests in 3.02s, 1.45MB read
    Requests/sec:    690.42
    Transfer/sec:    492.19KB
    [run.sh] Speed is 690.42, duration is 39
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 39s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   188.14ms  159.74ms   1.40s    72.63%
    Req/Sec   353.30    102.85   650.00     68.43%
    Latency Distribution
    50%  110.07ms
    75%  293.83ms
    90%  401.68ms
    99%  699.24ms
    18009 requests in 39.00s, 12.54MB read
    Requests/sec:    461.77
    Transfer/sec:    329.19KB
    ------------------------------
    stop time: 25.653032
    stop time: 25.456271
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-6qs7b        197m         24Mi
    service1-5c9649c5ff-fcph9        997m         20Mi
    service2-6c6d889d77-khf77        481m         11Mi
    ubuntu-client-7477c7845f-lxwcc   19m          6Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000115', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   185.12ms  156.48ms 859.50ms   70.53%
    Req/Sec   353.00    119.55   600.00     65.00%
    Latency Distribution
    50%  137.59ms
    75%  299.04ms
    90%  406.15ms
    99%  599.15ms
    2110 requests in 3.02s, 1.48MB read
    Requests/sec:    697.83
    Transfer/sec:    502.25KB
    [run.sh] Speed is 697.83, duration is 38
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 38s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   185.26ms  160.28ms   1.30s    72.11%
    Req/Sec   357.36     97.78   690.00     68.39%
    Latency Distribution
    50%  106.85ms
    75%  295.55ms
    90%  403.95ms
    99%  691.39ms
    18000 requests in 38.00s, 12.65MB read
    Requests/sec:    473.68
    Transfer/sec:    340.92KB
    ------------------------------
    stop time: 25.102506
    stop time: 25.437160
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-s9cdl        249m         22Mi
    service1-5c9649c5ff-hqp59        1m           17Mi
    service2-6c6d889d77-tcc28        1m           10Mi
    ubuntu-client-7477c7845f-twgcv   19m          0Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00023', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   195.17ms  162.08ms   1.10s    68.21%
    Req/Sec   353.60    112.25   606.00     70.00%
    Latency Distribution
    50%  183.14ms
    75%  290.96ms
    90%  400.91ms
    99%  707.11ms
    2112 requests in 3.02s, 1.48MB read
    Requests/sec:    698.54
    Transfer/sec:    502.08KB
    [run.sh] Speed is 698.54, duration is 38
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 38s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   185.11ms  157.02ms   1.20s    67.79%
    Req/Sec   357.26    105.28   710.00     70.44%
    Latency Distribution
    50%  114.20ms
    75%  293.31ms
    90%  400.51ms
    99%  694.65ms
    18000 requests in 38.00s, 12.63MB read
    Requests/sec:    473.68
    Transfer/sec:    340.46KB
    ------------------------------
    stop time: 25.250614
    stop time: 25.248627
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-zmrp7        201m         20Mi
    service1-5c9649c5ff-jstsk        211m         19Mi
    service2-6c6d889d77-w62hx        81m          9Mi
    ubuntu-client-7477c7845f-zqwmp   15m          4Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000345', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   193.60ms  150.53ms 803.60ms   70.60%
    Req/Sec   348.63    117.88   683.00     70.00%
    Latency Distribution
    50%  181.39ms
    75%  293.97ms
    90%  399.62ms
    99%  686.72ms
    2085 requests in 3.03s, 1.47MB read
    Requests/sec:    687.12
    Transfer/sec:    494.54KB
    [run.sh] Speed is 687.12, duration is 39
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 39s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   185.16ms  159.59ms   1.40s    66.85%
    Req/Sec   357.88    106.81   670.00     70.38%
    Latency Distribution
    50%  113.38ms
    75%  293.95ms
    90%  400.11ms
    99%  694.98ms
    18000 requests in 39.00s, 12.65MB read
    Requests/sec:    461.54
    Transfer/sec:    332.18KB
    ------------------------------
    stop time: 25.228498
    stop time: 25.244198
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-p5lkj        703m         25Mi
    service1-5c9649c5ff-6c642        797m         19Mi
    service2-6c6d889d77-klw5p        410m         9Mi
    ubuntu-client-7477c7845f-mds8c   42m          5Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00046', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   184.01ms  132.03ms 801.40ms   73.65%
    Req/Sec   358.72    115.89   620.00     68.97%
    Latency Distribution
    50%  192.07ms
    75%  290.47ms
    90%  388.23ms
    99%  590.32ms
    2101 requests in 3.02s, 1.47MB read
    Requests/sec:    695.92
    Transfer/sec:    500.19KB
    [run.sh] Speed is 695.92, duration is 38
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 38s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   185.69ms  152.63ms   1.10s    68.74%
    Req/Sec   354.56    118.38   750.00     68.96%
    Latency Distribution
    50%  110.53ms
    75%  294.26ms
    90%  398.77ms
    99%  678.97ms
    18001 requests in 38.00s, 12.63MB read
    Requests/sec:    473.71
    Transfer/sec:    340.48KB
    ------------------------------
    stop time: 25.634279
    stop time: 25.435181
    [run.sh] Checking the resource usage
    NAME                        CPU(cores)   MEMORY(bytes)
    service1-5c9649c5ff-g66xl   317m         12Mi
    service2-6c6d889d77-snptj   149m         9Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000575', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   192.84ms  156.58ms   1.01s    71.65%
    Req/Sec   336.45    112.41   580.00     63.33%
    Latency Distribution
    50%  161.24ms
    75%  294.57ms
    90%  399.92ms
    99%  699.95ms
    2011 requests in 3.02s, 1.41MB read
    Requests/sec:    666.46
    Transfer/sec:    479.67KB
    [run.sh] Speed is 666.46, duration is 40
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d40s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 40s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.78ms  152.73ms   1.20s    68.84%
    Req/Sec   351.64    100.62   640.00     68.95%
    Latency Distribution
    50%  115.99ms
    75%  294.64ms
    90%  399.15ms
    99%  639.99ms
    18004 requests in 40.00s, 12.65MB read
    Requests/sec:    450.10
    Transfer/sec:    323.95KB
    ------------------------------
    stop time: 25.684262
    stop time: 25.690073
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-ggvsf        830m         25Mi
    service1-5c9649c5ff-t5hck        996m         18Mi
    service2-6c6d889d77-hd6ql        484m         10Mi
    ubuntu-client-7477c7845f-spmmr   41m          6Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00069', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   188.26ms  139.23ms   1.08s    72.93%
    Req/Sec   351.10     83.78   570.00     75.00%
    Latency Distribution
    50%  186.72ms
    75%  285.66ms
    90%  394.65ms
    99%  595.55ms
    2098 requests in 3.02s, 1.47MB read
    Requests/sec:    694.91
    Transfer/sec:    499.47KB
    [run.sh] Speed is 694.91, duration is 38
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 38s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.01ms  139.73ms 914.14ms   72.66%
    Req/Sec   350.31    103.19   650.00     66.93%
    Latency Distribution
    50%  179.15ms
    75%  290.07ms
    90%  394.71ms
    99%  600.30ms
    18005 requests in 38.00s, 12.64MB read
    Requests/sec:    473.81
    Transfer/sec:    340.55KB
    ------------------------------
    stop time: 25.875164
    stop time: 25.676386
    [run.sh] Checking the resource usage
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000805', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   193.04ms  111.95ms 700.52ms   81.64%
    Req/Sec   322.43    140.69   660.00     71.67%
    Latency Distribution
    50%  194.74ms
    75%  279.85ms
    90%  305.63ms
    99%  503.50ms
    1929 requests in 3.03s, 1.36MB read
    Requests/sec:    637.21
    Transfer/sec:    458.61KB
    [run.sh] Speed is 637.21, duration is 42
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-6rltv        471m         25Mi
    service1-5c9649c5ff-ctc55        61m          18Mi
    service2-6c6d889d77-nlxsz        466m         10Mi
    ubuntu-client-7477c7845f-s97x9   20m          6Mi
    Running 42s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.22ms  111.89ms   1.18s    72.00%
    Req/Sec   344.31     78.90   620.00     69.27%
    Latency Distribution
    50%  173.65ms
    75%  243.00ms
    90%  330.95ms
    99%  526.11ms
    18000 requests in 42.00s, 12.65MB read
    Requests/sec:    428.57
    Transfer/sec:    308.45KB
    ------------------------------
    stop time: 26.102768
    stop time: 26.534086
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00092', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   194.55ms   84.53ms 693.69ms   54.78%
    Req/Sec   326.10    120.68   640.00     65.52%
    Latency Distribution
    50%  198.18ms
    75%  207.75ms
    90%  300.55ms
    99%  460.18ms
    1914 requests in 3.03s, 1.34MB read
    Requests/sec:    630.73
    Transfer/sec:    453.33KB
    [run.sh] Speed is 630.73, duration is 42
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-bbhwb        775m         25Mi
    service1-5c9649c5ff-5pmbr        1000m        16Mi
    service2-6c6d889d77-7svxg        446m         9Mi
    ubuntu-client-7477c7845f-5hs89   25m          5Mi
    Running 42s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   204.94ms  124.51ms   1.80s    85.57%
    Req/Sec   316.76     93.16   600.00     70.35%
    Latency Distribution
    50%  196.54ms
    75%  250.92ms
    90%  357.59ms
    99%  658.87ms
    18005 requests in 42.00s, 12.64MB read
    Requests/sec:    428.69
    Transfer/sec:    308.12KB
    ------------------------------
    stop time: 28.301272
    stop time: 28.904019
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.001035', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   215.11ms  118.79ms 810.91ms   75.66%
    Req/Sec   301.22    119.90   590.00     62.07%
    Latency Distribution
    50%  198.49ms
    75%  294.03ms
    90%  391.06ms
    99%  596.63ms
    1769 requests in 3.02s, 1.24MB read
    Requests/sec:    585.70
    Transfer/sec:    421.54KB
    [run.sh] Speed is 585.70, duration is 46
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-7bm42        320m         23Mi
    service1-5c9649c5ff-bkhnb        303m         11Mi
    service2-6c6d889d77-xk4dj        131m         8Mi
    ubuntu-client-7477c7845f-hkxr5   13m          3Mi
    Running 46s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   225.30ms  180.09ms   2.00s    86.12%
    Req/Sec   280.65    111.80   636.00     66.87%
    Latency Distribution
    50%  195.91ms
    75%  296.57ms
    90%  404.86ms
    99%  910.60ms
    18000 requests in 46.00s, 12.65MB read
    Socket errors: connect 0, read 0, write 0, timeout 72
    Requests/sec:    391.30
    Transfer/sec:    281.63KB
    ------------------------------
    stop time: 32.360905
    stop time: 32.550449
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '1159', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1159'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   328.26ms  232.74ms   1.25s    74.50%
    Req/Sec   182.57    111.58   434.00     61.67%
    Latency Distribution
    50%  293.66ms
    75%  473.50ms
    90%  622.88ms
    99%    1.02s
    1091 requests in 3.03s, 787.35KB read
    Requests/sec:    360.20
    Transfer/sec:    259.95KB
    [run.sh] Speed is 360.20, duration is 74
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d74s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-xwqnd        728m         24Mi
    service1-94ddd99c-rxm2f          996m         23Mi
    service2-657fbf87fc-wgzm8        714m         11Mi
    ubuntu-client-7477c7845f-4dnw4   25m          7Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   330.62ms  264.21ms   1.99s    77.07%
    Req/Sec   196.88     78.00   504.00     70.10%
    Latency Distribution
    50%  213.09ms
    75%  495.39ms
    90%  700.96ms
    99%    1.11s
    18000 requests in 1.23m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 2
    Requests/sec:    243.24
    Transfer/sec:    175.54KB
    ------------------------------
    stop time: 45.894368
    stop time: 45.996626
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '1044', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1044'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   317.92ms  201.86ms   1.20s    63.69%
    Req/Sec   197.55    107.39   454.00     65.52%
    Latency Distribution
    50%  283.23ms
    75%  454.13ms
    90%  598.16ms
    99%  898.16ms
    1159 requests in 3.03s, 836.43KB read
    Requests/sec:    382.73
    Transfer/sec:    276.21KB
    [run.sh] Speed is 382.73, duration is 70
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d70s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-7lnbw        747m         24Mi
    service1-57944f859d-4dpvs        539m         20Mi
    service2-b788d7cd6-vtc5b         335m         10Mi
    ubuntu-client-7477c7845f-kkj72   27m          6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   319.72ms  258.62ms   1.86s    77.80%
    Req/Sec   205.04     76.34   525.00     71.10%
    Latency Distribution
    50%  209.28ms
    75%  469.27ms
    90%  695.99ms
    99%    1.13s
    18000 requests in 1.17m, 12.69MB read
    Requests/sec:    257.14
    Transfer/sec:    185.57KB
    ------------------------------
    stop time: 43.907536
    stop time: 44.207389
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '929', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '929'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   312.96ms  265.33ms   1.71s    77.27%
    Req/Sec   209.28     79.54   420.00     65.52%
    Latency Distribution
    50%  200.00ms
    75%  471.53ms
    90%  700.75ms
    99%    1.15s
    1227 requests in 3.03s, 0.86MB read
    Requests/sec:    405.11
    Transfer/sec:    292.36KB
    [run.sh] Speed is 405.11, duration is 66
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d66s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-5jtg6        553m         23Mi
    service1-784bdf5989-8fbhz        245m         21Mi
    service2-bd546fd99-kzc4l         126m         10Mi
    ubuntu-client-7477c7845f-957zv   20m          5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   301.35ms  238.42ms   1.71s    78.84%
    Req/Sec   216.40     82.71   480.00     68.23%
    Latency Distribution
    50%  205.20ms
    75%  405.45ms
    90%  622.73ms
    99%    1.09s
    18003 requests in 1.10m, 12.69MB read
    Requests/sec:    272.77
    Transfer/sec:    196.85KB
    ------------------------------
    stop time: 41.670132
    stop time: 41.767717
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '814', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '814'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   308.68ms  235.22ms   1.61s    79.62%
    Req/Sec   214.48     85.52   410.00     70.69%
    Latency Distribution
    50%  235.30ms
    75%  407.64ms
    90%  651.54ms
    99%    1.10s
    1250 requests in 3.03s, 0.88MB read
    Requests/sec:    412.98
    Transfer/sec:    298.04KB
    [run.sh] Speed is 412.98, duration is 65
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d65s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-bxspb        567m         25Mi
    service1-9c5b86bb4-fjmk9         230m         18Mi
    service2-5f8ffb9858-68gxx        119m         9Mi
    ubuntu-client-7477c7845f-4skn7   21m          5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   285.75ms  223.65ms   1.50s    78.27%
    Req/Sec   226.50     86.97   540.00     71.61%
    Latency Distribution
    50%  203.22ms
    75%  402.96ms
    90%  600.36ms
    99%  941.34ms
    18000 requests in 1.08m, 12.69MB read
    Requests/sec:    276.92
    Transfer/sec:    199.85KB
    ------------------------------
    stop time: 40.016479
    stop time: 39.912738
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '699', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '699'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   271.90ms  209.67ms   1.09s    67.04%
    Req/Sec   233.22     99.31   410.00     65.52%
    Latency Distribution
    50%  201.33ms
    75%  404.47ms
    90%  510.56ms
    99%  809.06ms
    1351 requests in 3.02s, 0.95MB read
    Requests/sec:    446.66
    Transfer/sec:    322.34KB
    [run.sh] Speed is 446.66, duration is 60
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d60s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-qfvq2        760m         24Mi
    service1-5b5d5f7cd7-4b62w        425m         19Mi
    service2-6854b585df-6h7vk        236m         11Mi
    ubuntu-client-7477c7845f-zcqd9   27m          5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   272.72ms  213.92ms   1.80s    74.63%
    Req/Sec   239.89     87.57   565.00     65.38%
    Latency Distribution
    50%  200.76ms
    75%  397.56ms
    90%  595.07ms
    99%  906.04ms
    18001 requests in 1.00m, 12.69MB read
    Requests/sec:    300.02
    Transfer/sec:    216.52KB
    ------------------------------
    stop time: 37.565124
    stop time: 37.970801
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '584', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '584'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   260.09ms  188.20ms   1.17s    78.78%
    Req/Sec   252.26     93.44   464.00     67.24%
    Latency Distribution
    50%  202.05ms
    75%  363.47ms
    90%  511.24ms
    99%  864.64ms
    1484 requests in 3.02s, 1.05MB read
    Requests/sec:    491.50
    Transfer/sec:    354.71KB
    [run.sh] Speed is 491.50, duration is 54
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d54s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-z8vrm        904m         25Mi
    service1-6bbd797446-vtg87        996m         20Mi
    service2-7b6f55dc48-fxnl6        621m         10Mi
    ubuntu-client-7477c7845f-5tn4w   30m          7Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   256.79ms  180.01ms   1.50s    77.85%
    Req/Sec   252.29     87.48   626.00     67.69%
    Latency Distribution
    50%  202.78ms
    75%  379.50ms
    90%  501.57ms
    99%  798.39ms
    18000 requests in 0.90m, 12.69MB read
    Requests/sec:    333.33
    Transfer/sec:    240.56KB
    ------------------------------
    stop time: 35.694869
    stop time: 36.004801
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '469', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '469'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   245.07ms  145.30ms 800.39ms   68.49%
    Req/Sec   260.53     90.48   440.00     74.14%
    Latency Distribution
    50%  202.47ms
    75%  312.07ms
    90%  461.45ms
    99%  687.69ms
    1513 requests in 3.03s, 1.07MB read
    Requests/sec:    500.07
    Transfer/sec:    360.89KB
    [run.sh] Speed is 500.07, duration is 53
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d53s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-wndlh        948m         26Mi
    service1-6d7594d884-225k8        995m         21Mi
    service2-55876ccd86-g4wf8        602m         10Mi
    ubuntu-client-7477c7845f-v2zhp   31m          6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   242.12ms  157.41ms   1.20s    78.74%
    Req/Sec   266.59     98.02   555.00     68.49%
    Latency Distribution
    50%  200.93ms
    75%  303.38ms
    90%  484.59ms
    99%  707.97ms
    18002 requests in 0.88m, 12.69MB read
    Requests/sec:    339.66
    Transfer/sec:    245.13KB
    ------------------------------
    stop time: 33.676082
    stop time: 34.169385
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '354', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '354'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   231.68ms  121.53ms 806.36ms   67.67%
    Req/Sec   275.25    128.69   525.00     66.10%
    Latency Distribution
    50%  218.36ms
    75%  299.38ms
    90%  380.38ms
    99%  593.41ms
    1624 requests in 3.02s, 1.14MB read
    Requests/sec:    537.46
    Transfer/sec:    387.87KB
    [run.sh] Speed is 537.46, duration is 50
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d50s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 50s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   234.14ms  131.66ms   1.40s    69.22%
    Req/Sec   274.51    117.77   656.00     68.30%
    Latency Distribution
    50%  202.87ms
    75%  299.38ms
    90%  400.22ms
    99%  645.50ms
    18000 requests in 50.00s, 12.69MB read
    Requests/sec:    360.00
    Transfer/sec:    259.80KB
    ------------------------------
    stop time: 33.222425
    stop time: 32.813826
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '239', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '239'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   228.78ms   97.48ms 797.10ms   71.98%
    Req/Sec   284.09    114.37   490.00     62.07%
    Latency Distribution
    50%  202.34ms
    75%  298.26ms
    90%  390.22ms
    99%  507.55ms
    1651 requests in 3.03s, 1.16MB read
    Requests/sec:    545.74
    Transfer/sec:    393.85KB
    [run.sh] Speed is 545.74, duration is 49
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-smtbh        10m          23Mi
    service1-6fc4874db5-486nr        317m         14Mi
    service2-5df5c86459-6ph88        162m         9Mi
    ubuntu-client-7477c7845f-f6pgq   1m           3Mi
    Running 49s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   243.74ms  169.18ms   2.00s    87.42%
    Req/Sec   265.19     92.63   515.00     68.09%
    Latency Distribution
    50%  201.52ms
    75%  298.91ms
    90%  401.10ms
    99%  944.76ms
    18000 requests in 49.00s, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 46
    Requests/sec:    367.35
    Transfer/sec:    265.11KB
    ------------------------------
    stop time: 34.470127
    stop time: 34.112994
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '124', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '124'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   235.24ms  163.75ms   1.11s    77.12%
    Req/Sec   277.43     79.66   465.00     72.41%
    Latency Distribution
    50%  195.90ms
    75%  305.76ms
    90%  491.47ms
    99%  747.34ms
    1629 requests in 3.02s, 1.15MB read
    Requests/sec:    538.88
    Transfer/sec:    388.90KB
    [run.sh] Speed is 538.88, duration is 50
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d50s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-qt9dx        999m         22Mi
    service1-7596c57868-l2vz6        961m         12Mi
    service2-b4c9db646-fsvpz         453m         8Mi
    ubuntu-client-7477c7845f-qxzrd   33m          5Mi
    Running 50s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   228.14ms  156.53ms   1.30s    75.43%
    Req/Sec   284.76    103.32   630.00     66.03%
    Latency Distribution
    50%  197.10ms
    75%  299.04ms
    90%  446.43ms
    99%  745.43ms
    18000 requests in 50.00s, 12.69MB read
    Requests/sec:    360.00
    Transfer/sec:    259.80KB
    ------------------------------
    stop time: 31.818814
    stop time: 31.816216
    [run.sh] Test finished with status 0
[test.py] Groundtruth:  [704.3727440383994, 712.3117909010322, 712.8820015334488, 713.2569260813807, 704.9222764446697, 700.738997400161, 698.3301181050812, 683.9314522862632, 629.312417971967, 554.602512219973]
[test.py] Slowdown:  [391.76853392183347, 408.557347123657, 431.4588694634254, 450.39850696898486, 476.5944151739719, 502.09436110375407, 530.6176166493186, 545.155114877736, 524.9104951056397, 565.7261417178557]
[test.py] Predicted:  [717.6599405849332, 712.4908452348168, 720.1456278488635, 711.1636915693343, 714.7400138163217, 710.4555974132312, 706.4709817927315, 675.5705488847448, 600.2484928719073, 608.446556505164]
[test.py] Error percentage:  [1.8863870953259678, 0.025137072848131166, 1.01891004398907, -0.293475525508957, 1.392740405533577, 1.3866218448124255, 1.1657615039919251, -1.2224768101495185, -4.618361924864219, 9.708582831632528]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 1...
[test.py] Actual processing time range: [0, 115, 230, 345, 460, 575, 690, 805, 920, 1035]
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.0', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   185.73ms  144.02ms 897.38ms   70.53%
    Req/Sec   360.38    116.43   676.00     75.00%
    Latency Distribution
    50%  180.56ms
    75%  279.85ms
    90%  398.49ms
    99%  608.24ms
    2153 requests in 3.02s, 1.50MB read
    Requests/sec:    712.13
    Transfer/sec:    507.67KB
    [run.sh] Speed is 712.13, duration is 37
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 37s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   189.84ms  166.20ms   1.30s    67.42%
    Req/Sec   353.52    102.02   636.00     68.43%
    Latency Distribution
    50%  106.55ms
    75%  297.07ms
    90%  403.81ms
    99%  698.86ms
    18001 requests in 37.00s, 12.53MB read
    Requests/sec:    486.51
    Transfer/sec:    346.83KB
    ------------------------------
    stop time: 25.567098
    stop time: 25.604744
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-k6kz5        76m          25Mi
    service1-5c9649c5ff-8cb8f        680m         18Mi
    service2-6c6d889d77-lx88j        355m         11Mi
    ubuntu-client-7477c7845f-wdhr8   7m           6Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000115', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   195.86ms  165.13ms   1.21s    65.87%
    Req/Sec   349.07    121.15   580.00     66.67%
    Latency Distribution
    50%  191.60ms
    75%  299.52ms
    90%  406.81ms
    99%  697.58ms
    2088 requests in 3.02s, 1.47MB read
    Requests/sec:    691.20
    Transfer/sec:    497.47KB
    [run.sh] Speed is 691.20, duration is 39
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 39s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   184.80ms  150.34ms   1.09s    68.99%
    Req/Sec   353.90    102.29   696.00     69.55%
    Latency Distribution
    50%  110.19ms
    75%  294.80ms
    90%  398.35ms
    99%  606.97ms
    18000 requests in 39.00s, 12.65MB read
    Requests/sec:    461.54
    Transfer/sec:    332.18KB
    ------------------------------
    stop time: 25.574535
    stop time: 25.466328
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-ssv55        170m         21Mi
    service1-5c9649c5ff-9mqtr        319m         16Mi
    service2-6c6d889d77-7k7m4        150m         9Mi
    ubuntu-client-7477c7845f-m8p5k   15m          3Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00023', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   187.11ms  144.46ms 998.16ms   72.11%
    Req/Sec   352.43    122.61   650.00     71.67%
    Latency Distribution
    50%  190.99ms
    75%  288.26ms
    90%  395.30ms
    99%  613.50ms
    2106 requests in 3.02s, 1.48MB read
    Requests/sec:    696.58
    Transfer/sec:    500.67KB
    [run.sh] Speed is 696.58, duration is 38
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 38s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.89ms  153.02ms   1.11s    71.63%
    Req/Sec   353.13    103.17   666.00     67.25%
    Latency Distribution
    50%  140.78ms
    75%  294.82ms
    90%  399.39ms
    99%  688.70ms
    18000 requests in 38.00s, 12.63MB read
    Requests/sec:    473.68
    Transfer/sec:    340.46KB
    ------------------------------
    stop time: 25.505530
    stop time: 25.717442
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-cps5g        616m         23Mi
    service1-5c9649c5ff-2db5m        1003m        18Mi
    service2-6c6d889d77-z59h7        473m         10Mi
    ubuntu-client-7477c7845f-sbcgc   42m          5Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000345', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   181.17ms  125.73ms 702.96ms   75.26%
    Req/Sec   358.65    120.25   600.00     63.33%
    Latency Distribution
    50%  187.28ms
    75%  252.25ms
    90%  388.69ms
    99%  508.20ms
    2144 requests in 3.02s, 1.51MB read
    Requests/sec:    708.85
    Transfer/sec:    510.18KB
    [run.sh] Speed is 708.85, duration is 38
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 38s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.53ms  156.31ms   1.20s    67.40%
    Req/Sec   354.40    103.35   730.00     68.37%
    Latency Distribution
    50%  122.45ms
    75%  295.19ms
    90%  400.30ms
    99%  681.80ms
    18001 requests in 38.00s, 12.65MB read
    Requests/sec:    473.71
    Transfer/sec:    340.94KB
    ------------------------------
    stop time: 25.517108
    stop time: 25.613662
    [run.sh] Checking the resource usage
    NAME                        CPU(cores)   MEMORY(bytes)
    service1-5c9649c5ff-2wcqc   300m         18Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00046', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.93ms  151.97ms 801.79ms   65.93%
    Req/Sec   342.23    106.34   585.00     73.33%
    Latency Distribution
    50%  151.42ms
    75%  296.59ms
    90%  400.14ms
    99%  598.27ms
    2047 requests in 3.03s, 1.44MB read
    Requests/sec:    675.40
    Transfer/sec:    485.45KB
    [run.sh] Speed is 675.40, duration is 39
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 39s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   188.19ms  155.60ms   1.30s    70.51%
    Req/Sec   350.26    106.47   767.00     69.65%
    Latency Distribution
    50%  111.88ms
    75%  294.08ms
    90%  400.64ms
    99%  692.51ms
    18000 requests in 39.00s, 12.63MB read
    Requests/sec:    461.54
    Transfer/sec:    331.73KB
    ------------------------------
    stop time: 25.801475
    stop time: 25.794235
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-9xkx7        764m         25Mi
    service1-5c9649c5ff-jpc4d        995m         21Mi
    service2-6c6d889d77-px8ng        475m         10Mi
    ubuntu-client-7477c7845f-w2pbs   41m          6Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000575', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   191.16ms  130.41ms   1.00s    78.18%
    Req/Sec   339.56    139.96   650.00     72.88%
    Latency Distribution
    50%  189.17ms
    75%  289.56ms
    90%  363.45ms
    99%  601.45ms
    2026 requests in 3.02s, 1.42MB read
    Requests/sec:    670.12
    Transfer/sec:    482.31KB
    [run.sh] Speed is 670.12, duration is 40
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d40s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 40s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   187.00ms  151.58ms   1.40s    71.72%
    Req/Sec   350.85    112.52   770.00     68.29%
    Latency Distribution
    50%  135.44ms
    75%  293.77ms
    90%  397.98ms
    99%  659.62ms
    18000 requests in 40.00s, 12.65MB read
    Requests/sec:    450.00
    Transfer/sec:    323.88KB
    ------------------------------
    stop time: 25.920727
    stop time: 25.659942
    [run.sh] Checking the resource usage
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00069', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   188.89ms  123.03ms 668.32ms   75.19%
    Req/Sec   337.54    129.65   606.00     66.10%
    Latency Distribution
    50%  193.30ms
    75%  281.64ms
    90%  380.12ms
    99%  526.83ms
    2011 requests in 3.02s, 1.41MB read
    Requests/sec:    664.90
    Transfer/sec:    477.89KB
    [run.sh] Speed is 664.90, duration is 40
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d40s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 40s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   185.88ms  142.86ms   1.20s    71.40%
    Req/Sec   350.94     98.10   727.00     68.23%
    Latency Distribution
    50%  167.48ms
    75%  289.23ms
    90%  393.40ms
    99%  603.26ms
    18000 requests in 40.00s, 12.63MB read
    Requests/sec:    450.00
    Transfer/sec:    323.44KB
    ------------------------------
    stop time: 25.712953
    stop time: 25.911963
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-vm7hg        557m         25Mi
    service1-5c9649c5ff-k7krz        996m         17Mi
    service2-6c6d889d77-fwzhk        473m         9Mi
    ubuntu-client-7477c7845f-dvgz8   26m          6Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000805', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   184.62ms  107.09ms 773.20ms   74.05%
    Req/Sec   344.88     93.38   560.00     67.80%
    Latency Distribution
    50%  181.51ms
    75%  231.30ms
    90%  314.37ms
    99%  507.29ms
    2042 requests in 3.03s, 1.44MB read
    Requests/sec:    673.65
    Transfer/sec:    484.85KB
    [run.sh] Speed is 673.65, duration is 40
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d40s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 40s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   184.71ms  122.20ms   1.01s    76.76%
    Req/Sec   349.47    112.90   828.00     70.93%
    Latency Distribution
    50%  179.07ms
    75%  259.64ms
    90%  334.35ms
    99%  562.95ms
    18004 requests in 40.00s, 12.65MB read
    Requests/sec:    450.10
    Transfer/sec:    323.95KB
    ------------------------------
    stop time: 26.121452
    stop time: 25.701644
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-mqqkg        354m         22Mi
    service1-5c9649c5ff-n6kvh        1m           15Mi
    service2-6c6d889d77-9wcbx        1m           9Mi
    ubuntu-client-7477c7845f-4zmsk   14m          7Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00092', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   195.42ms   84.74ms 665.97ms   61.04%
    Req/Sec   326.02     88.04   570.00     74.14%
    Latency Distribution
    50%  196.80ms
    75%  226.77ms
    90%  300.43ms
    99%  463.69ms
    1923 requests in 3.03s, 1.35MB read
    Requests/sec:    635.66
    Transfer/sec:    456.88KB
    [run.sh] Speed is 635.66, duration is 42
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-krcxl        135m         25Mi
    service1-5c9649c5ff-9qf7l        338m         18Mi
    service2-6c6d889d77-mbg59        123m         9Mi
    ubuntu-client-7477c7845f-p6l8l   5m           4Mi
    Running 42s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   239.81ms  218.01ms   2.00s    91.33%
    Req/Sec   282.45    123.34   656.00     68.71%
    Latency Distribution
    50%  198.59ms
    75%  273.30ms
    90%  398.53ms
    99%    1.30s
    18000 requests in 42.00s, 12.63MB read
    Socket errors: connect 0, read 0, write 0, timeout 87
    Requests/sec:    428.57
    Transfer/sec:    308.04KB
    ------------------------------
    stop time: 32.675362
    stop time: 31.969742
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.001035', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   206.10ms  104.45ms 708.95ms   70.60%
    Req/Sec   312.10     89.89   470.00     67.24%
    Latency Distribution
    50%  197.14ms
    75%  286.65ms
    90%  328.23ms
    99%  500.93ms
    1820 requests in 3.02s, 1.28MB read
    Requests/sec:    601.81
    Transfer/sec:    433.14KB
    [run.sh] Speed is 601.81, duration is 44
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d44s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-98fdj        1003m        33Mi
    service1-5c9649c5ff-z4b8w        951m         15Mi
    service2-6c6d889d77-crtcf        409m         8Mi
    ubuntu-client-7477c7845f-4jfjx   34m          6Mi
    Running 44s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   238.10ms  208.33ms   1.99s    87.79%
    Req/Sec   288.80    113.83   640.00     68.32%
    Latency Distribution
    50%  196.03ms
    75%  299.49ms
    90%  456.07ms
    99%    1.20s
    18000 requests in 44.00s, 12.65MB read
    Socket errors: connect 0, read 0, write 0, timeout 28
    Requests/sec:    409.09
    Transfer/sec:    294.43KB
    ------------------------------
    stop time: 32.094016
    stop time: 32.486802
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '1159', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1159'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   340.15ms  253.61ms   1.85s    77.43%
    Req/Sec   195.57     71.16   360.00     67.86%
    Latency Distribution
    50%  255.17ms
    75%  495.95ms
    90%  694.72ms
    99%    1.11s
    1103 requests in 3.02s, 796.01KB read
    Requests/sec:    365.82
    Transfer/sec:    264.01KB
    [run.sh] Speed is 365.82, duration is 73
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d73s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                      CPU(cores)   MEMORY(bytes)
    service1-94ddd99c-pcbfb   220m         14Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   334.22ms  259.17ms   1.98s    74.80%
    Req/Sec   192.72     76.85   474.00     68.80%
    Latency Distribution
    50%  255.75ms
    75%  495.27ms
    90%  700.25ms
    99%    1.11s
    18000 requests in 1.22m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 1
    Requests/sec:    246.58
    Transfer/sec:    177.95KB
    ------------------------------
    stop time: 46.872726
    stop time: 46.922957
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '1044', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1044'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   313.97ms  202.57ms 926.79ms   65.23%
    Req/Sec   202.73     84.00   343.00     67.86%
    Latency Distribution
    50%  293.28ms
    75%  425.06ms
    90%  631.61ms
    99%  869.58ms
    1162 requests in 3.03s, 838.59KB read
    Requests/sec:    383.79
    Transfer/sec:    276.97KB
    [run.sh] Speed is 383.79, duration is 70
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d70s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   315.51ms  242.60ms   1.94s    75.09%
    Req/Sec   205.80     82.68   565.00     67.01%
    Latency Distribution
    50%  227.74ms
    75%  471.72ms
    90%  687.01ms
    99%    1.07s
    18000 requests in 1.17m, 12.69MB read
    Requests/sec:    257.14
    Transfer/sec:    185.57KB
    ------------------------------
    stop time: 43.635712
    stop time: 44.201558
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '929', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '929'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   304.95ms  230.58ms   1.21s    78.26%
    Req/Sec   207.79     77.77   400.00     68.97%
    Latency Distribution
    50%  261.63ms
    75%  458.23ms
    90%  603.06ms
    99%  998.47ms
    1223 requests in 3.03s, 0.86MB read
    Requests/sec:    403.90
    Transfer/sec:    291.49KB
    [run.sh] Speed is 403.90, duration is 66
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d66s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-q999r        785m         26Mi
    service1-784bdf5989-djz2t        992m         21Mi
    service2-bd546fd99-48q6w         683m         10Mi
    ubuntu-client-7477c7845f-s7mbl   28m          6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   301.52ms  240.38ms   1.80s    76.36%
    Req/Sec   216.19     79.90   470.00     68.03%
    Latency Distribution
    50%  205.65ms
    75%  484.96ms
    90%  606.50ms
    99%    1.00s
    18000 requests in 1.10m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 1
    Requests/sec:    272.73
    Transfer/sec:    196.82KB
    ------------------------------
    stop time: 41.634494
    stop time: 42.036324
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '814', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '814'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   296.28ms  242.24ms   1.74s    80.01%
    Req/Sec   216.93     69.93   340.00     66.67%
    Latency Distribution
    50%  203.32ms
    75%  408.03ms
    90%  635.62ms
    99%    1.10s
    1298 requests in 3.02s, 0.91MB read
    Requests/sec:    429.95
    Transfer/sec:    310.29KB
    [run.sh] Speed is 429.95, duration is 62
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d62s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   288.99ms  237.16ms   1.90s    77.46%
    Req/Sec   228.31     76.26   525.00     67.51%
    Latency Distribution
    50%  202.09ms
    75%  404.05ms
    90%  605.47ms
    99%    1.04s
    18000 requests in 1.03m, 12.69MB read
    Requests/sec:    290.32
    Transfer/sec:    209.52KB
    ------------------------------
    stop time: 39.416163
    stop time: 39.808870
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '699', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '699'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   276.12ms  188.75ms   1.20s    78.29%
    Req/Sec   232.47     93.82   383.00     59.32%
    Latency Distribution
    50%  205.24ms
    75%  394.50ms
    90%  504.82ms
    99%  897.82ms
    1377 requests in 3.02s, 0.97MB read
    Requests/sec:    455.40
    Transfer/sec:    328.65KB
    [run.sh] Speed is 455.40, duration is 59
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   274.92ms  216.35ms   1.80s    72.38%
    Req/Sec   238.83     81.06   505.00     67.46%
    Latency Distribution
    50%  200.57ms
    75%  398.33ms
    90%  592.22ms
    99%  949.72ms
    18000 requests in 0.98m, 12.69MB read
    Requests/sec:    305.08
    Transfer/sec:    220.17KB
    ------------------------------
    stop time: 37.687388
    stop time: 38.191383
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '584', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '584'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   249.35ms  159.69ms 900.52ms   72.59%
    Req/Sec   245.81     81.50   464.00     65.52%
    Latency Distribution
    50%  206.62ms
    75%  349.55ms
    90%  493.07ms
    99%  700.99ms
    1447 requests in 3.02s, 1.02MB read
    Requests/sec:    478.78
    Transfer/sec:    345.53KB
    [run.sh] Speed is 478.78, duration is 56
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d56s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                        CPU(cores)   MEMORY(bytes)
    service2-7b6f55dc48-5gggm   198m         9Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   256.89ms  179.65ms   1.44s    73.62%
    Req/Sec   251.16     95.37   560.00     68.62%
    Latency Distribution
    50%  203.22ms
    75%  350.79ms
    90%  502.10ms
    99%  801.57ms
    18000 requests in 0.93m, 12.69MB read
    Requests/sec:    321.43
    Transfer/sec:    231.97KB
    ------------------------------
    stop time: 36.004703
    stop time: 35.855545
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '469', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '469'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   245.22ms  164.34ms   1.09s    79.35%
    Req/Sec   261.16     63.65   420.00     67.24%
    Latency Distribution
    50%  199.10ms
    75%  333.58ms
    90%  490.27ms
    99%  783.37ms
    1543 requests in 3.03s, 1.09MB read
    Requests/sec:    509.26
    Transfer/sec:    367.52KB
    [run.sh] Speed is 509.26, duration is 53
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d53s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-jjqww        255m         24Mi
    service1-6d7594d884-hs2jn        317m         18Mi
    service2-55876ccd86-4stlg        54m          10Mi
    ubuntu-client-7477c7845f-f5rnc   9m           4Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   243.48ms  177.61ms   1.45s    78.33%
    Req/Sec   267.60     85.72   524.00     67.95%
    Latency Distribution
    50%  198.24ms
    75%  315.26ms
    90%  497.82ms
    99%  807.46ms
    18000 requests in 0.88m, 12.69MB read
    Requests/sec:    339.62
    Transfer/sec:    245.10KB
    ------------------------------
    stop time: 34.036566
    stop time: 33.643948
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '354', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '354'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   228.98ms  108.95ms 746.82ms   66.63%
    Req/Sec   271.41     86.96   454.00     70.69%
    Latency Distribution
    50%  201.87ms
    75%  298.22ms
    90%  386.72ms
    99%  539.69ms
    1591 requests in 3.02s, 1.12MB read
    Requests/sec:    526.42
    Transfer/sec:    379.90KB
    [run.sh] Speed is 526.42, duration is 51
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d51s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-6rcmf        994m         23Mi
    service1-d99659f55-fjdzz         450m         17Mi
    service2-7678f85f85-tpcp4        213m         10Mi
    ubuntu-client-7477c7845f-pwrph   31m          5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   229.45ms  124.19ms   1.09s    65.53%
    Req/Sec   279.77     86.40   606.00     67.13%
    Latency Distribution
    50%  200.80ms
    75%  298.89ms
    90%  399.31ms
    99%  601.01ms
    18005 requests in 0.85m, 12.69MB read
    Requests/sec:    353.04
    Transfer/sec:    254.78KB
    ------------------------------
    stop time: 32.304484
    stop time: 32.401658
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '239', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '239'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   224.42ms  131.44ms 894.73ms   78.97%
    Req/Sec   277.22     91.52   450.00     68.33%
    Latency Distribution
    50%  198.39ms
    75%  300.83ms
    90%  402.79ms
    99%  601.10ms
    1660 requests in 3.02s, 1.17MB read
    Requests/sec:    548.96
    Transfer/sec:    396.17KB
    [run.sh] Speed is 548.96, duration is 49
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-ct4vw        996m         27Mi
    service1-6fc4874db5-cmgtl        988m         17Mi
    service2-5df5c86459-65fgn        516m         9Mi
    ubuntu-client-7477c7845f-lk6sw   33m          5Mi
    Running 49s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   224.99ms  143.58ms   1.09s    80.00%
    Req/Sec   287.42     90.91   710.00     68.90%
    Latency Distribution
    50%  197.99ms
    75%  298.86ms
    90%  406.23ms
    99%  694.06ms
    18000 requests in 49.00s, 12.69MB read
    Requests/sec:    367.35
    Transfer/sec:    265.11KB
    ------------------------------
    stop time: 31.334890
    stop time: 31.718931
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '124', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '124'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   225.96ms  124.70ms 902.95ms   69.80%
    Req/Sec   278.29     77.60   460.00     72.41%
    Latency Distribution
    50%  199.76ms
    75%  299.36ms
    90%  398.92ms
    99%  611.32ms
    1637 requests in 3.03s, 1.15MB read
    Requests/sec:    540.80
    Transfer/sec:    390.28KB
    [run.sh] Speed is 540.80, duration is 49
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 49s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   262.45ms  224.61ms   2.00s    86.82%
    Req/Sec   259.10    110.98   620.00     69.68%
    Latency Distribution
    50%  199.97ms
    75%  303.01ms
    90%  499.44ms
    99%    1.30s
    18000 requests in 49.00s, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 44
    Requests/sec:    367.35
    Transfer/sec:    265.11KB
    ------------------------------
    stop time: 34.918350
    stop time: 35.525786
    [run.sh] Test finished with status 0
[test.py] Groundtruth:  [703.5119040663027, 705.3172278846461, 702.8096690680111, 704.0770166379267, 697.7324277541679, 697.9358875705935, 697.3376963945084, 694.6709629235581, 556.8867210732618, 557.4410655498356]
[test.py] Slowdown:  [383.81297356723763, 409.84880336103345, 430.2575361459954, 454.4018302901812, 474.4410001052864, 500.9723874039511, 531.9108539867176, 556.3614038370577, 570.9408157833924, 511.0432470915678]
[test.py] Predicted:  [691.4072274679652, 716.4277479631063, 716.8050850471315, 721.1961326338186, 709.9077946120799, 708.2112849218985, 708.7653044578146, 692.864888921633, 661.2072862618519, 545.6515091144416]
[test.py] Error percentage:  [-1.7206072176422897, 1.5752514810651066, 1.9913522245189865, 2.431426618303525, 1.7449908265123253, 1.4722551933920476, 1.6387480731919666, -0.25998985106908534, 18.732816072097737, -2.11494221793029]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 2...
[test.py] Actual processing time range: [0, 115, 230, 345, 460, 575, 690, 805, 920, 1035]
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.0', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.71ms  156.19ms   1.07s    66.92%
    Req/Sec   342.47     90.08   530.00     60.00%
    Latency Distribution
    50%  115.54ms
    75%  294.68ms
    90%  398.94ms
    99%  629.99ms
    2047 requests in 3.02s, 1.43MB read
    Requests/sec:    677.93
    Transfer/sec:    483.29KB
    [run.sh] Speed is 677.93, duration is 39
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 39s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.16ms  161.72ms   1.30s    68.72%
    Req/Sec   356.04    107.90   666.00     68.38%
    Latency Distribution
    50%  107.37ms
    75%  296.27ms
    90%  403.01ms
    99%  696.38ms
    18000 requests in 39.00s, 12.53MB read
    Requests/sec:    461.54
    Transfer/sec:    329.03KB
    ------------------------------
    stop time: 25.324113
    stop time: 25.485441
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-gd2nk        102m         23Mi
    service1-5c9649c5ff-bb862        314m         18Mi
    service2-6c6d889d77-p6l9q        148m         10Mi
    ubuntu-client-7477c7845f-c65xs   11m          5Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000115', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   183.15ms  127.36ms 896.09ms   76.01%
    Req/Sec   357.35    106.16   640.00     68.33%
    Latency Distribution
    50%  189.08ms
    75%  258.08ms
    90%  338.76ms
    99%  599.45ms
    2136 requests in 3.03s, 1.50MB read
    Requests/sec:    706.06
    Transfer/sec:    508.17KB
    [run.sh] Speed is 706.06, duration is 38
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 38s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   187.42ms  162.18ms   1.49s    66.61%
    Req/Sec   354.27    103.78   722.00     63.85%
    Latency Distribution
    50%  108.90ms
    75%  296.37ms
    90%  403.48ms
    99%  692.96ms
    18000 requests in 38.00s, 12.65MB read
    Requests/sec:    473.68
    Transfer/sec:    340.92KB
    ------------------------------
    stop time: 25.620435
    stop time: 25.514119
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-dg42f        368m         25Mi
    service1-5c9649c5ff-tvqdk        995m         20Mi
    service2-6c6d889d77-gz2b2        480m         9Mi
    ubuntu-client-7477c7845f-st7w5   28m          6Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00023', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   188.37ms  140.97ms 940.82ms   73.39%
    Req/Sec   353.42    105.59   575.00     66.67%
    Latency Distribution
    50%  164.95ms
    75%  271.18ms
    90%  394.96ms
    99%  605.17ms
    2112 requests in 3.02s, 1.48MB read
    Requests/sec:    698.23
    Transfer/sec:    501.85KB
    [run.sh] Speed is 698.23, duration is 38
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 38s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   188.58ms  166.38ms   1.45s    69.31%
    Req/Sec   355.06    101.17   676.00     68.31%
    Latency Distribution
    50%  106.59ms
    75%  297.06ms
    90%  403.97ms
    99%  700.59ms
    18001 requests in 38.00s, 12.63MB read
    Requests/sec:    473.71
    Transfer/sec:    340.48KB
    ------------------------------
    stop time: 25.460480
    stop time: 25.499982
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-57c65        199m         22Mi
    ubuntu-client-7477c7845f-sp8nr   15m          0Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000345', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   185.22ms  146.05ms 871.84ms   67.69%
    Req/Sec   347.00    106.78   560.00     70.00%
    Latency Distribution
    50%  189.85ms
    75%  294.75ms
    90%  397.69ms
    99%  600.61ms
    2074 requests in 3.02s, 1.46MB read
    Requests/sec:    686.38
    Transfer/sec:    494.01KB
    [run.sh] Speed is 686.38, duration is 39
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 39s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.14ms  161.42ms   1.22s    65.60%
    Req/Sec   355.29    105.65   656.00     69.43%
    Latency Distribution
    50%  107.39ms
    75%  296.73ms
    90%  401.39ms
    99%  693.82ms
    18000 requests in 39.00s, 12.65MB read
    Requests/sec:    461.54
    Transfer/sec:    332.18KB
    ------------------------------
    stop time: 25.326766
    stop time: 25.542459
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-4bnvz        689m         23Mi
    service1-5c9649c5ff-hrtvf        994m         21Mi
    service2-6c6d889d77-pzst2        477m         10Mi
    ubuntu-client-7477c7845f-2c5vs   42m          5Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00046', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   184.89ms  128.63ms 810.76ms   75.99%
    Req/Sec   341.82    113.97   570.00     71.67%
    Latency Distribution
    50%  178.06ms
    75%  264.73ms
    90%  374.35ms
    99%  593.35ms
    2045 requests in 3.02s, 1.44MB read
    Requests/sec:    677.05
    Transfer/sec:    486.63KB
    [run.sh] Speed is 677.05, duration is 39
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 39s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.86ms  151.86ms   1.18s    68.38%
    Req/Sec   352.37    105.28   730.00     67.71%
    Latency Distribution
    50%  123.65ms
    75%  291.28ms
    90%  398.19ms
    99%  677.10ms
    18002 requests in 39.00s, 12.64MB read
    Requests/sec:    461.59
    Transfer/sec:    331.77KB
    ------------------------------
    stop time: 25.623941
    stop time: 25.707667
    [run.sh] Checking the resource usage
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000575', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   198.13ms  165.60ms 996.96ms   70.14%
    Req/Sec   346.10    121.29   550.00     65.00%
    Latency Distribution
    50%  185.89ms
    75%  292.07ms
    90%  409.02ms
    99%  792.26ms
    2069 requests in 3.03s, 1.45MB read
    Requests/sec:    683.88
    Transfer/sec:    492.21KB
    [run.sh] Speed is 683.88, duration is 39
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 39s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   186.82ms  151.80ms   1.10s    69.20%
    Req/Sec   350.41    104.21   676.00     69.98%
    Latency Distribution
    50%  110.72ms
    75%  295.14ms
    90%  400.00ms
    99%  609.85ms
    18000 requests in 39.00s, 12.65MB read
    Requests/sec:    461.54
    Transfer/sec:    332.18KB
    ------------------------------
    stop time: 25.603400
    stop time: 25.908829
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-vn224        838m         25Mi
    service1-5c9649c5ff-4rxk5        565m         20Mi
    service2-6c6d889d77-722gl        236m         10Mi
    ubuntu-client-7477c7845f-nnts7   41m          5Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00069', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   184.09ms  126.11ms 798.31ms   71.04%
    Req/Sec   340.13     91.86   600.00     63.33%
    Latency Distribution
    50%  159.68ms
    75%  261.34ms
    90%  355.45ms
    99%  560.85ms
    2035 requests in 3.03s, 1.43MB read
    Requests/sec:    671.51
    Transfer/sec:    482.65KB
    [run.sh] Speed is 671.51, duration is 40
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d40s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 40s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   185.18ms  129.99ms   1.17s    74.12%
    Req/Sec   349.88    102.43   663.00     71.40%
    Latency Distribution
    50%  156.87ms
    75%  261.85ms
    90%  373.44ms
    99%  592.06ms
    18000 requests in 40.00s, 12.63MB read
    Requests/sec:    450.00
    Transfer/sec:    323.44KB
    ------------------------------
    stop time: 25.926582
    stop time: 25.831424
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-t5hdx        701m         25Mi
    service1-5c9649c5ff-xj2ws        407m         17Mi
    service2-6c6d889d77-lwvlm        226m         9Mi
    ubuntu-client-7477c7845f-cccfh   31m          6Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.000805', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   188.99ms  106.01ms 752.55ms   73.13%
    Req/Sec   339.19     70.82   565.00     74.58%
    Latency Distribution
    50%  155.33ms
    75%  247.46ms
    90%  310.97ms
    99%  535.68ms
    2006 requests in 3.03s, 1.41MB read
    Requests/sec:    662.04
    Transfer/sec:    476.49KB
    [run.sh] Speed is 662.04, duration is 40
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d40s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    Running 40s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   188.95ms  115.94ms   1.35s    76.96%
    Req/Sec   338.96    127.17   757.00     68.36%
    Latency Distribution
    50%  192.81ms
    75%  252.33ms
    90%  312.33ms
    99%  510.17ms
    18000 requests in 40.00s, 12.65MB read
    Requests/sec:    450.00
    Transfer/sec:    323.88KB
    ------------------------------
    stop time: 26.598885
    stop time: 26.854331
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-n7fgl        311m         23Mi
    service1-5c9649c5ff-455pm        290m         19Mi
    service2-6c6d889d77-q7hsr        147m         9Mi
    ubuntu-client-7477c7845f-d76wd   13m          4Mi
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00092', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   193.12ms  107.04ms 699.38ms   80.13%
    Req/Sec   325.72     91.71   505.00     76.67%
    Latency Distribution
    50%  193.85ms
    75%  278.76ms
    90%  306.68ms
    99%  503.07ms
    1945 requests in 3.03s, 1.37MB read
    Requests/sec:    640.97
    Transfer/sec:    460.70KB
    [run.sh] Speed is 640.97, duration is 42
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-mgzqk        998m         24Mi
    service1-5c9649c5ff-f7frb        998m         17Mi
    service2-6c6d889d77-9pz6q        448m         9Mi
    ubuntu-client-7477c7845f-vpgtr   36m          5Mi
    Running 42s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   193.71ms  108.07ms   1.00s    79.73%
    Req/Sec   331.76     95.55   595.00     67.96%
    Latency Distribution
    50%  193.00ms
    75%  225.03ms
    90%  319.72ms
    99%  506.87ms
    18000 requests in 42.00s, 12.63MB read
    Requests/sec:    428.57
    Transfer/sec:    308.03KB
    ------------------------------
    stop time: 27.227143
    stop time: 27.302948
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.001035', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   212.41ms  123.25ms 809.38ms   82.93%
    Req/Sec   295.33    114.73   535.00     68.33%
    Latency Distribution
    50%  197.64ms
    75%  292.47ms
    90%  389.71ms
    99%  602.14ms
    1767 requests in 3.02s, 1.24MB read
    Requests/sec:    584.61
    Transfer/sec:    420.76KB
    [run.sh] Speed is 584.61, duration is 46
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                        CPU(cores)   MEMORY(bytes)
    service1-5c9649c5ff-6h5r7   236m         13Mi
    Running 46s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   238.73ms  198.28ms   1.99s    88.37%
    Req/Sec   278.03    113.28   636.00     69.29%
    Latency Distribution
    50%  197.41ms
    75%  299.67ms
    90%  444.42ms
    99%    1.10s
    18000 requests in 46.00s, 12.65MB read
    Socket errors: connect 0, read 0, write 0, timeout 28
    Requests/sec:    391.30
    Transfer/sec:    281.63KB
    ------------------------------
    stop time: 32.590268
    stop time: 32.604446
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '1159', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1159'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   342.24ms  307.68ms   1.78s    76.95%
    Req/Sec   195.20     63.35   320.00     59.26%
    Latency Distribution
    50%  202.97ms
    75%  505.00ms
    90%  796.34ms
    99%    1.40s
    1126 requests in 3.02s, 812.61KB read
    Requests/sec:    372.26
    Transfer/sec:    268.65KB
    [run.sh] Speed is 372.26, duration is 72
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d72s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-kx7nr        354m         24Mi
    service1-94ddd99c-5q75j          817m         23Mi
    service2-657fbf87fc-6pp6j        522m         13Mi
    ubuntu-client-7477c7845f-495vp   13m          6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   330.56ms  254.18ms   1.85s    76.50%
    Req/Sec   196.56     84.13   494.00     67.98%
    Latency Distribution
    50%  280.33ms
    75%  495.39ms
    90%  698.88ms
    99%    1.10s
    18005 requests in 1.20m, 12.69MB read
    Requests/sec:    250.07
    Transfer/sec:    180.47KB
    ------------------------------
    stop time: 45.866591
    stop time: 46.070046
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '1044', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1044'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   298.26ms  222.95ms   1.33s    74.75%
    Req/Sec   206.84     77.62   420.00     70.69%
    Latency Distribution
    50%  238.63ms
    75%  432.62ms
    90%  604.49ms
    99%  994.91ms
    1202 requests in 3.03s, 867.46KB read
    Requests/sec:    397.05
    Transfer/sec:    286.54KB
    [run.sh] Speed is 397.05, duration is 68
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d68s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-8jxfp        14m          23Mi
    service1-57944f859d-hgvt2        318m         18Mi
    service2-b788d7cd6-mbvgl         158m         11Mi
    ubuntu-client-7477c7845f-2cdgx   2m           5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   317.27ms  246.77ms   1.96s    75.85%
    Req/Sec   206.35     79.27   464.00     69.99%
    Latency Distribution
    50%  231.58ms
    75%  471.10ms
    90%  675.03ms
    99%    1.10s
    18000 requests in 1.13m, 12.69MB read
    Requests/sec:    264.71
    Transfer/sec:    191.03KB
    ------------------------------
    stop time: 43.757223
    stop time: 43.996440
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '929', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '929'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   301.44ms  195.87ms   1.11s    60.68%
    Req/Sec   207.83    103.00   410.00     61.02%
    Latency Distribution
    50%  286.76ms
    75%  429.24ms
    90%  595.89ms
    99%  804.47ms
    1223 requests in 3.03s, 0.86MB read
    Requests/sec:    404.05
    Transfer/sec:    291.59KB
    [run.sh] Speed is 404.05, duration is 66
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d66s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-lccdz        178m         23Mi
    service1-784bdf5989-fj6nw        111m         17Mi
    service2-bd546fd99-ss4p9         20m          10Mi
    ubuntu-client-7477c7845f-45trj   7m           5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   300.98ms  232.00ms   1.81s    78.84%
    Req/Sec   215.90     85.70   490.00     65.43%
    Latency Distribution
    50%  207.41ms
    75%  407.81ms
    90%  615.65ms
    99%    1.00s
    18000 requests in 1.10m, 12.69MB read
    Requests/sec:    272.73
    Transfer/sec:    196.82KB
    ------------------------------
    stop time: 41.828025
    stop time: 42.033296
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '814', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '814'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   289.96ms  221.29ms   1.50s    76.24%
    Req/Sec   218.03     86.29   393.00     55.17%
    Latency Distribution
    50%  272.01ms
    75%  409.66ms
    90%  598.06ms
    99%  891.99ms
    1277 requests in 3.02s, 0.90MB read
    Requests/sec:    422.29
    Transfer/sec:    304.75KB
    [run.sh] Speed is 422.29, duration is 63
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d63s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-jtsx5        179m         24Mi
    service1-9c5b86bb4-5jwvt         100m         17Mi
    service2-5f8ffb9858-4hfzq        20m          10Mi
    ubuntu-client-7477c7845f-k8vc9   7m           5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   287.25ms  232.02ms   1.90s    77.66%
    Req/Sec   228.27     78.47   474.00     69.54%
    Latency Distribution
    50%  202.24ms
    75%  401.73ms
    90%  601.75ms
    99%    1.00s
    18000 requests in 1.05m, 12.69MB read
    Requests/sec:    285.71
    Transfer/sec:    206.19KB
    ------------------------------
    stop time: 39.445714
    stop time: 39.701778
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '699', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '699'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   288.74ms  235.85ms   1.80s    76.29%
    Req/Sec   232.71     78.70   400.00     75.86%
    Latency Distribution
    50%  205.40ms
    75%  403.48ms
    90%  600.81ms
    99%    1.07s
    1350 requests in 3.03s, 0.95MB read
    Requests/sec:    445.88
    Transfer/sec:    321.78KB
    [run.sh] Speed is 445.88, duration is 60
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d60s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-pqnl6        164m         23Mi
    service1-5b5d5f7cd7-wgrzg        498m         21Mi
    service2-6854b585df-pjdrs        267m         10Mi
    ubuntu-client-7477c7845f-sjrn4   7m           6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   269.38ms  207.80ms   1.50s    74.47%
    Req/Sec   241.45     91.40   670.00     69.17%
    Latency Distribution
    50%  201.45ms
    75%  396.70ms
    90%  572.96ms
    99%  903.71ms
    18007 requests in 1.00m, 12.69MB read
    Requests/sec:    300.12
    Transfer/sec:    216.59KB
    ------------------------------
    stop time: 37.047460
    stop time: 37.843606
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '584', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '584'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   254.46ms  180.73ms   1.09s    79.15%
    Req/Sec   241.65     90.24   404.00     66.67%
    Latency Distribution
    50%  201.96ms
    75%  337.21ms
    90%  506.83ms
    99%  817.31ms
    1445 requests in 3.02s, 1.02MB read
    Requests/sec:    478.13
    Transfer/sec:    345.05KB
    [run.sh] Speed is 478.13, duration is 56
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d56s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-5kl7n        883m         24Mi
    service1-6bbd797446-2h59l        1006m        19Mi
    service2-7b6f55dc48-c54sb        627m         10Mi
    ubuntu-client-7477c7845f-dvkx2   32m          6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   255.32ms  180.26ms   1.20s    78.70%
    Req/Sec   252.84     82.91   500.00     71.67%
    Latency Distribution
    50%  201.87ms
    75%  390.95ms
    90%  500.97ms
    99%  798.45ms
    18000 requests in 0.93m, 12.69MB read
    Requests/sec:    321.43
    Transfer/sec:    231.97KB
    ------------------------------
    stop time: 35.794451
    stop time: 35.703652
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '469', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '469'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   251.41ms  162.73ms 952.19ms   74.22%
    Req/Sec   260.03     96.11   470.00     74.14%
    Latency Distribution
    50%  206.84ms
    75%  338.15ms
    90%  491.41ms
    99%  780.39ms
    1510 requests in 3.03s, 1.06MB read
    Requests/sec:    498.94
    Transfer/sec:    360.08KB
    [run.sh] Speed is 498.94, duration is 54
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d54s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-n4vqt        963m         24Mi
    service1-6d7594d884-6w97d        1003m        23Mi
    service2-55876ccd86-fhtt5        600m         11Mi
    ubuntu-client-7477c7845f-rw6vj   31m          8Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   242.26ms  179.63ms   1.48s    72.03%
    Req/Sec   267.70     73.17   490.00     69.39%
    Latency Distribution
    50%  198.40ms
    75%  349.29ms
    90%  496.58ms
    99%  797.33ms
    18002 requests in 0.90m, 12.69MB read
    Requests/sec:    333.37
    Transfer/sec:    240.59KB
    ------------------------------
    stop time: 33.913276
    stop time: 33.630738
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '354', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '354'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   235.38ms  144.98ms 875.96ms   72.41%
    Req/Sec   268.91     60.32   400.00     77.59%
    Latency Distribution
    50%  199.83ms
    75%  306.32ms
    90%  431.14ms
    99%  683.31ms
    1581 requests in 3.03s, 1.11MB read
    Requests/sec:    522.46
    Transfer/sec:    377.05KB
    [run.sh] Speed is 522.46, duration is 51
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d51s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-kbgl9        955m         26Mi
    service1-d99659f55-m969v         708m         18Mi
    service2-7678f85f85-bcx8p        419m         9Mi
    ubuntu-client-7477c7845f-mzj52   30m          6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   229.24ms  122.73ms   1.09s    67.16%
    Req/Sec   278.93     79.45   636.00     72.14%
    Latency Distribution
    50%  202.13ms
    75%  299.27ms
    90%  398.66ms
    99%  603.24ms
    18000 requests in 0.85m, 12.69MB read
    Requests/sec:    352.94
    Transfer/sec:    254.71KB
    ------------------------------
    stop time: 32.665437
    stop time: 32.173528
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '239', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '239'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   225.07ms  105.75ms 697.12ms   66.02%
    Req/Sec   274.95     82.85   460.00     62.07%
    Latency Distribution
    50%  199.94ms
    75%  297.50ms
    90%  361.40ms
    99%  511.00ms
    1614 requests in 3.03s, 1.14MB read
    Requests/sec:    533.38
    Transfer/sec:    384.93KB
    [run.sh] Speed is 533.38, duration is 50
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d50s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                        CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-rd8gb   180m         22Mi
    service1-6fc4874db5-km7ss   310m         13Mi
    service2-5df5c86459-9swdf   159m         9Mi
    Running 50s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   250.28ms  188.03ms   1.94s    89.44%
    Req/Sec   259.00    119.91   550.00     64.37%
    Latency Distribution
    50%  200.72ms
    75%  299.84ms
    90%  403.87ms
    99%    1.14s
    18000 requests in 50.00s, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 67
    Requests/sec:    360.00
    Transfer/sec:    259.80KB
    ------------------------------
    stop time: 35.321208
    stop time: 34.787918
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '124', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '124'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   225.65ms  135.07ms 900.18ms   77.69%
    Req/Sec   276.53    100.71   505.00     67.24%
    Latency Distribution
    50%  199.24ms
    75%  299.03ms
    90%  403.68ms
    99%  606.27ms
    1625 requests in 3.03s, 1.15MB read
    Requests/sec:    537.19
    Transfer/sec:    387.68KB
    [run.sh] Speed is 537.19, duration is 50
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d50s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-52bpw        566m         24Mi
    service1-7596c57868-l8292        830m         13Mi
    service2-b4c9db646-8crqk         350m         8Mi
    ubuntu-client-7477c7845f-kwsp8   19m          5Mi
    Running 50s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   241.36ms  205.03ms   2.00s    87.20%
    Req/Sec   263.36    111.06   626.00     69.59%
    Latency Distribution
    50%  197.61ms
    75%  300.61ms
    90%  446.82ms
    99%    1.14s
    18000 requests in 50.00s, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 115
    Requests/sec:    360.00
    Transfer/sec:    259.80KB
    ------------------------------
    stop time: 35.662778
    stop time: 34.635173
    [run.sh] Test finished with status 0
[test.py] Groundtruth:  [708.5281638173797, 704.0249143465688, 706.4300162741853, 707.6970407943113, 701.3222730135396, 698.8631767419732, 695.5445694720157, 673.4861378593198, 660.1859512759662, 552.1920074685809]
[test.py] Slowdown:  [391.57403593085536, 410.239285395984, 429.2801445376707, 454.8470089235424, 480.6981916908487, 503.50986235257176, 532.985795010643, 555.2216942389502, 513.4852201694827, 512.1059645109713]
[test.py] Predicted:  [717.0075403500477, 717.6217584352402, 714.0964078947245, 722.3181790711837, 724.0094776058438, 713.2930057281588, 710.675174185498, 691.0982039989436, 585.3547557130868, 546.8632070753282]
[test.py] Error percentage:  [1.1967592772859217, 1.9313015507826252, 1.0852301634877994, 2.0660165910064907, 3.234918590966549, 2.0647573754645308, 2.1753609154001228, 2.6150599321322194, -11.334866399118365, -0.965026715558875]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Groundtruth: [704.3727440383994, 712.3117909010322, 712.8820015334488, 713.2569260813807, 704.9222764446697, 700.738997400161, 698.3301181050812, 683.9314522862632, 629.312417971967, 554.602512219973]
    Slowdown:    [391.76853392183347, 408.557347123657, 431.4588694634254, 450.39850696898486, 476.5944151739719, 502.09436110375407, 530.6176166493186, 545.155114877736, 524.9104951056397, 565.7261417178557]
    Predicted:   [717.6599405849332, 712.4908452348168, 720.1456278488635, 711.1636915693343, 714.7400138163217, 710.4555974132312, 706.4709817927315, 675.5705488847448, 600.2484928719073, 608.446556505164]
    Error Perc:  [1.8863870953259678, 0.025137072848131166, 1.01891004398907, -0.293475525508957, 1.392740405533577, 1.3866218448124255, 1.1657615039919251, -1.2224768101495185, -4.618361924864219, 9.708582831632528]
[test.py] Result for the experiment 1: 
    Groundtruth: [703.5119040663027, 705.3172278846461, 702.8096690680111, 704.0770166379267, 697.7324277541679, 697.9358875705935, 697.3376963945084, 694.6709629235581, 556.8867210732618, 557.4410655498356]
    Slowdown:    [383.81297356723763, 409.84880336103345, 430.2575361459954, 454.4018302901812, 474.4410001052864, 500.9723874039511, 531.9108539867176, 556.3614038370577, 570.9408157833924, 511.0432470915678]
    Predicted:   [691.4072274679652, 716.4277479631063, 716.8050850471315, 721.1961326338186, 709.9077946120799, 708.2112849218985, 708.7653044578146, 692.864888921633, 661.2072862618519, 545.6515091144416]
    Error Perc:  [-1.7206072176422897, 1.5752514810651066, 1.9913522245189865, 2.431426618303525, 1.7449908265123253, 1.4722551933920476, 1.6387480731919666, -0.25998985106908534, 18.732816072097737, -2.11494221793029]
[test.py] Result for the experiment 2: 
    Groundtruth: [708.5281638173797, 704.0249143465688, 706.4300162741853, 707.6970407943113, 701.3222730135396, 698.8631767419732, 695.5445694720157, 673.4861378593198, 660.1859512759662, 552.1920074685809]
    Slowdown:    [391.57403593085536, 410.239285395984, 429.2801445376707, 454.8470089235424, 480.6981916908487, 503.50986235257176, 532.985795010643, 555.2216942389502, 513.4852201694827, 512.1059645109713]
    Predicted:   [717.0075403500477, 717.6217584352402, 714.0964078947245, 722.3181790711837, 724.0094776058438, 713.2930057281588, 710.675174185498, 691.0982039989436, 585.3547557130868, 546.8632070753282]
    Error Perc:  [1.1967592772859217, 1.9313015507826252, 1.0852301634877994, 2.0660165910064907, 3.234918590966549, 2.0647573754645308, 2.1753609154001228, 2.6150599321322194, -11.334866399118365, -0.965026715558875]
