SLOWPOKE_DELAY_MICROS_SERVICE1=0.0
SLOWPOKE_DELAY_MICROS_SERVICE0=0.0
SLOWPOKE_DELAY_MICROS_SERVICE2=0.0
SLOWPOKE_POKER_BATCH_THRESHOLD=40000000
PROCESSING_TIME_SERVICE0=0.0
PROCESSING_TIME_SERVICE1=0.0
PROCESSING_TIME_SERVICE2=0.000500
bash run.sh synthetic chain-d2-http-sync 8 32 40000
[run.sh] Running benchmark synthetic with request chain-d2-http-sync, thread 8, conn 32, duration 60
[run.sh] Deleting all services
configmap "config-service0" deleted
deployment.apps "service0" deleted
service "service0" deleted
configmap "config-service1" deleted
deployment.apps "service1" deleted
service "service1" deleted
configmap "config-service2" deleted
deployment.apps "service2" deleted
service "service2" deleted
deployment.apps "ubuntu-client" deleted
[run.sh] Waiting for all pods to be deleted
[run.sh] Deploying all services
configmap/config-service0 created
deployment.apps/service0 created
service/service0 created
configmap/config-service1 created
deployment.apps/service1 created
service/service1 created
configmap/config-service2 created
deployment.apps/service2 created
service/service2 created
[run.sh] Client pod not found, deploying client
deployment.apps/ubuntu-client created
[run.sh] Waiting for all pods to be running
[run.sh] All pods are running
[run.sh] Running warmup test
[run.sh] /wrk/wrk -t8 -c32 -d3s -L http://service0:80/endpoint1
Running 3s test @ http://service0:80/endpoint1
  8 threads and 32 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    13.42ms    7.97ms  82.12ms   73.49%
    Req/Sec   309.24     98.83     1.28k    92.15%
  Latency Distribution
     50%   12.03ms
     75%   17.30ms
     90%   23.57ms
     99%   38.78ms
  7453 requests in 3.10s, 5.10MB read
Requests/sec:   2404.73
Transfer/sec:      1.64MB
[run.sh] Speed is 2404.73, duration is 66
[run.sh] Fix the request number.
[run.sh] Running the actual test
[run.sh] /wrk/wrk --timeout 20s -t8 -c32 -d66s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
[run.sh] Checking the resource usage
Running 1m test @ http://service0:80/endpoint1
  8 threads and 32 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    51.41ms  105.82ms   1.64s    93.58%
    Req/Sec   129.53    100.58   424.00     72.35%
  Latency Distribution
     50%   17.84ms
     75%   54.11ms
     90%  116.82ms
     99%  530.27ms
  40000 requests in 1.10m, 27.35MB read
Requests/sec:    606.06
Transfer/sec:    424.38KB
------------------------------
stop time: 42.822543
stop time: 41.320988
stop time: 37.278630
stop time: 43.088997
stop time: 43.305538
stop time: 40.079151
stop time: 38.494638
stop time: 39.276428
[run.sh] Test finished with status 0

(42.822543 + 41.320988 + 37.278630 + 43.088997 + 43.305538 + 40.079151 + 38.494638 + 39.276428) / 8 = 40.708364125

40000/40.708364125 = 982.5990520566
2000000/982.5990520566 = 2,035.41820625