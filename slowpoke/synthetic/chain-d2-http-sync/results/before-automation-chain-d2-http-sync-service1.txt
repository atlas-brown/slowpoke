[config.py] Random numbers for execution time: [816.2658925781716, 432.33282327479407, 1159.1121645128542]
[test.py] BENCHMARK:                        syncthetic
[test.py] REQUEST_TYPE:                     chain-d2-http-sync
[test.py] TARGET_SERVICE:                   service1
[test.py] NUM_THREADS:                      2
[test.py] NUM_CONN:                         128
[test.py] REPETITIONS:                      3
[test.py] NUM_REQ:                          18000
[test.py] REQUEST_RATIO:                    {'service0': 1, 'service1': 1, 'service2': 1}
[test.py] BASELINE_PROCESSING_TIME:         {'service0': 1159.11, 'service1': 816.27, 'service2': 432.33}
[test.py] TARGET_PROCESSING_TIME_RANGE:     [0, 816.27]
[test.py] TARGET_NUM_EXP:                   10
[test.py] CPU_QUOTA:                         {'service0': 1, 'service1': 1, 'service2': 1}
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 81, 162, 243, 324, 405, 486, 567, 648, 729]
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   237.93ms  199.39ms   1.30s    75.49%
    Req/Sec   292.53     73.35   444.00     70.69%
    Latency Distribution
    50%  194.29ms
    75%  303.67ms
    90%  506.77ms
    99%  898.14ms
    1724 requests in 3.03s, 1.20MB read
    Requests/sec:    569.50
    Transfer/sec:    405.99KB
    [run.sh] Speed is 569.50, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-8xwjf        321m         17Mi
    service2-6c6d889d77-ddztn        125m         7Mi
    ubuntu-client-7477c7845f-v88bm   13m          0Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   227.80ms  186.74ms   1.78s    77.88%
    Req/Sec   291.72     84.81   676.00     70.71%
    Latency Distribution
    50%  192.51ms
    75%  302.04ms
    90%  500.03ms
    99%  808.87ms
    18003 requests in 47.00s, 12.53MB read
    Requests/sec:    383.04
    Transfer/sec:    273.07KB
    ------------------------------
    stop time: 31.053242
    stop time: 30.972139
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '8.1e-05', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   238.54ms  185.01ms   1.20s    76.04%
    Req/Sec   290.57     87.76   470.00     70.69%
    Latency Distribution
    50%  196.34ms
    75%  331.03ms
    90%  502.91ms
    99%  830.43ms
    1704 requests in 3.02s, 1.20MB read
    Requests/sec:    563.70
    Transfer/sec:    405.71KB
    [run.sh] Speed is 563.70, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-zkvr7        1000m        25Mi
    service1-5c9649c5ff-sbdxn        278m         13Mi
    service2-6c6d889d77-4zrxf        381m         8Mi
    ubuntu-client-7477c7845f-tbqqb   32m          6Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   234.21ms  185.04ms   1.61s    76.99%
    Req/Sec   282.92     85.86   610.00     69.65%
    Latency Distribution
    50%  194.12ms
    75%  304.21ms
    90%  498.17ms
    99%  862.77ms
    18012 requests in 47.00s, 12.66MB read
    Requests/sec:    383.23
    Transfer/sec:    275.82KB
    ------------------------------
    stop time: 32.062821
    stop time: 31.831401
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000162', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   231.34ms  178.38ms   1.05s    75.50%
    Req/Sec   277.62     87.36   454.00     70.69%
    Latency Distribution
    50%  194.14ms
    75%  303.81ms
    90%  497.52ms
    99%  797.30ms
    1643 requests in 3.02s, 1.15MB read
    Requests/sec:    543.74
    Transfer/sec:    391.34KB
    [run.sh] Speed is 543.74, duration is 49
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-9tgsh        997m         21Mi
    service1-5c9649c5ff-wmlnq        583m         13Mi
    service2-6c6d889d77-5zmcd        382m         8Mi
    ubuntu-client-7477c7845f-jwhpq   33m          6Mi
    Running 49s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   229.95ms  189.81ms   1.50s    78.87%
    Req/Sec   286.82     77.79   500.00     68.20%
    Latency Distribution
    50%  189.64ms
    75%  304.38ms
    90%  501.92ms
    99%  842.90ms
    18002 requests in 49.00s, 12.65MB read
    Requests/sec:    367.39
    Transfer/sec:    264.42KB
    ------------------------------
    stop time: 31.399337
    stop time: 31.690567
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000243', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   232.85ms  175.82ms   1.10s    77.24%
    Req/Sec   283.52     71.80   470.00     65.52%
    Latency Distribution
    50%  195.49ms
    75%  360.02ms
    90%  494.89ms
    99%  791.86ms
    1676 requests in 3.03s, 1.18MB read
    Requests/sec:    553.95
    Transfer/sec:    398.70KB
    [run.sh] Speed is 553.95, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   229.58ms  182.97ms   1.41s    76.44%
    Req/Sec   287.19     80.95   585.00     70.81%
    Latency Distribution
    50%  193.66ms
    75%  302.93ms
    90%  498.02ms
    99%  802.67ms
    18003 requests in 48.00s, 12.65MB read
    Socket errors: connect 0, read 0, write 0, timeout 1
    Requests/sec:    375.06
    Transfer/sec:    269.94KB
    ------------------------------
    stop time: 31.503583
    stop time: 31.527964
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000324', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   230.24ms  178.02ms   1.20s    75.71%
    Req/Sec   281.73     85.47   474.00     63.33%
    Latency Distribution
    50%  195.57ms
    75%  304.42ms
    90%  493.23ms
    99%  786.02ms
    1685 requests in 3.02s, 1.18MB read
    Requests/sec:    557.12
    Transfer/sec:    400.97KB
    [run.sh] Speed is 557.12, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-wmf4z        835m         26Mi
    service1-5c9649c5ff-q8jlb        54m          13Mi
    service2-6c6d889d77-b6qvc        5m           8Mi
    ubuntu-client-7477c7845f-6dwx8   30m          5Mi
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   234.54ms  187.48ms   1.59s    78.96%
    Req/Sec   281.80     88.08   620.00     67.45%
    Latency Distribution
    50%  194.63ms
    75%  303.73ms
    90%  500.80ms
    99%  854.80ms
    18010 requests in 48.00s, 12.66MB read
    Requests/sec:    375.21
    Transfer/sec:    270.05KB
    ------------------------------
    stop time: 31.972569
    stop time: 32.152167
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000405', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   232.05ms  178.08ms   1.10s    79.03%
    Req/Sec   283.93     76.27   460.00     62.07%
    Latency Distribution
    50%  192.64ms
    75%  304.08ms
    90%  493.66ms
    99%  809.82ms
    1689 requests in 3.02s, 1.19MB read
    Requests/sec:    558.95
    Transfer/sec:    402.29KB
    [run.sh] Speed is 558.95, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-pkkg4        995m         26Mi
    service1-5c9649c5ff-n7r48        696m         14Mi
    service2-6c6d889d77-qjb8r        372m         9Mi
    ubuntu-client-7477c7845f-ktccw   33m          6Mi
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   231.47ms  185.06ms   1.61s    78.83%
    Req/Sec   285.51     78.62   550.00     68.78%
    Latency Distribution
    50%  193.96ms
    75%  303.69ms
    90%  498.88ms
    99%  832.46ms
    18003 requests in 48.00s, 12.65MB read
    Requests/sec:    375.06
    Transfer/sec:    269.94KB
    ------------------------------
    stop time: 31.795992
    stop time: 31.496307
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000486', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   229.92ms  185.45ms   1.21s    77.08%
    Req/Sec   281.50    104.22   600.00     79.31%
    Latency Distribution
    50%  195.12ms
    75%  304.86ms
    90%  498.44ms
    99%  802.87ms
    1648 requests in 3.03s, 1.16MB read
    Requests/sec:    544.22
    Transfer/sec:    391.69KB
    [run.sh] Speed is 544.22, duration is 49
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 49s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   228.68ms  174.64ms   1.50s    78.91%
    Req/Sec   284.53     84.44   590.00     68.83%
    Latency Distribution
    50%  194.85ms
    75%  301.98ms
    90%  497.30ms
    99%  794.36ms
    18007 requests in 49.00s, 12.66MB read
    Requests/sec:    367.49
    Transfer/sec:    264.49KB
    ------------------------------
    stop time: 31.575977
    stop time: 31.885155
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000567', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   226.71ms  166.11ms 995.34ms   73.56%
    Req/Sec   292.97     83.98   490.00     65.52%
    Latency Distribution
    50%  193.37ms
    75%  303.65ms
    90%  466.10ms
    99%  704.03ms
    1735 requests in 3.02s, 1.22MB read
    Requests/sec:    574.33
    Transfer/sec:    413.36KB
    [run.sh] Speed is 574.33, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-l9g8v        321m         25Mi
    service1-5c9649c5ff-bsk9x        260m         12Mi
    service2-6c6d889d77-2lqqw        126m         8Mi
    ubuntu-client-7477c7845f-rw7rh   12m          4Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   226.50ms  170.09ms   1.80s    74.74%
    Req/Sec   289.57     87.68   580.00     70.74%
    Latency Distribution
    50%  195.18ms
    75%  301.01ms
    90%  468.75ms
    99%  789.29ms
    18000 requests in 47.00s, 12.65MB read
    Requests/sec:    382.98
    Transfer/sec:    275.64KB
    ------------------------------
    stop time: 31.878938
    stop time: 30.787737
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000648', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   228.01ms  168.37ms   1.10s    77.41%
    Req/Sec   292.55     86.46   464.00     67.24%
    Latency Distribution
    50%  192.30ms
    75%  306.47ms
    90%  487.95ms
    99%  774.09ms
    1715 requests in 3.02s, 1.21MB read
    Requests/sec:    567.64
    Transfer/sec:    408.55KB
    [run.sh] Speed is 567.64, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-f7q62        1001m        25Mi
    service1-5c9649c5ff-2zjg2        843m         13Mi
    service2-6c6d889d77-6qpfc        391m         8Mi
    ubuntu-client-7477c7845f-wkkn8   31m          6Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   242.79ms  209.94ms   2.00s    81.05%
    Req/Sec   277.87     96.83   550.00     68.41%
    Latency Distribution
    50%  195.69ms
    75%  302.29ms
    90%  499.39ms
    99%    1.10s
    18001 requests in 47.00s, 12.65MB read
    Socket errors: connect 0, read 0, write 0, timeout 13
    Requests/sec:    383.00
    Transfer/sec:    275.65KB
    ------------------------------
    stop time: 32.442298
    stop time: 32.864029
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000729', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   231.50ms  164.09ms   1.20s    75.65%
    Req/Sec   289.07    107.51   600.00     70.69%
    Latency Distribution
    50%  199.39ms
    75%  300.42ms
    90%  462.98ms
    99%  794.20ms
    1710 requests in 3.02s, 1.20MB read
    Requests/sec:    565.52
    Transfer/sec:    407.02KB
    [run.sh] Speed is 565.52, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   235.46ms  183.29ms   1.91s    81.90%
    Req/Sec   280.98     99.97   636.00     67.13%
    Latency Distribution
    50%  196.39ms
    75%  301.77ms
    90%  495.30ms
    99%  896.34ms
    18000 requests in 47.00s, 12.65MB read
    Requests/sec:    382.98
    Transfer/sec:    275.64KB
    ------------------------------
    stop time: 31.769215
    stop time: 32.715405
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '816', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '816'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   312.93ms  247.23ms   1.50s    80.93%
    Req/Sec   200.73     74.69   440.00     76.79%
    Latency Distribution
    50%  202.61ms
    75%  415.80ms
    90%  699.45ms
    99%    1.10s
    1136 requests in 3.03s, 819.83KB read
    Requests/sec:    375.38
    Transfer/sec:    270.90KB
    [run.sh] Speed is 375.38, duration is 71
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d71s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-86cd8b947b-c68vc        325m         24Mi
    service1-5c9649c5ff-vvhll        212m         12Mi
    service2-5c45474c64-mb96w        188m         9Mi
    ubuntu-client-7477c7845f-2w5lx   10m          4Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   331.93ms  272.73ms   2.00s    82.60%
    Req/Sec   198.06     74.32   515.00     70.00%
    Latency Distribution
    50%  205.17ms
    75%  490.35ms
    90%  704.92ms
    99%    1.21s
    18001 requests in 1.18m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 4
    Requests/sec:    253.53
    Transfer/sec:    182.97KB
    ------------------------------
    stop time: 46.679942
    stop time: 44.772894
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '735', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '735'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   332.28ms  249.62ms   1.80s    78.25%
    Req/Sec   200.91     68.75   363.00     69.64%
    Latency Distribution
    50%  283.14ms
    75%  454.39ms
    90%  700.56ms
    99%    1.13s
    1168 requests in 3.02s, 842.92KB read
    Requests/sec:    386.42
    Transfer/sec:    278.87KB
    [run.sh] Speed is 386.42, duration is 69
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d69s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                        CPU(cores)   MEMORY(bytes)
    service0-65cff68cdb-xvj86   220m         18Mi
    service1-5c9649c5ff-xbn9n   215m         10Mi
    service2-649d7fcfc8-sq6fw   180m         7Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   322.95ms  263.49ms   2.00s    79.11%
    Req/Sec   195.61     86.59   600.00     70.90%
    Latency Distribution
    50%  211.77ms
    75%  434.09ms
    90%  701.80ms
    99%    1.20s
    18000 requests in 1.15m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 76
    Requests/sec:    260.87
    Transfer/sec:    188.26KB
    ------------------------------
    stop time: 47.016026
    stop time: 46.613210
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '654', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '654'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   303.41ms  168.51ms   1.00s    67.56%
    Req/Sec   208.29    113.86   446.00     66.07%
    Latency Distribution
    50%  295.11ms
    75%  400.77ms
    90%  513.22ms
    99%  808.81ms
    1181 requests in 3.03s, 852.30KB read
    Requests/sec:    389.93
    Transfer/sec:    281.41KB
    [run.sh] Speed is 389.93, duration is 69
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d69s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                        CPU(cores)   MEMORY(bytes)
    service1-5c9649c5ff-47jnh   215m         15Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   321.47ms  266.39ms   2.00s    79.54%
    Req/Sec   203.91     86.80   525.00     69.76%
    Latency Distribution
    50%  205.36ms
    75%  433.34ms
    90%  701.12ms
    99%    1.21s
    18000 requests in 1.15m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 35
    Requests/sec:    260.87
    Transfer/sec:    188.26KB
    ------------------------------
    stop time: 44.770256
    stop time: 44.868132
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '573', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '573'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   295.95ms  203.83ms   1.02s    77.59%
    Req/Sec   218.98    111.28   505.00     69.64%
    Latency Distribution
    50%  227.66ms
    75%  390.30ms
    90%  606.17ms
    99%  900.42ms
    1236 requests in 3.02s, 0.87MB read
    Requests/sec:    408.79
    Transfer/sec:    295.02KB
    [run.sh] Speed is 408.79, duration is 66
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d66s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   302.25ms  231.56ms   1.81s    82.44%
    Req/Sec   215.76     84.15   570.00     68.62%
    Latency Distribution
    50%  204.93ms
    75%  401.62ms
    90%  609.24ms
    99%    1.03s
    18003 requests in 1.10m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 2
    Requests/sec:    272.77
    Transfer/sec:    196.85KB
    ------------------------------
    stop time: 41.501528
    stop time: 42.477666
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '492', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '492'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   299.08ms  219.48ms   1.35s    79.70%
    Req/Sec   231.20     98.72   560.00     69.64%
    Latency Distribution
    50%  242.68ms
    75%  400.88ms
    90%  598.73ms
    99%    1.04s
    1331 requests in 3.03s, 0.94MB read
    Requests/sec:    438.99
    Transfer/sec:    316.81KB
    [run.sh] Speed is 438.99, duration is 61
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d61s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   291.93ms  238.94ms   1.86s    79.08%
    Req/Sec   224.44     88.61   610.00     70.40%
    Latency Distribution
    50%  200.52ms
    75%  401.99ms
    90%  623.20ms
    99%    1.10s
    18000 requests in 1.02m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 5
    Requests/sec:    295.08
    Transfer/sec:    212.95KB
    ------------------------------
    stop time: 40.269983
    stop time: 40.272363
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '411', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '411'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   262.36ms  172.52ms   1.10s    80.54%
    Req/Sec   235.31     89.05   430.00     60.34%
    Latency Distribution
    50%  205.13ms
    75%  309.46ms
    90%  501.02ms
    99%  801.59ms
    1379 requests in 3.03s, 0.97MB read
    Requests/sec:    455.73
    Transfer/sec:    328.89KB
    [run.sh] Speed is 455.73, duration is 59
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-5bf76fff9f-nw2x5        320m         17Mi
    service1-5c9649c5ff-kpzf6        244m         11Mi
    service2-85fc8775d7-bcttd        163m         8Mi
    ubuntu-client-7477c7845f-47jvm   10m          0Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   279.47ms  222.26ms   1.99s    80.18%
    Req/Sec   234.90     80.49   555.00     70.40%
    Latency Distribution
    50%  200.04ms
    75%  398.39ms
    90%  598.92ms
    99%  998.95ms
    18000 requests in 0.98m, 12.69MB read
    Requests/sec:    305.08
    Transfer/sec:    220.17KB
    ------------------------------
    stop time: 38.638503
    stop time: 38.540144
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '330', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '330'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   264.90ms  184.38ms   1.27s    80.39%
    Req/Sec   235.38     96.60   474.00     74.14%
    Latency Distribution
    50%  200.58ms
    75%  339.55ms
    90%  514.56ms
    99%  880.84ms
    1380 requests in 3.02s, 0.97MB read
    Requests/sec:    456.22
    Transfer/sec:    329.24KB
    [run.sh] Speed is 456.22, duration is 59
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-69784ff859-2smxf        11m          24Mi
    service1-5c9649c5ff-pmxkm        149m         11Mi
    service2-8964d99f-89km6          46m          8Mi
    ubuntu-client-7477c7845f-8lssh   2m           5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   276.71ms  227.92ms   1.91s    82.48%
    Req/Sec   237.04     94.87   570.00     68.86%
    Latency Distribution
    50%  198.87ms
    75%  395.48ms
    90%  596.96ms
    99%    1.09s
    18000 requests in 0.98m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 2
    Requests/sec:    305.08
    Transfer/sec:    220.17KB
    ------------------------------
    stop time: 38.504968
    stop time: 37.903930
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '249', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '249'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   252.46ms  173.62ms   1.08s    77.26%
    Req/Sec   252.54     96.19   574.00     75.00%
    Latency Distribution
    50%  200.82ms
    75%  329.45ms
    90%  502.93ms
    99%  801.57ms
    1460 requests in 3.02s, 1.03MB read
    Requests/sec:    483.16
    Transfer/sec:    348.68KB
    [run.sh] Speed is 483.16, duration is 55
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-79f6bfcb94-9dz7v        791m         24Mi
    service1-5c9649c5ff-rjhnm        800m         14Mi
    service2-6966f9f446-ds688        409m         8Mi
    ubuntu-client-7477c7845f-jrdc2   23m          5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   258.94ms  201.81ms   1.60s    79.10%
    Req/Sec   252.49     84.14   500.00     67.28%
    Latency Distribution
    50%  198.43ms
    75%  331.28ms
    90%  524.91ms
    99%  925.02ms
    18001 requests in 0.92m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 1
    Requests/sec:    327.29
    Transfer/sec:    236.20KB
    ------------------------------
    stop time: 35.721027
    stop time: 36.014441
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '168', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '168'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   248.30ms  186.02ms   1.20s    82.11%
    Req/Sec   267.24     94.58   495.00     70.69%
    Latency Distribution
    50%  199.07ms
    75%  306.86ms
    90%  501.77ms
    99%  902.74ms
    1555 requests in 3.03s, 1.10MB read
    Requests/sec:    513.68
    Transfer/sec:    370.71KB
    [run.sh] Speed is 513.68, duration is 52
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d52s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-566866d46b-cc79q        995m         27Mi
    service1-5c9649c5ff-4zpwj        852m         14Mi
    service2-865ffc4f4b-njttd        440m         8Mi
    ubuntu-client-7477c7845f-j55dc   28m          6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   253.87ms  198.02ms   2.00s    80.92%
    Req/Sec   259.32     98.06   595.00     69.60%
    Latency Distribution
    50%  198.62ms
    75%  306.69ms
    90%  510.58ms
    99%  908.71ms
    18001 requests in 0.87m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 3
    Requests/sec:    346.17
    Transfer/sec:    249.83KB
    ------------------------------
    stop time: 34.986205
    stop time: 34.686845
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '87', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '87'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   238.34ms  145.54ms   1.02s    77.92%
    Req/Sec   273.31     87.69   440.00     70.69%
    Latency Distribution
    50%  200.14ms
    75%  300.90ms
    90%  405.79ms
    99%  710.75ms
    1594 requests in 3.03s, 1.12MB read
    Requests/sec:    526.41
    Transfer/sec:    379.90KB
    [run.sh] Speed is 526.41, duration is 51
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d51s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-65984b998-th7l4         864m         21Mi
    service1-5c9649c5ff-qlfkr        611m         14Mi
    service2-7557789b74-s9kwf        332m         9Mi
    ubuntu-client-7477c7845f-9rscm   26m          5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   230.59ms  161.70ms   1.41s    76.94%
    Req/Sec   280.38     82.71   570.00     70.76%
    Latency Distribution
    50%  196.98ms
    75%  301.41ms
    90%  489.86ms
    99%  737.03ms
    18002 requests in 0.85m, 12.69MB read
    Requests/sec:    352.98
    Transfer/sec:    254.74KB
    ------------------------------
    stop time: 32.063348
    stop time: 32.358477
    [run.sh] Test finished with status 0
[test.py] Groundtruth:  [580.4075592860929, 563.4312285702454, 570.6142776822104, 571.1425740510541, 561.4058200567094, 568.789577386026, 567.2763605918658, 574.4680087143605, 551.2482733870486, 558.2726547818689]
[test.py] Slowdown:  [393.6455289369047, 384.4952873480673, 401.61364793842563, 428.6776079322695, 446.96984614776426, 466.4502605234839, 471.1493156202829, 501.84380200879156, 516.6990680040561, 558.8168295449562]
[test.py] Predicted:  [580.0172832261128, 536.0372162300872, 544.7557064219494, 568.3479989745739, 573.0601920458417, 577.173490671682, 557.9736307241857, 573.5977908072286, 565.9013322732116, 587.4663563321245]
[test.py] Error percentage:  [-0.06724172587623901, -4.861997516480013, -4.531707717741735, -0.4892955285505312, 2.0759264640247324, 1.4739920735161307, -1.639893800258862, -0.1514823965705901, 2.6581595976944854, 5.229290974615672]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 1...
[test.py] Actual processing time range: [0, 81, 162, 243, 324, 405, 486, 567, 648, 729]
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   229.35ms  174.36ms   1.29s    80.03%
    Req/Sec   291.57     74.70   494.00     72.41%
    Latency Distribution
    50%  196.54ms
    75%  298.57ms
    90%  468.22ms
    99%  801.27ms
    1716 requests in 3.03s, 1.19MB read
    Requests/sec:    566.95
    Transfer/sec:    404.18KB
    [run.sh] Speed is 566.95, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                        CPU(cores)   MEMORY(bytes)
    service1-5c9649c5ff-wbpp8   155m         10Mi
    service2-6c6d889d77-rbx4t   96m          7Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   225.75ms  191.40ms   1.60s    78.10%
    Req/Sec   295.67     85.29   740.00     69.84%
    Latency Distribution
    50%  190.62ms
    75%  303.36ms
    90%  499.14ms
    99%  867.77ms
    18008 requests in 47.00s, 12.54MB read
    Requests/sec:    383.15
    Transfer/sec:    273.14KB
    ------------------------------
    stop time: 30.383263
    stop time: 30.884007
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '8.1e-05', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   220.87ms  151.53ms   1.09s    79.17%
    Req/Sec   288.44     92.56   545.00     71.19%
    Latency Distribution
    50%  196.99ms
    75%  295.69ms
    90%  404.11ms
    99%  722.52ms
    1706 requests in 3.03s, 1.20MB read
    Requests/sec:    563.70
    Transfer/sec:    405.71KB
    [run.sh] Speed is 563.70, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-8hpdc        749m         27Mi
    service1-5c9649c5ff-8hxtc        490m         12Mi
    service2-6c6d889d77-ttst9        318m         8Mi
    ubuntu-client-7477c7845f-grxdx   26m          5Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   228.04ms  186.41ms   1.40s    77.62%
    Req/Sec   290.87     77.97   570.00     67.48%
    Latency Distribution
    50%  192.62ms
    75%  303.89ms
    90%  499.24ms
    99%  804.33ms
    18001 requests in 47.00s, 12.65MB read
    Requests/sec:    383.00
    Transfer/sec:    275.65KB
    ------------------------------
    stop time: 30.903873
    stop time: 31.107907
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000162', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   240.46ms  204.24ms   1.31s    77.44%
    Req/Sec   287.93     73.48   460.00     67.24%
    Latency Distribution
    50%  193.30ms
    75%  321.12ms
    90%  501.94ms
    99%  967.35ms
    1689 requests in 3.03s, 1.19MB read
    Requests/sec:    557.92
    Transfer/sec:    401.55KB
    [run.sh] Speed is 557.92, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-mk6gq        1005m        27Mi
    service1-5c9649c5ff-r4bcc        572m         13Mi
    service2-6c6d889d77-z68jk        379m         8Mi
    ubuntu-client-7477c7845f-vpqkx   34m          6Mi
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   231.86ms  186.44ms   1.31s    78.20%
    Req/Sec   284.71     86.92   590.00     69.72%
    Latency Distribution
    50%  194.21ms
    75%  302.65ms
    90%  501.38ms
    99%  807.53ms
    18000 requests in 48.00s, 12.65MB read
    Requests/sec:    375.00
    Transfer/sec:    269.90KB
    ------------------------------
    stop time: 32.092011
    stop time: 31.601772
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000243', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   227.71ms  158.93ms   1.10s    78.00%
    Req/Sec   284.36    119.26   590.00     63.79%
    Latency Distribution
    50%  198.57ms
    75%  298.52ms
    90%  491.86ms
    99%  696.92ms
    1667 requests in 3.03s, 1.17MB read
    Requests/sec:    550.80
    Transfer/sec:    396.43KB
    [run.sh] Speed is 550.80, duration is 49
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 49s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   227.41ms  181.70ms   1.50s    77.46%
    Req/Sec   289.19     80.82   660.00     70.35%
    Latency Distribution
    50%  191.91ms
    75%  301.90ms
    90%  498.79ms
    99%  803.26ms
    18000 requests in 49.00s, 12.65MB read
    Requests/sec:    367.35
    Transfer/sec:    264.39KB
    ------------------------------
    stop time: 31.321594
    stop time: 31.330613
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000324', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   229.43ms  158.83ms   1.25s    77.45%
    Req/Sec   288.55     88.50   474.00     65.52%
    Latency Distribution
    50%  197.01ms
    75%  300.77ms
    90%  416.70ms
    99%  746.47ms
    1710 requests in 3.02s, 1.20MB read
    Requests/sec:    566.50
    Transfer/sec:    407.72KB
    [run.sh] Speed is 566.50, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-vgh2c        340m         25Mi
    service1-5c9649c5ff-44dfg        318m         11Mi
    service2-6c6d889d77-wgwj6        148m         8Mi
    ubuntu-client-7477c7845f-nd6c6   13m          5Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   228.33ms  175.93ms   1.40s    77.34%
    Req/Sec   287.77     83.10   620.00     67.09%
    Latency Distribution
    50%  193.41ms
    75%  302.90ms
    90%  495.94ms
    99%  798.80ms
    18001 requests in 47.00s, 12.65MB read
    Requests/sec:    383.00
    Transfer/sec:    275.65KB
    ------------------------------
    stop time: 31.205459
    stop time: 31.595779
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000405', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   233.21ms  176.70ms   1.30s    76.54%
    Req/Sec   281.91     74.50   510.00     75.86%
    Latency Distribution
    50%  192.88ms
    75%  307.75ms
    90%  493.67ms
    99%  804.47ms
    1680 requests in 3.02s, 1.18MB read
    Requests/sec:    555.80
    Transfer/sec:    400.02KB
    [run.sh] Speed is 555.80, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-stp2n        1002m        26Mi
    service1-5c9649c5ff-wljxz        723m         13Mi
    service2-6c6d889d77-q4c5k        384m         8Mi
    ubuntu-client-7477c7845f-txx2k   32m          5Mi
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   226.23ms  167.59ms   1.70s    70.35%
    Req/Sec   288.92    100.41   700.00     71.86%
    Latency Distribution
    50%  194.05ms
    75%  300.66ms
    90%  455.85ms
    99%  756.06ms
    18001 requests in 48.00s, 12.65MB read
    Requests/sec:    375.02
    Transfer/sec:    269.91KB
    ------------------------------
    stop time: 31.279812
    stop time: 31.422637
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000486', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   232.83ms  154.08ms   1.10s    77.72%
    Req/Sec   282.31    124.58   643.00     68.97%
    Latency Distribution
    50%  198.58ms
    75%  301.12ms
    90%  405.58ms
    99%  799.13ms
    1655 requests in 3.02s, 1.16MB read
    Requests/sec:    547.93
    Transfer/sec:    394.36KB
    [run.sh] Speed is 547.93, duration is 49
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 49s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   231.01ms  179.74ms   1.51s    80.26%
    Req/Sec   283.49     92.36   626.00     67.92%
    Latency Distribution
    50%  195.70ms
    75%  301.67ms
    90%  497.79ms
    99%  807.68ms
    18000 requests in 49.00s, 12.65MB read
    Requests/sec:    367.35
    Transfer/sec:    264.39KB
    ------------------------------
    stop time: 32.259584
    stop time: 31.564191
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000567', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   223.81ms  152.96ms   1.19s    79.25%
    Req/Sec   288.33     84.07   505.00     65.52%
    Latency Distribution
    50%  196.70ms
    75%  298.74ms
    90%  406.12ms
    99%  706.03ms
    1694 requests in 3.02s, 1.19MB read
    Requests/sec:    560.74
    Transfer/sec:    403.58KB
    [run.sh] Speed is 560.74, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-grdkk        92m          23Mi
    service1-5c9649c5ff-jgh8l        53m          11Mi
    service2-6c6d889d77-stlhc        21m          8Mi
    ubuntu-client-7477c7845f-h4ft2   4m           3Mi
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   236.20ms  184.93ms   1.51s    79.73%
    Req/Sec   281.24     94.68   636.00     71.21%
    Latency Distribution
    50%  195.34ms
    75%  305.16ms
    90%  499.97ms
    99%  808.72ms
    18003 requests in 48.00s, 12.65MB read
    Requests/sec:    375.06
    Transfer/sec:    269.94KB
    ------------------------------
    stop time: 32.639869
    stop time: 32.234790
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000648', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   223.19ms  142.54ms 999.44ms   77.65%
    Req/Sec   288.74    109.84   585.00     74.14%
    Latency Distribution
    50%  198.61ms
    75%  296.02ms
    90%  402.19ms
    99%  700.84ms
    1709 requests in 3.03s, 1.20MB read
    Requests/sec:    564.65
    Transfer/sec:    406.40KB
    [run.sh] Speed is 564.65, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-f9ftg        996m         24Mi
    service1-5c9649c5ff-f4949        795m         14Mi
    service2-6c6d889d77-j8f5q        385m         8Mi
    ubuntu-client-7477c7845f-zdfc4   33m          6Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   226.88ms  169.75ms   1.31s    75.78%
    Req/Sec   286.54     86.92   595.00     70.11%
    Latency Distribution
    50%  194.93ms
    75%  301.63ms
    90%  495.40ms
    99%  774.94ms
    18000 requests in 47.00s, 12.65MB read
    Requests/sec:    382.98
    Transfer/sec:    275.64KB
    ------------------------------
    stop time: 31.772039
    stop time: 31.270651
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000729', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   231.95ms  144.05ms 884.22ms   80.43%
    Req/Sec   283.10     83.85   454.00     70.69%
    Latency Distribution
    50%  198.85ms
    75%  297.04ms
    90%  405.79ms
    99%  698.08ms
    1670 requests in 3.02s, 1.17MB read
    Requests/sec:    552.68
    Transfer/sec:    397.78KB
    [run.sh] Speed is 552.68, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-ckt78        321m         24Mi
    service1-5c9649c5ff-5wvxb        872m         14Mi
    service2-6c6d889d77-lrhfx        115m         8Mi
    ubuntu-client-7477c7845f-m5ctf   10m          5Mi
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   226.74ms  173.77ms   1.50s    77.99%
    Req/Sec   289.59     82.54   535.00     67.85%
    Latency Distribution
    50%  193.79ms
    75%  302.08ms
    90%  496.05ms
    99%  801.25ms
    18000 requests in 48.00s, 12.65MB read
    Requests/sec:    375.00
    Transfer/sec:    269.90KB
    ------------------------------
    stop time: 31.346800
    stop time: 31.139350
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '816', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '816'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   331.99ms  230.42ms   1.30s    70.11%
    Req/Sec   201.64    102.92   430.00     67.86%
    Latency Distribution
    50%  264.63ms
    75%  492.95ms
    90%  659.29ms
    99%    1.06s
    1130 requests in 3.02s, 815.50KB read
    Requests/sec:    373.85
    Transfer/sec:    269.80KB
    [run.sh] Speed is 373.85, duration is 72
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d72s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-86cd8b947b-s6klk        323m         12Mi
    service2-5c45474c64-ml8qs        185m         8Mi
    ubuntu-client-7477c7845f-hzns5   10m          0Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   333.82ms  264.57ms   1.90s    80.04%
    Req/Sec   196.22     74.86   460.00     66.34%
    Latency Distribution
    50%  211.30ms
    75%  463.14ms
    90%  704.96ms
    99%    1.20s
    18000 requests in 1.20m, 12.69MB read
    Requests/sec:    250.00
    Transfer/sec:    180.42KB
    ------------------------------
    stop time: 46.462453
    stop time: 45.767164
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '735', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '735'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   311.96ms  237.82ms   1.53s    81.81%
    Req/Sec   205.43     68.30   300.00     67.86%
    Latency Distribution
    50%  224.31ms
    75%  420.81ms
    90%  606.60ms
    99%    1.20s
    1185 requests in 3.03s, 855.19KB read
    Requests/sec:    391.27
    Transfer/sec:    282.37KB
    [run.sh] Speed is 391.27, duration is 69
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d69s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-65cff68cdb-r62zb        324m         22Mi
    ubuntu-client-7477c7845f-jm4cr   10m          0Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   328.35ms  274.01ms   1.91s    82.07%
    Req/Sec   197.89     79.65   490.00     70.03%
    Latency Distribution
    50%  208.39ms
    75%  437.89ms
    90%  704.19ms
    99%    1.27s
    18016 requests in 1.15m, 12.70MB read
    Socket errors: connect 0, read 0, write 0, timeout 77
    Requests/sec:    261.10
    Transfer/sec:    188.43KB
    ------------------------------
    stop time: 45.986667
    stop time: 45.981533
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '654', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '654'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   303.77ms  203.66ms   1.20s    70.76%
    Req/Sec   214.32     94.58   440.00     66.07%
    Latency Distribution
    50%  275.79ms
    75%  399.06ms
    90%  601.47ms
    99%  980.14ms
    1240 requests in 3.02s, 0.87MB read
    Requests/sec:    410.89
    Transfer/sec:    296.53KB
    [run.sh] Speed is 410.89, duration is 65
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d65s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   318.24ms  264.93ms   1.91s    78.98%
    Req/Sec   209.59     85.09   520.00     70.20%
    Latency Distribution
    50%  204.24ms
    75%  427.34ms
    90%  697.61ms
    99%    1.23s
    18000 requests in 1.08m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 21
    Requests/sec:    276.92
    Transfer/sec:    199.85KB
    ------------------------------
    stop time: 44.325585
    stop time: 43.049102
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '573', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '573'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   288.14ms  194.73ms   1.41s    78.23%
    Req/Sec   211.36     98.73   444.00     63.79%
    Latency Distribution
    50%  204.01ms
    75%  394.33ms
    90%  598.79ms
    99%  892.67ms
    1246 requests in 3.04s, 0.88MB read
    Requests/sec:    410.23
    Transfer/sec:    296.05KB
    [run.sh] Speed is 410.23, duration is 65
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d65s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   314.15ms  275.44ms   2.00s    79.98%
    Req/Sec   210.22     82.07   510.00     71.73%
    Latency Distribution
    50%  201.07ms
    75%  405.44ms
    90%  701.20ms
    99%    1.30s
    18001 requests in 1.08m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 23
    Requests/sec:    276.94
    Transfer/sec:    199.86KB
    ------------------------------
    stop time: 43.074461
    stop time: 43.283243
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '492', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '492'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   276.69ms  200.33ms   1.60s    81.84%
    Req/Sec   230.12     81.09   370.00     69.64%
    Latency Distribution
    50%  203.66ms
    75%  390.88ms
    90%  512.00ms
    99%  996.56ms
    1329 requests in 3.03s, 0.94MB read
    Requests/sec:    438.42
    Transfer/sec:    316.40KB
    [run.sh] Speed is 438.42, duration is 61
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d61s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   291.92ms  240.24ms   1.90s    81.17%
    Req/Sec   226.27     78.38   520.00     71.77%
    Latency Distribution
    50%  199.98ms
    75%  401.60ms
    90%  608.52ms
    99%    1.10s
    18000 requests in 1.02m, 12.69MB read
    Requests/sec:    295.08
    Transfer/sec:    212.95KB
    ------------------------------
    stop time: 40.074214
    stop time: 40.064429
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '411', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '411'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   264.73ms  186.26ms   1.50s    83.78%
    Req/Sec   235.50     80.86   420.00     72.41%
    Latency Distribution
    50%  201.96ms
    75%  306.33ms
    90%  503.80ms
    99%  908.66ms
    1371 requests in 3.02s, 0.97MB read
    Requests/sec:    453.53
    Transfer/sec:    327.30KB
    [run.sh] Speed is 453.53, duration is 59
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   282.77ms  218.51ms   1.60s    81.54%
    Req/Sec   234.49     83.22   510.00     66.10%
    Latency Distribution
    50%  201.12ms
    75%  397.98ms
    90%  598.68ms
    99%    1.00s
    18000 requests in 0.98m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 3
    Requests/sec:    305.08
    Transfer/sec:    220.17KB
    ------------------------------
    stop time: 38.350279
    stop time: 39.756403
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '330', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '330'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   275.98ms  218.85ms   1.71s    80.76%
    Req/Sec   246.78     78.84   460.00     74.14%
    Latency Distribution
    50%  200.79ms
    75%  369.44ms
    90%  594.16ms
    99%    1.00s
    1439 requests in 3.02s, 1.01MB read
    Requests/sec:    476.04
    Transfer/sec:    343.55KB
    [run.sh] Speed is 476.04, duration is 56
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d56s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-69784ff859-p7g4z        321m         22Mi
    service1-5c9649c5ff-b8h8r        256m         12Mi
    service2-8964d99f-8m5vs          157m         8Mi
    ubuntu-client-7477c7845f-4wds4   11m          4Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   271.93ms  218.49ms   2.00s    78.51%
    Req/Sec   240.79     92.62   560.00     70.45%
    Latency Distribution
    50%  199.69ms
    75%  392.68ms
    90%  596.19ms
    99%    1.00s
    18002 requests in 0.93m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 10
    Requests/sec:    321.46
    Transfer/sec:    231.99KB
    ------------------------------
    stop time: 37.750588
    stop time: 37.543992
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '249', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '249'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   254.99ms  169.28ms   1.10s    80.69%
    Req/Sec   254.43     82.06   440.00     67.24%
    Latency Distribution
    50%  202.47ms
    75%  324.11ms
    90%  497.61ms
    99%  804.35ms
    1485 requests in 3.04s, 1.05MB read
    Requests/sec:    488.95
    Transfer/sec:    352.87KB
    [run.sh] Speed is 488.95, duration is 55
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-79f6bfcb94-9lpqj        607m         26Mi
    service1-5c9649c5ff-nnr9r        555m         13Mi
    service2-6966f9f446-9wtn2        270m         8Mi
    ubuntu-client-7477c7845f-9225g   19m          5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   257.08ms  190.62ms   1.40s    81.20%
    Req/Sec   254.67     83.55   590.00     68.46%
    Latency Distribution
    50%  199.18ms
    75%  310.09ms
    90%  506.86ms
    99%  898.09ms
    18000 requests in 0.92m, 12.69MB read
    Requests/sec:    327.27
    Transfer/sec:    236.19KB
    ------------------------------
    stop time: 35.311933
    stop time: 35.719213
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '168', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '168'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   239.44ms  157.46ms   1.10s    76.96%
    Req/Sec   264.62    105.47   525.00     62.07%
    Latency Distribution
    50%  199.71ms
    75%  303.35ms
    90%  451.08ms
    99%  703.72ms
    1563 requests in 3.03s, 1.10MB read
    Requests/sec:    516.34
    Transfer/sec:    372.63KB
    [run.sh] Speed is 516.34, duration is 52
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d52s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-566866d46b-x49hn        996m         24Mi
    service1-5c9649c5ff-fttwt        873m         14Mi
    service2-865ffc4f4b-h7ftn        453m         9Mi
    ubuntu-client-7477c7845f-w9v8j   28m          6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   260.40ms  218.65ms   2.00s    83.76%
    Req/Sec   251.23    105.86   565.00     66.20%
    Latency Distribution
    50%  198.65ms
    75%  339.35ms
    90%  511.70ms
    99%    1.10s
    18001 requests in 0.87m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 53
    Requests/sec:    346.17
    Transfer/sec:    249.83KB
    ------------------------------
    stop time: 35.811123
    stop time: 36.321041
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '87', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '87'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   233.19ms  139.98ms 897.28ms   76.40%
    Req/Sec   279.22     84.83   510.00     67.24%
    Latency Distribution
    50%  198.23ms
    75%  301.33ms
    90%  409.50ms
    99%  645.09ms
    1655 requests in 3.03s, 1.17MB read
    Requests/sec:    546.87
    Transfer/sec:    394.66KB
    [run.sh] Speed is 546.87, duration is 49
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-65984b998-f2mbd         996m         30Mi
    service1-5c9649c5ff-csprg        778m         13Mi
    service2-7557789b74-shdvz        408m         8Mi
    ubuntu-client-7477c7845f-nvwjj   27m          6Mi
    Running 49s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   236.12ms  180.24ms   1.40s    80.02%
    Req/Sec   278.77     81.28   590.00     68.89%
    Latency Distribution
    50%  195.13ms
    75%  303.11ms
    90%  500.84ms
    99%  805.55ms
    18000 requests in 49.00s, 12.69MB read
    Requests/sec:    367.35
    Transfer/sec:    265.11KB
    ------------------------------
    stop time: 32.074781
    stop time: 32.972150
    [run.sh] Test finished with status 0
[test.py] Groundtruth:  [587.5894258059809, 580.5348596669859, 565.2042994525856, 574.6006680977735, 573.2371072047974, 574.1402540752435, 564.0531291043189, 554.9162115827075, 571.0416227480141, 576.127669891648]
[test.py] Slowdown:  [390.3301474189143, 391.43964979199336, 412.01864334003284, 416.8707403337171, 449.2214823253246, 460.9080692993718, 478.1220640317006, 506.8199237557, 499.0838760916697, 553.446556917497]
[test.py] Predicted:  [572.847988723551, 549.6310754081622, 564.0779463589137, 547.7785874080555, 576.7666566966141, 568.7117361660316, 567.779820032723, 580.1078504287302, 544.8399989563287, 581.5342427311975]
[test.py] Error percentage:  [-2.5087989053256825, -5.323329640626762, -0.19928247091588377, -4.667951532063644, 0.6157224379676525, -0.9455037981887392, 0.6606985647472312, 4.539719388296873, -4.588391239432908, 0.9384331151056069]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 2...
[test.py] Actual processing time range: [0, 81, 162, 243, 324, 405, 486, 567, 648, 729]
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   233.10ms  185.57ms   1.39s    79.52%
    Req/Sec   287.71     97.61   545.00     72.41%
    Latency Distribution
    50%  197.53ms
    75%  303.39ms
    90%  491.74ms
    99%  908.86ms
    1674 requests in 3.02s, 1.17MB read
    Requests/sec:    553.70
    Transfer/sec:    394.73KB
    [run.sh] Speed is 553.70, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-q927s        315m         17Mi
    service1-5c9649c5ff-hqwvq        151m         10Mi
    service2-6c6d889d77-vkz7c        121m         7Mi
    ubuntu-client-7477c7845f-cgcnr   13m          0Mi
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   225.13ms  186.19ms   1.70s    77.90%
    Req/Sec   294.04     77.71   575.00     69.33%
    Latency Distribution
    50%  193.21ms
    75%  301.50ms
    90%  498.32ms
    99%  807.25ms
    18001 requests in 48.00s, 12.53MB read
    Requests/sec:    375.02
    Transfer/sec:    267.35KB
    ------------------------------
    stop time: 30.673337
    stop time: 30.771535
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '8.1e-05', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   237.44ms  183.53ms   1.50s    79.74%
    Req/Sec   291.14     90.95   520.00     63.79%
    Latency Distribution
    50%  197.33ms
    75%  301.66ms
    90%  493.25ms
    99%  807.12ms
    1706 requests in 3.02s, 1.20MB read
    Requests/sec:    564.03
    Transfer/sec:    405.95KB
    [run.sh] Speed is 564.03, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-t4ts4        886m         28Mi
    service1-5c9649c5ff-gvk7f        510m         13Mi
    service2-6c6d889d77-h7q7q        325m         9Mi
    ubuntu-client-7477c7845f-xdgwd   30m          6Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   225.68ms  187.30ms   1.79s    79.95%
    Req/Sec   294.71     83.48   560.00     65.30%
    Latency Distribution
    50%  192.02ms
    75%  301.76ms
    90%  498.70ms
    99%  811.31ms
    18002 requests in 47.00s, 12.65MB read
    Requests/sec:    383.02
    Transfer/sec:    275.67KB
    ------------------------------
    stop time: 30.597505
    stop time: 30.703886
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000162', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   230.30ms  182.19ms   1.60s    78.89%
    Req/Sec   297.40     81.67   460.00     62.07%
    Latency Distribution
    50%  195.05ms
    75%  301.91ms
    90%  494.50ms
    99%  809.22ms
    1754 requests in 3.03s, 1.23MB read
    Requests/sec:    579.57
    Transfer/sec:    417.13KB
    [run.sh] Speed is 579.57, duration is 46
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-rmrcv        1001m        22Mi
    service1-5c9649c5ff-jxtnk        582m         12Mi
    service2-6c6d889d77-sphpd        389m         8Mi
    ubuntu-client-7477c7845f-fwqjw   32m          6Mi
    Running 46s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   227.47ms  185.11ms   1.37s    77.53%
    Req/Sec   292.21     92.88   737.00     69.37%
    Latency Distribution
    50%  160.59ms
    75%  302.83ms
    90%  499.39ms
    99%  838.22ms
    18017 requests in 46.00s, 12.66MB read
    Requests/sec:    391.67
    Transfer/sec:    281.90KB
    ------------------------------
    stop time: 30.678997
    stop time: 31.215668
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000243', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   238.27ms  173.65ms   1.19s    81.33%
    Req/Sec   280.35     93.31   454.00     68.33%
    Latency Distribution
    50%  197.55ms
    75%  304.77ms
    90%  491.34ms
    99%  803.39ms
    1676 requests in 3.03s, 1.18MB read
    Requests/sec:    553.67
    Transfer/sec:    398.49KB
    [run.sh] Speed is 553.67, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   228.55ms  181.67ms   1.70s    77.94%
    Req/Sec   288.96     84.76   660.00     69.50%
    Latency Distribution
    50%  193.61ms
    75%  303.07ms
    90%  498.12ms
    99%  803.30ms
    18000 requests in 48.00s, 12.65MB read
    Requests/sec:    375.00
    Transfer/sec:    269.90KB
    ------------------------------
    stop time: 30.955604
    stop time: 31.554435
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000324', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   233.75ms  175.29ms   1.30s    80.00%
    Req/Sec   281.13     95.54   570.00     75.00%
    Latency Distribution
    50%  195.95ms
    75%  303.30ms
    90%  495.19ms
    99%  799.02ms
    1681 requests in 3.02s, 1.18MB read
    Requests/sec:    555.81
    Transfer/sec:    400.03KB
    [run.sh] Speed is 555.81, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-9t787        758m         25Mi
    service1-5c9649c5ff-8vgxz        542m         11Mi
    service2-6c6d889d77-kq6ks        272m         8Mi
    ubuntu-client-7477c7845f-kn8dh   26m          5Mi
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   224.89ms  173.57ms   1.40s    75.11%
    Req/Sec   290.96     83.69   540.00     68.66%
    Latency Distribution
    50%  192.87ms
    75%  301.26ms
    90%  494.87ms
    99%  798.78ms
    18000 requests in 48.00s, 12.65MB read
    Requests/sec:    375.00
    Transfer/sec:    269.90KB
    ------------------------------
    stop time: 31.137215
    stop time: 31.037180
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000405', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   228.16ms  163.55ms   1.20s    80.05%
    Req/Sec   293.62     82.99   500.00     62.07%
    Latency Distribution
    50%  197.40ms
    75%  298.08ms
    90%  447.52ms
    99%  802.57ms
    1721 requests in 3.02s, 1.21MB read
    Requests/sec:    569.33
    Transfer/sec:    409.76KB
    [run.sh] Speed is 569.33, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-dkj62        1001m        27Mi
    service1-5c9649c5ff-qvthz        722m         14Mi
    service2-6c6d889d77-q96cd        390m         8Mi
    ubuntu-client-7477c7845f-thrcj   31m          6Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   226.76ms  180.72ms   1.70s    78.25%
    Req/Sec   293.01     94.39   660.00     69.43%
    Latency Distribution
    50%  175.34ms
    75%  300.48ms
    90%  492.46ms
    99%  828.18ms
    18000 requests in 47.00s, 12.65MB read
    Requests/sec:    382.98
    Transfer/sec:    275.64KB
    ------------------------------
    stop time: 30.914904
    stop time: 30.915445
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000486', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   225.75ms  155.98ms   1.21s    74.84%
    Req/Sec   285.69     86.57   515.00     70.69%
    Latency Distribution
    50%  195.98ms
    75%  299.35ms
    90%  457.59ms
    99%  733.08ms
    1682 requests in 3.03s, 1.18MB read
    Requests/sec:    555.94
    Transfer/sec:    400.12KB
    [run.sh] Speed is 555.94, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   229.52ms  184.81ms   1.89s    79.90%
    Req/Sec   286.11     96.20   660.00     70.95%
    Latency Distribution
    50%  194.59ms
    75%  300.94ms
    90%  494.90ms
    99%  846.95ms
    18000 requests in 48.00s, 12.65MB read
    Socket errors: connect 0, read 0, write 0, timeout 1
    Requests/sec:    375.00
    Transfer/sec:    269.90KB
    ------------------------------
    stop time: 31.612597
    stop time: 31.701772
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000567', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   222.48ms  157.06ms   1.20s    80.45%
    Req/Sec   289.83     96.84   500.00     67.24%
    Latency Distribution
    50%  196.01ms
    75%  295.38ms
    90%  406.15ms
    99%  797.47ms
    1730 requests in 3.03s, 1.22MB read
    Requests/sec:    570.80
    Transfer/sec:    410.82KB
    [run.sh] Speed is 570.80, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-xq2vx        320m         22Mi
    service1-5c9649c5ff-cjpvq        277m         11Mi
    service2-6c6d889d77-drjtm        93m          8Mi
    ubuntu-client-7477c7845f-zn22f   12m          5Mi
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   227.15ms  174.32ms   1.56s    77.80%
    Req/Sec   288.04     94.43   670.00     69.97%
    Latency Distribution
    50%  193.65ms
    75%  302.61ms
    90%  494.32ms
    99%  799.72ms
    18000 requests in 47.00s, 12.65MB read
    Requests/sec:    382.98
    Transfer/sec:    275.64KB
    ------------------------------
    stop time: 31.281641
    stop time: 31.482256
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000648', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   226.50ms  154.31ms 903.06ms   75.29%
    Req/Sec   286.19    121.24   595.00     67.24%
    Latency Distribution
    50%  197.13ms
    75%  297.16ms
    90%  428.55ms
    99%  704.02ms
    1684 requests in 3.02s, 1.18MB read
    Requests/sec:    556.73
    Transfer/sec:    400.69KB
    [run.sh] Speed is 556.73, duration is 48
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-59b5458ffc-6m6k9        1003m        24Mi
    service1-5c9649c5ff-n72lv        848m         13Mi
    service2-6c6d889d77-hr8lx        402m         9Mi
    ubuntu-client-7477c7845f-r2zqx   31m          6Mi
    Running 48s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   237.23ms  199.08ms   1.99s    82.99%
    Req/Sec   280.34    105.62   616.00     70.14%
    Latency Distribution
    50%  193.74ms
    75%  303.00ms
    90%  499.75ms
    99%  961.07ms
    18000 requests in 48.00s, 12.65MB read
    Socket errors: connect 0, read 0, write 0, timeout 14
    Requests/sec:    375.00
    Transfer/sec:    269.90KB
    ------------------------------
    stop time: 32.117557
    stop time: 32.514390
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.000729', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   224.01ms  139.87ms 805.64ms   76.33%
    Req/Sec   289.81    106.75   550.00     65.52%
    Latency Distribution
    50%  198.10ms
    75%  298.46ms
    90%  402.55ms
    99%  699.93ms
    1703 requests in 3.02s, 1.20MB read
    Requests/sec:    563.02
    Transfer/sec:    405.22KB
    [run.sh] Speed is 563.02, duration is 47
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 47s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   238.78ms  194.06ms   1.89s    84.59%
    Req/Sec   282.07    102.65   575.00     70.74%
    Latency Distribution
    50%  196.47ms
    75%  301.00ms
    90%  497.19ms
    99%    1.00s
    18000 requests in 47.00s, 12.65MB read
    Requests/sec:    382.98
    Transfer/sec:    275.64KB
    ------------------------------
    stop time: 31.507680
    stop time: 32.811694
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '816', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '816'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   321.89ms  223.35ms   1.51s    77.31%
    Req/Sec   199.32     98.88   565.00     67.86%
    Latency Distribution
    50%  267.39ms
    75%  408.85ms
    90%  619.36ms
    99%    1.00s
    1140 requests in 3.03s, 822.71KB read
    Requests/sec:    376.81
    Transfer/sec:    271.94KB
    [run.sh] Speed is 376.81, duration is 71
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d71s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-86cd8b947b-wrjz6        26m          22Mi
    service1-5c9649c5ff-pg2j5        14m          12Mi
    service2-5c45474c64-vhqs4        73m          8Mi
    ubuntu-client-7477c7845f-p5f4c   2m           4Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   338.90ms  282.51ms   2.00s    80.63%
    Req/Sec   194.51     75.97   490.00     70.23%
    Latency Distribution
    50%  208.62ms
    75%  467.39ms
    90%  755.95ms
    99%    1.30s
    18001 requests in 1.18m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 10
    Requests/sec:    253.53
    Transfer/sec:    182.97KB
    ------------------------------
    stop time: 46.290417
    stop time: 46.793045
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '735', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '735'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   307.14ms  216.10ms   1.50s    78.82%
    Req/Sec   202.67     83.60   454.00     70.69%
    Latency Distribution
    50%  212.39ms
    75%  405.61ms
    90%  619.17ms
    99%  958.54ms
    1198 requests in 3.02s, 864.57KB read
    Requests/sec:    397.30
    Transfer/sec:    286.72KB
    [run.sh] Speed is 397.30, duration is 67
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d67s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-65cff68cdb-gjf27        323m         22Mi
    service1-5c9649c5ff-v7g7h        218m         11Mi
    service2-649d7fcfc8-xqd2m        185m         8Mi
    ubuntu-client-7477c7845f-jdgnd   10m          0Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   328.25ms  278.60ms   1.90s    80.29%
    Req/Sec   201.61     83.71   530.00     71.25%
    Latency Distribution
    50%  204.57ms
    75%  496.62ms
    90%  706.40ms
    99%    1.29s
    18010 requests in 1.12m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 3
    Requests/sec:    268.81
    Transfer/sec:    193.99KB
    ------------------------------
    stop time: 45.127820
    stop time: 44.712059
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '654', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '654'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   304.90ms  278.10ms   1.95s    84.71%
    Req/Sec   218.14    111.49   580.00     78.57%
    Latency Distribution
    50%  198.96ms
    75%  409.14ms
    90%  699.68ms
    99%    1.33s
    1243 requests in 3.02s, 0.88MB read
    Requests/sec:    412.18
    Transfer/sec:    297.46KB
    [run.sh] Speed is 412.18, duration is 65
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d65s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-767766684d-hqw4j        325m         19Mi
    service1-5c9649c5ff-qz75d        229m         10Mi
    service2-856fc95c68-g6b2c        183m         8Mi
    ubuntu-client-7477c7845f-9qjvh   10m          0Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   324.55ms  268.87ms   1.90s    79.03%
    Req/Sec   209.34     89.46   515.00     68.72%
    Latency Distribution
    50%  210.47ms
    75%  441.18ms
    90%  699.01ms
    99%    1.29s
    18000 requests in 1.08m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 15
    Requests/sec:    276.92
    Transfer/sec:    199.85KB
    ------------------------------
    stop time: 44.126746
    stop time: 43.671385
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '573', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '573'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   309.71ms  243.09ms   1.74s    78.42%
    Req/Sec   212.75     88.61   430.00     71.67%
    Latency Distribution
    50%  205.70ms
    75%  402.54ms
    90%  622.22ms
    99%    1.20s
    1273 requests in 3.03s, 0.90MB read
    Requests/sec:    420.02
    Transfer/sec:    303.12KB
    [run.sh] Speed is 420.02, duration is 64
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d64s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-86d74c4bdb-cb9q6        322m         14Mi
    service1-5c9649c5ff-p6njj        229m         10Mi
    service2-7759c76dd6-swhtl        175m         8Mi
    ubuntu-client-7477c7845f-fn9zm   10m          0Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   300.71ms  231.04ms   1.81s    78.74%
    Req/Sec   218.05     76.66   454.00     66.99%
    Latency Distribution
    50%  204.93ms
    75%  401.59ms
    90%  606.66ms
    99%    1.05s
    18000 requests in 1.07m, 12.69MB read
    Requests/sec:    281.25
    Transfer/sec:    202.97KB
    ------------------------------
    stop time: 40.998611
    stop time: 42.013536
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '492', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '492'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   290.42ms  228.56ms   1.47s    82.64%
    Req/Sec   229.75    102.09   535.00     73.21%
    Latency Distribution
    50%  203.17ms
    75%  397.67ms
    90%  601.64ms
    99%    1.10s
    1337 requests in 3.02s, 0.94MB read
    Requests/sec:    443.19
    Transfer/sec:    319.84KB
    [run.sh] Speed is 443.19, duration is 60
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d60s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-5799dd8df6-5fjsd        133m         23Mi
    service1-5c9649c5ff-78tpf        104m         10Mi
    service2-65866b59cb-th9gb        137m         8Mi
    ubuntu-client-7477c7845f-zbch8   4m           0Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   310.80ms  264.07ms   1.99s    81.92%
    Req/Sec   216.72     86.91   580.00     70.55%
    Latency Distribution
    50%  202.92ms
    75%  401.47ms
    90%  690.07ms
    99%    1.30s
    18000 requests in 1.00m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 16
    Requests/sec:    300.00
    Transfer/sec:    216.50KB
    ------------------------------
    stop time: 41.866370
    stop time: 41.571424
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '411', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '411'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   263.09ms  184.53ms   1.10s    81.80%
    Req/Sec   236.19     88.27   474.00     72.41%
    Latency Distribution
    50%  200.48ms
    75%  385.88ms
    90%  506.42ms
    99%  806.44ms
    1373 requests in 3.02s, 0.97MB read
    Requests/sec:    455.33
    Transfer/sec:    328.60KB
    [run.sh] Speed is 455.33, duration is 59
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-5bf76fff9f-qt6rp        322m         24Mi
    service1-5c9649c5ff-7f9tl        245m         11Mi
    service2-85fc8775d7-f88f5        179m         8Mi
    ubuntu-client-7477c7845f-9bw2p   10m          4Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   278.47ms  212.90ms   1.81s    78.37%
    Req/Sec   235.82     82.50   545.00     70.12%
    Latency Distribution
    50%  200.80ms
    75%  397.47ms
    90%  597.81ms
    99%  911.68ms
    18000 requests in 0.98m, 12.69MB read
    Requests/sec:    305.08
    Transfer/sec:    220.17KB
    ------------------------------
    stop time: 38.712081
    stop time: 38.629389
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '330', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '330'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   272.27ms  200.44ms   1.40s    77.34%
    Req/Sec   242.69     99.90   484.00     68.97%
    Latency Distribution
    50%  203.00ms
    75%  368.76ms
    90%  531.24ms
    99%  905.01ms
    1415 requests in 3.02s, 1.00MB read
    Requests/sec:    467.97
    Transfer/sec:    337.72KB
    [run.sh] Speed is 467.97, duration is 57
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d57s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-69784ff859-9hlhh        270m         28Mi
    service1-5c9649c5ff-vwht4        202m         15Mi
    service2-8964d99f-xwv65          492m         9Mi
    ubuntu-client-7477c7845f-jxvf9   9m           6Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   281.43ms  237.02ms   1.97s    82.96%
    Req/Sec   235.10    100.26   610.00     69.97%
    Latency Distribution
    50%  200.01ms
    75%  396.98ms
    90%  598.31ms
    99%    1.15s
    18000 requests in 0.95m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 35
    Requests/sec:    315.79
    Transfer/sec:    227.90KB
    ------------------------------
    stop time: 38.794462
    stop time: 38.526753
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '249', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '249'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   254.33ms  177.83ms   1.00s    77.70%
    Req/Sec   256.19     80.67   424.00     62.07%
    Latency Distribution
    50%  199.70ms
    75%  326.23ms
    90%  504.80ms
    99%  803.47ms
    1507 requests in 3.02s, 1.06MB read
    Requests/sec:    498.37
    Transfer/sec:    359.67KB
    [run.sh] Speed is 498.37, duration is 54
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d54s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-79f6bfcb94-25czv        1004m        26Mi
    service1-5c9649c5ff-9m8bb        839m         13Mi
    service2-6966f9f446-rnvth        473m         9Mi
    ubuntu-client-7477c7845f-5bzkp   27m          5Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   261.12ms  213.51ms   2.00s    81.57%
    Req/Sec   252.35     94.30   600.00     68.39%
    Latency Distribution
    50%  197.24ms
    75%  350.80ms
    90%  552.78ms
    99%    1.01s
    18000 requests in 0.90m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 2
    Requests/sec:    333.33
    Transfer/sec:    240.56KB
    ------------------------------
    stop time: 35.759627
    stop time: 36.206631
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '168', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '168'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   249.48ms  191.80ms   1.19s    79.11%
    Req/Sec   272.71     84.54   444.00     70.69%
    Latency Distribution
    50%  197.47ms
    75%  341.70ms
    90%  522.04ms
    99%  893.57ms
    1595 requests in 3.03s, 1.12MB read
    Requests/sec:    526.23
    Transfer/sec:    379.77KB
    [run.sh] Speed is 526.23, duration is 51
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d51s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    NAME                             CPU(cores)   MEMORY(bytes)
    service0-566866d46b-wwrhf        995m         29Mi
    service1-5c9649c5ff-zpvd2        848m         14Mi
    service2-865ffc4f4b-lp4mw        443m         8Mi
    ubuntu-client-7477c7845f-xj7kb   29m          7Mi
    Running 1m test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   259.90ms  212.33ms   1.83s    79.24%
    Req/Sec   256.38     87.22   490.00     70.41%
    Latency Distribution
    50%  197.01ms
    75%  365.67ms
    90%  568.13ms
    99%    1.00s
    18000 requests in 0.85m, 12.69MB read
    Socket errors: connect 0, read 0, write 0, timeout 1
    Requests/sec:    352.94
    Transfer/sec:    254.71KB
    ------------------------------
    stop time: 35.594047
    stop time: 34.997479
    [run.sh] Test finished with status 0
[test.py] Running (pre_run: False) workload syncthetic/chain-d2-http-sync request with the following configuration: {'PROCESSING_TIME_SERVICE0': '0.00115911', 'PROCESSING_TIME_SERVICE1': '0.00081627', 'PROCESSING_TIME_SERVICE2': '0.00043233', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '87', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '87'}
[test.py] Executing cmd `bash run.sh syncthetic chain-d2-http-sync 2 128 18000`:
    [run.sh] Running benchmark syncthetic with request chain-d2-http-sync, thread 2, conn 128, duration 60
    [run.sh] Deleting all services
    configmap "config-service0" deleted
    deployment.apps "service0" deleted
    service "service0" deleted
    configmap "config-service1" deleted
    deployment.apps "service1" deleted
    service "service1" deleted
    configmap "config-service2" deleted
    deployment.apps "service2" deleted
    service "service2" deleted
    deployment.apps "ubuntu-client" deleted
    [run.sh] Waiting for all pods to be deleted
    [run.sh] Deploying all services
    configmap/config-service0 created
    deployment.apps/service0 created
    service/service0 created
    configmap/config-service1 created
    deployment.apps/service1 created
    service/service1 created
    configmap/config-service2 created
    deployment.apps/service2 created
    service/service2 created
    [run.sh] Client pod not found, deploying client
    deployment.apps/ubuntu-client created
    [run.sh] Waiting for all pods to be running
    [run.sh] All pods are running
    [run.sh] Fix the request number.
    [run.sh] Running warmup test
    [run.sh] /wrk/wrk -t2 -c128 -d3s -L http://service0:80/endpoint1
    Running 3s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   239.72ms  202.66ms   1.26s    79.57%
    Req/Sec   273.00     82.89   494.00     75.00%
    Latency Distribution
    50%  191.24ms
    75%  336.86ms
    90%  506.59ms
    99%  996.27ms
    1632 requests in 3.02s, 1.15MB read
    Requests/sec:    540.14
    Transfer/sec:    389.81KB
    [run.sh] Speed is 540.14, duration is 49
    [run.sh] Running the actual test
    [run.sh] /wrk/wrk -t2 -c128 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
    [run.sh] Checking the resource usage
    Running 49s test @ http://service0:80/endpoint1
    2 threads and 128 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   237.87ms  176.85ms   1.74s    79.34%
    Req/Sec   276.42     99.27   620.00     71.17%
    Latency Distribution
    50%  196.63ms
    75%  302.33ms
    90%  498.15ms
    99%  804.31ms
    18003 requests in 49.00s, 12.69MB read
    Requests/sec:    367.41
    Transfer/sec:    265.15KB
    ------------------------------
    stop time: 32.062249
    stop time: 33.463935
    [run.sh] Test finished with status 0
[test.py] Groundtruth:  [585.8910406713842, 587.2623673417133, 581.6333281713376, 575.9074954344533, 579.01649063091, 582.2383438269126, 568.5913098178393, 573.5781511463509, 557.000085422152, 559.7069399338369]
[test.py] Slowdown:  [386.7496892197671, 400.71291725582137, 410.0315073905161, 433.6714722003275, 431.45915386976793, 465.46826689484953, 465.5902005678519, 500.2344293071344, 509.97622575831554, 549.3986953368137]
[test.py] Predicted:  [565.1691703608583, 568.0907317906526, 560.3600288280329, 577.1596106205513, 547.8111793470803, 575.6707163502475, 550.1937560803096, 571.4962619858244, 557.8471537847931, 577.0667517476787]
[test.py] Error percentage:  [-3.5368129689746235, -3.2645775750696484, -3.6575103786071135, 0.21741602532078694, -5.389364860718848, -1.127996386067193, -3.2356375167646654, -0.3629652134352901, 0.15207688199888825, 3.1015895239558624]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Groundtruth: [580.4075592860929, 563.4312285702454, 570.6142776822104, 571.1425740510541, 561.4058200567094, 568.789577386026, 567.2763605918658, 574.4680087143605, 551.2482733870486, 558.2726547818689]
    Slowdown:    [393.6455289369047, 384.4952873480673, 401.61364793842563, 428.6776079322695, 446.96984614776426, 466.4502605234839, 471.1493156202829, 501.84380200879156, 516.6990680040561, 558.8168295449562]
    Predicted:   [580.0172832261128, 536.0372162300872, 544.7557064219494, 568.3479989745739, 573.0601920458417, 577.173490671682, 557.9736307241857, 573.5977908072286, 565.9013322732116, 587.4663563321245]
    Error Perc:  [-0.06724172587623901, -4.861997516480013, -4.531707717741735, -0.4892955285505312, 2.0759264640247324, 1.4739920735161307, -1.639893800258862, -0.1514823965705901, 2.6581595976944854, 5.229290974615672]
[test.py] Result for the experiment 1: 
    Groundtruth: [587.5894258059809, 580.5348596669859, 565.2042994525856, 574.6006680977735, 573.2371072047974, 574.1402540752435, 564.0531291043189, 554.9162115827075, 571.0416227480141, 576.127669891648]
    Slowdown:    [390.3301474189143, 391.43964979199336, 412.01864334003284, 416.8707403337171, 449.2214823253246, 460.9080692993718, 478.1220640317006, 506.8199237557, 499.0838760916697, 553.446556917497]
    Predicted:   [572.847988723551, 549.6310754081622, 564.0779463589137, 547.7785874080555, 576.7666566966141, 568.7117361660316, 567.779820032723, 580.1078504287302, 544.8399989563287, 581.5342427311975]
    Error Perc:  [-2.5087989053256825, -5.323329640626762, -0.19928247091588377, -4.667951532063644, 0.6157224379676525, -0.9455037981887392, 0.6606985647472312, 4.539719388296873, -4.588391239432908, 0.9384331151056069]
[test.py] Result for the experiment 2: 
    Groundtruth: [585.8910406713842, 587.2623673417133, 581.6333281713376, 575.9074954344533, 579.01649063091, 582.2383438269126, 568.5913098178393, 573.5781511463509, 557.000085422152, 559.7069399338369]
    Slowdown:    [386.7496892197671, 400.71291725582137, 410.0315073905161, 433.6714722003275, 431.45915386976793, 465.46826689484953, 465.5902005678519, 500.2344293071344, 509.97622575831554, 549.3986953368137]
    Predicted:   [565.1691703608583, 568.0907317906526, 560.3600288280329, 577.1596106205513, 547.8111793470803, 575.6707163502475, 550.1937560803096, 571.4962619858244, 557.8471537847931, 577.0667517476787]
    Error Perc:  [-3.5368129689746235, -3.2645775750696484, -3.6575103786071135, 0.21741602532078694, -5.389364860718848, -1.127996386067193, -3.2356375167646654, -0.3629652134352901, 0.15207688199888825, 3.1015895239558624]
