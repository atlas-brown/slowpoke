[config.py] Random numbers for execution time: [522.2551759100179, 696.0933418365564, 1061.686329548961]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : dynamic-cache-http-async
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 22745
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.25}
baseline_service_processing_time : {'service0': 1061.69, 'service1': 696.09, 'service2': 4178.04}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2}
target_processing_time_range     : [0, 4178.04]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 417, 834, 1251, 1668, 2085, 2502, 2919, 3336, 3753]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-5276x cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   384.86ms  307.04ms   2.10s    78.61%
        Req/Sec   180.31     78.34   370.00     63.89%
        Latency Distribution
        50%  289.51ms
        75%  552.52ms
        90%  833.39ms
        99%    1.35s
        3941 requests in 3.03s, 611.93KB read
        Requests/sec:   1302.30
        Transfer/sec:    202.21KB
        [run.sh] Speed is 1302.30, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   370.30ms  409.92ms   3.09s    85.30%
        Req/Sec   193.08     93.83     1.10k    75.51%
        Latency Distribution
        50%  198.65ms
        75%  458.72ms
        90%    1.04s
        99%    1.81s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 12.773055
        stop time: 12.400925
        stop time: 13.269162
        stop time: 13.134921
        stop time: 13.244849
        stop time: 13.442102
        stop time: 13.452636
        stop time: 13.673620
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-5276x        997m         73Mi
        service1-7585bd9d88-ptpqv        755m         40Mi
        service2-84cffc954f-7cwl2        1366m        16Mi
        ubuntu-client-76886f6bbd-qp794   33m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [12.773055, 12.400925, 13.269162, 13.134921, 13.244849, 13.442102, 13.452636, 13.67362]
    [exp] Throughput: 1518.1523099588799
[test.py] Baseline throughput: 1518.1523099588799
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   379.51ms  356.07ms   2.35s    81.10%
        Req/Sec   182.58     77.81   410.00     73.28%
        Latency Distribution
        50%  231.66ms
        75%  577.74ms
        90%  940.64ms
        99%    1.51s
        4234 requests in 3.03s, 657.43KB read
        Requests/sec:   1398.65
        Transfer/sec:    217.17KB
        [run.sh] Speed is 1398.65, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   369.21ms  418.49ms   3.38s    84.94%
        Req/Sec   199.44     98.21   620.00     71.50%
        Latency Distribution
        50%  177.10ms
        75%  554.82ms
        90%  949.35ms
        99%    1.91s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.179044
        stop time: 12.690806
        stop time: 12.621371
        stop time: 12.708392
        stop time: 13.086791
        stop time: 13.446191
        stop time: 13.531845
        stop time: 13.557693
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-w9ztp   2m           53Mi
        service1-7585bd9d88-62fps   2m           20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.179044, 12.690806, 12.621371, 12.708392, 13.086791, 13.446191, 13.531845, 13.557693]
    [exp] Throughput: 1541.0972147913778
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   561.10ms  393.60ms   2.10s    61.16%
        Req/Sec   144.55     99.22   400.00     60.14%
        Latency Distribution
        50%  550.29ms
        75%  795.55ms
        90%    1.20s
        99%    1.45s
        2307 requests in 3.02s, 358.22KB read
        Requests/sec:    764.05
        Transfer/sec:    118.64KB
        [run.sh] Speed is 764.05, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74576c5f89-nkh4l        1129m        69Mi
        service1-57cdc6957f-w5kd5        718m         38Mi
        service2-84cffc954f-4ggqk        864m         15Mi
        ubuntu-client-76886f6bbd-hnxr9   31m          21Mi
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   671.25ms  714.51ms   4.64s    85.12%
        Req/Sec   118.42     75.19     0.92k    68.32%
        Latency Distribution
        50%  408.64ms
        75%  892.72ms
        90%    1.69s
        99%    3.23s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 23.497931
        stop time: 23.098371
        stop time: 23.529643
        stop time: 23.850013
        stop time: 23.572261
        stop time: 23.825587
        stop time: 24.184313
        stop time: 24.392361
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.497931, 23.098371, 23.529643, 23.850013, 23.572261, 23.825587, 24.184313, 24.392361]
    [exp] Throughput: 842.3247996004011
[test.py] Finished running 0th optmization experiment: groundtruth->1541.0972147913778, slowdown->842.3247996004011, predicted->1503.9052659994843, err->-2.413342158750725
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000417', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   330.11ms  265.62ms   1.75s    73.53%
        Req/Sec   192.23     96.34   420.00     67.87%
        Latency Distribution
        50%  232.53ms
        75%  484.04ms
        90%  731.42ms
        99%    1.07s
        4270 requests in 3.03s, 663.02KB read
        Requests/sec:   1411.54
        Transfer/sec:    219.17KB
        [run.sh] Speed is 1411.54, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   367.35ms  394.40ms   2.69s    84.43%
        Req/Sec   191.91     91.71   630.00     70.93%
        Latency Distribution
        50%  203.00ms
        75%  488.05ms
        90%  968.97ms
        99%    1.77s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.774949
        stop time: 12.679571
        stop time: 13.083346
        stop time: 13.592011
        stop time: 13.474299
        stop time: 13.313995
        stop time: 13.390425
        stop time: 13.266844
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [12.774949, 12.679571, 13.083346, 13.592011, 13.474299, 13.313995, 13.390425, 13.266844]
    [exp] Throughput: 1515.5039846388515
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   521.90ms  320.29ms   1.75s    74.06%
        Req/Sec   115.03     71.49   303.00     67.53%
        Latency Distribution
        50%  457.99ms
        75%  699.64ms
        90%  973.76ms
        99%    1.48s
        2327 requests in 3.04s, 361.32KB read
        Requests/sec:    766.22
        Transfer/sec:    118.97KB
        [run.sh] Speed is 766.22, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f77f7cb57-9882j        259m         69Mi
        service1-9d4b979b7-vgc8d         112m         37Mi
        service2-84cffc954f-w7cwk        118m         14Mi
        ubuntu-client-76886f6bbd-q68lj   3m           13Mi
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   608.12ms  566.48ms   3.86s    83.71%
        Req/Sec   121.97     82.32   515.00     67.19%
        Latency Distribution
        50%  442.77ms
        75%  778.92ms
        90%    1.30s
        99%    2.78s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 22.244363
        stop time: 22.755797
        stop time: 22.772057
        stop time: 23.145197
        stop time: 22.768277
        stop time: 23.205722
        stop time: 22.789993
        stop time: 22.551444
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.244363, 22.755797, 22.772057, 23.145197, 22.768277, 23.205722, 22.789993, 22.551444]
    [exp] Throughput: 877.9975728854594
[test.py] Finished running 1th optmization experiment: groundtruth->1515.5039846388515, slowdown->877.9975728854594, predicted->1495.15872277935, err->-1.342474982957558
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   317.61ms  256.89ms   1.33s    72.95%
        Req/Sec   192.19     97.27   540.00     72.22%
        Latency Distribution
        50%  232.60ms
        75%  466.37ms
        90%  695.29ms
        99%    1.16s
        4190 requests in 3.03s, 650.60KB read
        Requests/sec:   1384.48
        Transfer/sec:    214.97KB
        [run.sh] Speed is 1384.48, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   384.87ms  440.06ms   3.02s    84.88%
        Req/Sec   190.71     78.48   636.00     66.67%
        Latency Distribution
        50%  188.46ms
        75%  569.46ms
        90%    1.02s
        99%    1.99s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.681199
        stop time: 13.241895
        stop time: 13.214002
        stop time: 13.176688
        stop time: 13.399518
        stop time: 13.065941
        stop time: 13.389978
        stop time: 13.480445
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-8wwl9        1654m        65Mi
        service1-7585bd9d88-dmhrx        1m           34Mi
        service2-84cffc954f-xmlh9        77m          10Mi
        ubuntu-client-76886f6bbd-m9vnb   10m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.681199, 13.241895, 13.214002, 13.176688, 13.399518, 13.065941, 13.389978, 13.480445]
    [exp] Throughput: 1514.4392411046524
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   513.33ms  385.10ms   2.27s    73.34%
        Req/Sec   129.85     84.68   343.00     60.84%
        Latency Distribution
        50%  409.74ms
        75%  734.16ms
        90%    1.05s
        99%    1.61s
        2591 requests in 3.02s, 402.31KB read
        Requests/sec:    857.91
        Transfer/sec:    133.21KB
        [run.sh] Speed is 857.91, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   600.71ms  632.64ms   5.14s    85.05%
        Req/Sec   127.47     82.85     0.99k    70.67%
        Latency Distribution
        50%  369.09ms
        75%  869.43ms
        90%    1.49s
        99%    2.88s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.740483
        stop time: 21.915240
        stop time: 22.122601
        stop time: 21.916134
        stop time: 21.599268
        stop time: 21.929723
        stop time: 21.444773
        stop time: 21.589627
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service1-cdd6b68cc-455vg         283m         39Mi
        service2-84cffc954f-vdljc        177m         14Mi
        ubuntu-client-76886f6bbd-gb8dm   15m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.740483, 21.91524, 22.122601, 21.916134, 21.599268, 21.929723, 21.444773, 21.589627]
    [exp] Throughput: 928.8401134046438
[test.py] Finished running 2th optmization experiment: groundtruth->1514.4392411046524, slowdown->928.8401134046438, predicted->1518.3571899038473, err->0.25870623877502286
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001251', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   358.69ms  315.66ms   1.77s    82.13%
        Req/Sec   192.93     76.62   420.00     73.02%
        Latency Distribution
        50%  225.53ms
        75%  542.36ms
        90%  793.41ms
        99%    1.45s
        4178 requests in 3.02s, 648.73KB read
        Requests/sec:   1381.86
        Transfer/sec:    214.57KB
        [run.sh] Speed is 1381.86, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   383.57ms  429.83ms   3.91s    85.87%
        Req/Sec   193.00     89.90   666.00     69.56%
        Latency Distribution
        50%  208.23ms
        75%  517.43ms
        90%  938.80ms
        99%    2.00s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.546229
        stop time: 13.539535
        stop time: 13.066976
        stop time: 12.812082
        stop time: 13.320986
        stop time: 13.465580
        stop time: 13.040781
        stop time: 13.307579
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pncgl        1776m        67Mi
        service1-7585bd9d88-xqwdc        1093m        48Mi
        service2-84cffc954f-rp2cl        440m         18Mi
        ubuntu-client-76886f6bbd-qb94g   40m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.546229, 13.539535, 13.066976, 12.812082, 13.320986, 13.46558, 13.040781, 13.307579]
    [exp] Throughput: 1508.014891797858
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   530.52ms  424.79ms   2.08s    74.75%
        Req/Sec   133.55     62.97   420.00     70.78%
        Latency Distribution
        50%  419.95ms
        75%  767.11ms
        90%    1.21s
        99%    1.83s
        2664 requests in 3.02s, 413.65KB read
        Requests/sec:    883.40
        Transfer/sec:    137.17KB
        [run.sh] Speed is 883.40, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   544.28ms  517.51ms   3.96s    83.85%
        Req/Sec   131.58     81.60   490.00     68.92%
        Latency Distribution
        50%  362.50ms
        75%  747.41ms
        90%    1.29s
        99%    2.36s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 18.742273
        stop time: 19.699641
        stop time: 19.795968
        stop time: 20.375559
        stop time: 20.821707
        stop time: 20.901810
        stop time: 20.845941
        stop time: 20.734632
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.742273, 19.699641, 19.795968, 20.375559, 20.821707, 20.90181, 20.845941, 20.734632]
    [exp] Throughput: 988.1573601810912
[test.py] Finished running 3th optmization experiment: groundtruth->1508.014891797858, slowdown->988.1573601810912, predicted->1547.737082148593, err->2.634071491388134
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001668', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   352.06ms  297.34ms   1.60s    77.40%
        Req/Sec   178.94     89.92   424.00     68.10%
        Latency Distribution
        50%  247.84ms
        75%  495.63ms
        90%  802.28ms
        99%    1.23s
        4155 requests in 3.03s, 645.16KB read
        Requests/sec:   1370.89
        Transfer/sec:    212.86KB
        [run.sh] Speed is 1370.89, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   397.66ms  481.19ms   3.12s    85.17%
        Req/Sec   196.10     86.18   610.00     71.84%
        Latency Distribution
        50%  168.54ms
        75%  583.32ms
        90%    1.11s
        99%    2.10s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.064945
        stop time: 11.729455
        stop time: 13.170268
        stop time: 13.575167
        stop time: 13.519246
        stop time: 13.357232
        stop time: 13.607616
        stop time: 13.405857
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-xp59s        630m         67Mi
        service1-7585bd9d88-xh5dj        332m         38Mi
        service2-84cffc954f-wbv6p        692m         11Mi
        ubuntu-client-76886f6bbd-h7wrw   55m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.064945, 11.729455, 13.170268, 13.575167, 13.519246, 13.357232, 13.607616, 13.405857]
    [exp] Throughput: 1532.1299231619605
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   450.25ms  361.55ms   2.17s    77.95%
        Req/Sec   122.70     69.87   373.00     69.31%
        Latency Distribution
        50%  333.90ms
        75%  577.08ms
        90%  984.09ms
        99%    1.63s
        2791 requests in 3.03s, 433.37KB read
        Requests/sec:    921.07
        Transfer/sec:    143.02KB
        [run.sh] Speed is 921.07, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   553.03ms  633.20ms   5.46s    85.94%
        Req/Sec   133.56     77.57   510.00     67.96%
        Latency Distribution
        50%  313.18ms
        75%  672.83ms
        90%    1.46s
        99%    2.88s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.268371
        stop time: 19.775004
        stop time: 18.763095
        stop time: 19.415784
        stop time: 19.602058
        stop time: 19.573130
        stop time: 19.958924
        stop time: 19.648861
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.268371, 19.775004, 18.763095, 19.415784, 19.602058, 19.57313, 19.958924, 19.648861]
    [exp] Throughput: 1025.6066612434724
[test.py] Finished running 4th optmization experiment: groundtruth->1532.1299231619605, slowdown->1025.6066612434724, predicted->1512.224058450787, err->-1.2992282449580028
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002085', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   362.65ms  340.10ms   2.07s    81.46%
        Req/Sec   189.37     79.96   444.00     72.22%
        Latency Distribution
        50%  216.26ms
        75%  552.85ms
        90%  862.75ms
        99%    1.41s
        4122 requests in 3.03s, 640.04KB read
        Requests/sec:   1359.02
        Transfer/sec:    211.02KB
        [run.sh] Speed is 1359.02, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   358.31ms  410.74ms   3.06s    85.17%
        Req/Sec   193.94     96.30   717.00     70.53%
        Latency Distribution
        50%  186.30ms
        75%  485.89ms
        90%  941.37ms
        99%    2.03s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.584183
        stop time: 12.869896
        stop time: 13.144807
        stop time: 12.633800
        stop time: 13.069536
        stop time: 13.445561
        stop time: 13.648865
        stop time: 13.440101
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-zxm8b        494m         67Mi
        service1-7585bd9d88-ktgln        410m         40Mi
        service2-84cffc954f-5sjfc        268m         10Mi
        ubuntu-client-76886f6bbd-5r55s   19m          14Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.584183, 12.869896, 13.144807, 12.6338, 13.069536, 13.445561, 13.648865, 13.440101]
    [exp] Throughput: 1511.7622329839328
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   497.89ms  382.99ms   1.99s    79.33%
        Req/Sec   131.76     75.98   333.00     61.26%
        Latency Distribution
        50%  354.34ms
        75%  689.64ms
        90%    1.04s
        99%    1.68s
        2973 requests in 3.02s, 461.63KB read
        Requests/sec:    985.42
        Transfer/sec:    153.01KB
        [run.sh] Speed is 985.42, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   524.29ms  575.01ms   5.67s    85.38%
        Req/Sec   137.00     72.90   420.00     66.31%
        Latency Distribution
        50%  292.98ms
        75%  695.72ms
        90%    1.35s
        99%    2.56s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.357047
        stop time: 18.449082
        stop time: 17.695230
        stop time: 18.274036
        stop time: 18.042165
        stop time: 18.601178
        stop time: 18.889705
        stop time: 18.763266
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f696d68d6-cq992        600m         69Mi
        service1-5b7949c96d-49wpb        483m         37Mi
        service2-84cffc954f-tkwhs        947m         13Mi
        ubuntu-client-76886f6bbd-xdrfz   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.357047, 18.449082, 17.69523, 18.274036, 18.042165, 18.601178, 18.889705, 18.763266]
    [exp] Throughput: 1087.9046764867605
[test.py] Finished running 5th optmization experiment: groundtruth->1511.7622329839328, slowdown->1087.9046764867605, predicted->1520.7548487201075, err->0.5948432590768564
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002502', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   345.72ms  243.31ms   1.44s    77.39%
        Req/Sec   197.09     90.60   404.00     71.30%
        Latency Distribution
        50%  267.44ms
        75%  464.73ms
        90%  698.86ms
        99%    1.14s
        4284 requests in 3.03s, 665.19KB read
        Requests/sec:   1413.00
        Transfer/sec:    219.40KB
        [run.sh] Speed is 1413.00, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   370.68ms  408.84ms   3.85s    84.80%
        Req/Sec   188.85     82.41   570.00     72.41%
        Latency Distribution
        50%  195.98ms
        75%  542.59ms
        90%  953.40ms
        99%    1.81s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.252560
        stop time: 13.073272
        stop time: 13.075890
        stop time: 13.647631
        stop time: 13.393530
        stop time: 13.582012
        stop time: 13.610168
        stop time: 13.439481
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-7wvgl        643m         57Mi
        service1-7585bd9d88-tgjvh        428m         38Mi
        service2-84cffc954f-7mt2f        122m         11Mi
        ubuntu-client-76886f6bbd-q8fdk   22m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.25256, 13.073272, 13.07589, 13.647631, 13.39353, 13.582012, 13.610168, 13.439481]
    [exp] Throughput: 1494.2860741951886
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   469.72ms  413.25ms   2.69s    79.51%
        Req/Sec   145.64     68.31   292.00     69.15%
        Latency Distribution
        50%  343.48ms
        75%  679.43ms
        90%    1.15s
        99%    1.80s
        2979 requests in 3.03s, 462.56KB read
        Requests/sec:    983.73
        Transfer/sec:    152.75KB
        [run.sh] Speed is 983.73, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   461.15ms  479.53ms   3.48s    84.80%
        Req/Sec   147.87     83.94   535.00     67.26%
        Latency Distribution
        50%  280.83ms
        75%  625.49ms
        90%    1.10s
        99%    2.33s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 16.625536
        stop time: 16.925547
        stop time: 17.625676
        stop time: 17.328295
        stop time: 17.682842
        stop time: 17.517243
        stop time: 17.499939
        stop time: 17.602146
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-559cb467b4-jbp75        1333m        65Mi
        service1-cb57b799d-sbtz6         960m         44Mi
        service2-84cffc954f-s6m6r        1246m        18Mi
        ubuntu-client-76886f6bbd-vbk87   40m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.625536, 16.925547, 17.625676, 17.328295, 17.682842, 17.517243, 17.499939, 17.602146]
    [exp] Throughput: 1152.6777597684686
[test.py] Finished running 6th optmization experiment: groundtruth->1494.2860741951886, slowdown->1152.6777597684686, predicted->1519.6641116807236, err->1.6983386196116084
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002919', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   336.27ms  250.50ms   1.59s    73.59%
        Req/Sec   182.82     79.28   420.00     70.54%
        Latency Distribution
        50%  248.01ms
        75%  474.35ms
        90%  723.35ms
        99%    1.08s
        4155 requests in 3.02s, 645.16KB read
        Requests/sec:   1374.66
        Transfer/sec:    213.45KB
        [run.sh] Speed is 1374.66, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   390.53ms  465.05ms   3.85s    86.57%
        Req/Sec   195.21     87.12   810.00     72.98%
        Latency Distribution
        50%  194.42ms
        75%  551.48ms
        90%    1.03s
        99%    2.03s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.606094
        stop time: 12.089922
        stop time: 13.113291
        stop time: 13.353387
        stop time: 13.485204
        stop time: 13.517588
        stop time: 13.171021
        stop time: 13.427282
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-cdm7n   2m           65Mi
        service1-7585bd9d88-q9hw2   2m           32Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.606094, 12.089922, 13.113291, 13.353387, 13.485204, 13.517588, 13.171021, 13.427282]
    [exp] Throughput: 1527.2452583783506
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   442.63ms  267.81ms   2.06s    71.23%
        Req/Sec   142.68     89.73   383.00     63.77%
        Latency Distribution
        50%  368.20ms
        75%  626.01ms
        90%  814.02ms
        99%    1.20s
        3219 requests in 3.03s, 499.83KB read
        Requests/sec:   1061.25
        Transfer/sec:    164.78KB
        [run.sh] Speed is 1061.25, duration is 28
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d28s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 28s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   463.40ms  521.34ms   3.43s    85.58%
        Req/Sec   155.31     79.23   818.00     69.53%
        Latency Distribution
        50%  244.17ms
        75%  546.20ms
        90%    1.24s
        99%    2.36s
        20000 requests in 28.00s, 3.03MB read
        Requests/sec:    714.28
        Transfer/sec:    110.91KB
        ------------------------------
        stop time: 15.206867
        stop time: 16.023384
        stop time: 15.647217
        stop time: 16.326883
        stop time: 16.468935
        stop time: 16.602872
        stop time: 16.751051
        stop time: 16.650808
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-854764b98f-7h9mh        1592m        65Mi
        service1-7cf689c479-pppj4        1048m        40Mi
        service2-84cffc954f-c5gch        1253m        17Mi
        ubuntu-client-76886f6bbd-8rfkf   35m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.206867, 16.023384, 15.647217, 16.326883, 16.468935, 16.602872, 16.751051, 16.650808]
    [exp] Throughput: 1233.8251594331518
[test.py] Finished running 7th optmization experiment: groundtruth->1527.2452583783506, slowdown->1233.8251594331518, predicted->1531.1412551781161, err->0.25509961667206743
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003336', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   404.61ms  388.72ms   2.53s    82.09%
        Req/Sec   174.03     77.72   393.00     69.26%
        Latency Distribution
        50%  245.15ms
        75%  636.90ms
        90%    1.04s
        99%    1.51s
        4029 requests in 3.03s, 625.60KB read
        Requests/sec:   1331.78
        Transfer/sec:    206.79KB
        [run.sh] Speed is 1331.78, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   386.06ms  467.46ms   3.72s    86.07%
        Req/Sec   192.78     90.34   777.00     74.00%
        Latency Distribution
        50%  174.61ms
        75%  531.13ms
        90%  994.23ms
        99%    2.20s
        20001 requests in 22.00s, 3.03MB read
        Requests/sec:    909.13
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.576755
        stop time: 12.829044
        stop time: 13.056688
        stop time: 13.209666
        stop time: 13.258323
        stop time: 13.261374
        stop time: 13.499848
        stop time: 13.608508
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [12.576755, 12.829044, 13.056688, 13.209666, 13.258323, 13.261374, 13.499848, 13.608508]
    [exp] Throughput: 1519.4652135818233
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   458.64ms  422.54ms   2.92s    85.67%
        Req/Sec   161.38     75.36   370.00     70.37%
        Latency Distribution
        50%  303.78ms
        75%  611.28ms
        90%    1.04s
        99%    2.09s
        3502 requests in 3.03s, 543.77KB read
        Requests/sec:   1155.25
        Transfer/sec:    179.38KB
        [run.sh] Speed is 1155.25, duration is 25
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d25s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 25s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   425.80ms  439.22ms   3.50s    86.63%
        Req/Sec   165.39     79.10   565.00     67.67%
        Latency Distribution
        50%  251.89ms
        75%  541.58ms
        90%    1.05s
        99%    2.10s
        20000 requests in 25.00s, 3.03MB read
        Requests/sec:    799.99
        Transfer/sec:    124.22KB
        ------------------------------
        stop time: 14.361070
        stop time: 15.216866
        stop time: 15.283853
        stop time: 15.605258
        stop time: 15.643594
        stop time: 15.599729
        stop time: 15.401186
        stop time: 15.592826
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-768756f486-6jt8n        1175m        67Mi
        service1-698c8454b8-n625r        649m         46Mi
        service2-84cffc954f-tr5wg        474m         29Mi
        ubuntu-client-76886f6bbd-slf2t   7m           17Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.36107, 15.216866, 15.283853, 15.605258, 15.643594, 15.599729, 15.401186, 15.592826]
    [exp] Throughput: 1303.946912018187
[test.py] Finished running 8th optmization experiment: groundtruth->1519.4652135818233, slowdown->1303.946912018187, predicted->1511.3790500684174, err->-0.5321716773195739
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003753', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   339.74ms  321.74ms   2.07s    81.01%
        Req/Sec   175.03     79.99   380.00     67.26%
        Latency Distribution
        50%  215.89ms
        75%  513.22ms
        90%  824.61ms
        99%    1.37s
        3968 requests in 3.03s, 616.12KB read
        Requests/sec:   1308.98
        Transfer/sec:    203.25KB
        [run.sh] Speed is 1308.98, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   344.22ms  339.66ms   2.49s    83.53%
        Req/Sec   190.34     83.96   520.00     70.31%
        Latency Distribution
        50%  211.04ms
        75%  424.86ms
        90%  854.64ms
        99%    1.46s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.174588
        stop time: 13.044015
        stop time: 13.280860
        stop time: 13.500236
        stop time: 12.834784
        stop time: 13.510204
        stop time: 13.432484
        stop time: 13.590472
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.174588, 13.044015, 13.28086, 13.500236, 12.834784, 13.510204, 13.432484, 13.590472]
    [exp] Throughput: 1504.2168415821716
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   417.86ms  398.53ms   2.56s    82.63%
        Req/Sec   173.92     81.48   430.00     66.67%
        Latency Distribution
        50%  280.94ms
        75%  611.30ms
        90%  949.67ms
        99%    1.77s
        3790 requests in 3.03s, 588.49KB read
        Requests/sec:   1251.23
        Transfer/sec:    194.28KB
        [run.sh] Speed is 1251.23, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   418.16ms  488.99ms   3.79s    85.05%
        Req/Sec   179.45     86.21     0.96k    75.25%
        Latency Distribution
        50%  199.24ms
        75%  602.31ms
        90%    1.16s
        99%    2.08s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.169886
        stop time: 14.385791
        stop time: 14.270174
        stop time: 14.142700
        stop time: 14.588219
        stop time: 14.547679
        stop time: 14.070393
        stop time: 14.063862
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-59d54698d4-l4dxv        197m         64Mi
        service1-569f565446-l7zwb        1m           47Mi
        service2-84cffc954f-fvd7s        479m         23Mi
        ubuntu-client-76886f6bbd-4g87t   21m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.169886, 14.385791, 14.270174, 14.1427, 14.588219, 14.547679, 14.070393, 14.063862]
    [exp] Throughput: 1412.9444646417005
[test.py] Finished running 9th optmization experiment: groundtruth->1504.2168415821716, slowdown->1412.9444646417005, predicted->1527.6227028564556, err->1.5560164350816041
[test.py] Baseline throughput:  1518.1523099588799
[test.py] Groundtruth:  [1541.0972147913778, 1515.5039846388515, 1514.4392411046524, 1508.014891797858, 1532.1299231619605, 1511.7622329839328, 1494.2860741951886, 1527.2452583783506, 1519.4652135818233, 1504.2168415821716]
[test.py] Slowdown:  [842.3247996004011, 877.9975728854594, 928.8401134046438, 988.1573601810912, 1025.6066612434724, 1087.9046764867605, 1152.6777597684686, 1233.8251594331518, 1303.946912018187, 1412.9444646417005]
[test.py] Predicted:  [1503.9052659994843, 1495.15872277935, 1518.3571899038473, 1547.737082148593, 1512.224058450787, 1520.7548487201075, 1519.6641116807236, 1531.1412551781161, 1511.3790500684174, 1527.6227028564556]
[test.py] Error percentage:  [-2.413342158750725, -1.342474982957558, 0.25870623877502286, 2.634071491388134, -1.2992282449580028, 0.5948432590768564, 1.6983386196116084, 0.25509961667206743, -0.5321716773195739, 1.5560164350816041]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 1...
[test.py] Actual processing time range: [0, 417, 834, 1251, 1668, 2085, 2502, 2919, 3336, 3753]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   402.91ms  430.57ms   2.48s    85.59%
        Req/Sec   189.16     77.44   404.00     69.91%
        Latency Distribution
        50%  228.49ms
        75%  583.57ms
        90%    1.02s
        99%    1.89s
        4104 requests in 3.02s, 637.24KB read
        Requests/sec:   1356.72
        Transfer/sec:    210.66KB
        [run.sh] Speed is 1356.72, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   408.90ms  528.28ms   3.54s    84.36%
        Req/Sec   196.00     95.27   808.00     74.50%
        Latency Distribution
        50%  151.64ms
        75%  593.05ms
        90%    1.21s
        99%    2.29s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 11.605919
        stop time: 13.072187
        stop time: 13.152064
        stop time: 13.487619
        stop time: 13.562946
        stop time: 12.911615
        stop time: 13.513041
        stop time: 13.143487
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-5stlp        2m           65Mi
        service1-7585bd9d88-p52vd        1m           42Mi
        service2-84cffc954f-5sxb8        1m           23Mi
        ubuntu-client-76886f6bbd-v5rcl   14m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.605919, 13.072187, 13.152064, 13.487619, 13.562946, 12.911615, 13.513041, 13.143487]
    [exp] Throughput: 1531.8498682197428
[test.py] Baseline throughput: 1531.8498682197428
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   326.39ms  157.80ms   1.00s    67.00%
        Req/Sec   188.06     75.19   360.00     68.81%
        Latency Distribution
        50%  302.41ms
        75%  425.33ms
        90%  549.99ms
        99%  790.21ms
        4162 requests in 3.02s, 646.25KB read
        Requests/sec:   1377.98
        Transfer/sec:    213.96KB
        [run.sh] Speed is 1377.98, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   362.14ms  378.62ms   2.64s    85.21%
        Req/Sec   192.30     82.03   510.00     67.61%
        Latency Distribution
        50%  196.94ms
        75%  510.96ms
        90%  896.02ms
        99%    1.73s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.370076
        stop time: 12.677117
        stop time: 13.375056
        stop time: 13.146507
        stop time: 13.669202
        stop time: 13.568702
        stop time: 13.583385
        stop time: 13.259449
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-mp5kj        636m         68Mi
        service1-7585bd9d88-fzx84        421m         37Mi
        service2-84cffc954f-qrcbs        23m          9Mi
        ubuntu-client-76886f6bbd-v9lv7   12m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.370076, 12.677117, 13.375056, 13.146507, 13.669202, 13.568702, 13.583385, 13.259449]
    [exp] Throughput: 1500.2415295097412
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   593.87ms  419.17ms   2.33s    68.19%
        Req/Sec   131.98     94.23   424.00     61.54%
        Latency Distribution
        50%  503.04ms
        75%  798.68ms
        90%    1.28s
        99%    2.00s
        2346 requests in 3.03s, 364.27KB read
        Requests/sec:    775.40
        Transfer/sec:    120.40KB
        [run.sh] Speed is 775.40, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74576c5f89-q8tnv        1094m        68Mi
        service1-57cdc6957f-44gh8        740m         44Mi
        service2-84cffc954f-rq2n4        867m         16Mi
        ubuntu-client-76886f6bbd-4q62h   30m          23Mi
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   642.23ms  610.39ms   4.19s    84.18%
        Req/Sec   124.64     82.92   440.00     62.50%
        Latency Distribution
        50%  435.42ms
        75%  904.22ms
        90%    1.47s
        99%    2.90s
        20000 requests in 38.00s, 3.03MB read
        Requests/sec:    526.31
        Transfer/sec:     81.72KB
        ------------------------------
        stop time: 23.257973
        stop time: 24.125139
        stop time: 23.359774
        stop time: 23.926130
        stop time: 23.990747
        stop time: 24.106609
        stop time: 24.092517
        stop time: 23.598395
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.257973, 24.125139, 23.359774, 23.92613, 23.990747, 24.106609, 24.092517, 23.598395]
    [exp] Throughput: 840.0833858367948
[test.py] Finished running 0th optmization experiment: groundtruth->1500.2415295097412, slowdown->840.0833858367948, predicted->1496.775141827864, err->-0.23105530767502425
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000417', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   380.97ms  315.48ms   1.83s    83.83%
        Req/Sec   178.66     84.56   393.00     69.41%
        Latency Distribution
        50%  290.70ms
        75%  507.28ms
        90%  784.98ms
        99%    1.48s
        3985 requests in 3.04s, 618.76KB read
        Requests/sec:   1312.24
        Transfer/sec:    203.76KB
        [run.sh] Speed is 1312.24, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   368.92ms  425.78ms   2.92s    84.65%
        Req/Sec   192.47     86.01   610.00     68.85%
        Latency Distribution
        50%  171.31ms
        75%  519.79ms
        90%    1.04s
        99%    1.83s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.269164
        stop time: 12.787019
        stop time: 12.956055
        stop time: 13.613011
        stop time: 13.604557
        stop time: 13.088502
        stop time: 13.630945
        stop time: 13.512665
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-7585bd9d88-g5q2q   2m           3Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.269164, 12.787019, 12.956055, 13.613011, 13.604557, 13.088502, 13.630945, 13.512665]
    [exp] Throughput: 1517.1353132416955
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   589.20ms  332.83ms   2.71s    75.38%
        Req/Sec   109.50     73.90   300.00     62.94%
        Latency Distribution
        50%  506.25ms
        75%  765.63ms
        90%    1.03s
        99%    1.65s
        2147 requests in 3.03s, 333.37KB read
        Requests/sec:    709.39
        Transfer/sec:    110.15KB
        [run.sh] Speed is 709.39, duration is 42
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f77f7cb57-hfmf4        337m         73Mi
        service1-9d4b979b7-t9d98         123m         40Mi
        service2-84cffc954f-28cp8        850m         12Mi
        ubuntu-client-76886f6bbd-8hc2c   19m          19Mi
        Running 42s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   610.62ms  611.27ms   5.21s    85.61%
        Req/Sec   123.78     86.61   626.00     69.52%
        Latency Distribution
        50%  397.52ms
        75%  778.54ms
        90%    1.54s
        99%    2.70s
        20000 requests in 42.00s, 3.03MB read
        Requests/sec:    476.19
        Transfer/sec:     73.94KB
        ------------------------------
        stop time: 22.909140
        stop time: 22.882399
        stop time: 22.487529
        stop time: 22.969429
        stop time: 23.203746
        stop time: 23.289411
        stop time: 22.460132
        stop time: 22.966586
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.90914, 22.882399, 22.487529, 22.969429, 23.203746, 23.289411, 22.460132, 22.966586]
    [exp] Throughput: 873.513250420766
[test.py] Finished running 1th optmization experiment: groundtruth->1517.1353132416955, slowdown->873.513250420766, predicted->1482.2010077262323, err->-2.3026492897867024
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   313.14ms  253.01ms   1.46s    79.03%
        Req/Sec   183.04     87.92   515.00     74.12%
        Latency Distribution
        50%  223.13ms
        75%  442.25ms
        90%  663.02ms
        99%    1.19s
        4178 requests in 3.03s, 648.73KB read
        Requests/sec:   1377.65
        Transfer/sec:    213.91KB
        [run.sh] Speed is 1377.65, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   396.95ms  492.62ms   3.76s    84.32%
        Req/Sec   194.36     97.89     1.32k    74.24%
        Latency Distribution
        50%  168.06ms
        75%  550.42ms
        90%    1.16s
        99%    2.05s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.058455
        stop time: 12.422824
        stop time: 12.563450
        stop time: 12.621434
        stop time: 13.290654
        stop time: 13.338610
        stop time: 13.367107
        stop time: 13.565395
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-flz5n        164m         64Mi
        service1-7585bd9d88-b5v85        302m         36Mi
        service2-84cffc954f-tvsm8        1m           12Mi
        ubuntu-client-76886f6bbd-knlq6   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.058455, 12.422824, 12.56345, 12.621434, 13.290654, 13.33861, 13.367107, 13.565395]
    [exp] Throughput: 1535.0971811020058
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   550.43ms  316.79ms   1.67s    67.90%
        Req/Sec   124.72     81.08   292.00     59.65%
        Latency Distribution
        50%  509.33ms
        75%  741.47ms
        90%    1.06s
        99%    1.30s
        2437 requests in 3.03s, 378.40KB read
        Requests/sec:    803.81
        Transfer/sec:    124.81KB
        [run.sh] Speed is 803.81, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-64686d547f-ph2ft        390m         69Mi
        service1-cdd6b68cc-lp4rt         120m         37Mi
        service2-84cffc954f-8mn7q        333m         11Mi
        ubuntu-client-76886f6bbd-qzsx6   20m          0Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   596.76ms  606.12ms   6.15s    87.77%
        Req/Sec   127.47     79.06   420.00     65.00%
        Latency Distribution
        50%  410.74ms
        75%  766.46ms
        90%    1.36s
        99%    2.83s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 21.134406
        stop time: 21.317893
        stop time: 21.134367
        stop time: 22.150976
        stop time: 21.990528
        stop time: 22.179660
        stop time: 21.831339
        stop time: 22.179397
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.134406, 21.317893, 21.134367, 22.150976, 21.990528, 22.17966, 21.831339, 22.179397]
    [exp] Throughput: 919.9707867876509
[test.py] Finished running 2th optmization experiment: groundtruth->1535.0971811020058, slowdown->919.9707867876509, predicted->1494.7995084277077, err->-2.6250893539762425
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001251', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-b6fl7 cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   354.38ms  220.29ms   1.63s    69.68%
        Req/Sec   173.84    116.71   494.00     66.23%
        Latency Distribution
        50%  293.62ms
        75%  474.07ms
        90%  680.56ms
        99%  938.90ms
        4058 requests in 3.03s, 630.10KB read
        Requests/sec:   1338.41
        Transfer/sec:    207.82KB
        [run.sh] Speed is 1338.41, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   391.98ms  484.16ms   3.77s    86.61%
        Req/Sec   194.38     89.65   555.00     70.49%
        Latency Distribution
        50%  184.26ms
        75%  485.39ms
        90%    1.05s
        99%    2.20s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 11.688176
        stop time: 12.805310
        stop time: 13.528901
        stop time: 13.503480
        stop time: 13.038163
        stop time: 13.431782
        stop time: 13.341749
        stop time: 13.259163
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-b6fl7        1861m        65Mi
        service1-7585bd9d88-nlvxm        1296m        37Mi
        service2-84cffc954f-87nqg        206m         10Mi
        ubuntu-client-76886f6bbd-l82rn   43m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [11.688176, 12.80531, 13.528901, 13.50348, 13.038163, 13.431782, 13.341749, 13.259163]
    [exp] Throughput: 1529.6846199504298
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b565f6b89-nx6ks cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   447.48ms  313.99ms   1.56s    69.54%
        Req/Sec   131.49     99.83   414.00     62.86%
        Latency Distribution
        50%  407.83ms
        75%  622.55ms
        90%  820.89ms
        99%    1.41s
        2557 requests in 3.03s, 397.03KB read
        Requests/sec:    845.09
        Transfer/sec:    131.22KB
        [run.sh] Speed is 845.09, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service2-84cffc954f-4cj5t   2m           3Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   589.77ms  686.30ms   5.31s    85.74%
        Req/Sec   128.23     75.25   710.00     67.90%
        Latency Distribution
        50%  313.54ms
        75%  796.96ms
        90%    1.55s
        99%    3.03s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 20.170575
        stop time: 20.536395
        stop time: 20.587293
        stop time: 20.071835
        stop time: 20.835106
        stop time: 21.172077
        stop time: 20.370088
        stop time: 20.890261
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [20.170575, 20.536395, 20.587293, 20.071835, 20.835106, 21.172077, 20.370088, 20.890261]
    [exp] Throughput: 971.8548998767748
[test.py] Finished running 3th optmization experiment: groundtruth->1529.6846199504298, slowdown->971.8548998767748, predicted->1508.1132249936209, err->-1.4101857778702107
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001668', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-r5dgv cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   381.56ms  340.96ms   1.68s    82.02%
        Req/Sec   180.22     91.04   494.00     72.40%
        Latency Distribution
        50%  253.09ms
        75%  504.27ms
        90%  943.56ms
        99%    1.44s
        4035 requests in 3.02s, 626.53KB read
        Requests/sec:   1334.94
        Transfer/sec:    207.28KB
        [run.sh] Speed is 1334.94, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   368.87ms  394.48ms   2.52s    86.56%
        Req/Sec   191.76     93.28   680.00     70.90%
        Latency Distribution
        50%  211.59ms
        75%  506.61ms
        90%  862.26ms
        99%    1.89s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.443810
        stop time: 12.466175
        stop time: 13.419582
        stop time: 13.536762
        stop time: 13.593102
        stop time: 13.356159
        stop time: 13.462031
        stop time: 13.269582
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-r5dgv        1200m        71Mi
        service1-7585bd9d88-h45p4        598m         38Mi
        service2-84cffc954f-k2bg7        147m         11Mi
        ubuntu-client-76886f6bbd-rs94k   36m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [12.44381, 12.466175, 13.419582, 13.536762, 13.593102, 13.356159, 13.462031, 13.269582]
    [exp] Throughput: 1515.9094267993062
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-557f58cfb4-qhddv cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   492.78ms  295.13ms   1.64s    73.71%
        Req/Sec   123.62     69.99   320.00     61.33%
        Latency Distribution
        50%  430.24ms
        75%  626.54ms
        90%  946.92ms
        99%    1.49s
        2739 requests in 3.02s, 425.29KB read
        Requests/sec:    907.46
        Transfer/sec:    140.90KB
        [run.sh] Speed is 907.46, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   557.23ms  642.69ms   4.18s    85.68%
        Req/Sec   136.24     84.50   710.00     69.99%
        Latency Distribution
        50%  304.05ms
        75%  732.62ms
        90%    1.47s
        99%    3.00s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.012972
        stop time: 18.600137
        stop time: 19.623643
        stop time: 19.372469
        stop time: 19.939399
        stop time: 19.345071
        stop time: 20.036693
        stop time: 19.818231
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
        > error: metrics not available yet
    [exp] Times: [19.012972, 18.600137, 19.623643, 19.372469, 19.939399, 19.345071, 20.036693, 19.818231]
    [exp] Throughput: 1027.2964546105275
[test.py] Finished running 4th optmization experiment: groundtruth->1515.9094267993062, slowdown->1027.2964546105275, predicted->1515.9006370714544, err->-0.0005798319936779907
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002085', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   356.26ms  313.83ms   1.69s    80.70%
        Req/Sec   197.93     86.21   434.00     69.34%
        Latency Distribution
        50%  209.63ms
        75%  556.29ms
        90%  760.01ms
        99%    1.40s
        4260 requests in 3.02s, 661.46KB read
        Requests/sec:   1409.62
        Transfer/sec:    218.88KB
        [run.sh] Speed is 1409.62, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   390.65ms  455.64ms   2.89s    84.79%
        Req/Sec   189.73     80.31   525.00     73.36%
        Latency Distribution
        50%  191.36ms
        75%  539.23ms
        90%    1.04s
        99%    2.06s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.327778
        stop time: 13.013831
        stop time: 13.459690
        stop time: 13.458510
        stop time: 13.385479
        stop time: 13.231427
        stop time: 13.400245
        stop time: 13.436038
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-8vv77        203m         64Mi
        service1-7585bd9d88-p9qk2        349m         47Mi
        service2-84cffc954f-rmtmv        269m         20Mi
        ubuntu-client-76886f6bbd-652nf   9m           13Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.327778, 13.013831, 13.45969, 13.45851, 13.385479, 13.231427, 13.400245, 13.436038]
    [exp] Throughput: 1499.3487485001592
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-5f696d68d6-w9wx8 cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   491.47ms  326.83ms   1.58s    68.80%
        Req/Sec   136.74     84.18   353.00     64.80%
        Latency Distribution
        50%  432.84ms
        75%  680.97ms
        90%  927.46ms
        99%    1.36s
        2785 requests in 3.03s, 432.44KB read
        Requests/sec:    919.03
        Transfer/sec:    142.70KB
        [run.sh] Speed is 919.03, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   499.32ms  567.60ms   4.49s    86.98%
        Req/Sec   145.35     84.42   560.00     65.26%
        Latency Distribution
        50%  283.43ms
        75%  634.79ms
        90%    1.23s
        99%    2.69s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 17.221264
        stop time: 17.166981
        stop time: 17.548020
        stop time: 18.236471
        stop time: 18.710668
        stop time: 18.392844
        stop time: 18.689822
        stop time: 18.639905
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f696d68d6-w9wx8        410m         64Mi
        service1-5b7949c96d-44b95        424m         39Mi
        service2-84cffc954f-fqnkc        832m         15Mi
        ubuntu-client-76886f6bbd-ksv2v   13m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [17.221264, 17.166981, 17.54802, 18.236471, 18.710668, 18.392844, 18.689822, 18.639905]
    [exp] Throughput: 1106.4549718640603
[test.py] Finished running 5th optmization experiment: groundtruth->1499.3487485001592, slowdown->1106.4549718640603, predicted->1557.2507419448164, err->3.861809569159819
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002502', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   313.97ms  236.57ms   1.70s    76.82%
        Req/Sec   183.35     77.84   414.00     73.66%
        Latency Distribution
        50%  243.16ms
        75%  421.21ms
        90%  657.33ms
        99%    1.05s
        4132 requests in 3.02s, 641.59KB read
        Requests/sec:   1367.93
        Transfer/sec:    212.40KB
        [run.sh] Speed is 1367.93, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   379.21ms  410.85ms   3.10s    85.84%
        Req/Sec   188.52     88.99   737.00     67.94%
        Latency Distribution
        50%  213.99ms
        75%  499.40ms
        90%  971.62ms
        99%    1.81s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.38
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.997115
        stop time: 13.415102
        stop time: 13.525348
        stop time: 13.431413
        stop time: 13.342593
        stop time: 13.121177
        stop time: 13.317396
        stop time: 13.614610
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pnrxx        621m         59Mi
        service1-7585bd9d88-pkxzj        410m         32Mi
        service2-84cffc954f-qrvjc        192m         12Mi
        ubuntu-client-76886f6bbd-79nvd   21m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.997115, 13.415102, 13.525348, 13.431413, 13.342593, 13.121177, 13.317396, 13.61461]
    [exp] Throughput: 1498.6219141197105
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   470.59ms  382.29ms   1.80s    68.77%
        Req/Sec   133.61     85.83   420.00     70.75%
        Latency Distribution
        50%  357.33ms
        75%  723.24ms
        90%    1.03s
        99%    1.67s
        3014 requests in 3.03s, 467.99KB read
        Requests/sec:    994.24
        Transfer/sec:    154.38KB
        [run.sh] Speed is 994.24, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   483.49ms  533.84ms   4.97s    87.01%
        Req/Sec   148.87     78.04   464.00     66.10%
        Latency Distribution
        50%  281.32ms
        75%  612.24ms
        90%    1.22s
        99%    2.48s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 16.688017
        stop time: 17.282744
        stop time: 17.592638
        stop time: 17.061092
        stop time: 17.712897
        stop time: 17.440666
        stop time: 17.741025
        stop time: 17.372443
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-559cb467b4-rzc6p        1190m        74Mi
        service1-cb57b799d-mhvxh         925m         40Mi
        service2-84cffc954f-4htlt        1284m        15Mi
        ubuntu-client-76886f6bbd-wszlp   35m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.688017, 17.282744, 17.592638, 17.061092, 17.712897, 17.440666, 17.741025, 17.372443]
    [exp] Throughput: 1151.978160337245
[test.py] Finished running 6th optmization experiment: groundtruth->1498.6219141197105, slowdown->1151.978160337245, predicted->1518.4483598774239, err->1.3229785025103822
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002919', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   345.56ms  252.28ms   1.56s    72.34%
        Req/Sec   176.80    105.60   460.00     64.29%
        Latency Distribution
        50%  269.86ms
        75%  485.42ms
        90%  721.09ms
        99%    1.09s
        4082 requests in 3.03s, 633.83KB read
        Requests/sec:   1349.04
        Transfer/sec:    209.47KB
        [run.sh] Speed is 1349.04, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   388.14ms  452.16ms   3.50s    86.44%
        Req/Sec   191.91     85.43   690.00     71.23%
        Latency Distribution
        50%  200.05ms
        75%  505.92ms
        90%    1.03s
        99%    2.20s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.434856
        stop time: 13.147403
        stop time: 12.526869
        stop time: 13.560685
        stop time: 13.498838
        stop time: 13.624777
        stop time: 13.343011
        stop time: 13.412132
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-2j556        25m          63Mi
        service1-7585bd9d88-ht6q5        2m           33Mi
        ubuntu-client-76886f6bbd-lg86g   4m           11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.434856, 13.147403, 12.526869, 13.560685, 13.498838, 13.624777, 13.343011, 13.412132]
    [exp] Throughput: 1515.889779313071
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   402.62ms  402.83ms   2.95s    84.45%
        Req/Sec   150.29     81.10   340.00     65.32%
        Latency Distribution
        50%  242.53ms
        75%  579.34ms
        90%    1.01s
        99%    1.67s
        3362 requests in 3.02s, 522.03KB read
        Requests/sec:   1113.50
        Transfer/sec:    172.90KB
        [run.sh] Speed is 1113.50, duration is 26
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d26s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 26s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   444.05ms  428.77ms   3.74s    84.86%
        Req/Sec   153.99     80.49   595.00     66.67%
        Latency Distribution
        50%  281.83ms
        75%  565.42ms
        90%    1.06s
        99%    1.96s
        20000 requests in 26.00s, 3.03MB read
        Requests/sec:    769.23
        Transfer/sec:    119.44KB
        ------------------------------
        stop time: 15.876831
        stop time: 16.853458
        stop time: 16.727510
        stop time: 16.035293
        stop time: 16.690922
        stop time: 16.891801
        stop time: 16.106760
        stop time: 16.151386
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-854764b98f-m4kbd        1604m        67Mi
        service1-7cf689c479-xcnjh        1038m        43Mi
        service2-84cffc954f-jh2dg        1324m        17Mi
        ubuntu-client-76886f6bbd-jj2rw   43m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.876831, 16.853458, 16.72751, 16.035293, 16.690922, 16.891801, 16.10676, 16.151386]
    [exp] Throughput: 1218.2682893421604
[test.py] Finished running 7th optmization experiment: groundtruth->1515.889779313071, slowdown->1218.2682893421604, predicted->1507.2561051667599, err->-0.5695449803892334
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003336', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   359.42ms  237.88ms   1.52s    71.60%
        Req/Sec   197.38     86.12   440.00     72.60%
        Latency Distribution
        50%  297.51ms
        75%  495.47ms
        90%  727.59ms
        99%    1.00s
        4159 requests in 3.02s, 645.78KB read
        Requests/sec:   1375.93
        Transfer/sec:    213.65KB
        [run.sh] Speed is 1375.93, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   413.75ms  508.84ms   3.29s    85.81%
        Req/Sec   190.99     83.94   616.00     72.13%
        Latency Distribution
        50%  186.38ms
        75%  556.86ms
        90%    1.18s
        99%    2.29s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.806933
        stop time: 12.793397
        stop time: 12.569896
        stop time: 13.362977
        stop time: 13.554569
        stop time: 13.601402
        stop time: 13.681282
        stop time: 13.510774
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [12.806933, 12.793397, 12.569896, 13.362977, 13.554569, 13.601402, 13.681282, 13.510774]
    [exp] Throughput: 1511.1271374539187
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   403.20ms  320.24ms   2.07s    71.67%
        Req/Sec   161.00     98.59   494.00     67.65%
        Latency Distribution
        50%  335.22ms
        75%  568.25ms
        90%  830.36ms
        99%    1.47s
        3456 requests in 3.03s, 536.62KB read
        Requests/sec:   1141.63
        Transfer/sec:    177.27KB
        [run.sh] Speed is 1141.63, duration is 26
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d26s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 26s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   420.90ms  444.01ms   5.24s    83.95%
        Req/Sec   166.09     68.15   400.00     70.44%
        Latency Distribution
        50%  233.15ms
        75%  557.96ms
        90%    1.04s
        99%    1.94s
        20000 requests in 26.00s, 3.03MB read
        Requests/sec:    769.23
        Transfer/sec:    119.44KB
        ------------------------------
        stop time: 15.255087
        stop time: 15.520589
        stop time: 15.383085
        stop time: 15.529968
        stop time: 15.421247
        stop time: 15.393182
        stop time: 15.481697
        stop time: 15.356995
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-768756f486-v2rm5        1564m        68Mi
        service1-698c8454b8-cf9tr        848m         43Mi
        service2-84cffc954f-l7d97        734m         20Mi
        ubuntu-client-76886f6bbd-ns4pq   36m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.255087, 15.520589, 15.383085, 15.529968, 15.421247, 15.393182, 15.481697, 15.356995]
    [exp] Throughput: 1297.2077198452919
[test.py] Finished running 8th optmization experiment: groundtruth->1511.1271374539187, slowdown->1297.2077198452919, predicted->1502.3326061104563, err->-0.581984872449601
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003753', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   427.65ms  422.17ms   2.91s    87.02%
        Req/Sec   191.14     71.46   460.00     77.78%
        Latency Distribution
        50%  244.57ms
        75%  572.09ms
        90%  990.26ms
        99%    1.94s
        4137 requests in 3.02s, 642.37KB read
        Requests/sec:   1368.00
        Transfer/sec:    212.41KB
        [run.sh] Speed is 1368.00, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   387.55ms  434.02ms   3.15s    85.66%
        Req/Sec   194.52     86.10   520.00     71.91%
        Latency Distribution
        50%  194.49ms
        75%  551.66ms
        90%    1.02s
        99%    1.92s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.805977
        stop time: 13.512485
        stop time: 13.024649
        stop time: 13.525248
        stop time: 13.158051
        stop time: 13.547597
        stop time: 13.373080
        stop time: 13.441115
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [12.805977, 13.512485, 13.024649, 13.525248, 13.158051, 13.547597, 13.37308, 13.441115]
    [exp] Throughput: 1503.926159030303
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   360.00ms  243.55ms   1.67s    78.63%
        Req/Sec   171.36     84.30   410.00     66.67%
        Latency Distribution
        50%  285.29ms
        75%  482.39ms
        90%  723.22ms
        99%    1.13s
        3948 requests in 3.02s, 613.02KB read
        Requests/sec:   1305.83
        Transfer/sec:    202.76KB
        [run.sh] Speed is 1305.83, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   451.27ms  567.28ms   4.41s    86.67%
        Req/Sec   178.19     76.97   500.00     69.25%
        Latency Distribution
        50%  199.19ms
        75%  584.24ms
        90%    1.28s
        99%    2.51s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.909689
        stop time: 13.983394
        stop time: 14.428916
        stop time: 14.410063
        stop time: 14.110369
        stop time: 14.175594
        stop time: 14.333685
        stop time: 13.975837
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-59d54698d4-5x9fj        603m         64Mi
        service1-569f565446-qxj5z        208m         32Mi
        service2-84cffc954f-h7khk        155m         12Mi
        ubuntu-client-76886f6bbd-whz5v   8m           11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.909689, 13.983394, 14.428916, 14.410063, 14.110369, 14.175594, 14.333685, 13.975837]
    [exp] Throughput: 1411.8367884553259
[test.py] Finished running 9th optmization experiment: groundtruth->1503.926159030303, slowdown->1411.8367884553259, predicted->1526.3280086331401, err->1.4895578129501545
[test.py] Baseline throughput:  1531.8498682197428
[test.py] Groundtruth:  [1500.2415295097412, 1517.1353132416955, 1535.0971811020058, 1529.6846199504298, 1515.9094267993062, 1499.3487485001592, 1498.6219141197105, 1515.889779313071, 1511.1271374539187, 1503.926159030303]
[test.py] Slowdown:  [840.0833858367948, 873.513250420766, 919.9707867876509, 971.8548998767748, 1027.2964546105275, 1106.4549718640603, 1151.978160337245, 1218.2682893421604, 1297.2077198452919, 1411.8367884553259]
[test.py] Predicted:  [1496.775141827864, 1482.2010077262323, 1494.7995084277077, 1508.1132249936209, 1515.9006370714544, 1557.2507419448164, 1518.4483598774239, 1507.2561051667599, 1502.3326061104563, 1526.3280086331401]
[test.py] Error percentage:  [-0.23105530767502425, -2.3026492897867024, -2.6250893539762425, -1.4101857778702107, -0.0005798319936779907, 3.861809569159819, 1.3229785025103822, -0.5695449803892334, -0.581984872449601, 1.4895578129501545]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 2...
[test.py] Actual processing time range: [0, 417, 834, 1251, 1668, 2085, 2502, 2919, 3336, 3753]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   335.52ms  345.60ms   2.19s    84.18%
        Req/Sec   170.14     65.82   343.00     69.58%
        Latency Distribution
        50%  183.01ms
        75%  488.64ms
        90%  899.04ms
        99%    1.36s
        4071 requests in 3.02s, 632.12KB read
        Requests/sec:   1349.61
        Transfer/sec:    209.56KB
        [run.sh] Speed is 1349.61, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   378.54ms  399.08ms   2.66s    88.11%
        Req/Sec   191.03     85.37   595.00     69.99%
        Latency Distribution
        50%  232.18ms
        75%  468.96ms
        90%  888.71ms
        99%    1.90s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.627204
        stop time: 12.808483
        stop time: 13.052532
        stop time: 13.307492
        stop time: 13.489046
        stop time: 13.630777
        stop time: 13.594912
        stop time: 13.619221
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-qg5qp        643m         63Mi
        service1-7585bd9d88-8dp6j        629m         35Mi
        service2-84cffc954f-gqkjd        1m           17Mi
        ubuntu-client-76886f6bbd-sp594   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.627204, 12.808483, 13.052532, 13.307492, 13.489046, 13.630777, 13.594912, 13.619221]
    [exp] Throughput: 1507.589767524664
[test.py] Baseline throughput: 1507.589767524664
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   353.34ms  238.61ms   1.23s    71.70%
        Req/Sec   185.29     96.04   505.00     72.43%
        Latency Distribution
        50%  272.30ms
        75%  490.23ms
        90%  733.34ms
        99%  957.93ms
        4007 requests in 3.03s, 622.18KB read
        Requests/sec:   1322.95
        Transfer/sec:    205.42KB
        [run.sh] Speed is 1322.95, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   377.04ms  403.54ms   2.73s    86.19%
        Req/Sec   191.21     94.40   575.00     71.01%
        Latency Distribution
        50%  214.48ms
        75%  490.92ms
        90%  917.47ms
        99%    1.87s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.293927
        stop time: 13.453887
        stop time: 12.976904
        stop time: 13.123617
        stop time: 13.212026
        stop time: 13.396425
        stop time: 13.498018
        stop time: 13.610788
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pknk7        122m         57Mi
        service1-7585bd9d88-96xml        2m           42Mi
        service2-84cffc954f-hmvm2        25m          13Mi
        ubuntu-client-76886f6bbd-pm422   21m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.293927, 13.453887, 12.976904, 13.123617, 13.212026, 13.396425, 13.498018, 13.610788]
    [exp] Throughput: 1501.4227106250205
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   612.94ms  503.79ms   1.99s    65.84%
        Req/Sec   145.05     89.97   373.00     68.47%
        Latency Distribution
        50%  499.20ms
        75%  961.41ms
        90%    1.22s
        99%    1.97s
        2322 requests in 3.02s, 360.54KB read
        Requests/sec:    767.68
        Transfer/sec:    119.20KB
        [run.sh] Speed is 767.68, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74576c5f89-jcgsc        1074m        68Mi
        service1-57cdc6957f-jrvwb        720m         50Mi
        service2-84cffc954f-4x2nb        923m         20Mi
        ubuntu-client-76886f6bbd-b42m9   31m          23Mi
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   638.72ms  637.64ms   4.69s    84.18%
        Req/Sec   119.88     77.51   490.00     65.66%
        Latency Distribution
        50%  410.12ms
        75%  891.02ms
        90%    1.60s
        99%    2.77s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 23.888912
        stop time: 23.774254
        stop time: 23.787949
        stop time: 23.770539
        stop time: 23.381714
        stop time: 24.219205
        stop time: 23.891518
        stop time: 24.205073
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.888912, 23.774254, 23.787949, 23.770539, 23.381714, 24.219205, 23.891518, 24.205073]
    [exp] Throughput: 838.0510193308829
[test.py] Finished running 0th optmization experiment: groundtruth->1501.4227106250205, slowdown->838.0510193308829, predicted->1490.335676128597, err->-0.738435246647369
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000417', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-whsrg cannot connect to service2
        [run.sh] service0-7b65886d58-whsrg cannot connect to service2
        [run.sh] service0-7b65886d58-whsrg cannot connect to service2
        [run.sh] service1-7585bd9d88-7vg92 cannot connect to service2
        [run.sh] service1-7585bd9d88-7vg92 cannot connect to service2
        [run.sh] ubuntu-client-76886f6bbd-chf76 cannot connect to service2
        [run.sh] ubuntu-client-76886f6bbd-chf76 cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   359.31ms  263.86ms   1.56s    80.41%
        Req/Sec   194.05     85.32   490.00     69.44%
        Latency Distribution
        50%  278.89ms
        75%  480.47ms
        90%  734.17ms
        99%    1.30s
        4256 requests in 3.02s, 660.84KB read
        Requests/sec:   1407.47
        Transfer/sec:    218.54KB
        [run.sh] Speed is 1407.47, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   393.25ms  456.42ms   3.53s    86.48%
        Req/Sec   192.23     80.97   646.00     72.72%
        Latency Distribution
        50%  201.49ms
        75%  497.93ms
        90%    1.03s
        99%    2.17s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.38
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.068421
        stop time: 12.807398
        stop time: 12.655335
        stop time: 13.467926
        stop time: 13.550666
        stop time: 13.312675
        stop time: 13.536453
        stop time: 13.573723
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-whsrg        35m          67Mi
        service1-7585bd9d88-7vg92        226m         33Mi
        service2-84cffc954f-htws4        1m           8Mi
        ubuntu-client-76886f6bbd-chf76   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > command terminated with exit code 1
        > curl: (28) Connection timed out after 1002 milliseconds
        > command terminated with exit code 28
        > curl: (28) Connection timed out after 1002 milliseconds
        > command terminated with exit code 28
    [exp] Times: [13.068421, 12.807398, 12.655335, 13.467926, 13.550666, 13.312675, 13.536453, 13.573723]
    [exp] Throughput: 1509.8242803278663
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-6f77f7cb57-5sfwv cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   576.94ms  401.79ms   2.23s    66.33%
        Req/Sec   119.40     78.52   300.00     58.08%
        Latency Distribution
        50%  485.46ms
        75%  820.37ms
        90%    1.13s
        99%    1.68s
        2330 requests in 3.02s, 361.79KB read
        Requests/sec:    771.37
        Transfer/sec:    119.77KB
        [run.sh] Speed is 771.37, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f77f7cb57-5sfwv        403m         69Mi
        service1-9d4b979b7-ntqmh         133m         36Mi
        service2-84cffc954f-chqkj        309m         9Mi
        ubuntu-client-76886f6bbd-d2m89   17m          0Mi
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   602.20ms  549.73ms   3.40s    80.69%
        Req/Sec   118.87     76.65   570.00     62.75%
        Latency Distribution
        50%  421.40ms
        75%  820.92ms
        90%    1.44s
        99%    2.42s
        20000 requests in 38.00s, 3.03MB read
        Requests/sec:    526.31
        Transfer/sec:     81.72KB
        ------------------------------
        stop time: 22.255918
        stop time: 22.262983
        stop time: 22.988636
        stop time: 23.175121
        stop time: 23.142762
        stop time: 23.281151
        stop time: 23.167085
        stop time: 23.160972
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [22.255918, 22.262983, 22.988636, 23.175121, 23.142762, 23.281151, 23.167085, 23.160972]
    [exp] Throughput: 872.2453429022135
[test.py] Finished running 1th optmization experiment: groundtruth->1509.8242803278663, slowdown->872.2453429022135, predicted->1478.554108630183, err->-2.071113314649623
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   370.99ms  343.70ms   1.82s    78.58%
        Req/Sec   192.31     92.86   474.00     70.83%
        Latency Distribution
        50%  221.91ms
        75%  543.16ms
        90%  856.12ms
        99%    1.48s
        4178 requests in 3.03s, 648.73KB read
        Requests/sec:   1380.72
        Transfer/sec:    214.39KB
        [run.sh] Speed is 1380.72, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   377.35ms  409.54ms   3.44s    85.72%
        Req/Sec   189.31     82.65   616.00     68.04%
        Latency Distribution
        50%  212.83ms
        75%  512.37ms
        90%  944.66ms
        99%    1.95s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.107246
        stop time: 13.463881
        stop time: 12.670320
        stop time: 13.492758
        stop time: 13.444756
        stop time: 13.162924
        stop time: 13.053350
        stop time: 13.582158
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-72v2k        1679m        66Mi
        service1-7585bd9d88-mcrkx        1291m        42Mi
        service2-84cffc954f-w4qfq        401m         14Mi
        ubuntu-client-76886f6bbd-rtwv5   51m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.107246, 13.463881, 12.67032, 13.492758, 13.444756, 13.162924, 13.05335, 13.582158]
    [exp] Throughput: 1509.7559533286499
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   534.27ms  374.01ms   1.98s    69.21%
        Req/Sec   122.87     80.35   333.00     62.35%
        Latency Distribution
        50%  466.60ms
        75%  733.61ms
        90%    1.04s
        99%    1.88s
        2520 requests in 3.03s, 391.29KB read
        Requests/sec:    832.43
        Transfer/sec:    129.25KB
        [run.sh] Speed is 832.43, duration is 36
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d36s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 36s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   614.77ms  682.90ms   5.25s    87.20%
        Req/Sec   126.55     81.33   535.00     65.39%
        Latency Distribution
        50%  380.48ms
        75%  765.51ms
        90%    1.50s
        99%    3.20s
        20000 requests in 36.00s, 3.03MB read
        Requests/sec:    555.55
        Transfer/sec:     86.26KB
        ------------------------------
        stop time: 20.504650
        stop time: 20.674864
        stop time: 20.674017
        stop time: 21.708804
        stop time: 21.830983
        stop time: 21.770761
        stop time: 21.731054
        stop time: 21.839451
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [20.50465, 20.674864, 20.674017, 21.708804, 21.830983, 21.770761, 21.731054, 21.839451]
    [exp] Throughput: 937.1270673550241
[test.py] Finished running 2th optmization experiment: groundtruth->1509.7559533286499, slowdown->937.1270673550241, predicted->1540.6275422761685, err->2.0448065715160224
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001251', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   396.49ms  375.48ms   2.09s    85.75%
        Req/Sec   189.25     79.70   440.00     72.22%
        Latency Distribution
        50%  243.06ms
        75%  572.80ms
        90%  894.46ms
        99%    1.77s
        4130 requests in 3.03s, 641.28KB read
        Requests/sec:   1363.28
        Transfer/sec:    211.68KB
        [run.sh] Speed is 1363.28, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   358.63ms  388.49ms   2.60s    85.26%
        Req/Sec   195.14    100.11   610.00     70.20%
        Latency Distribution
        50%  186.13ms
        75%  512.27ms
        90%  917.41ms
        99%    1.65s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.660980
        stop time: 12.756878
        stop time: 13.136813
        stop time: 13.141835
        stop time: 13.668321
        stop time: 13.333853
        stop time: 13.292704
        stop time: 13.600284
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-lffrp        1661m        68Mi
        service1-7585bd9d88-dxpx9        881m         41Mi
        service2-84cffc954f-5g9gw        217m         11Mi
        ubuntu-client-76886f6bbd-mxrsz   25m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.66098, 12.756878, 13.136813, 13.141835, 13.668321, 13.333853, 13.292704, 13.600284]
    [exp] Throughput: 1515.2710723349874
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   445.19ms  310.75ms   1.48s    69.88%
        Req/Sec   141.45     87.42   343.00     55.15%
        Latency Distribution
        50%  428.38ms
        75%  616.53ms
        90%  876.73ms
        99%    1.25s
        2652 requests in 3.02s, 411.79KB read
        Requests/sec:    878.16
        Transfer/sec:    136.36KB
        [run.sh] Speed is 878.16, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   569.31ms  578.43ms   5.04s    85.58%
        Req/Sec   129.17     73.82   380.00     65.89%
        Latency Distribution
        50%  355.58ms
        75%  748.70ms
        90%    1.37s
        99%    2.66s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 20.982764
        stop time: 20.442815
        stop time: 20.608227
        stop time: 20.639564
        stop time: 20.728034
        stop time: 20.952925
        stop time: 20.633601
        stop time: 20.692051
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [20.982764, 20.442815, 20.608227, 20.639564, 20.728034, 20.952925, 20.633601, 20.692051]
    [exp] Throughput: 965.7171556532228
[test.py] Finished running 3th optmization experiment: groundtruth->1515.2710723349874, slowdown->965.7171556532228, predicted->1493.3845723536003, err->-1.4443950248228914
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001668', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-xr7cv cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   349.26ms  274.09ms   1.61s    74.36%
        Req/Sec   195.75     86.08   505.00     74.07%
        Latency Distribution
        50%  258.14ms
        75%  491.34ms
        90%  763.18ms
        99%    1.11s
        4279 requests in 3.02s, 664.42KB read
        Requests/sec:   1417.26
        Transfer/sec:    220.06KB
        [run.sh] Speed is 1417.26, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   417.86ms  512.14ms   2.95s    85.51%
        Req/Sec   189.97     86.51     1.07k    73.83%
        Latency Distribution
        50%  182.11ms
        75%  567.75ms
        90%    1.20s
        99%    2.14s
        20001 requests in 21.00s, 3.03MB read
        Requests/sec:    952.42
        Transfer/sec:    147.89KB
        ------------------------------
        stop time: 12.832664
        stop time: 12.881743
        stop time: 12.745920
        stop time: 13.122012
        stop time: 13.169483
        stop time: 13.628949
        stop time: 13.568246
        stop time: 13.226012
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-xr7cv        701m         65Mi
        service1-7585bd9d88-vkfmh        219m         38Mi
        service2-84cffc954f-g7cdh        78m          15Mi
        ubuntu-client-76886f6bbd-4jdgh   11m          16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [12.832664, 12.881743, 12.74592, 13.122012, 13.169483, 13.628949, 13.568246, 13.226012]
    [exp] Throughput: 1521.273647568949
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   475.95ms  311.31ms   1.66s    71.47%
        Req/Sec   146.99    100.18   440.00     63.95%
        Latency Distribution
        50%  414.35ms
        75%  650.60ms
        90%  867.27ms
        99%    1.33s
        2880 requests in 3.02s, 447.19KB read
        Requests/sec:    952.30
        Transfer/sec:    147.87KB
        [run.sh] Speed is 952.30, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   513.57ms  474.04ms   4.07s    80.16%
        Req/Sec   132.01     84.85   610.00     68.76%
        Latency Distribution
        50%  335.80ms
        75%  735.02ms
        90%    1.21s
        99%    2.10s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 19.878352
        stop time: 19.249087
        stop time: 18.869646
        stop time: 19.874308
        stop time: 19.963472
        stop time: 19.863334
        stop time: 19.678248
        stop time: 19.540169
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-557f58cfb4-fghjs        2m           65Mi
        service1-bd8cf8ccd-lhb9j         1m           46Mi
        service2-84cffc954f-f6k6d        349m         19Mi
        ubuntu-client-76886f6bbd-6z9zh   13m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.878352, 19.249087, 18.869646, 19.874308, 19.963472, 19.863334, 19.678248, 19.540169]
    [exp] Throughput: 1019.6498247196462
[test.py] Finished running 4th optmization experiment: groundtruth->1521.273647568949, slowdown->1019.6498247196462, predicted->1499.3091558237256, err->-1.4438225351713267
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002085', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   338.08ms  298.77ms   1.74s    82.72%
        Req/Sec   178.59     83.29   410.00     67.89%
        Latency Distribution
        50%  213.34ms
        75%  477.67ms
        90%  795.28ms
        99%    1.30s
        3977 requests in 3.02s, 617.52KB read
        Requests/sec:   1314.76
        Transfer/sec:    204.15KB
        [run.sh] Speed is 1314.76, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   380.45ms  449.53ms   3.50s    85.43%
        Req/Sec   192.12     80.66   616.00     71.86%
        Latency Distribution
        50%  174.80ms
        75%  528.82ms
        90%    1.04s
        99%    1.94s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.874427
        stop time: 12.331755
        stop time: 13.139611
        stop time: 13.402852
        stop time: 13.570658
        stop time: 13.056596
        stop time: 13.566344
        stop time: 13.488709
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-l5zs8        7m           60Mi
        service1-7585bd9d88-s2lrc        241m         34Mi
        service2-84cffc954f-gcnnl        261m         10Mi
        ubuntu-client-76886f6bbd-m2hzt   21m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.874427, 12.331755, 13.139611, 13.402852, 13.570658, 13.056596, 13.566344, 13.488709]
    [exp] Throughput: 1517.5809092570844
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   517.22ms  393.43ms   2.10s    69.00%
        Req/Sec   153.33     88.19   530.00     68.10%
        Latency Distribution
        50%  479.31ms
        75%  710.05ms
        90%    1.04s
        99%    1.64s
        2848 requests in 3.03s, 442.22KB read
        Requests/sec:    939.11
        Transfer/sec:    145.82KB
        [run.sh] Speed is 939.11, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   512.39ms  555.60ms   3.75s    84.64%
        Req/Sec   141.17     82.93   660.00     68.04%
        Latency Distribution
        50%  286.70ms
        75%  718.05ms
        90%    1.30s
        99%    2.51s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.253456
        stop time: 17.324459
        stop time: 18.701982
        stop time: 18.315012
        stop time: 18.689884
        stop time: 18.583059
        stop time: 18.654478
        stop time: 18.826146
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f696d68d6-t66kx        257m         69Mi
        service1-5b7949c96d-lgsrg        343m         50Mi
        service2-84cffc954f-6b8th        774m         22Mi
        ubuntu-client-76886f6bbd-dlbjd   30m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.253456, 17.324459, 18.701982, 18.315012, 18.689884, 18.583059, 18.654478, 18.826146]
    [exp] Throughput: 1085.8612477267834
[test.py] Finished running 5th optmization experiment: groundtruth->1517.5809092570844, slowdown->1085.8612477267834, predicted->1516.7648588637026, err->-0.05377310615888795
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002502', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   305.02ms  238.75ms   1.56s    75.13%
        Req/Sec   182.30     94.53   470.00     74.55%
        Latency Distribution
        50%  230.21ms
        75%  432.67ms
        90%  664.99ms
        99%    1.11s
        4090 requests in 3.02s, 635.07KB read
        Requests/sec:   1352.98
        Transfer/sec:    210.08KB
        [run.sh] Speed is 1352.98, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   371.49ms  385.94ms   3.08s    85.53%
        Req/Sec   188.81     83.50   520.00     71.93%
        Latency Distribution
        50%  203.08ms
        75%  498.51ms
        90%  931.27ms
        99%    1.72s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.101132
        stop time: 13.302921
        stop time: 13.394327
        stop time: 13.462863
        stop time: 13.096651
        stop time: 13.358486
        stop time: 13.393232
        stop time: 13.513422
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-rwzlv        629m         67Mi
        service1-7585bd9d88-9m7d7        414m         38Mi
        service2-84cffc954f-shzkz        213m         12Mi
        ubuntu-client-76886f6bbd-s4h4k   10m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.101132, 13.302921, 13.394327, 13.462863, 13.096651, 13.358486, 13.393232, 13.513422]
    [exp] Throughput: 1500.6138354682348
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   459.58ms  291.00ms   1.98s    74.63%
        Req/Sec   147.25    100.91   440.00     59.90%
        Latency Distribution
        50%  383.92ms
        75%  616.09ms
        90%  880.12ms
        99%    1.35s
        3229 requests in 3.04s, 501.38KB read
        Requests/sec:   1063.15
        Transfer/sec:    165.08KB
        [run.sh] Speed is 1063.15, duration is 28
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d28s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 28s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   464.83ms  413.31ms   3.45s    82.30%
        Req/Sec   150.73     84.14   480.00     65.51%
        Latency Distribution
        50%  318.98ms
        75%  623.55ms
        90%    1.01s
        99%    1.96s
        20000 requests in 28.00s, 3.03MB read
        Requests/sec:    714.28
        Transfer/sec:    110.91KB
        ------------------------------
        stop time: 17.232962
        stop time: 16.946952
        stop time: 17.700249
        stop time: 17.578450
        stop time: 17.912547
        stop time: 17.878519
        stop time: 17.616142
        stop time: 17.030990
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-559cb467b4-vppk4        1018m        69Mi
        service1-cb57b799d-dgr97         823m         44Mi
        service2-84cffc954f-sq68x        1259m        16Mi
        ubuntu-client-76886f6bbd-xm4fv   38m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.232962, 16.946952, 17.700249, 17.57845, 17.912547, 17.878519, 17.616142, 17.03099]
    [exp] Throughput: 1143.7001233716474
[test.py] Finished running 6th optmization experiment: groundtruth->1500.6138354682348, slowdown->1143.7001233716474, predicted->1504.098513338689, err->0.23221682941279737
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002919', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   376.73ms  272.62ms   1.60s    72.87%
        Req/Sec   190.57    103.01   444.00     62.87%
        Latency Distribution
        50%  309.91ms
        75%  520.66ms
        90%  796.74ms
        99%    1.23s
        3983 requests in 3.03s, 618.45KB read
        Requests/sec:   1315.62
        Transfer/sec:    204.28KB
        [run.sh] Speed is 1315.62, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   396.48ms  505.37ms   3.95s    84.97%
        Req/Sec   194.39     91.41     0.85k    70.25%
        Latency Distribution
        50%  166.54ms
        75%  513.34ms
        90%    1.14s
        99%    2.18s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.597111
        stop time: 12.776891
        stop time: 12.377326
        stop time: 13.152284
        stop time: 13.464315
        stop time: 13.521759
        stop time: 13.368220
        stop time: 13.033441
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-7585bd9d88-8l5q5   2m           26Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.597111, 12.776891, 12.377326, 13.152284, 13.464315, 13.521759, 13.36822, 13.033441]
    [exp] Throughput: 1534.1637115876927
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   392.77ms  357.68ms   2.10s    81.37%
        Req/Sec   148.56     72.36   343.00     71.05%
        Latency Distribution
        50%  284.75ms
        75%  566.12ms
        90%  917.31ms
        99%    1.58s
        3498 requests in 3.03s, 543.15KB read
        Requests/sec:   1153.73
        Transfer/sec:    179.14KB
        [run.sh] Speed is 1153.73, duration is 26
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d26s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 26s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   462.82ms  513.60ms   3.40s    85.00%
        Req/Sec   156.04     78.40   500.00     67.38%
        Latency Distribution
        50%  241.21ms
        75%  642.79ms
        90%    1.28s
        99%    2.17s
        20000 requests in 26.00s, 3.03MB read
        Requests/sec:    769.23
        Transfer/sec:    119.44KB
        ------------------------------
        stop time: 15.411245
        stop time: 16.204609
        stop time: 16.227970
        stop time: 15.965459
        stop time: 16.562555
        stop time: 16.086089
        stop time: 15.897172
        stop time: 16.608300
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-854764b98f-vkjnr        982m         69Mi
        service1-7cf689c479-k68wr        1044m        41Mi
        service2-84cffc954f-nms2g        1315m        13Mi
        ubuntu-client-76886f6bbd-q7c8s   41m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.411245, 16.204609, 16.22797, 15.965459, 16.562555, 16.086089, 15.897172, 16.6083]
    [exp] Throughput: 1240.6620889388937
[test.py] Finished running 7th optmization experiment: groundtruth->1534.1637115876927, slowdown->1240.6620889388937, predicted->1541.6842663576006, err->0.49020549196310653
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003336', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   348.77ms  281.22ms   1.95s    78.10%
        Req/Sec   197.59    104.31   525.00     72.60%
        Latency Distribution
        50%  285.01ms
        75%  455.43ms
        90%  719.98ms
        99%    1.33s
        4258 requests in 3.03s, 661.15KB read
        Requests/sec:   1406.81
        Transfer/sec:    218.44KB
        [run.sh] Speed is 1406.81, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   376.25ms  456.09ms   3.37s    85.82%
        Req/Sec   198.18     90.46   686.00     71.79%
        Latency Distribution
        50%  176.17ms
        75%  519.92ms
        90%  983.05ms
        99%    2.08s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.612390
        stop time: 11.512409
        stop time: 12.348342
        stop time: 13.517483
        stop time: 13.393035
        stop time: 13.606847
        stop time: 13.282484
        stop time: 13.656264
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [12.61239, 11.512409, 12.348342, 13.517483, 13.393035, 13.606847, 13.282484, 13.656264]
    [exp] Throughput: 1539.5087893154705
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   409.68ms  271.01ms   1.48s    78.15%
        Req/Sec   154.45     86.27   390.00     65.79%
        Latency Distribution
        50%  325.63ms
        75%  524.06ms
        90%  755.06ms
        99%    1.22s
        3547 requests in 3.02s, 550.75KB read
        Requests/sec:   1175.52
        Transfer/sec:    182.53KB
        [run.sh] Speed is 1175.52, duration is 25
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d25s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 25s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   427.87ms  446.10ms   3.42s    85.13%
        Req/Sec   165.31     77.04   440.00     72.53%
        Latency Distribution
        50%  245.54ms
        75%  608.16ms
        90%    1.10s
        99%    1.96s
        20000 requests in 25.00s, 3.03MB read
        Requests/sec:    800.00
        Transfer/sec:    124.22KB
        ------------------------------
        stop time: 15.334269
        stop time: 15.234563
        stop time: 15.063535
        stop time: 15.522409
        stop time: 15.566976
        stop time: 15.490105
        stop time: 15.591794
        stop time: 15.001412
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-768756f486-qz6qz        68m          72Mi
        service1-698c8454b8-gg648        181m         41Mi
        service2-84cffc954f-5mwrp        740m         14Mi
        ubuntu-client-76886f6bbd-hq47m   16m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.334269, 15.234563, 15.063535, 15.522409, 15.566976, 15.490105, 15.591794, 15.001412]
    [exp] Throughput: 1302.877878903087
[test.py] Finished running 8th optmization experiment: groundtruth->1539.5087893154705, slowdown->1302.877878903087, predicted->1509.9430267353437, err->-1.92046728055856
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003753', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   311.84ms  284.06ms   1.49s    82.87%
        Req/Sec   171.56     95.17   420.00     63.88%
        Latency Distribution
        50%  220.31ms
        75%  444.80ms
        90%  683.48ms
        99%    1.32s
        3908 requests in 3.02s, 606.81KB read
        Requests/sec:   1293.38
        Transfer/sec:    200.83KB
        [run.sh] Speed is 1293.38, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   370.23ms  453.19ms   3.38s    84.71%
        Req/Sec   197.85     95.06   838.00     71.47%
        Latency Distribution
        50%  161.17ms
        75%  520.69ms
        90%    1.04s
        99%    1.92s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 11.594296
        stop time: 11.798979
        stop time: 13.054078
        stop time: 13.477295
        stop time: 13.304270
        stop time: 13.415617
        stop time: 13.502466
        stop time: 13.254397
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [11.594296, 11.798979, 13.054078, 13.477295, 13.30427, 13.415617, 13.502466, 13.254397]
    [exp] Throughput: 1547.3678605389841
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   357.59ms  235.10ms   1.25s    73.01%
        Req/Sec   167.84     84.55   383.00     64.78%
        Latency Distribution
        50%  278.20ms
        75%  475.45ms
        90%  726.87ms
        99%    1.10s
        3874 requests in 3.02s, 601.53KB read
        Requests/sec:   1281.26
        Transfer/sec:    198.95KB
        [run.sh] Speed is 1281.26, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   378.02ms  389.23ms   2.89s    84.95%
        Req/Sec   183.64     89.53   570.00     71.36%
        Latency Distribution
        50%  220.93ms
        75%  535.84ms
        90%  905.05ms
        99%    1.84s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 12.544238
        stop time: 13.255252
        stop time: 13.514448
        stop time: 14.175547
        stop time: 14.444398
        stop time: 14.380854
        stop time: 14.382567
        stop time: 14.110643
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-59d54698d4-7nlk2        602m         72Mi
        service1-569f565446-ts4gd        395m         39Mi
        service2-84cffc954f-pfkvq        44m          11Mi
        ubuntu-client-76886f6bbd-2z4zw   15m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.544238, 13.255252, 13.514448, 14.175547, 14.444398, 14.380854, 14.382567, 14.110643]
    [exp] Throughput: 1443.9397564147632
[test.py] Finished running 9th optmization experiment: groundtruth->1547.3678605389841, slowdown->1443.9397564147632, predicted->1563.9181102372056, err->1.0695743475282369
[test.py] Baseline throughput:  1507.589767524664
[test.py] Groundtruth:  [1501.4227106250205, 1509.8242803278663, 1509.7559533286499, 1515.2710723349874, 1521.273647568949, 1517.5809092570844, 1500.6138354682348, 1534.1637115876927, 1539.5087893154705, 1547.3678605389841]
[test.py] Slowdown:  [838.0510193308829, 872.2453429022135, 937.1270673550241, 965.7171556532228, 1019.6498247196462, 1085.8612477267834, 1143.7001233716474, 1240.6620889388937, 1302.877878903087, 1443.9397564147632]
[test.py] Predicted:  [1490.335676128597, 1478.554108630183, 1540.6275422761685, 1493.3845723536003, 1499.3091558237256, 1516.7648588637026, 1504.098513338689, 1541.6842663576006, 1509.9430267353437, 1563.9181102372056]
[test.py] Error percentage:  [-0.738435246647369, -2.071113314649623, 2.0448065715160224, -1.4443950248228914, -1.4438225351713267, -0.05377310615888795, 0.23221682941279737, 0.49020549196310653, -1.92046728055856, 1.0695743475282369]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 3...
[test.py] Actual processing time range: [0, 417, 834, 1251, 1668, 2085, 2502, 2919, 3336, 3753]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   411.89ms  389.29ms   2.78s    87.05%
        Req/Sec   181.67     84.36   404.00     65.20%
        Latency Distribution
        50%  256.20ms
        75%  514.02ms
        90%  961.22ms
        99%    1.81s
        4203 requests in 3.02s, 652.61KB read
        Requests/sec:   1392.45
        Transfer/sec:    216.21KB
        [run.sh] Speed is 1392.45, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   402.38ms  488.33ms   3.86s    86.08%
        Req/Sec   192.20     86.71   797.00     71.43%
        Latency Distribution
        50%  180.16ms
        75%  589.23ms
        90%    1.08s
        99%    2.17s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.440023
        stop time: 13.492966
        stop time: 13.637423
        stop time: 13.168419
        stop time: 13.694698
        stop time: 13.376495
        stop time: 12.462907
        stop time: 12.479167
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-48q2d        194m         69Mi
        service1-7585bd9d88-fhmjk        391m         50Mi
        service2-84cffc954f-529j2        1m           22Mi
        ubuntu-client-76886f6bbd-qjf6l   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.440023, 13.492966, 13.637423, 13.168419, 13.694698, 13.376495, 12.462907, 12.479167]
    [exp] Throughput: 1512.972347839378
[test.py] Baseline throughput: 1512.972347839378
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   356.39ms  193.39ms   1.31s    71.54%
        Req/Sec   178.52     94.58   500.00     72.69%
        Latency Distribution
        50%  330.68ms
        75%  465.04ms
        90%  634.41ms
        99%  903.12ms
        3954 requests in 3.03s, 613.95KB read
        Requests/sec:   1306.36
        Transfer/sec:    202.84KB
        [run.sh] Speed is 1306.36, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   365.48ms  380.63ms   3.50s    84.46%
        Req/Sec   191.45     93.39   700.00     71.86%
        Latency Distribution
        50%  197.47ms
        75%  498.73ms
        90%  903.42ms
        99%    1.82s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.610655
        stop time: 12.685517
        stop time: 13.565898
        stop time: 13.402824
        stop time: 13.355169
        stop time: 13.624373
        stop time: 13.586889
        stop time: 13.376020
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-hvvfd        554m         67Mi
        service1-7585bd9d88-tsrw5        97m          40Mi
        service2-84cffc954f-xnbqq        23m          10Mi
        ubuntu-client-76886f6bbd-fv8sr   25m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.610655, 12.685517, 13.565898, 13.402824, 13.355169, 13.624373, 13.586889, 13.37602]
    [exp] Throughput: 1506.4871454982704
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   517.05ms  404.29ms   1.93s    68.66%
        Req/Sec   132.29     74.98   353.00     66.25%
        Latency Distribution
        50%  407.48ms
        75%  681.34ms
        90%    1.21s
        99%    1.53s
        2463 requests in 3.02s, 382.44KB read
        Requests/sec:    814.62
        Transfer/sec:    126.49KB
        [run.sh] Speed is 814.62, duration is 36
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d36s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74576c5f89-d2mjh        1095m        68Mi
        service1-57cdc6957f-mslbq        728m         35Mi
        service2-84cffc954f-g8mgm        925m         12Mi
        ubuntu-client-76886f6bbd-5xwhb   31m          23Mi
        Running 36s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   649.23ms  679.72ms   5.53s    84.94%
        Req/Sec   120.31     79.40   470.00     66.37%
        Latency Distribution
        50%  405.93ms
        75%  916.42ms
        90%    1.58s
        99%    3.17s
        20000 requests in 36.00s, 3.03MB read
        Requests/sec:    555.55
        Transfer/sec:     86.26KB
        ------------------------------
        stop time: 22.702683
        stop time: 23.709842
        stop time: 22.587971
        stop time: 23.890715
        stop time: 23.825139
        stop time: 23.763606
        stop time: 23.759516
        stop time: 24.193176
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.702683, 23.709842, 22.587971, 23.890715, 23.825139, 23.763606, 23.759516, 24.193176]
    [exp] Throughput: 849.1097572433414
[test.py] Finished running 0th optmization experiment: groundtruth->1506.4871454982704, slowdown->849.1097572433414, predicted->1525.6715987306716, err->1.2734561519312504
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000417', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   329.41ms  244.14ms   1.15s    78.41%
        Req/Sec   190.01    109.31   620.00     78.50%
        Latency Distribution
        50%  244.43ms
        75%  462.42ms
        90%  713.87ms
        99%  984.28ms
        4081 requests in 3.03s, 633.67KB read
        Requests/sec:   1348.46
        Transfer/sec:    209.38KB
        [run.sh] Speed is 1348.46, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   367.86ms  407.36ms   3.55s    85.00%
        Req/Sec   190.47     84.15   590.00     70.19%
        Latency Distribution
        50%  188.49ms
        75%  514.68ms
        90%  960.54ms
        99%    1.89s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.364513
        stop time: 12.906135
        stop time: 13.446563
        stop time: 13.327660
        stop time: 13.376496
        stop time: 13.439702
        stop time: 13.506144
        stop time: 13.493232
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.364513, 12.906135, 13.446563, 13.32766, 13.376496, 13.439702, 13.506144, 13.493232]
    [exp] Throughput: 1497.279933655526
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   495.97ms  413.10ms   1.73s    63.17%
        Req/Sec   120.04     83.29   380.00     60.87%
        Latency Distribution
        50%  371.84ms
        75%  734.61ms
        90%    1.20s
        99%    1.48s
        2320 requests in 3.02s, 360.23KB read
        Requests/sec:    767.54
        Transfer/sec:    119.18KB
        [run.sh] Speed is 767.54, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f77f7cb57-mp6dm        1106m        70Mi
        service1-9d4b979b7-9kgg2         556m         42Mi
        service2-84cffc954f-kkh2m        381m         15Mi
        ubuntu-client-76886f6bbd-9g5wf   36m          19Mi
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   606.30ms  580.39ms   5.24s    86.27%
        Req/Sec   120.07     75.00   480.00     67.92%
        Latency Distribution
        50%  430.79ms
        75%  788.82ms
        90%    1.34s
        99%    2.85s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 21.265281
        stop time: 21.997682
        stop time: 22.498907
        stop time: 22.504582
        stop time: 23.129741
        stop time: 22.835009
        stop time: 22.845270
        stop time: 22.735275
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.265281, 21.997682, 22.498907, 22.504582, 23.129741, 22.835009, 22.84527, 22.735275]
    [exp] Throughput: 889.8195066198873
[test.py] Finished running 1th optmization experiment: groundtruth->1497.279933655526, slowdown->889.8195066198873, predicted->1529.769110896376, err->2.1698799610256922
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   332.32ms  240.82ms   1.33s    77.28%
        Req/Sec   175.91     97.12   424.00     66.22%
        Latency Distribution
        50%  237.46ms
        75%  459.56ms
        90%  740.55ms
        99%    1.01s
        4001 requests in 3.03s, 621.25KB read
        Requests/sec:   1322.23
        Transfer/sec:    205.31KB
        [run.sh] Speed is 1322.23, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   371.62ms  396.82ms   2.87s    85.78%
        Req/Sec   191.23     92.55   606.00     69.80%
        Latency Distribution
        50%  203.66ms
        75%  495.46ms
        90%  925.77ms
        99%    1.82s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.101249
        stop time: 13.430258
        stop time: 13.552230
        stop time: 12.811376
        stop time: 13.535081
        stop time: 13.309095
        stop time: 13.378215
        stop time: 13.294649
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.101249, 13.430258, 13.55223, 12.811376, 13.535081, 13.309095, 13.378215, 13.294649]
    [exp] Throughput: 1503.5876588269011
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   542.83ms  344.36ms   2.15s    67.75%
        Req/Sec   122.20     82.55   323.00     63.03%
        Latency Distribution
        50%  527.69ms
        75%  715.53ms
        90%    1.06s
        99%    1.45s
        2432 requests in 3.02s, 377.62KB read
        Requests/sec:    805.81
        Transfer/sec:    125.12KB
        [run.sh] Speed is 805.81, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-64686d547f-b4pdt        106m         61Mi
        service1-cdd6b68cc-ssnhx         269m         38Mi
        service2-84cffc954f-28x84        324m         14Mi
        ubuntu-client-76886f6bbd-pj5jg   7m           11Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   606.56ms  679.24ms   5.39s    86.55%
        Req/Sec   123.71     73.79   480.00     68.05%
        Latency Distribution
        50%  356.45ms
        75%  784.84ms
        90%    1.58s
        99%    3.07s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 20.594149
        stop time: 21.749578
        stop time: 21.076226
        stop time: 21.816929
        stop time: 21.754240
        stop time: 21.823460
        stop time: 21.406870
        stop time: 21.753689
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.594149, 21.749578, 21.076226, 21.816929, 21.75424, 21.82346, 21.40687, 21.753689]
    [exp] Throughput: 930.3670232199431
[test.py] Finished running 2th optmization experiment: groundtruth->1503.5876588269011, slowdown->930.3670232199431, predicted->1522.4416317525602, err->1.2539324072644293
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001251', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   333.27ms  211.01ms   1.28s    73.39%
        Req/Sec   196.52     81.32   410.00     69.44%
        Latency Distribution
        50%  270.61ms
        75%  442.15ms
        90%  658.17ms
        99%  934.78ms
        4253 requests in 3.02s, 660.38KB read
        Requests/sec:   1406.06
        Transfer/sec:    218.32KB
        [run.sh] Speed is 1406.06, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   391.54ms  478.22ms   4.39s    84.93%
        Req/Sec   199.62    101.81   777.00     74.04%
        Latency Distribution
        50%  171.59ms
        75%  565.06ms
        90%    1.09s
        99%    2.11s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.427814
        stop time: 11.846884
        stop time: 12.207398
        stop time: 13.175197
        stop time: 13.415053
        stop time: 13.523600
        stop time: 13.521077
        stop time: 13.226677
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-bnrxv        2m           65Mi
        service1-7585bd9d88-qtgm8        247m         46Mi
        service2-84cffc954f-zdkrg        325m         16Mi
        ubuntu-client-76886f6bbd-sgxlk   6m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.427814, 11.846884, 12.207398, 13.175197, 13.415053, 13.5236, 13.521077, 13.226677]
    [exp] Throughput: 1548.2317741671723
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   512.44ms  455.61ms   2.22s    74.21%
        Req/Sec   128.35     75.60   303.00     59.24%
        Latency Distribution
        50%  358.25ms
        75%  714.40ms
        90%    1.15s
        99%    2.04s
        2671 requests in 3.03s, 414.74KB read
        Requests/sec:    880.32
        Transfer/sec:    136.69KB
        [run.sh] Speed is 880.32, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   539.21ms  474.55ms   3.62s    79.70%
        Req/Sec   131.86     89.14   600.00     68.67%
        Latency Distribution
        50%  382.18ms
        75%  722.47ms
        90%    1.17s
        99%    2.23s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.372460
        stop time: 20.395373
        stop time: 20.009864
        stop time: 19.969644
        stop time: 20.891604
        stop time: 20.903145
        stop time: 20.548191
        stop time: 20.789279
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b565f6b89-v2fqc        434m         54Mi
        service1-7b65977d8c-4tzwn        152m         29Mi
        service2-84cffc954f-5f2fv        2m           11Mi
        ubuntu-client-76886f6bbd-rdv67   21m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.37246, 20.395373, 20.009864, 19.969644, 20.891604, 20.903145, 20.548191, 20.789279]
    [exp] Throughput: 982.3209247372723
[test.py] Finished running 3th optmization experiment: groundtruth->1548.2317741671723, slowdown->982.3209247372723, predicted->1533.466566020145, err->-0.9536820257399691
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001668', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   354.25ms  246.72ms   1.45s    73.20%
        Req/Sec   185.17    105.93   420.00     64.73%
        Latency Distribution
        50%  281.76ms
        75%  491.64ms
        90%  701.03ms
        99%    1.14s
        3952 requests in 3.03s, 613.64KB read
        Requests/sec:   1305.34
        Transfer/sec:    202.68KB
        [run.sh] Speed is 1305.34, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   395.50ms  473.23ms   3.63s    86.49%
        Req/Sec   193.85     96.47     0.90k    73.25%
        Latency Distribution
        50%  199.09ms
        75%  510.39ms
        90%    1.05s
        99%    2.17s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.306962
        stop time: 13.272208
        stop time: 12.993069
        stop time: 13.375091
        stop time: 13.401553
        stop time: 13.607753
        stop time: 13.552543
        stop time: 13.359952
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-w9tb9        1079m        64Mi
        service1-7585bd9d88-gntjh        1000m        36Mi
        service2-84cffc954f-2j9jr        704m         13Mi
        ubuntu-client-76886f6bbd-mtnb5   35m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.306962, 13.272208, 12.993069, 13.375091, 13.401553, 13.607753, 13.552543, 13.359952]
    [exp] Throughput: 1511.2998329985346
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   460.09ms  354.57ms   1.73s    75.54%
        Req/Sec   128.89     77.89   350.00     61.34%
        Latency Distribution
        50%  341.31ms
        75%  644.82ms
        90%    1.03s
        99%    1.62s
        2783 requests in 3.03s, 432.13KB read
        Requests/sec:    919.81
        Transfer/sec:    142.82KB
        [run.sh] Speed is 919.81, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   575.88ms  679.60ms   5.15s    86.77%
        Req/Sec   135.42     79.23   490.00     67.45%
        Latency Distribution
        50%  309.02ms
        75%  770.11ms
        90%    1.48s
        99%    3.11s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.531158
        stop time: 18.585985
        stop time: 19.622197
        stop time: 19.357763
        stop time: 19.283320
        stop time: 19.334571
        stop time: 19.836067
        stop time: 19.847533
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-557f58cfb4-nnpwp   2m           3Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.531158, 18.585985, 19.622197, 19.357763, 19.28332, 19.334571, 19.836067, 19.847533]
    [exp] Throughput: 1029.6103451231997
[test.py] Finished running 4th optmization experiment: groundtruth->1511.2998329985346, slowdown->1029.6103451231997, predicted->1520.9444410973106, err->0.6381664239081083
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002085', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   365.16ms  278.43ms   1.42s    73.54%
        Req/Sec   175.58    102.13   410.00     61.70%
        Latency Distribution
        50%  274.60ms
        75%  518.52ms
        90%  804.85ms
        99%    1.23s
        4166 requests in 3.02s, 646.87KB read
        Requests/sec:   1378.37
        Transfer/sec:    214.02KB
        [run.sh] Speed is 1378.37, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   414.69ms  495.58ms   2.99s    85.48%
        Req/Sec   189.72     90.90     1.14k    72.36%
        Latency Distribution
        50%  187.62ms
        75%  609.51ms
        90%    1.16s
        99%    2.14s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.060662
        stop time: 13.060298
        stop time: 13.668084
        stop time: 13.510370
        stop time: 13.498561
        stop time: 13.383476
        stop time: 13.400762
        stop time: 13.239321
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-sp6fq        405m         68Mi
        service1-7585bd9d88-krdk8        1294m        37Mi
        service2-84cffc954f-lg27q        536m         13Mi
        ubuntu-client-76886f6bbd-2q5ck   53m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.060662, 13.060298, 13.668084, 13.51037, 13.498561, 13.383476, 13.400762, 13.239321]
    [exp] Throughput: 1497.825335479642
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   464.96ms  381.90ms   2.01s    73.47%
        Req/Sec   143.90     78.60   310.00     63.43%
        Latency Distribution
        50%  383.36ms
        75%  695.40ms
        90%    1.01s
        99%    1.54s
        2837 requests in 3.03s, 440.51KB read
        Requests/sec:    937.75
        Transfer/sec:    145.61KB
        [run.sh] Speed is 937.75, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   505.59ms  505.32ms   3.92s    86.73%
        Req/Sec   143.29     88.18   696.00     67.13%
        Latency Distribution
        50%  321.23ms
        75%  666.63ms
        90%    1.16s
        99%    2.43s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.227355
        stop time: 18.337836
        stop time: 18.748124
        stop time: 18.495001
        stop time: 18.825454
        stop time: 18.473213
        stop time: 18.491179
        stop time: 18.827551
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.227355, 18.337836, 18.748124, 18.495001, 18.825454, 18.473213, 18.491179, 18.827551]
    [exp] Throughput: 1077.980336196869
[test.py] Finished running 5th optmization experiment: groundtruth->1497.825335479642, slowdown->1077.980336196869, predicted->1501.4322772449502, err->0.24081190776180572
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002502', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   398.73ms  438.71ms   2.29s    85.81%
        Req/Sec   189.04     72.76   404.00     71.76%
        Latency Distribution
        50%  175.00ms
        75%  579.98ms
        90%    1.06s
        99%    1.91s
        4111 requests in 3.02s, 638.33KB read
        Requests/sec:   1362.06
        Transfer/sec:    211.49KB
        [run.sh] Speed is 1362.06, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   374.37ms  428.41ms   3.06s    87.36%
        Req/Sec   196.58     89.33   656.00     71.24%
        Latency Distribution
        50%  205.31ms
        75%  474.50ms
        90%  910.26ms
        99%    2.09s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.178285
        stop time: 12.893078
        stop time: 13.143117
        stop time: 13.041323
        stop time: 13.315582
        stop time: 13.497332
        stop time: 13.475710
        stop time: 13.518004
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-mvjgg        523m         66Mi
        service1-7585bd9d88-g42kb        655m         31Mi
        service2-84cffc954f-zw7b2        129m         10Mi
        ubuntu-client-76886f6bbd-fc9qg   33m          15Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.178285, 12.893078, 13.143117, 13.041323, 13.315582, 13.497332, 13.47571, 13.518004]
    [exp] Throughput: 1508.545471676017
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   397.57ms  281.82ms   1.48s    73.21%
        Req/Sec   132.33     78.33   320.00     61.82%
        Latency Distribution
        50%  323.98ms
        75%  508.59ms
        90%  820.60ms
        99%    1.36s
        3039 requests in 3.03s, 471.88KB read
        Requests/sec:   1002.83
        Transfer/sec:    155.71KB
        [run.sh] Speed is 1002.83, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   491.47ms  553.87ms   4.30s    87.40%
        Req/Sec   151.04     83.17   484.00     66.69%
        Latency Distribution
        50%  278.26ms
        75%  626.04ms
        90%    1.19s
        99%    2.61s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 16.958582
        stop time: 16.994148
        stop time: 17.281429
        stop time: 16.818111
        stop time: 17.357209
        stop time: 17.635133
        stop time: 17.701045
        stop time: 17.353241
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-559cb467b4-gfx4f        515m         70Mi
        service1-cb57b799d-mm6dc         531m         41Mi
        service2-84cffc954f-7l2bq        1m           17Mi
        ubuntu-client-76886f6bbd-hzrjn   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.958582, 16.994148, 17.281429, 16.818111, 17.357209, 17.635133, 17.701045, 17.353241]
    [exp] Throughput: 1158.589983824491
[test.py] Finished running 6th optmization experiment: groundtruth->1508.545471676017, slowdown->1158.589983824491, predicted->1529.9570661535652, err->1.4193536011718275
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002919', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   355.75ms  359.80ms   2.13s    85.68%
        Req/Sec   191.83     68.30   380.00     70.83%
        Latency Distribution
        50%  185.27ms
        75%  510.92ms
        90%  855.82ms
        99%    1.59s
        4149 requests in 3.03s, 644.23KB read
        Requests/sec:   1368.66
        Transfer/sec:    212.52KB
        [run.sh] Speed is 1368.66, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   400.62ms  480.14ms   3.83s    85.39%
        Req/Sec   191.73     92.42   550.00     71.98%
        Latency Distribution
        50%  179.21ms
        75%  585.65ms
        90%    1.12s
        99%    2.07s
        20001 requests in 21.00s, 3.03MB read
        Requests/sec:    952.42
        Transfer/sec:    147.89KB
        ------------------------------
        stop time: 12.140587
        stop time: 12.586064
        stop time: 12.841332
        stop time: 13.402457
        stop time: 13.579304
        stop time: 13.580979
        stop time: 13.531575
        stop time: 12.951745
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-gnc8n        628m         49Mi
        service1-7585bd9d88-dc8th        346m         46Mi
        service2-84cffc954f-htm6w        378m         21Mi
        ubuntu-client-76886f6bbd-6m9pc   9m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.140587, 12.586064, 12.841332, 13.402457, 13.579304, 13.580979, 13.531575, 12.951745]
    [exp] Throughput: 1529.43137853873
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   433.33ms  314.57ms   1.98s    72.12%
        Req/Sec   158.82     80.43   363.00     67.66%
        Latency Distribution
        50%  366.76ms
        75%  596.82ms
        90%  889.27ms
        99%    1.37s
        3379 requests in 3.03s, 524.67KB read
        Requests/sec:   1114.03
        Transfer/sec:    172.98KB
        [run.sh] Speed is 1114.03, duration is 26
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d26s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 26s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   444.92ms  431.44ms   2.98s    84.91%
        Req/Sec   155.14     83.69   610.00     66.72%
        Latency Distribution
        50%  290.70ms
        75%  599.75ms
        90%    1.05s
        99%    1.94s
        20000 requests in 26.00s, 3.03MB read
        Requests/sec:    769.23
        Transfer/sec:    119.44KB
        ------------------------------
        stop time: 16.318353
        stop time: 16.423730
        stop time: 16.301506
        stop time: 16.606479
        stop time: 16.178282
        stop time: 16.402101
        stop time: 16.541772
        stop time: 16.512905
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-854764b98f-z2kqg        1309m        68Mi
        service1-7cf689c479-77nhq        1054m        45Mi
        service2-84cffc954f-pjzws        633m         19Mi
        ubuntu-client-76886f6bbd-rg2vt   44m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.318353, 16.42373, 16.301506, 16.606479, 16.178282, 16.402101, 16.541772, 16.512905]
    [exp] Throughput: 1218.7214381205465
[test.py] Finished running 7th optmization experiment: groundtruth->1529.43137853873, slowdown->1218.7214381205465, predicted->1507.9497982400871, err->-1.4045468531688658
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003336', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   315.82ms  272.45ms   1.65s    75.33%
        Req/Sec   185.33     94.97   440.00     66.07%
        Latency Distribution
        50%  207.82ms
        75%  464.64ms
        90%  749.18ms
        99%    1.08s
        4180 requests in 3.02s, 649.04KB read
        Requests/sec:   1383.09
        Transfer/sec:    214.76KB
        [run.sh] Speed is 1383.09, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   403.75ms  476.38ms   4.45s    86.44%
        Req/Sec   190.46     79.02   676.00     70.03%
        Latency Distribution
        50%  201.65ms
        75%  526.59ms
        90%    1.06s
        99%    2.21s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.376786
        stop time: 12.938497
        stop time: 13.353354
        stop time: 13.547742
        stop time: 13.576439
        stop time: 13.253584
        stop time: 13.469557
        stop time: 13.578280
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-mcvh2   2m           65Mi
        service2-84cffc954f-bf8tv   332m         10Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.376786, 12.938497, 13.353354, 13.547742, 13.576439, 13.253584, 13.469557, 13.57828]
    [exp] Throughput: 1508.0931962761897
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   414.78ms  319.14ms   1.74s    69.74%
        Req/Sec   170.08     87.54   494.00     66.99%
        Latency Distribution
        50%  336.69ms
        75%  591.76ms
        90%  879.66ms
        99%    1.37s
        3628 requests in 3.02s, 563.33KB read
        Requests/sec:   1200.95
        Transfer/sec:    186.48KB
        [run.sh] Speed is 1200.95, duration is 24
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d24s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 24s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   447.99ms  507.77ms   3.45s    86.58%
        Req/Sec   165.51     71.44   535.00     68.11%
        Latency Distribution
        50%  242.16ms
        75%  606.75ms
        90%    1.14s
        99%    2.41s
        20000 requests in 24.00s, 3.03MB read
        Requests/sec:    833.33
        Transfer/sec:    129.39KB
        ------------------------------
        stop time: 15.197348
        stop time: 14.386280
        stop time: 15.014860
        stop time: 15.145686
        stop time: 15.572261
        stop time: 15.734814
        stop time: 15.409210
        stop time: 15.588538
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-768756f486-znblz        1686m        65Mi
        service1-698c8454b8-lqfsq        1120m        39Mi
        service2-84cffc954f-w42wp        1136m        16Mi
        ubuntu-client-76886f6bbd-pftsw   51m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.197348, 14.38628, 15.01486, 15.145686, 15.572261, 15.734814, 15.40921, 15.588538]
    [exp] Throughput: 1310.9489134105706
[test.py] Finished running 8th optmization experiment: groundtruth->1508.0931962761897, slowdown->1310.9489134105706, predicted->1520.7940499160916, err->0.8421796259848563
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003753', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   339.99ms  327.50ms   2.02s    83.60%
        Req/Sec   190.38     71.75   400.00     73.15%
        Latency Distribution
        50%  184.27ms
        75%  531.29ms
        90%  799.01ms
        99%    1.41s
        4159 requests in 3.02s, 645.78KB read
        Requests/sec:   1376.65
        Transfer/sec:    213.76KB
        [run.sh] Speed is 1376.65, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   383.88ms  432.25ms   2.85s    85.23%
        Req/Sec   189.93     86.43   580.00     69.63%
        Latency Distribution
        50%  193.88ms
        75%  563.14ms
        90%  998.66ms
        99%    1.92s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.578917
        stop time: 12.606746
        stop time: 13.616755
        stop time: 13.293031
        stop time: 13.480595
        stop time: 13.354186
        stop time: 13.629264
        stop time: 13.559025
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service2-84cffc954f-44gjz   2m           3Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.578917, 12.606746, 13.616755, 13.293031, 13.480595, 13.354186, 13.629264, 13.559025]
    [exp] Throughput: 1507.7481433754272
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   375.66ms  294.91ms   1.67s    78.16%
        Req/Sec   158.42     79.07   474.00     66.67%
        Latency Distribution
        50%  262.92ms
        75%  533.17ms
        90%  802.90ms
        99%    1.27s
        3790 requests in 3.03s, 588.49KB read
        Requests/sec:   1251.91
        Transfer/sec:    194.39KB
        [run.sh] Speed is 1251.91, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   416.50ms  516.52ms   3.78s    86.45%
        Req/Sec   177.51     80.20   616.00     70.67%
        Latency Distribution
        50%  192.04ms
        75%  591.20ms
        90%    1.12s
        99%    2.43s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.548647
        stop time: 13.983556
        stop time: 14.370719
        stop time: 13.822816
        stop time: 14.308805
        stop time: 14.400193
        stop time: 14.511697
        stop time: 14.159139
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-59d54698d4-8zbd8        1447m        72Mi
        service1-569f565446-4nkf8        693m         36Mi
        service2-84cffc954f-jntpd        1519m        14Mi
        ubuntu-client-76886f6bbd-6srd7   24m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.548647, 13.983556, 14.370719, 13.822816, 14.308805, 14.400193, 14.511697, 14.159139]
    [exp] Throughput: 1414.6075844963675
[test.py] Finished running 9th optmization experiment: groundtruth->1507.7481433754272, slowdown->1414.6075844963675, predicted->1529.566930273506, err->1.447110845000452
[test.py] Baseline throughput:  1512.972347839378
[test.py] Groundtruth:  [1506.4871454982704, 1497.279933655526, 1503.5876588269011, 1548.2317741671723, 1511.2998329985346, 1497.825335479642, 1508.545471676017, 1529.43137853873, 1508.0931962761897, 1507.7481433754272]
[test.py] Slowdown:  [849.1097572433414, 889.8195066198873, 930.3670232199431, 982.3209247372723, 1029.6103451231997, 1077.980336196869, 1158.589983824491, 1218.7214381205465, 1310.9489134105706, 1414.6075844963675]
[test.py] Predicted:  [1525.6715987306716, 1529.769110896376, 1522.4416317525602, 1533.466566020145, 1520.9444410973106, 1501.4322772449502, 1529.9570661535652, 1507.9497982400871, 1520.7940499160916, 1529.566930273506]
[test.py] Error percentage:  [1.2734561519312504, 2.1698799610256922, 1.2539324072644293, -0.9536820257399691, 0.6381664239081083, 0.24081190776180572, 1.4193536011718275, -1.4045468531688658, 0.8421796259848563, 1.447110845000452]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 4...
[test.py] Actual processing time range: [0, 417, 834, 1251, 1668, 2085, 2502, 2919, 3336, 3753]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   396.42ms  346.20ms   1.90s    80.61%
        Req/Sec   176.23     77.82   390.00     71.82%
        Latency Distribution
        50%  257.52ms
        75%  576.45ms
        90%  903.40ms
        99%    1.45s
        3992 requests in 3.04s, 619.85KB read
        Requests/sec:   1314.62
        Transfer/sec:    204.13KB
        [run.sh] Speed is 1314.62, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   381.24ms  431.37ms   3.25s    85.02%
        Req/Sec   190.00     81.37   515.00     71.48%
        Latency Distribution
        50%  197.74ms
        75%  510.57ms
        90%  990.45ms
        99%    1.91s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.005943
        stop time: 13.289130
        stop time: 12.923844
        stop time: 13.353096
        stop time: 13.397997
        stop time: 13.093986
        stop time: 13.477790
        stop time: 13.165183
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.005943, 13.28913, 12.923844, 13.353096, 13.397997, 13.093986, 13.47779, 13.165183]
    [exp] Throughput: 1513.6182743069664
[test.py] Baseline throughput: 1513.6182743069664
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   391.54ms  406.55ms   2.24s    85.79%
        Req/Sec   182.17     85.50   474.00     69.72%
        Latency Distribution
        50%  246.53ms
        75%  550.66ms
        90%  989.74ms
        99%    1.93s
        4076 requests in 3.02s, 632.89KB read
        Requests/sec:   1350.18
        Transfer/sec:    209.65KB
        [run.sh] Speed is 1350.18, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   359.04ms  346.48ms   2.50s    85.41%
        Req/Sec   192.54     91.01   620.00     70.67%
        Latency Distribution
        50%  224.26ms
        75%  477.64ms
        90%  845.60ms
        99%    1.62s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.656619
        stop time: 13.302094
        stop time: 13.419944
        stop time: 13.286834
        stop time: 13.519530
        stop time: 13.509357
        stop time: 13.609879
        stop time: 13.563820
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-f9x67        389m         65Mi
        service1-7585bd9d88-zbjjn        1m           35Mi
        service2-84cffc954f-phwgw        23m          11Mi
        ubuntu-client-76886f6bbd-f4k9j   15m          16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.656619, 13.302094, 13.419944, 13.286834, 13.51953, 13.509357, 13.609879, 13.56382]
    [exp] Throughput: 1497.1730051809582
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   553.11ms  500.73ms   2.85s    78.59%
        Req/Sec   113.70     76.11   333.00     61.68%
        Latency Distribution
        50%  379.32ms
        75%  825.74ms
        90%    1.38s
        99%    2.03s
        2307 requests in 3.03s, 358.22KB read
        Requests/sec:    761.85
        Transfer/sec:    118.30KB
        [run.sh] Speed is 761.85, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74576c5f89-m4hk2        424m         70Mi
        service1-57cdc6957f-bq9cj        432m         39Mi
        service2-84cffc954f-rktts        940m         13Mi
        ubuntu-client-76886f6bbd-wzdx4   26m          22Mi
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   615.29ms  507.73ms   3.52s    73.30%
        Req/Sec   121.93     80.28   474.00     68.53%
        Latency Distribution
        50%  472.41ms
        75%  876.56ms
        90%    1.31s
        99%    2.29s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 23.918367
        stop time: 23.882704
        stop time: 23.902769
        stop time: 23.714906
        stop time: 23.948239
        stop time: 23.725967
        stop time: 23.942899
        stop time: 24.214058
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.918367, 23.882704, 23.902769, 23.714906, 23.948239, 23.725967, 23.942899, 24.214058]
    [exp] Throughput: 836.6017052588506
[test.py] Finished running 0th optmization experiment: groundtruth->1497.1730051809582, slowdown->836.6017052588506, predicted->1485.7584159230066, err->-0.7624095023388366
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000417', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
