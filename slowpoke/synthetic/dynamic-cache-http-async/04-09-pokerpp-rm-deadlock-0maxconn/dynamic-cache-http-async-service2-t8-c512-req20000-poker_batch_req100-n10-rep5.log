[config.py] Random numbers for execution time: [522.2551759100179, 696.0933418365564, 1061.686329548961]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : dynamic-cache-http-async
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 22745
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.25}
baseline_service_processing_time : {'service0': 1061.69, 'service1': 696.09, 'service2': 4178.04}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2}
target_processing_time_range     : [0, 4178.04]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 417, 834, 1251, 1668, 2085, 2502, 2919, 3336, 3753]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-5276x cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   384.86ms  307.04ms   2.10s    78.61%
        Req/Sec   180.31     78.34   370.00     63.89%
        Latency Distribution
        50%  289.51ms
        75%  552.52ms
        90%  833.39ms
        99%    1.35s
        3941 requests in 3.03s, 611.93KB read
        Requests/sec:   1302.30
        Transfer/sec:    202.21KB
        [run.sh] Speed is 1302.30, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   370.30ms  409.92ms   3.09s    85.30%
        Req/Sec   193.08     93.83     1.10k    75.51%
        Latency Distribution
        50%  198.65ms
        75%  458.72ms
        90%    1.04s
        99%    1.81s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 12.773055
        stop time: 12.400925
        stop time: 13.269162
        stop time: 13.134921
        stop time: 13.244849
        stop time: 13.442102
        stop time: 13.452636
        stop time: 13.673620
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-5276x        997m         73Mi
        service1-7585bd9d88-ptpqv        755m         40Mi
        service2-84cffc954f-7cwl2        1366m        16Mi
        ubuntu-client-76886f6bbd-qp794   33m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [12.773055, 12.400925, 13.269162, 13.134921, 13.244849, 13.442102, 13.452636, 13.67362]
    [exp] Throughput: 1518.1523099588799
[test.py] Baseline throughput: 1518.1523099588799
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   379.51ms  356.07ms   2.35s    81.10%
        Req/Sec   182.58     77.81   410.00     73.28%
        Latency Distribution
        50%  231.66ms
        75%  577.74ms
        90%  940.64ms
        99%    1.51s
        4234 requests in 3.03s, 657.43KB read
        Requests/sec:   1398.65
        Transfer/sec:    217.17KB
        [run.sh] Speed is 1398.65, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   369.21ms  418.49ms   3.38s    84.94%
        Req/Sec   199.44     98.21   620.00     71.50%
        Latency Distribution
        50%  177.10ms
        75%  554.82ms
        90%  949.35ms
        99%    1.91s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.179044
        stop time: 12.690806
        stop time: 12.621371
        stop time: 12.708392
        stop time: 13.086791
        stop time: 13.446191
        stop time: 13.531845
        stop time: 13.557693
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-w9ztp   2m           53Mi
        service1-7585bd9d88-62fps   2m           20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.179044, 12.690806, 12.621371, 12.708392, 13.086791, 13.446191, 13.531845, 13.557693]
    [exp] Throughput: 1541.0972147913778
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   561.10ms  393.60ms   2.10s    61.16%
        Req/Sec   144.55     99.22   400.00     60.14%
        Latency Distribution
        50%  550.29ms
        75%  795.55ms
        90%    1.20s
        99%    1.45s
        2307 requests in 3.02s, 358.22KB read
        Requests/sec:    764.05
        Transfer/sec:    118.64KB
        [run.sh] Speed is 764.05, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74576c5f89-nkh4l        1129m        69Mi
        service1-57cdc6957f-w5kd5        718m         38Mi
        service2-84cffc954f-4ggqk        864m         15Mi
        ubuntu-client-76886f6bbd-hnxr9   31m          21Mi
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   671.25ms  714.51ms   4.64s    85.12%
        Req/Sec   118.42     75.19     0.92k    68.32%
        Latency Distribution
        50%  408.64ms
        75%  892.72ms
        90%    1.69s
        99%    3.23s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 23.497931
        stop time: 23.098371
        stop time: 23.529643
        stop time: 23.850013
        stop time: 23.572261
        stop time: 23.825587
        stop time: 24.184313
        stop time: 24.392361
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.497931, 23.098371, 23.529643, 23.850013, 23.572261, 23.825587, 24.184313, 24.392361]
    [exp] Throughput: 842.3247996004011
[test.py] Finished running 0th optmization experiment: groundtruth->1541.0972147913778, slowdown->842.3247996004011, predicted->1503.9052659994843, err->-2.413342158750725
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000417', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   330.11ms  265.62ms   1.75s    73.53%
        Req/Sec   192.23     96.34   420.00     67.87%
        Latency Distribution
        50%  232.53ms
        75%  484.04ms
        90%  731.42ms
        99%    1.07s
        4270 requests in 3.03s, 663.02KB read
        Requests/sec:   1411.54
        Transfer/sec:    219.17KB
        [run.sh] Speed is 1411.54, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   367.35ms  394.40ms   2.69s    84.43%
        Req/Sec   191.91     91.71   630.00     70.93%
        Latency Distribution
        50%  203.00ms
        75%  488.05ms
        90%  968.97ms
        99%    1.77s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.774949
        stop time: 12.679571
        stop time: 13.083346
        stop time: 13.592011
        stop time: 13.474299
        stop time: 13.313995
        stop time: 13.390425
        stop time: 13.266844
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [12.774949, 12.679571, 13.083346, 13.592011, 13.474299, 13.313995, 13.390425, 13.266844]
    [exp] Throughput: 1515.5039846388515
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   521.90ms  320.29ms   1.75s    74.06%
        Req/Sec   115.03     71.49   303.00     67.53%
        Latency Distribution
        50%  457.99ms
        75%  699.64ms
        90%  973.76ms
        99%    1.48s
        2327 requests in 3.04s, 361.32KB read
        Requests/sec:    766.22
        Transfer/sec:    118.97KB
        [run.sh] Speed is 766.22, duration is 39
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d39s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f77f7cb57-9882j        259m         69Mi
        service1-9d4b979b7-vgc8d         112m         37Mi
        service2-84cffc954f-w7cwk        118m         14Mi
        ubuntu-client-76886f6bbd-q68lj   3m           13Mi
        Running 39s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   608.12ms  566.48ms   3.86s    83.71%
        Req/Sec   121.97     82.32   515.00     67.19%
        Latency Distribution
        50%  442.77ms
        75%  778.92ms
        90%    1.30s
        99%    2.78s
        20000 requests in 39.00s, 3.03MB read
        Requests/sec:    512.82
        Transfer/sec:     79.63KB
        ------------------------------
        stop time: 22.244363
        stop time: 22.755797
        stop time: 22.772057
        stop time: 23.145197
        stop time: 22.768277
        stop time: 23.205722
        stop time: 22.789993
        stop time: 22.551444
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.244363, 22.755797, 22.772057, 23.145197, 22.768277, 23.205722, 22.789993, 22.551444]
    [exp] Throughput: 877.9975728854594
[test.py] Finished running 1th optmization experiment: groundtruth->1515.5039846388515, slowdown->877.9975728854594, predicted->1495.15872277935, err->-1.342474982957558
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   317.61ms  256.89ms   1.33s    72.95%
        Req/Sec   192.19     97.27   540.00     72.22%
        Latency Distribution
        50%  232.60ms
        75%  466.37ms
        90%  695.29ms
        99%    1.16s
        4190 requests in 3.03s, 650.60KB read
        Requests/sec:   1384.48
        Transfer/sec:    214.97KB
        [run.sh] Speed is 1384.48, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   384.87ms  440.06ms   3.02s    84.88%
        Req/Sec   190.71     78.48   636.00     66.67%
        Latency Distribution
        50%  188.46ms
        75%  569.46ms
        90%    1.02s
        99%    1.99s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.681199
        stop time: 13.241895
        stop time: 13.214002
        stop time: 13.176688
        stop time: 13.399518
        stop time: 13.065941
        stop time: 13.389978
        stop time: 13.480445
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-8wwl9        1654m        65Mi
        service1-7585bd9d88-dmhrx        1m           34Mi
        service2-84cffc954f-xmlh9        77m          10Mi
        ubuntu-client-76886f6bbd-m9vnb   10m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.681199, 13.241895, 13.214002, 13.176688, 13.399518, 13.065941, 13.389978, 13.480445]
    [exp] Throughput: 1514.4392411046524
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   513.33ms  385.10ms   2.27s    73.34%
        Req/Sec   129.85     84.68   343.00     60.84%
        Latency Distribution
        50%  409.74ms
        75%  734.16ms
        90%    1.05s
        99%    1.61s
        2591 requests in 3.02s, 402.31KB read
        Requests/sec:    857.91
        Transfer/sec:    133.21KB
        [run.sh] Speed is 857.91, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   600.71ms  632.64ms   5.14s    85.05%
        Req/Sec   127.47     82.85     0.99k    70.67%
        Latency Distribution
        50%  369.09ms
        75%  869.43ms
        90%    1.49s
        99%    2.88s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 19.740483
        stop time: 21.915240
        stop time: 22.122601
        stop time: 21.916134
        stop time: 21.599268
        stop time: 21.929723
        stop time: 21.444773
        stop time: 21.589627
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service1-cdd6b68cc-455vg         283m         39Mi
        service2-84cffc954f-vdljc        177m         14Mi
        ubuntu-client-76886f6bbd-gb8dm   15m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.740483, 21.91524, 22.122601, 21.916134, 21.599268, 21.929723, 21.444773, 21.589627]
    [exp] Throughput: 928.8401134046438
[test.py] Finished running 2th optmization experiment: groundtruth->1514.4392411046524, slowdown->928.8401134046438, predicted->1518.3571899038473, err->0.25870623877502286
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001251', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   358.69ms  315.66ms   1.77s    82.13%
        Req/Sec   192.93     76.62   420.00     73.02%
        Latency Distribution
        50%  225.53ms
        75%  542.36ms
        90%  793.41ms
        99%    1.45s
        4178 requests in 3.02s, 648.73KB read
        Requests/sec:   1381.86
        Transfer/sec:    214.57KB
        [run.sh] Speed is 1381.86, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   383.57ms  429.83ms   3.91s    85.87%
        Req/Sec   193.00     89.90   666.00     69.56%
        Latency Distribution
        50%  208.23ms
        75%  517.43ms
        90%  938.80ms
        99%    2.00s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.546229
        stop time: 13.539535
        stop time: 13.066976
        stop time: 12.812082
        stop time: 13.320986
        stop time: 13.465580
        stop time: 13.040781
        stop time: 13.307579
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pncgl        1776m        67Mi
        service1-7585bd9d88-xqwdc        1093m        48Mi
        service2-84cffc954f-rp2cl        440m         18Mi
        ubuntu-client-76886f6bbd-qb94g   40m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.546229, 13.539535, 13.066976, 12.812082, 13.320986, 13.46558, 13.040781, 13.307579]
    [exp] Throughput: 1508.014891797858
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   530.52ms  424.79ms   2.08s    74.75%
        Req/Sec   133.55     62.97   420.00     70.78%
        Latency Distribution
        50%  419.95ms
        75%  767.11ms
        90%    1.21s
        99%    1.83s
        2664 requests in 3.02s, 413.65KB read
        Requests/sec:    883.40
        Transfer/sec:    137.17KB
        [run.sh] Speed is 883.40, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   544.28ms  517.51ms   3.96s    83.85%
        Req/Sec   131.58     81.60   490.00     68.92%
        Latency Distribution
        50%  362.50ms
        75%  747.41ms
        90%    1.29s
        99%    2.36s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 18.742273
        stop time: 19.699641
        stop time: 19.795968
        stop time: 20.375559
        stop time: 20.821707
        stop time: 20.901810
        stop time: 20.845941
        stop time: 20.734632
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.742273, 19.699641, 19.795968, 20.375559, 20.821707, 20.90181, 20.845941, 20.734632]
    [exp] Throughput: 988.1573601810912
[test.py] Finished running 3th optmization experiment: groundtruth->1508.014891797858, slowdown->988.1573601810912, predicted->1547.737082148593, err->2.634071491388134
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001668', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   352.06ms  297.34ms   1.60s    77.40%
        Req/Sec   178.94     89.92   424.00     68.10%
        Latency Distribution
        50%  247.84ms
        75%  495.63ms
        90%  802.28ms
        99%    1.23s
        4155 requests in 3.03s, 645.16KB read
        Requests/sec:   1370.89
        Transfer/sec:    212.86KB
        [run.sh] Speed is 1370.89, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   397.66ms  481.19ms   3.12s    85.17%
        Req/Sec   196.10     86.18   610.00     71.84%
        Latency Distribution
        50%  168.54ms
        75%  583.32ms
        90%    1.11s
        99%    2.10s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.064945
        stop time: 11.729455
        stop time: 13.170268
        stop time: 13.575167
        stop time: 13.519246
        stop time: 13.357232
        stop time: 13.607616
        stop time: 13.405857
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-xp59s        630m         67Mi
        service1-7585bd9d88-xh5dj        332m         38Mi
        service2-84cffc954f-wbv6p        692m         11Mi
        ubuntu-client-76886f6bbd-h7wrw   55m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.064945, 11.729455, 13.170268, 13.575167, 13.519246, 13.357232, 13.607616, 13.405857]
    [exp] Throughput: 1532.1299231619605
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '313.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   450.25ms  361.55ms   2.17s    77.95%
        Req/Sec   122.70     69.87   373.00     69.31%
        Latency Distribution
        50%  333.90ms
        75%  577.08ms
        90%  984.09ms
        99%    1.63s
        2791 requests in 3.03s, 433.37KB read
        Requests/sec:    921.07
        Transfer/sec:    143.02KB
        [run.sh] Speed is 921.07, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   553.03ms  633.20ms   5.46s    85.94%
        Req/Sec   133.56     77.57   510.00     67.96%
        Latency Distribution
        50%  313.18ms
        75%  672.83ms
        90%    1.46s
        99%    2.88s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.268371
        stop time: 19.775004
        stop time: 18.763095
        stop time: 19.415784
        stop time: 19.602058
        stop time: 19.573130
        stop time: 19.958924
        stop time: 19.648861
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [19.268371, 19.775004, 18.763095, 19.415784, 19.602058, 19.57313, 19.958924, 19.648861]
    [exp] Throughput: 1025.6066612434724
[test.py] Finished running 4th optmization experiment: groundtruth->1532.1299231619605, slowdown->1025.6066612434724, predicted->1512.224058450787, err->-1.2992282449580028
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002085', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   362.65ms  340.10ms   2.07s    81.46%
        Req/Sec   189.37     79.96   444.00     72.22%
        Latency Distribution
        50%  216.26ms
        75%  552.85ms
        90%  862.75ms
        99%    1.41s
        4122 requests in 3.03s, 640.04KB read
        Requests/sec:   1359.02
        Transfer/sec:    211.02KB
        [run.sh] Speed is 1359.02, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   358.31ms  410.74ms   3.06s    85.17%
        Req/Sec   193.94     96.30   717.00     70.53%
        Latency Distribution
        50%  186.30ms
        75%  485.89ms
        90%  941.37ms
        99%    2.03s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.584183
        stop time: 12.869896
        stop time: 13.144807
        stop time: 12.633800
        stop time: 13.069536
        stop time: 13.445561
        stop time: 13.648865
        stop time: 13.440101
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-zxm8b        494m         67Mi
        service1-7585bd9d88-ktgln        410m         40Mi
        service2-84cffc954f-5sjfc        268m         10Mi
        ubuntu-client-76886f6bbd-5r55s   19m          14Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.584183, 12.869896, 13.144807, 12.6338, 13.069536, 13.445561, 13.648865, 13.440101]
    [exp] Throughput: 1511.7622329839328
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '261.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   497.89ms  382.99ms   1.99s    79.33%
        Req/Sec   131.76     75.98   333.00     61.26%
        Latency Distribution
        50%  354.34ms
        75%  689.64ms
        90%    1.04s
        99%    1.68s
        2973 requests in 3.02s, 461.63KB read
        Requests/sec:    985.42
        Transfer/sec:    153.01KB
        [run.sh] Speed is 985.42, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   524.29ms  575.01ms   5.67s    85.38%
        Req/Sec   137.00     72.90   420.00     66.31%
        Latency Distribution
        50%  292.98ms
        75%  695.72ms
        90%    1.35s
        99%    2.56s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.357047
        stop time: 18.449082
        stop time: 17.695230
        stop time: 18.274036
        stop time: 18.042165
        stop time: 18.601178
        stop time: 18.889705
        stop time: 18.763266
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f696d68d6-cq992        600m         69Mi
        service1-5b7949c96d-49wpb        483m         37Mi
        service2-84cffc954f-tkwhs        947m         13Mi
        ubuntu-client-76886f6bbd-xdrfz   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.357047, 18.449082, 17.69523, 18.274036, 18.042165, 18.601178, 18.889705, 18.763266]
    [exp] Throughput: 1087.9046764867605
[test.py] Finished running 5th optmization experiment: groundtruth->1511.7622329839328, slowdown->1087.9046764867605, predicted->1520.7548487201075, err->0.5948432590768564
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002502', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   345.72ms  243.31ms   1.44s    77.39%
        Req/Sec   197.09     90.60   404.00     71.30%
        Latency Distribution
        50%  267.44ms
        75%  464.73ms
        90%  698.86ms
        99%    1.14s
        4284 requests in 3.03s, 665.19KB read
        Requests/sec:   1413.00
        Transfer/sec:    219.40KB
        [run.sh] Speed is 1413.00, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   370.68ms  408.84ms   3.85s    84.80%
        Req/Sec   188.85     82.41   570.00     72.41%
        Latency Distribution
        50%  195.98ms
        75%  542.59ms
        90%  953.40ms
        99%    1.81s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.252560
        stop time: 13.073272
        stop time: 13.075890
        stop time: 13.647631
        stop time: 13.393530
        stop time: 13.582012
        stop time: 13.610168
        stop time: 13.439481
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-7wvgl        643m         57Mi
        service1-7585bd9d88-tgjvh        428m         38Mi
        service2-84cffc954f-7mt2f        122m         11Mi
        ubuntu-client-76886f6bbd-q8fdk   22m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.25256, 13.073272, 13.07589, 13.647631, 13.39353, 13.582012, 13.610168, 13.439481]
    [exp] Throughput: 1494.2860741951886
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '209.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   469.72ms  413.25ms   2.69s    79.51%
        Req/Sec   145.64     68.31   292.00     69.15%
        Latency Distribution
        50%  343.48ms
        75%  679.43ms
        90%    1.15s
        99%    1.80s
        2979 requests in 3.03s, 462.56KB read
        Requests/sec:    983.73
        Transfer/sec:    152.75KB
        [run.sh] Speed is 983.73, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   461.15ms  479.53ms   3.48s    84.80%
        Req/Sec   147.87     83.94   535.00     67.26%
        Latency Distribution
        50%  280.83ms
        75%  625.49ms
        90%    1.10s
        99%    2.33s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 16.625536
        stop time: 16.925547
        stop time: 17.625676
        stop time: 17.328295
        stop time: 17.682842
        stop time: 17.517243
        stop time: 17.499939
        stop time: 17.602146
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-559cb467b4-jbp75        1333m        65Mi
        service1-cb57b799d-sbtz6         960m         44Mi
        service2-84cffc954f-s6m6r        1246m        18Mi
        ubuntu-client-76886f6bbd-vbk87   40m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.625536, 16.925547, 17.625676, 17.328295, 17.682842, 17.517243, 17.499939, 17.602146]
    [exp] Throughput: 1152.6777597684686
[test.py] Finished running 6th optmization experiment: groundtruth->1494.2860741951886, slowdown->1152.6777597684686, predicted->1519.6641116807236, err->1.6983386196116084
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.002919', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   336.27ms  250.50ms   1.59s    73.59%
        Req/Sec   182.82     79.28   420.00     70.54%
        Latency Distribution
        50%  248.01ms
        75%  474.35ms
        90%  723.35ms
        99%    1.08s
        4155 requests in 3.02s, 645.16KB read
        Requests/sec:   1374.66
        Transfer/sec:    213.45KB
        [run.sh] Speed is 1374.66, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   390.53ms  465.05ms   3.85s    86.57%
        Req/Sec   195.21     87.12   810.00     72.98%
        Latency Distribution
        50%  194.42ms
        75%  551.48ms
        90%    1.03s
        99%    2.03s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 12.606094
        stop time: 12.089922
        stop time: 13.113291
        stop time: 13.353387
        stop time: 13.485204
        stop time: 13.517588
        stop time: 13.171021
        stop time: 13.427282
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-cdm7n   2m           65Mi
        service1-7585bd9d88-q9hw2   2m           32Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.606094, 12.089922, 13.113291, 13.353387, 13.485204, 13.517588, 13.171021, 13.427282]
    [exp] Throughput: 1527.2452583783506
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '157.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   442.63ms  267.81ms   2.06s    71.23%
        Req/Sec   142.68     89.73   383.00     63.77%
        Latency Distribution
        50%  368.20ms
        75%  626.01ms
        90%  814.02ms
        99%    1.20s
        3219 requests in 3.03s, 499.83KB read
        Requests/sec:   1061.25
        Transfer/sec:    164.78KB
        [run.sh] Speed is 1061.25, duration is 28
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d28s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 28s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   463.40ms  521.34ms   3.43s    85.58%
        Req/Sec   155.31     79.23   818.00     69.53%
        Latency Distribution
        50%  244.17ms
        75%  546.20ms
        90%    1.24s
        99%    2.36s
        20000 requests in 28.00s, 3.03MB read
        Requests/sec:    714.28
        Transfer/sec:    110.91KB
        ------------------------------
        stop time: 15.206867
        stop time: 16.023384
        stop time: 15.647217
        stop time: 16.326883
        stop time: 16.468935
        stop time: 16.602872
        stop time: 16.751051
        stop time: 16.650808
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-854764b98f-7h9mh        1592m        65Mi
        service1-7cf689c479-pppj4        1048m        40Mi
        service2-84cffc954f-c5gch        1253m        17Mi
        ubuntu-client-76886f6bbd-8rfkf   35m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.206867, 16.023384, 15.647217, 16.326883, 16.468935, 16.602872, 16.751051, 16.650808]
    [exp] Throughput: 1233.8251594331518
[test.py] Finished running 7th optmization experiment: groundtruth->1527.2452583783506, slowdown->1233.8251594331518, predicted->1531.1412551781161, err->0.25509961667206743
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003336', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   404.61ms  388.72ms   2.53s    82.09%
        Req/Sec   174.03     77.72   393.00     69.26%
        Latency Distribution
        50%  245.15ms
        75%  636.90ms
        90%    1.04s
        99%    1.51s
        4029 requests in 3.03s, 625.60KB read
        Requests/sec:   1331.78
        Transfer/sec:    206.79KB
        [run.sh] Speed is 1331.78, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   386.06ms  467.46ms   3.72s    86.07%
        Req/Sec   192.78     90.34   777.00     74.00%
        Latency Distribution
        50%  174.61ms
        75%  531.13ms
        90%  994.23ms
        99%    2.20s
        20001 requests in 22.00s, 3.03MB read
        Requests/sec:    909.13
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.576755
        stop time: 12.829044
        stop time: 13.056688
        stop time: 13.209666
        stop time: 13.258323
        stop time: 13.261374
        stop time: 13.499848
        stop time: 13.608508
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [12.576755, 12.829044, 13.056688, 13.209666, 13.258323, 13.261374, 13.499848, 13.608508]
    [exp] Throughput: 1519.4652135818233
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '105.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   458.64ms  422.54ms   2.92s    85.67%
        Req/Sec   161.38     75.36   370.00     70.37%
        Latency Distribution
        50%  303.78ms
        75%  611.28ms
        90%    1.04s
        99%    2.09s
        3502 requests in 3.03s, 543.77KB read
        Requests/sec:   1155.25
        Transfer/sec:    179.38KB
        [run.sh] Speed is 1155.25, duration is 25
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d25s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 25s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   425.80ms  439.22ms   3.50s    86.63%
        Req/Sec   165.39     79.10   565.00     67.67%
        Latency Distribution
        50%  251.89ms
        75%  541.58ms
        90%    1.05s
        99%    2.10s
        20000 requests in 25.00s, 3.03MB read
        Requests/sec:    799.99
        Transfer/sec:    124.22KB
        ------------------------------
        stop time: 14.361070
        stop time: 15.216866
        stop time: 15.283853
        stop time: 15.605258
        stop time: 15.643594
        stop time: 15.599729
        stop time: 15.401186
        stop time: 15.592826
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-768756f486-6jt8n        1175m        67Mi
        service1-698c8454b8-n625r        649m         46Mi
        service2-84cffc954f-tr5wg        474m         29Mi
        ubuntu-client-76886f6bbd-slf2t   7m           17Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.36107, 15.216866, 15.283853, 15.605258, 15.643594, 15.599729, 15.401186, 15.592826]
    [exp] Throughput: 1303.946912018187
[test.py] Finished running 8th optmization experiment: groundtruth->1519.4652135818233, slowdown->1303.946912018187, predicted->1511.3790500684174, err->-0.5321716773195739
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.003753', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   339.74ms  321.74ms   2.07s    81.01%
        Req/Sec   175.03     79.99   380.00     67.26%
        Latency Distribution
        50%  215.89ms
        75%  513.22ms
        90%  824.61ms
        99%    1.37s
        3968 requests in 3.03s, 616.12KB read
        Requests/sec:   1308.98
        Transfer/sec:    203.25KB
        [run.sh] Speed is 1308.98, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   344.22ms  339.66ms   2.49s    83.53%
        Req/Sec   190.34     83.96   520.00     70.31%
        Latency Distribution
        50%  211.04ms
        75%  424.86ms
        90%  854.64ms
        99%    1.46s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.174588
        stop time: 13.044015
        stop time: 13.280860
        stop time: 13.500236
        stop time: 12.834784
        stop time: 13.510204
        stop time: 13.432484
        stop time: 13.590472
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.174588, 13.044015, 13.28086, 13.500236, 12.834784, 13.510204, 13.432484, 13.590472]
    [exp] Throughput: 1504.2168415821716
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '53.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   417.86ms  398.53ms   2.56s    82.63%
        Req/Sec   173.92     81.48   430.00     66.67%
        Latency Distribution
        50%  280.94ms
        75%  611.30ms
        90%  949.67ms
        99%    1.77s
        3790 requests in 3.03s, 588.49KB read
        Requests/sec:   1251.23
        Transfer/sec:    194.28KB
        [run.sh] Speed is 1251.23, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   418.16ms  488.99ms   3.79s    85.05%
        Req/Sec   179.45     86.21     0.96k    75.25%
        Latency Distribution
        50%  199.24ms
        75%  602.31ms
        90%    1.16s
        99%    2.08s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.169886
        stop time: 14.385791
        stop time: 14.270174
        stop time: 14.142700
        stop time: 14.588219
        stop time: 14.547679
        stop time: 14.070393
        stop time: 14.063862
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-59d54698d4-l4dxv        197m         64Mi
        service1-569f565446-l7zwb        1m           47Mi
        service2-84cffc954f-fvd7s        479m         23Mi
        ubuntu-client-76886f6bbd-4g87t   21m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.169886, 14.385791, 14.270174, 14.1427, 14.588219, 14.547679, 14.070393, 14.063862]
    [exp] Throughput: 1412.9444646417005
[test.py] Finished running 9th optmization experiment: groundtruth->1504.2168415821716, slowdown->1412.9444646417005, predicted->1527.6227028564556, err->1.5560164350816041
[test.py] Baseline throughput:  1518.1523099588799
[test.py] Groundtruth:  [1541.0972147913778, 1515.5039846388515, 1514.4392411046524, 1508.014891797858, 1532.1299231619605, 1511.7622329839328, 1494.2860741951886, 1527.2452583783506, 1519.4652135818233, 1504.2168415821716]
[test.py] Slowdown:  [842.3247996004011, 877.9975728854594, 928.8401134046438, 988.1573601810912, 1025.6066612434724, 1087.9046764867605, 1152.6777597684686, 1233.8251594331518, 1303.946912018187, 1412.9444646417005]
[test.py] Predicted:  [1503.9052659994843, 1495.15872277935, 1518.3571899038473, 1547.737082148593, 1512.224058450787, 1520.7548487201075, 1519.6641116807236, 1531.1412551781161, 1511.3790500684174, 1527.6227028564556]
[test.py] Error percentage:  [-2.413342158750725, -1.342474982957558, 0.25870623877502286, 2.634071491388134, -1.2992282449580028, 0.5948432590768564, 1.6983386196116084, 0.25509961667206743, -0.5321716773195739, 1.5560164350816041]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 1...
[test.py] Actual processing time range: [0, 417, 834, 1251, 1668, 2085, 2502, 2919, 3336, 3753]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   402.91ms  430.57ms   2.48s    85.59%
        Req/Sec   189.16     77.44   404.00     69.91%
        Latency Distribution
        50%  228.49ms
        75%  583.57ms
        90%    1.02s
        99%    1.89s
        4104 requests in 3.02s, 637.24KB read
        Requests/sec:   1356.72
        Transfer/sec:    210.66KB
        [run.sh] Speed is 1356.72, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   408.90ms  528.28ms   3.54s    84.36%
        Req/Sec   196.00     95.27   808.00     74.50%
        Latency Distribution
        50%  151.64ms
        75%  593.05ms
        90%    1.21s
        99%    2.29s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 11.605919
        stop time: 13.072187
        stop time: 13.152064
        stop time: 13.487619
        stop time: 13.562946
        stop time: 12.911615
        stop time: 13.513041
        stop time: 13.143487
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-5stlp        2m           65Mi
        service1-7585bd9d88-p52vd        1m           42Mi
        service2-84cffc954f-5sxb8        1m           23Mi
        ubuntu-client-76886f6bbd-v5rcl   14m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.605919, 13.072187, 13.152064, 13.487619, 13.562946, 12.911615, 13.513041, 13.143487]
    [exp] Throughput: 1531.8498682197428
[test.py] Baseline throughput: 1531.8498682197428
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   326.39ms  157.80ms   1.00s    67.00%
        Req/Sec   188.06     75.19   360.00     68.81%
        Latency Distribution
        50%  302.41ms
        75%  425.33ms
        90%  549.99ms
        99%  790.21ms
        4162 requests in 3.02s, 646.25KB read
        Requests/sec:   1377.98
        Transfer/sec:    213.96KB
        [run.sh] Speed is 1377.98, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   362.14ms  378.62ms   2.64s    85.21%
        Req/Sec   192.30     82.03   510.00     67.61%
        Latency Distribution
        50%  196.94ms
        75%  510.96ms
        90%  896.02ms
        99%    1.73s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.370076
        stop time: 12.677117
        stop time: 13.375056
        stop time: 13.146507
        stop time: 13.669202
        stop time: 13.568702
        stop time: 13.583385
        stop time: 13.259449
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-mp5kj        636m         68Mi
        service1-7585bd9d88-fzx84        421m         37Mi
        service2-84cffc954f-qrcbs        23m          9Mi
        ubuntu-client-76886f6bbd-v9lv7   12m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.370076, 12.677117, 13.375056, 13.146507, 13.669202, 13.568702, 13.583385, 13.259449]
    [exp] Throughput: 1500.2415295097412
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '522.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   593.87ms  419.17ms   2.33s    68.19%
        Req/Sec   131.98     94.23   424.00     61.54%
        Latency Distribution
        50%  503.04ms
        75%  798.68ms
        90%    1.28s
        99%    2.00s
        2346 requests in 3.03s, 364.27KB read
        Requests/sec:    775.40
        Transfer/sec:    120.40KB
        [run.sh] Speed is 775.40, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74576c5f89-q8tnv        1094m        68Mi
        service1-57cdc6957f-44gh8        740m         44Mi
        service2-84cffc954f-rq2n4        867m         16Mi
        ubuntu-client-76886f6bbd-4q62h   30m          23Mi
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   642.23ms  610.39ms   4.19s    84.18%
        Req/Sec   124.64     82.92   440.00     62.50%
        Latency Distribution
        50%  435.42ms
        75%  904.22ms
        90%    1.47s
        99%    2.90s
        20000 requests in 38.00s, 3.03MB read
        Requests/sec:    526.31
        Transfer/sec:     81.72KB
        ------------------------------
        stop time: 23.257973
        stop time: 24.125139
        stop time: 23.359774
        stop time: 23.926130
        stop time: 23.990747
        stop time: 24.106609
        stop time: 24.092517
        stop time: 23.598395
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [23.257973, 24.125139, 23.359774, 23.92613, 23.990747, 24.106609, 24.092517, 23.598395]
    [exp] Throughput: 840.0833858367948
[test.py] Finished running 0th optmization experiment: groundtruth->1500.2415295097412, slowdown->840.0833858367948, predicted->1496.775141827864, err->-0.23105530767502425
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000417', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   380.97ms  315.48ms   1.83s    83.83%
        Req/Sec   178.66     84.56   393.00     69.41%
        Latency Distribution
        50%  290.70ms
        75%  507.28ms
        90%  784.98ms
        99%    1.48s
        3985 requests in 3.04s, 618.76KB read
        Requests/sec:   1312.24
        Transfer/sec:    203.76KB
        [run.sh] Speed is 1312.24, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   368.92ms  425.78ms   2.92s    84.65%
        Req/Sec   192.47     86.01   610.00     68.85%
        Latency Distribution
        50%  171.31ms
        75%  519.79ms
        90%    1.04s
        99%    1.83s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.269164
        stop time: 12.787019
        stop time: 12.956055
        stop time: 13.613011
        stop time: 13.604557
        stop time: 13.088502
        stop time: 13.630945
        stop time: 13.512665
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-7585bd9d88-g5q2q   2m           3Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.269164, 12.787019, 12.956055, 13.613011, 13.604557, 13.088502, 13.630945, 13.512665]
    [exp] Throughput: 1517.1353132416955
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '470.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   589.20ms  332.83ms   2.71s    75.38%
        Req/Sec   109.50     73.90   300.00     62.94%
        Latency Distribution
        50%  506.25ms
        75%  765.63ms
        90%    1.03s
        99%    1.65s
        2147 requests in 3.03s, 333.37KB read
        Requests/sec:    709.39
        Transfer/sec:    110.15KB
        [run.sh] Speed is 709.39, duration is 42
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d42s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f77f7cb57-hfmf4        337m         73Mi
        service1-9d4b979b7-t9d98         123m         40Mi
        service2-84cffc954f-28cp8        850m         12Mi
        ubuntu-client-76886f6bbd-8hc2c   19m          19Mi
        Running 42s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   610.62ms  611.27ms   5.21s    85.61%
        Req/Sec   123.78     86.61   626.00     69.52%
        Latency Distribution
        50%  397.52ms
        75%  778.54ms
        90%    1.54s
        99%    2.70s
        20000 requests in 42.00s, 3.03MB read
        Requests/sec:    476.19
        Transfer/sec:     73.94KB
        ------------------------------
        stop time: 22.909140
        stop time: 22.882399
        stop time: 22.487529
        stop time: 22.969429
        stop time: 23.203746
        stop time: 23.289411
        stop time: 22.460132
        stop time: 22.966586
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [22.90914, 22.882399, 22.487529, 22.969429, 23.203746, 23.289411, 22.460132, 22.966586]
    [exp] Throughput: 873.513250420766
[test.py] Finished running 1th optmization experiment: groundtruth->1517.1353132416955, slowdown->873.513250420766, predicted->1482.2010077262323, err->-2.3026492897867024
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.000834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   313.14ms  253.01ms   1.46s    79.03%
        Req/Sec   183.04     87.92   515.00     74.12%
        Latency Distribution
        50%  223.13ms
        75%  442.25ms
        90%  663.02ms
        99%    1.19s
        4178 requests in 3.03s, 648.73KB read
        Requests/sec:   1377.65
        Transfer/sec:    213.91KB
        [run.sh] Speed is 1377.65, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   396.95ms  492.62ms   3.76s    84.32%
        Req/Sec   194.36     97.89     1.32k    74.24%
        Latency Distribution
        50%  168.06ms
        75%  550.42ms
        90%    1.16s
        99%    2.05s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.058455
        stop time: 12.422824
        stop time: 12.563450
        stop time: 12.621434
        stop time: 13.290654
        stop time: 13.338610
        stop time: 13.367107
        stop time: 13.565395
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-flz5n        164m         64Mi
        service1-7585bd9d88-b5v85        302m         36Mi
        service2-84cffc954f-tvsm8        1m           12Mi
        ubuntu-client-76886f6bbd-knlq6   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.058455, 12.422824, 12.56345, 12.621434, 13.290654, 13.33861, 13.367107, 13.565395]
    [exp] Throughput: 1535.0971811020058
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '418.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   550.43ms  316.79ms   1.67s    67.90%
        Req/Sec   124.72     81.08   292.00     59.65%
        Latency Distribution
        50%  509.33ms
        75%  741.47ms
        90%    1.06s
        99%    1.30s
        2437 requests in 3.03s, 378.40KB read
        Requests/sec:    803.81
        Transfer/sec:    124.81KB
        [run.sh] Speed is 803.81, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-64686d547f-ph2ft        390m         69Mi
        service1-cdd6b68cc-lp4rt         120m         37Mi
        service2-84cffc954f-8mn7q        333m         11Mi
        ubuntu-client-76886f6bbd-qzsx6   20m          0Mi
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   596.76ms  606.12ms   6.15s    87.77%
        Req/Sec   127.47     79.06   420.00     65.00%
        Latency Distribution
        50%  410.74ms
        75%  766.46ms
        90%    1.36s
        99%    2.83s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 21.134406
        stop time: 21.317893
        stop time: 21.134367
        stop time: 22.150976
        stop time: 21.990528
        stop time: 22.179660
        stop time: 21.831339
        stop time: 22.179397
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.134406, 21.317893, 21.134367, 22.150976, 21.990528, 22.17966, 21.831339, 22.179397]
    [exp] Throughput: 919.9707867876509
[test.py] Finished running 2th optmization experiment: groundtruth->1535.0971811020058, slowdown->919.9707867876509, predicted->1494.7995084277077, err->-2.6250893539762425
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001251', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-b6fl7 cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   354.38ms  220.29ms   1.63s    69.68%
        Req/Sec   173.84    116.71   494.00     66.23%
        Latency Distribution
        50%  293.62ms
        75%  474.07ms
        90%  680.56ms
        99%  938.90ms
        4058 requests in 3.03s, 630.10KB read
        Requests/sec:   1338.41
        Transfer/sec:    207.82KB
        [run.sh] Speed is 1338.41, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   391.98ms  484.16ms   3.77s    86.61%
        Req/Sec   194.38     89.65   555.00     70.49%
        Latency Distribution
        50%  184.26ms
        75%  485.39ms
        90%    1.05s
        99%    2.20s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 11.688176
        stop time: 12.805310
        stop time: 13.528901
        stop time: 13.503480
        stop time: 13.038163
        stop time: 13.431782
        stop time: 13.341749
        stop time: 13.259163
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-b6fl7        1861m        65Mi
        service1-7585bd9d88-nlvxm        1296m        37Mi
        service2-84cffc954f-87nqg        206m         10Mi
        ubuntu-client-76886f6bbd-l82rn   43m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [11.688176, 12.80531, 13.528901, 13.50348, 13.038163, 13.431782, 13.341749, 13.259163]
    [exp] Throughput: 1529.6846199504298
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.00417804', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '365.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b565f6b89-nx6ks cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   447.48ms  313.99ms   1.56s    69.54%
        Req/Sec   131.49     99.83   414.00     62.86%
        Latency Distribution
        50%  407.83ms
        75%  622.55ms
        90%  820.89ms
        99%    1.41s
        2557 requests in 3.03s, 397.03KB read
        Requests/sec:    845.09
        Transfer/sec:    131.22KB
        [run.sh] Speed is 845.09, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service2-84cffc954f-4cj5t   2m           3Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   589.77ms  686.30ms   5.31s    85.74%
        Req/Sec   128.23     75.25   710.00     67.90%
        Latency Distribution
        50%  313.54ms
        75%  796.96ms
        90%    1.55s
        99%    3.03s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 20.170575
        stop time: 20.536395
        stop time: 20.587293
        stop time: 20.071835
        stop time: 20.835106
        stop time: 21.172077
        stop time: 20.370088
        stop time: 20.890261
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [20.170575, 20.536395, 20.587293, 20.071835, 20.835106, 21.172077, 20.370088, 20.890261]
    [exp] Throughput: 971.8548998767748
[test.py] Finished running 3th optmization experiment: groundtruth->1529.6846199504298, slowdown->971.8548998767748, predicted->1508.1132249936209, err->-1.4101857778702107
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00106169', 'PROCESSING_TIME_SERVICE1': '0.00069609', 'PROCESSING_TIME_SERVICE2': '0.001668', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-r5dgv cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   381.56ms  340.96ms   1.68s    82.02%
        Req/Sec   180.22     91.04   494.00     72.40%
        Latency Distribution
        50%  253.09ms
        75%  504.27ms
        90%  943.56ms
        99%    1.44s
        4035 requests in 3.02s, 626.53KB read
        Requests/sec:   1334.94
        Transfer/sec:    207.28KB
        [run.sh] Speed is 1334.94, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   368.87ms  394.48ms   2.52s    86.56%
        Req/Sec   191.76     93.28   680.00     70.90%
        Latency Distribution
        50%  211.59ms
        75%  506.61ms
        90%  862.26ms
        99%    1.89s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.443810
        stop time: 12.466175
        stop time: 13.419582
        stop time: 13.536762
        stop time: 13.593102
        stop time: 13.356159
        stop time: 13.462031
        stop time: 13.269582
