[config.py] Random numbers for execution time: [387.0230605843116, 801.8589887679466, 1121.3077728304881]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service1
request_type                     : dynamic-cache-http-async
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 13755
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.25}
baseline_service_processing_time : {'service0': 1121.31, 'service1': 801.86, 'service2': 1548.09}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2}
target_processing_time_range     : [0, 801.86]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 80, 160, 240, 320, 400, 480, 560, 640, 720]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        configmap "config-service1" deleted
        configmap "config-service2" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   375.85ms  297.35ms   1.60s    72.01%
        Req/Sec   185.82     91.73   360.00     62.50%
        Latency Distribution
        50%  340.42ms
        75%  526.10ms
        90%  816.29ms
        99%    1.35s
        3940 requests in 3.03s, 611.78KB read
        Requests/sec:   1301.17
        Transfer/sec:    202.04KB
        [run.sh] Speed is 1301.17, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   354.38ms  281.09ms   2.07s    70.43%
        Req/Sec   185.29     98.02   580.00     67.88%
        Latency Distribution
        50%  290.64ms
        75%  507.27ms
        90%  745.38ms
        99%    1.19s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.549849
        stop time: 14.190760
        stop time: 13.943885
        stop time: 13.667971
        stop time: 13.891086
        stop time: 14.148278
        stop time: 14.221723
        stop time: 14.135337
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-p9kpg        2m           70Mi
        service1-7755b7b4b5-rhvx8        1m           38Mi
        service2-958786d58-gtphg         1m           11Mi
        ubuntu-client-76886f6bbd-rbpnz   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.549849, 14.19076, 13.943885, 13.667971, 13.891086, 14.148278, 14.221723, 14.135337]
    [exp] Throughput: 1431.7815723429699
[test.py] Baseline throughput: 1431.7815723429699
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-wgssz cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   349.29ms  270.71ms   1.55s    68.68%
        Req/Sec   179.40     98.04   490.00     66.98%
        Latency Distribution
        50%  287.55ms
        75%  549.72ms
        90%  684.14ms
        99%    1.16s
        3952 requests in 3.02s, 613.64KB read
        Requests/sec:   1307.81
        Transfer/sec:    203.07KB
        [run.sh] Speed is 1307.81, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   386.22ms  377.25ms   2.85s    86.46%
        Req/Sec   184.65    101.29   646.00     71.13%
        Latency Distribution
        50%  282.62ms
        75%  541.07ms
        90%  857.11ms
        99%    1.88s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.027227
        stop time: 13.748143
        stop time: 14.153092
        stop time: 13.812159
        stop time: 14.006392
        stop time: 14.234298
        stop time: 14.080114
        stop time: 14.336616
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-wgssz        631m         63Mi
        service1-7755b7b4b5-j2hwh        108m         28Mi
        service2-958786d58-pw6kl         200m         10Mi
        ubuntu-client-76886f6bbd-2v9rq   24m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [14.027227, 13.748143, 14.153092, 13.812159, 14.006392, 14.234298, 14.080114, 14.336616]
    [exp] Throughput: 1423.5123546325865
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '400.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1603.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   560.94ms  479.90ms   2.28s    69.43%
        Req/Sec   127.73     71.95   280.00     58.33%
        Latency Distribution
        50%  484.68ms
        75%  847.28ms
        90%    1.21s
        99%    1.85s
        2334 requests in 3.03s, 362.41KB read
        Requests/sec:    771.16
        Transfer/sec:    119.74KB
        [run.sh] Speed is 771.16, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-788678d7df-76hrq        1260m        67Mi
        service1-7755b7b4b5-cljm6        781m         46Mi
        service2-7cbc657d97-p6c9k        411m         22Mi
        ubuntu-client-76886f6bbd-2cstd   33m          22Mi
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   589.83ms  634.65ms   4.42s    86.90%
        Req/Sec   123.67     81.29   480.00     67.04%
        Latency Distribution
        50%  396.23ms
        75%  811.46ms
        90%    1.48s
        99%    2.95s
        20001 requests in 38.00s, 3.03MB read
        Requests/sec:    526.34
        Transfer/sec:     81.73KB
        ------------------------------
        stop time: 20.462930
        stop time: 20.518226
        stop time: 21.294282
        stop time: 21.543901
        stop time: 22.041496
        stop time: 22.195326
        stop time: 22.119901
        stop time: 21.960122
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.46293, 20.518226, 21.294282, 21.543901, 22.041496, 22.195326, 22.119901, 21.960122]
    [exp] Throughput: 929.4966129840544
[test.py] Finished running 0th optmization experiment: groundtruth->1423.5123546325865, slowdown->929.4966129840544, predicted->1481.654560684607, err->4.084418787290911
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '8e-05', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   356.53ms  224.50ms   1.41s    65.78%
        Req/Sec   184.41    116.35   530.00     65.89%
        Latency Distribution
        50%  313.55ms
        75%  494.75ms
        90%  633.14ms
        99%  950.09ms
        3963 requests in 3.03s, 615.35KB read
        Requests/sec:   1309.64
        Transfer/sec:    203.35KB
        [run.sh] Speed is 1309.64, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   376.19ms  364.47ms   3.22s    86.05%
        Req/Sec   182.81     86.94   670.00     68.66%
        Latency Distribution
        50%  265.42ms
        75%  541.25ms
        90%  830.73ms
        99%    1.68s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.725818
        stop time: 13.358126
        stop time: 13.987704
        stop time: 13.782087
        stop time: 14.128696
        stop time: 14.242089
        stop time: 14.097203
        stop time: 14.158001
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-v5hmn   2m           52Mi
        service1-7755b7b4b5-767mk   26m          25Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.725818, 13.358126, 13.987704, 13.782087, 14.128696, 14.242089, 14.097203, 14.158001]
    [exp] Throughput: 1435.2385730700228
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '360.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1443.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   433.00ms  321.07ms   1.67s    63.04%
        Req/Sec   126.84     84.18   353.00     63.54%
        Latency Distribution
        50%  389.51ms
        75%  668.62ms
        90%  872.97ms
        99%    1.32s
        2511 requests in 3.02s, 389.89KB read
        Requests/sec:    831.60
        Transfer/sec:    129.13KB
        [run.sh] Speed is 831.60, duration is 36
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d36s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d789b6d66-m4rtb        1319m        65Mi
        service1-7755b7b4b5-fg8dg        390m         32Mi
        service2-55fb5cdf7f-jjxzn        225m         10Mi
        ubuntu-client-76886f6bbd-h2pvp   34m          18Mi
        Running 36s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   530.75ms  341.50ms   2.37s    68.00%
        Req/Sec   125.93     77.00   383.00     68.65%
        Latency Distribution
        50%  485.63ms
        75%  723.42ms
        90%  968.64ms
        99%    1.67s
        20001 requests in 36.00s, 3.03MB read
        Requests/sec:    555.58
        Transfer/sec:     86.27KB
        ------------------------------
        stop time: 20.946301
        stop time: 21.257898
        stop time: 21.141553
        stop time: 21.189153
        stop time: 21.137962
        stop time: 21.105996
        stop time: 20.912913
        stop time: 21.173960
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.946301, 21.257898, 21.141553, 21.189153, 21.137962, 21.105996, 20.912913, 21.17396]
    [exp] Throughput: 947.4983130976908
[test.py] Finished running 1th optmization experiment: groundtruth->1435.2385730700228, slowdown->947.4983130976908, predicted->1439.9245133973097, err->0.3264920839790133
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00016', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   390.07ms  360.67ms   2.25s    83.52%
        Req/Sec   184.62     91.61   444.00     66.98%
        Latency Distribution
        50%  245.93ms
        75%  526.77ms
        90%  880.08ms
        99%    1.64s
        4080 requests in 3.02s, 633.52KB read
        Requests/sec:   1351.71
        Transfer/sec:    209.88KB
        [run.sh] Speed is 1351.71, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   405.18ms  465.11ms   3.21s    86.16%
        Req/Sec   185.25    101.40   717.00     73.73%
        Latency Distribution
        50%  222.56ms
        75%  586.13ms
        90%    1.11s
        99%    1.97s
        20001 requests in 22.00s, 3.03MB read
        Requests/sec:    909.13
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.639829
        stop time: 14.014749
        stop time: 13.633735
        stop time: 14.009295
        stop time: 13.907948
        stop time: 14.137534
        stop time: 13.783858
        stop time: 13.710912
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.639829, 14.014749, 13.633735, 14.009295, 13.907948, 14.137534, 13.783858, 13.710912]
    [exp] Throughput: 1443.5500649326864
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '320.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1283.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   504.31ms  295.19ms   1.40s    68.11%
        Req/Sec   125.10     78.74   400.00     63.58%
        Latency Distribution
        50%  489.03ms
        75%  718.78ms
        90%  888.57ms
        99%    1.23s
        2593 requests in 3.02s, 402.62KB read
        Requests/sec:    858.92
        Transfer/sec:    133.37KB
        [run.sh] Speed is 858.92, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   568.57ms  613.94ms   4.21s    88.64%
        Req/Sec   138.64     76.99   757.00     67.70%
        Latency Distribution
        50%  345.47ms
        75%  765.70ms
        90%    1.27s
        99%    2.84s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 20.143642
        stop time: 20.229980
        stop time: 20.074500
        stop time: 20.017677
        stop time: 20.186135
        stop time: 20.464176
        stop time: 20.271856
        stop time: 20.389652
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d5685b766-9wrwn        627m         69Mi
        service1-7755b7b4b5-7twcm        314m         35Mi
        service2-6f89f64dfc-cn96f        101m         13Mi
        ubuntu-client-76886f6bbd-g7ss7   6m           16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.143642, 20.22998, 20.0745, 20.017677, 20.186135, 20.464176, 20.271856, 20.389652]
    [exp] Throughput: 989.0119657961584
[test.py] Finished running 2th optmization experiment: groundtruth->1443.5500649326864, slowdown->989.0119657961584, predicted->1448.897152915283, err->0.3704123682642011
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00024', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   352.69ms  310.94ms   2.05s    75.96%
        Req/Sec   187.60    103.12   500.00     70.73%
        Latency Distribution
        50%  265.04ms
        75%  519.79ms
        90%  795.08ms
        99%    1.39s
        4026 requests in 3.02s, 625.13KB read
        Requests/sec:   1330.96
        Transfer/sec:    206.66KB
        [run.sh] Speed is 1330.96, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   372.19ms  363.89ms   2.83s    86.07%
        Req/Sec   181.59     98.43   575.00     71.72%
        Latency Distribution
        50%  259.73ms
        75%  529.86ms
        90%  815.95ms
        99%    1.72s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.688848
        stop time: 13.812639
        stop time: 13.609128
        stop time: 14.066467
        stop time: 13.949444
        stop time: 14.153744
        stop time: 13.945908
        stop time: 14.174621
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-gkpdz        461m         68Mi
        service1-7755b7b4b5-gp5jp        21m          28Mi
        service2-958786d58-8rdlq         1m           9Mi
        ubuntu-client-76886f6bbd-kvnns   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.688848, 13.812639, 13.609128, 14.066467, 13.949444, 14.153744, 13.945908, 14.174621]
    [exp] Throughput: 1436.255407827012
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '280.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1123.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   669.42ms  309.52ms   1.76s    70.36%
        Req/Sec    98.69     75.72   340.00     72.39%
        Latency Distribution
        50%  658.62ms
        75%  896.66ms
        90%    1.00s
        99%    1.54s
        1852 requests in 3.03s, 287.57KB read
        Requests/sec:    611.21
        Transfer/sec:     94.90KB
        [run.sh] Speed is 611.21, duration is 49
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d49s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-75ddd887-9hmnv          255m         62Mi
        service1-7755b7b4b5-l92jt        244m         31Mi
        service2-dc56fbc74-sc45q         107m         8Mi
        ubuntu-client-76886f6bbd-gw8kc   14m          0Mi
        Running 49s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   490.16ms  417.33ms   3.21s    76.19%
        Req/Sec   137.82     85.16   464.00     66.64%
        Latency Distribution
        50%  421.20ms
        75%  685.35ms
        90%  990.47ms
        99%    1.98s
        20000 requests in 49.00s, 3.03MB read
        Requests/sec:    408.16
        Transfer/sec:     63.38KB
        ------------------------------
        stop time: 19.214542
        stop time: 19.205539
        stop time: 19.535671
        stop time: 19.461295
        stop time: 19.681368
        stop time: 19.192979
        stop time: 19.490562
        stop time: 19.250670
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.214542, 19.205539, 19.535671, 19.461295, 19.681368, 19.192979, 19.490562, 19.25067]
    [exp] Throughput: 1032.0408299089252
[test.py] Finished running 3th optmization experiment: groundtruth->1436.255407827012, slowdown->1032.0408299089252, predicted->1453.4378556210427, err->1.1963365081442492
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00032', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   377.38ms  352.74ms   1.82s    76.67%
        Req/Sec   174.30     75.98   420.00     68.10%
        Latency Distribution
        50%  264.97ms
        75%  564.01ms
        90%  875.63ms
        99%    1.48s
        4086 requests in 3.03s, 634.45KB read
        Requests/sec:   1350.42
        Transfer/sec:    209.68KB
        [run.sh] Speed is 1350.42, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   413.65ms  476.12ms   4.55s    88.48%
        Req/Sec   184.50     97.85   620.00     74.88%
        Latency Distribution
        50%  239.52ms
        75%  551.87ms
        90%  994.53ms
        99%    2.31s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.992422
        stop time: 13.967379
        stop time: 13.602498
        stop time: 14.169579
        stop time: 14.309819
        stop time: 13.737815
        stop time: 14.176768
        stop time: 13.576909
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-6lpnp        318m         63Mi
        service1-7755b7b4b5-54248        261m         31Mi
        service2-958786d58-wgddp         282m         9Mi
        ubuntu-client-76886f6bbd-r8qnm   37m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.992422, 13.967379, 13.602498, 14.169579, 14.309819, 13.737815, 14.176768, 13.576909]
    [exp] Throughput: 1434.5505713102134
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '240.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '963.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   483.55ms  234.46ms   1.39s    68.97%
        Req/Sec   135.13    107.23   424.00     71.51%
        Latency Distribution
        50%  477.98ms
        75%  611.51ms
        90%  765.48ms
        99%    1.13s
        2714 requests in 3.02s, 421.41KB read
        Requests/sec:    899.13
        Transfer/sec:    139.61KB
        [run.sh] Speed is 899.13, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   488.31ms  463.45ms   4.22s    83.18%
        Req/Sec   140.53     77.12   470.00     68.85%
        Latency Distribution
        50%  391.55ms
        75%  668.19ms
        90%    1.04s
        99%    2.11s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 17.596763
        stop time: 18.285727
        stop time: 18.399797
        stop time: 18.492409
        stop time: 18.496179
        stop time: 18.794251
        stop time: 18.763215
        stop time: 18.383519
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [17.596763, 18.285727, 18.399797, 18.492409, 18.496179, 18.794251, 18.763215, 18.383519]
    [exp] Throughput: 1086.8689519988402
[test.py] Finished running 4th optmization experiment: groundtruth->1434.5505713102134, slowdown->1086.8689519988402, predicted->1472.441508641483, err->2.6413106717222865
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0004', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   353.14ms  224.14ms   1.26s    65.36%
        Req/Sec   180.07    104.17   434.00     64.60%
        Latency Distribution
        50%  353.03ms
        75%  471.06ms
        90%  648.76ms
        99%  955.27ms
        4066 requests in 3.03s, 631.34KB read
        Requests/sec:   1341.94
        Transfer/sec:    208.37KB
        [run.sh] Speed is 1341.94, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   387.08ms  390.00ms   3.62s    88.02%
        Req/Sec   182.59    100.03   660.00     70.70%
        Latency Distribution
        50%  265.09ms
        75%  520.42ms
        90%  836.90ms
        99%    1.93s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.015685
        stop time: 13.545206
        stop time: 13.663711
        stop time: 13.655895
        stop time: 14.115772
        stop time: 14.276513
        stop time: 14.107659
        stop time: 14.037747
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-vctc9        650m         69Mi
        service1-7755b7b4b5-f957w        202m         30Mi
        service2-958786d58-5l4mc         94m          9Mi
        ubuntu-client-76886f6bbd-sdn5n   2m           14Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.015685, 13.545206, 13.663711, 13.655895, 14.115772, 14.276513, 14.107659, 14.037747]
    [exp] Throughput: 1436.0312519173262
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '200.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '803.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   443.31ms  217.61ms   1.21s    66.20%
        Req/Sec   145.62    107.00   450.00     61.05%
        Latency Distribution
        50%  435.05ms
        75%  581.77ms
        90%  709.46ms
        99%    1.03s
        2926 requests in 3.03s, 454.33KB read
        Requests/sec:    967.26
        Transfer/sec:    150.19KB
        [run.sh] Speed is 967.26, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   524.99ms  634.61ms   5.11s    85.55%
        Req/Sec   151.01     77.59   500.00     68.74%
        Latency Distribution
        50%  236.89ms
        75%  774.41ms
        90%    1.45s
        99%    2.76s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 17.782311
        stop time: 17.958253
        stop time: 17.138751
        stop time: 17.221757
        stop time: 17.498430
        stop time: 17.894406
        stop time: 17.764973
        stop time: 18.022041
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-9994fb58c-gp5np         792m         66Mi
        service1-7755b7b4b5-cnxc2        358m         32Mi
        service2-559ddfcfcb-99wx7        120m         10Mi
        ubuntu-client-76886f6bbd-ptscq   4m           22Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.782311, 17.958253, 17.138751, 17.221757, 17.49843, 17.894406, 17.764973, 18.022041]
    [exp] Throughput: 1132.4954405379658
[test.py] Finished running 5th optmization experiment: groundtruth->1436.0312519173262, slowdown->1132.4954405379658, predicted->1466.1127912458255, err->2.0947691276450784
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   332.64ms  348.60ms   1.80s    84.31%
        Req/Sec   183.06     82.97   434.00     69.44%
        Latency Distribution
        50%  193.00ms
        75%  499.63ms
        90%  806.54ms
        99%    1.54s
        3960 requests in 3.02s, 614.88KB read
        Requests/sec:   1311.13
        Transfer/sec:    203.58KB
        [run.sh] Speed is 1311.13, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   394.62ms  431.89ms   2.32s    85.32%
        Req/Sec   182.38     88.22   595.00     70.58%
        Latency Distribution
        50%  223.19ms
        75%  564.08ms
        90%    1.06s
        99%    1.81s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.051365
        stop time: 13.399044
        stop time: 14.054335
        stop time: 13.893043
        stop time: 14.062583
        stop time: 13.714998
        stop time: 13.475561
        stop time: 14.115631
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-9kfwh        618m         59Mi
        service1-7755b7b4b5-7tcvv        318m         35Mi
        service2-958786d58-9z9lm         211m         12Mi
        ubuntu-client-76886f6bbd-tzntj   21m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.051365, 13.399044, 14.054335, 13.893043, 14.062583, 13.714998, 13.475561, 14.115631]
    [exp] Throughput: 1444.47927244468
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '160.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '643.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   419.13ms  257.83ms   1.62s    68.37%
        Req/Sec   145.90     98.09   480.00     67.42%
        Latency Distribution
        50%  401.80ms
        75%  560.75ms
        90%  735.82ms
        99%    1.10s
        3253 requests in 3.02s, 505.10KB read
        Requests/sec:   1078.34
        Transfer/sec:    167.44KB
        [run.sh] Speed is 1078.34, duration is 27
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d27s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 27s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   467.86ms  457.76ms   3.24s    87.35%
        Req/Sec   154.10     86.09   540.00     70.74%
        Latency Distribution
        50%  332.93ms
        75%  598.31ms
        90%    1.05s
        99%    2.29s
        20000 requests in 27.00s, 3.03MB read
        Requests/sec:    740.74
        Transfer/sec:    115.02KB
        ------------------------------
        stop time: 16.090747
        stop time: 16.269969
        stop time: 17.327035
        stop time: 17.329687
        stop time: 16.777287
        stop time: 16.957587
        stop time: 17.086265
        stop time: 17.413196
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f464877cb-grvxg         1593m        68Mi
        service1-7755b7b4b5-kztm6        957m         31Mi
        service2-756d446d74-xh2p4        410m         9Mi
        ubuntu-client-76886f6bbd-mxtgx   28m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.090747, 16.269969, 17.327035, 17.329687, 16.777287, 16.957587, 17.086265, 17.413196]
    [exp] Throughput: 1182.9789469746913
[test.py] Finished running 6th optmization experiment: groundtruth->1444.47927244468, slowdown->1182.9789469746913, predicted->1461.147543455281, err->1.153929400620003
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00056', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   363.85ms  240.65ms   1.70s    66.25%
        Req/Sec   183.86    122.45   444.00     55.61%
        Latency Distribution
        50%  317.76ms
        75%  503.71ms
        90%  702.42ms
        99%    1.02s
        3965 requests in 3.02s, 615.66KB read
        Requests/sec:   1312.27
        Transfer/sec:    203.76KB
        [run.sh] Speed is 1312.27, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   384.08ms  410.06ms   4.17s    87.16%
        Req/Sec   187.42     97.53   585.00     70.41%
        Latency Distribution
        50%  247.40ms
        75%  546.47ms
        90%  903.41ms
        99%    1.85s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.228993
        stop time: 13.464189
        stop time: 13.502922
        stop time: 14.013712
        stop time: 13.824462
        stop time: 14.129002
        stop time: 14.119950
        stop time: 14.134918
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-bng62        2m           70Mi
        service1-7755b7b4b5-q26pg        2m           34Mi
        service2-958786d58-7fx5c         2m           11Mi
        ubuntu-client-76886f6bbd-7rlgg   11m          11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.228993, 13.464189, 13.502922, 14.013712, 13.824462, 14.129002, 14.11995, 14.134918]
    [exp] Throughput: 1449.0371637097192
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '120.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '483.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-5bf5bf77b8-v9qnj cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   417.37ms  321.52ms   2.10s    66.41%
        Req/Sec   144.97     82.59   410.00     65.50%
        Latency Distribution
        50%  345.81ms
        75%  613.55ms
        90%  892.29ms
        99%    1.36s
        3360 requests in 3.03s, 521.72KB read
        Requests/sec:   1109.06
        Transfer/sec:    172.21KB
        [run.sh] Speed is 1109.06, duration is 27
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d27s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 27s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   421.06ms  350.58ms   2.66s    73.96%
        Req/Sec   161.50     94.60   540.00     65.56%
        Latency Distribution
        50%  351.24ms
        75%  581.70ms
        90%  877.85ms
        99%    1.59s
        20000 requests in 27.00s, 3.03MB read
        Requests/sec:    740.74
        Transfer/sec:    115.02KB
        ------------------------------
        stop time: 15.574424
        stop time: 16.225987
        stop time: 16.291274
        stop time: 16.481914
        stop time: 16.367073
        stop time: 16.482084
        stop time: 16.343727
        stop time: 16.285497
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5bf5bf77b8-v9qnj        1689m        69Mi
        service1-7755b7b4b5-94g99        1204m        36Mi
        service2-677597bc9b-kgmvj        552m         10Mi
        ubuntu-client-76886f6bbd-lzzr8   41m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [15.574424, 16.225987, 16.291274, 16.481914, 16.367073, 16.482084, 16.343727, 16.285497]
    [exp] Throughput: 1230.2773091190152
[test.py] Finished running 7th optmization experiment: groundtruth->1449.0371637097192, slowdown->1230.2773091190152, predicted->1445.3062685281484, err->-0.25747408520697934
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00064', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   364.70ms  234.93ms   1.30s    64.20%
        Req/Sec   181.31    108.28   505.00     63.85%
        Latency Distribution
        50%  323.16ms
        75%  524.16ms
        90%  700.64ms
        99%  933.07ms
        3875 requests in 3.03s, 601.68KB read
        Requests/sec:   1280.81
        Transfer/sec:    198.88KB
        [run.sh] Speed is 1280.81, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   384.26ms  421.96ms   2.99s    86.13%
        Req/Sec   183.21     82.04   555.00     69.50%
        Latency Distribution
        50%  221.06ms
        75%  538.22ms
        90%  949.85ms
        99%    1.92s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.338094
        stop time: 14.002245
        stop time: 13.939738
        stop time: 13.883760
        stop time: 14.080931
        stop time: 14.111661
        stop time: 13.875249
        stop time: 13.886208
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.338094, 14.002245, 13.939738, 13.88376, 14.080931, 14.111661, 13.875249, 13.886208]
    [exp] Throughput: 1439.912202793347
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '323.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7779556975-mmndl cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   378.64ms  350.84ms   2.56s    81.27%
        Req/Sec   163.29     77.52   360.00     65.50%
        Latency Distribution
        50%  249.79ms
        75%  503.14ms
        90%  910.83ms
        99%    1.47s
        3739 requests in 3.02s, 580.57KB read
        Requests/sec:   1238.52
        Transfer/sec:    192.31KB
        [run.sh] Speed is 1238.52, duration is 24
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d24s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 24s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   412.81ms  360.44ms   2.73s    80.82%
        Req/Sec   169.14     96.14   610.00     66.06%
        Latency Distribution
        50%  334.45ms
        75%  552.46ms
        90%  831.93ms
        99%    1.89s
        20000 requests in 24.00s, 3.03MB read
        Requests/sec:    833.33
        Transfer/sec:    129.39KB
        ------------------------------
        stop time: 15.516249
        stop time: 14.930235
        stop time: 15.365229
        stop time: 15.774340
        stop time: 15.637859
        stop time: 15.443717
        stop time: 15.569667
        stop time: 15.425722
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7779556975-mmndl        700m         66Mi
        service1-7755b7b4b5-bx4wz        715m         35Mi
        service2-bcfd688d7-x8f52         373m         9Mi
        ubuntu-client-76886f6bbd-fdrg8   34m          16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [15.516249, 14.930235, 15.365229, 15.77434, 15.637859, 15.443717, 15.569667, 15.425722]
    [exp] Throughput: 1293.8387125567322
[test.py] Finished running 8th optmization experiment: groundtruth->1439.912202793347, slowdown->1293.8387125567322, predicted->1445.1621742024136, err->0.36460357783494934
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00072', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-lsgrn cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   360.00ms  267.23ms   1.89s    72.83%
        Req/Sec   185.62     81.87   414.00     66.67%
        Latency Distribution
        50%  311.81ms
        75%  503.21ms
        90%  715.74ms
        99%    1.33s
        4068 requests in 3.02s, 631.65KB read
        Requests/sec:   1346.59
        Transfer/sec:    209.09KB
        [run.sh] Speed is 1346.59, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   377.64ms  343.26ms   2.90s    84.32%
        Req/Sec   181.32     91.58   474.00     69.72%
        Latency Distribution
        50%  287.83ms
        75%  511.30ms
        90%  794.46ms
        99%    1.69s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.604184
        stop time: 13.621235
        stop time: 14.166763
        stop time: 14.235100
        stop time: 14.238190
        stop time: 14.331666
        stop time: 14.161197
        stop time: 14.168976
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-lsgrn        2m           70Mi
        service1-7755b7b4b5-x5jlv        1m           37Mi
        service2-958786d58-fvnbl         1m           13Mi
        ubuntu-client-76886f6bbd-6t2kf   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [13.604184, 13.621235, 14.166763, 14.2351, 14.23819, 14.331666, 14.161197, 14.168976]
    [exp] Throughput: 1421.8770410322875
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '40.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '163.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   393.82ms  302.12ms   1.68s    66.19%
        Req/Sec   185.21     96.62   450.00     69.31%
        Latency Distribution
        50%  343.53ms
        75%  560.17ms
        90%  826.25ms
        99%    1.23s
        3857 requests in 3.02s, 598.89KB read
        Requests/sec:   1275.36
        Transfer/sec:    198.03KB
        [run.sh] Speed is 1275.36, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   366.29ms  264.30ms   1.61s    70.24%
        Req/Sec   178.08     94.06   535.00     70.07%
        Latency Distribution
        50%  309.09ms
        75%  508.20ms
        90%  742.40ms
        99%    1.17s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.857928
        stop time: 13.948821
        stop time: 14.231790
        stop time: 14.492051
        stop time: 14.759023
        stop time: 14.666354
        stop time: 14.773557
        stop time: 14.717330
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-c888f8587-gf9k8         374m         51Mi
        service1-7755b7b4b5-d4gkd        44m          43Mi
        service2-5c548c8f45-qxnfg        199m         19Mi
        ubuntu-client-76886f6bbd-6zh8p   3m           7Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.857928, 13.948821, 14.23179, 14.492051, 14.759023, 14.666354, 14.773557, 14.71733]
    [exp] Throughput: 1385.9191000562041
[test.py] Finished running 9th optmization experiment: groundtruth->1421.8770410322875, slowdown->1385.9191000562041, predicted->1469.2640880432996, err->3.3327106102373625
[test.py] Baseline throughput:  1431.7815723429699
[test.py] Groundtruth:  [1423.5123546325865, 1435.2385730700228, 1443.5500649326864, 1436.255407827012, 1434.5505713102134, 1436.0312519173262, 1444.47927244468, 1449.0371637097192, 1439.912202793347, 1421.8770410322875]
[test.py] Slowdown:  [929.4966129840544, 947.4983130976908, 989.0119657961584, 1032.0408299089252, 1086.8689519988402, 1132.4954405379658, 1182.9789469746913, 1230.2773091190152, 1293.8387125567322, 1385.9191000562041]
[test.py] Predicted:  [1481.654560684607, 1439.9245133973097, 1448.897152915283, 1453.4378556210427, 1472.441508641483, 1466.1127912458255, 1461.147543455281, 1445.3062685281484, 1445.1621742024136, 1469.2640880432996]
[test.py] Error percentage:  [4.084418787290911, 0.3264920839790133, 0.3704123682642011, 1.1963365081442492, 2.6413106717222865, 2.0947691276450784, 1.153929400620003, -0.25747408520697934, 0.36460357783494934, 3.3327106102373625]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 1...
[test.py] Actual processing time range: [0, 80, 160, 240, 320, 400, 480, 560, 640, 720]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   342.28ms  211.89ms   1.13s    64.97%
        Req/Sec   169.37    102.63   510.00     67.97%
        Latency Distribution
        50%  319.31ms
        75%  475.74ms
        90%  628.58ms
        99%  994.71ms
        3917 requests in 3.02s, 608.21KB read
        Requests/sec:   1295.46
        Transfer/sec:    201.15KB
        [run.sh] Speed is 1295.46, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   365.28ms  374.69ms   2.60s    86.06%
        Req/Sec   182.22     88.11   707.00     70.49%
        Latency Distribution
        50%  235.78ms
        75%  541.09ms
        90%  863.84ms
        99%    1.66s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.224063
        stop time: 13.657757
        stop time: 13.937075
        stop time: 14.188758
        stop time: 14.158322
        stop time: 14.041643
        stop time: 13.837859
        stop time: 14.183752
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-qgv5t        2m           64Mi
        service1-7755b7b4b5-l6px9        879m         35Mi
        service2-958786d58-swxfp         383m         12Mi
        ubuntu-client-76886f6bbd-shs8m   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.224063, 13.657757, 13.937075, 14.188758, 14.158322, 14.041643, 13.837859, 14.183752]
    [exp] Throughput: 1438.4708177739865
[test.py] Baseline throughput: 1438.4708177739865
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   386.68ms  275.17ms   1.88s    78.04%
        Req/Sec   190.39    131.53   610.00     65.05%
        Latency Distribution
        50%  325.22ms
        75%  475.76ms
        90%  757.13ms
        99%    1.27s
        4099 requests in 3.03s, 636.47KB read
        Requests/sec:   1352.97
        Transfer/sec:    210.08KB
        [run.sh] Speed is 1352.97, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   367.49ms  291.61ms   2.34s    79.08%
        Req/Sec   183.27    105.81   650.00     71.03%
        Latency Distribution
        50%  301.07ms
        75%  496.92ms
        90%  710.24ms
        99%    1.47s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.744974
        stop time: 13.646782
        stop time: 13.953347
        stop time: 14.266333
        stop time: 14.197666
        stop time: 14.093062
        stop time: 14.197533
        stop time: 14.039864
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-fs4cf        647m         54Mi
        service1-7755b7b4b5-k8vwz        2m           26Mi
        service2-958786d58-7n8q5         2m           10Mi
        ubuntu-client-76886f6bbd-tnvtx   21m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.744974, 13.646782, 13.953347, 14.266333, 14.197666, 14.093062, 14.197533, 14.039864]
    [exp] Throughput: 1426.7935291810177
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '400.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1603.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   556.38ms  306.50ms   1.59s    64.89%
        Req/Sec   122.80     87.02   420.00     64.25%
        Latency Distribution
        50%  512.15ms
        75%  761.01ms
        90%  980.94ms
        99%    1.29s
        2548 requests in 3.03s, 395.64KB read
        Requests/sec:    841.70
        Transfer/sec:    130.69KB
        [run.sh] Speed is 841.70, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-788678d7df-qwwtg        1250m        65Mi
        service1-7755b7b4b5-mh826        898m         35Mi
        service2-7cbc657d97-j7mdv        394m         12Mi
        ubuntu-client-76886f6bbd-6dx9h   33m          22Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   595.66ms  575.34ms   3.86s    86.32%
        Req/Sec   126.24     77.85   545.00     71.75%
        Latency Distribution
        50%  421.40ms
        75%  813.64ms
        90%    1.33s
        99%    2.67s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 21.986746
        stop time: 21.263763
        stop time: 22.176758
        stop time: 22.337620
        stop time: 21.590649
        stop time: 22.112714
        stop time: 21.565827
        stop time: 21.888920
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.986746, 21.263763, 22.176758, 22.33762, 21.590649, 22.112714, 21.565827, 21.88892]
    [exp] Throughput: 914.6881927709024
[test.py] Finished running 0th optmization experiment: groundtruth->1426.7935291810177, slowdown->914.6881927709024, predicted->1444.3796870854321, err->1.2325650169235727
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '8e-05', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   410.15ms  368.08ms   2.11s    77.37%
        Req/Sec   181.05     90.92   444.00     68.75%
        Latency Distribution
        50%  397.34ms
        75%  583.44ms
        90%  873.90ms
        99%    1.73s
        3847 requests in 3.03s, 597.34KB read
        Requests/sec:   1270.97
        Transfer/sec:    197.35KB
        [run.sh] Speed is 1270.97, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   362.41ms  310.56ms   2.54s    74.05%
        Req/Sec   184.34     97.34   790.00     70.92%
        Latency Distribution
        50%  292.31ms
        75%  528.68ms
        90%  780.61ms
        99%    1.33s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.491141
        stop time: 13.529382
        stop time: 14.014024
        stop time: 14.061787
        stop time: 14.160537
        stop time: 14.158049
        stop time: 14.048853
        stop time: 14.140984
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.491141, 13.529382, 14.014024, 14.061787, 14.160537, 14.158049, 14.048853, 14.140984]
    [exp] Throughput: 1433.6306471237601
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '360.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1443.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   542.28ms  647.47ms   3.00s    83.45%
        Req/Sec   124.39     57.51   303.00     70.41%
        Latency Distribution
        50%  251.59ms
        75%  767.51ms
        90%    1.61s
        99%    2.48s
        2584 requests in 3.02s, 401.23KB read
        Socket errors: connect 0, read 0, write 0, timeout 1
        Requests/sec:    854.97
        Transfer/sec:    132.75KB
        [run.sh] Speed is 854.97, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d789b6d66-w7tcg        668m         72Mi
        service1-7755b7b4b5-7gkvp        612m         37Mi
        service2-55fb5cdf7f-f4q4c        288m         11Mi
        ubuntu-client-76886f6bbd-wlrlb   22m          20Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   569.17ms  551.80ms   4.40s    84.30%
        Req/Sec   127.89     82.06   500.00     67.65%
        Latency Distribution
        50%  434.96ms
        75%  789.64ms
        90%    1.25s
        99%    2.59s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 20.946045
        stop time: 20.226348
        stop time: 21.138487
        stop time: 20.948971
        stop time: 21.366675
        stop time: 21.458387
        stop time: 21.338920
        stop time: 21.180668
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.946045, 20.226348, 21.138487, 20.948971, 21.366675, 21.458387, 21.33892, 21.180668]
    [exp] Throughput: 948.9663624104554
[test.py] Finished running 1th optmization experiment: groundtruth->1433.6306471237601, slowdown->948.9663624104554, predicted->1443.317741502532, err->0.6757036338618161
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00016', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   341.88ms  214.87ms   1.51s    68.34%
        Req/Sec   172.35    107.96   540.00     71.82%
        Latency Distribution
        50%  290.14ms
        75%  500.97ms
        90%  646.71ms
        99%  949.52ms
        3889 requests in 3.02s, 603.86KB read
        Requests/sec:   1286.78
        Transfer/sec:    199.80KB
        [run.sh] Speed is 1286.78, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   406.51ms  463.35ms   4.23s    85.42%
        Req/Sec   180.22     92.86   580.00     70.92%
        Latency Distribution
        50%  229.42ms
        75%  632.35ms
        90%    1.17s
        99%    2.00s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.565204
        stop time: 14.179603
        stop time: 14.203847
        stop time: 14.036593
        stop time: 14.136615
        stop time: 14.238132
        stop time: 13.949513
        stop time: 14.049859
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.565204, 14.179603, 14.203847, 14.036593, 14.136615, 14.238132, 13.949513, 14.049859]
    [exp] Throughput: 1424.0023390662423
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '320.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1283.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-6d5685b766-glmg8 cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   472.09ms  397.84ms   1.85s    68.79%
        Req/Sec   121.84     71.15   290.00     59.80%
        Latency Distribution
        50%  383.07ms
        75%  701.18ms
        90%    1.08s
        99%    1.65s
        2675 requests in 3.02s, 415.36KB read
        Requests/sec:    885.94
        Transfer/sec:    137.56KB
        [run.sh] Speed is 885.94, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   549.93ms  574.33ms   5.29s    85.99%
        Req/Sec   132.22     68.98   410.00     66.94%
        Latency Distribution
        50%  380.12ms
        75%  791.16ms
        90%    1.32s
        99%    2.55s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.310255
        stop time: 19.431403
        stop time: 20.093308
        stop time: 20.065324
        stop time: 19.935296
        stop time: 20.212632
        stop time: 20.493574
        stop time: 20.390279
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d5685b766-glmg8        52m          63Mi
        service1-7755b7b4b5-rrlq6        107m         25Mi
        service2-6f89f64dfc-kv8x4        59m          10Mi
        ubuntu-client-76886f6bbd-wfkng   5m           18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [19.310255, 19.431403, 20.093308, 20.065324, 19.935296, 20.212632, 20.493574, 20.390279]
    [exp] Throughput: 1000.4247365745673
[test.py] Finished running 2th optmization experiment: groundtruth->1424.0023390662423, slowdown->1000.4247365745673, predicted->1473.5234859520858, err->3.4776029173039107
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00024', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   356.02ms  240.73ms   1.41s    69.41%
        Req/Sec   188.91    100.13   494.00     68.40%
        Latency Distribution
        50%  289.34ms
        75%  506.36ms
        90%  717.74ms
        99%    1.00s
        4053 requests in 3.03s, 629.32KB read
        Requests/sec:   1337.49
        Transfer/sec:    207.68KB
        [run.sh] Speed is 1337.49, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   391.97ms  434.25ms   3.61s    87.38%
        Req/Sec   187.82    100.33   696.00     72.46%
        Latency Distribution
        50%  255.94ms
        75%  549.46ms
        90%  957.34ms
        99%    2.02s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.511463
        stop time: 13.434496
        stop time: 13.785732
        stop time: 13.916379
        stop time: 14.102177
        stop time: 14.006223
        stop time: 13.754315
        stop time: 14.189962
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-8vdfs        2m           67Mi
        service1-7755b7b4b5-5qvkg        1m           35Mi
        service2-958786d58-kzpvh         1m           13Mi
        ubuntu-client-76886f6bbd-6kn2b   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.511463, 13.434496, 13.785732, 13.916379, 14.102177, 14.006223, 13.754315, 14.189962]
    [exp] Throughput: 1458.5133134963976
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '280.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1123.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   494.12ms  313.81ms   1.81s    72.82%
        Req/Sec   122.23     85.71   400.00     67.15%
        Latency Distribution
        50%  449.39ms
        75%  647.52ms
        90%  893.47ms
        99%    1.42s
        2790 requests in 3.02s, 433.21KB read
        Requests/sec:    922.48
        Transfer/sec:    143.24KB
        [run.sh] Speed is 922.48, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   518.90ms  443.34ms   4.01s    82.07%
        Req/Sec   134.26     76.85   470.00     67.26%
        Latency Distribution
        50%  410.28ms
        75%  700.19ms
        90%    1.04s
        99%    2.17s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    625.00
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 19.657255
        stop time: 19.041261
        stop time: 19.674051
        stop time: 19.660386
        stop time: 19.559848
        stop time: 19.564652
        stop time: 19.864011
        stop time: 19.856373
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-75ddd887-mg549          473m         59Mi
        service1-7755b7b4b5-7bqrm        333m         34Mi
        service2-dc56fbc74-bkqkh         145m         9Mi
        ubuntu-client-76886f6bbd-pbj8n   17m          8Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.657255, 19.041261, 19.674051, 19.660386, 19.559848, 19.564652, 19.864011, 19.856373]
    [exp] Throughput: 1019.901874348255
[test.py] Finished running 3th optmization experiment: groundtruth->1458.5133134963976, slowdown->1019.901874348255, predicted->1429.4771427364287, err->-1.9908060139925883
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00032', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   459.19ms  510.57ms   2.71s    85.33%
        Req/Sec   183.62    100.22   490.00     65.47%
        Latency Distribution
        50%  286.18ms
        75%  671.78ms
        90%    1.13s
        99%    2.19s
        4169 requests in 3.04s, 647.33KB read
        Requests/sec:   1372.96
        Transfer/sec:    213.18KB
        [run.sh] Speed is 1372.96, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   392.08ms  441.50ms   3.57s    85.78%
        Req/Sec   182.79     90.51   670.00     72.94%
        Latency Distribution
        50%  209.44ms
        75%  589.72ms
        90%    1.01s
        99%    1.90s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.378091
        stop time: 13.516141
        stop time: 13.987582
        stop time: 14.154082
        stop time: 14.118517
        stop time: 14.186249
        stop time: 13.909038
        stop time: 14.234060
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-4d7xl        634m         56Mi
        service1-7755b7b4b5-llzgw        156m         22Mi
        service2-958786d58-czqt8         111m         9Mi
        ubuntu-client-76886f6bbd-9xrn7   20m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.378091, 13.516141, 13.987582, 14.154082, 14.118517, 14.186249, 13.909038, 14.23406]
    [exp] Throughput: 1435.1866137274164
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '240.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '963.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   470.24ms  276.33ms   1.50s    72.45%
        Req/Sec   145.49     93.38   424.00     61.26%
        Latency Distribution
        50%  433.85ms
        75%  608.22ms
        90%  781.22ms
        99%    1.30s
        2845 requests in 3.02s, 441.75KB read
        Requests/sec:    941.68
        Transfer/sec:    146.22KB
        [run.sh] Speed is 941.68, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   502.94ms  480.90ms   4.19s    85.94%
        Req/Sec   142.44     80.38   474.00     66.86%
        Latency Distribution
        50%  377.98ms
        75%  706.01ms
        90%    1.06s
        99%    2.42s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 18.877473
        stop time: 18.921587
        stop time: 18.564373
        stop time: 18.875783
        stop time: 18.754291
        stop time: 18.705528
        stop time: 18.055253
        stop time: 18.555900
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-686fb79d75-clcgb        200m         68Mi
        service1-7755b7b4b5-bt6hc        267m         40Mi
        service2-5d558db67c-h7fsk        123m         14Mi
        ubuntu-client-76886f6bbd-qvcwp   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.877473, 18.921587, 18.564373, 18.875783, 18.754291, 18.705528, 18.055253, 18.5559]
    [exp] Throughput: 1071.594659032912
[test.py] Finished running 4th optmization experiment: groundtruth->1435.1866137274164, slowdown->1071.594659032912, predicted->1444.5467223650176, err->0.6521875655801561
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0004', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   366.29ms  200.50ms   1.07s    69.36%
        Req/Sec   179.82    110.84   444.00     66.19%
        Latency Distribution
        50%  344.33ms
        75%  479.38ms
        90%  617.09ms
        99%  974.96ms
        3957 requests in 3.03s, 614.42KB read
        Requests/sec:   1305.83
        Transfer/sec:    202.76KB
        [run.sh] Speed is 1305.83, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   343.52ms  268.49ms   2.02s    67.71%
        Req/Sec   189.72    108.45   676.00     65.00%
        Latency Distribution
        50%  301.05ms
        75%  490.89ms
        90%  713.12ms
        99%    1.16s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.168601
        stop time: 13.069994
        stop time: 13.799156
        stop time: 14.014762
        stop time: 13.994010
        stop time: 14.153990
        stop time: 14.081088
        stop time: 13.882164
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-cjrcv        1756m        61Mi
        service1-7755b7b4b5-bh4cp        681m         27Mi
        service2-958786d58-fxfgf         497m         9Mi
        ubuntu-client-76886f6bbd-n2klf   48m          16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.168601, 13.069994, 13.799156, 14.014762, 13.99401, 14.15399, 14.081088, 13.882164]
    [exp] Throughput: 1452.3831860684863
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '200.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '803.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   496.39ms  426.01ms   2.89s    79.39%
        Req/Sec   141.00     75.50   363.00     65.71%
        Latency Distribution
        50%  390.86ms
        75%  677.54ms
        90%    1.00s
        99%    1.95s
        3012 requests in 3.03s, 467.68KB read
        Requests/sec:    993.59
        Transfer/sec:    154.28KB
        [run.sh] Speed is 993.59, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   463.36ms  396.36ms   3.38s    77.25%
        Req/Sec   146.21     79.71   560.00     71.44%
        Latency Distribution
        50%  364.64ms
        75%  652.10ms
        90%  986.25ms
        99%    1.80s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 16.917268
        stop time: 17.617473
        stop time: 17.905500
        stop time: 17.627813
        stop time: 18.176587
        stop time: 18.149180
        stop time: 17.923089
        stop time: 17.826440
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [16.917268, 17.617473, 17.9055, 17.627813, 18.176587, 18.14918, 17.923089, 17.82644]
    [exp] Throughput: 1125.6242377853061
[test.py] Finished running 5th optmization experiment: groundtruth->1452.3831860684863, slowdown->1125.6242377853061, predicted->1454.6175242318823, err->0.15383944022680068
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   372.69ms  280.10ms   1.60s    78.10%
        Req/Sec   167.09     92.69   494.00     71.75%
        Latency Distribution
        50%  292.49ms
        75%  481.46ms
        90%  767.63ms
        99%    1.46s
        3802 requests in 3.03s, 590.35KB read
        Requests/sec:   1254.44
        Transfer/sec:    194.78KB
        [run.sh] Speed is 1254.44, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   356.15ms  299.45ms   2.12s    69.96%
        Req/Sec   186.33    106.32   610.00     67.97%
        Latency Distribution
        50%  283.46ms
        75%  526.71ms
        90%  768.68ms
        99%    1.29s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.875115
        stop time: 13.972148
        stop time: 13.896038
        stop time: 13.848080
        stop time: 14.096744
        stop time: 14.233270
        stop time: 13.967636
        stop time: 14.130179
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-tvtjx        1828m        69Mi
        service1-7755b7b4b5-ksnpv        956m         35Mi
        service2-958786d58-r22vj         642m         10Mi
        ubuntu-client-76886f6bbd-b487s   40m          17Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.875115, 13.972148, 13.896038, 13.84808, 14.096744, 14.23327, 13.967636, 14.130179]
    [exp] Throughput: 1428.3264450802678
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '160.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '643.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   469.79ms  345.56ms   2.01s    72.00%
        Req/Sec   136.06     78.40   350.00     66.09%
        Latency Distribution
        50%  388.94ms
        75%  624.07ms
        90%  969.27ms
        99%    1.54s
        3182 requests in 3.04s, 494.08KB read
        Requests/sec:   1048.18
        Transfer/sec:    162.75KB
        [run.sh] Speed is 1048.18, duration is 28
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d28s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 28s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   439.32ms  334.80ms   3.11s    76.82%
        Req/Sec   154.15     92.36   646.00     64.56%
        Latency Distribution
        50%  372.53ms
        75%  583.12ms
        90%  839.83ms
        99%    1.71s
        20000 requests in 28.00s, 3.03MB read
        Requests/sec:    714.28
        Transfer/sec:    110.91KB
        ------------------------------
        stop time: 16.180747
        stop time: 17.056615
        stop time: 16.630353
        stop time: 17.047257
        stop time: 16.910752
        stop time: 16.888145
        stop time: 17.281137
        stop time: 17.098432
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [16.180747, 17.056615, 16.630353, 17.047257, 16.910752, 16.888145, 17.281137, 17.098432]
    [exp] Throughput: 1184.3654463808966
[test.py] Finished running 6th optmization experiment: groundtruth->1428.3264450802678, slowdown->1184.3654463808966, predicted->1463.2633380705872, err->2.4460019703938225
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00056', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   350.83ms  260.05ms   1.34s    66.40%
        Req/Sec   168.38     91.25   590.00     67.54%
        Latency Distribution
        50%  327.26ms
        75%  516.27ms
        90%  679.09ms
        99%    1.08s
        3947 requests in 3.03s, 612.86KB read
        Requests/sec:   1303.78
        Transfer/sec:    202.44KB
        [run.sh] Speed is 1303.78, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   358.66ms  337.45ms   2.77s    80.89%
        Req/Sec   182.14     94.04   740.00     70.45%
        Latency Distribution
        50%  251.79ms
        75%  541.48ms
        90%  820.61ms
        99%    1.50s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.884744
        stop time: 13.314693
        stop time: 13.287809
        stop time: 14.150308
        stop time: 13.998694
        stop time: 14.171050
        stop time: 14.289479
        stop time: 14.057529
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-nnfh7        684m         68Mi
        service1-7755b7b4b5-5dpkt        499m         31Mi
        service2-958786d58-j6d9f         291m         9Mi
        ubuntu-client-76886f6bbd-xfswn   8m           16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.884744, 13.314693, 13.287809, 14.150308, 13.998694, 14.17105, 14.289479, 14.057529]
    [exp] Throughput: 1439.4404117821582
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '120.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '483.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   422.03ms  303.93ms   1.96s    68.53%
        Req/Sec   150.53     86.41   363.00     59.36%
        Latency Distribution
        50%  336.54ms
        75%  602.04ms
        90%  838.53ms
        99%    1.24s
        3353 requests in 3.03s, 520.63KB read
        Requests/sec:   1108.13
        Transfer/sec:    172.06KB
        [run.sh] Speed is 1108.13, duration is 27
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d27s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 27s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   427.51ms  384.91ms   3.35s    80.40%
        Req/Sec   158.58     81.42   525.00     69.70%
        Latency Distribution
        50%  329.12ms
        75%  589.76ms
        90%  918.30ms
        99%    1.82s
        20000 requests in 27.00s, 3.03MB read
        Requests/sec:    740.73
        Transfer/sec:    115.02KB
        ------------------------------
        stop time: 16.058459
        stop time: 16.182290
        stop time: 16.175172
        stop time: 16.544393
        stop time: 15.817511
        stop time: 16.527734
        stop time: 16.036060
        stop time: 16.401654
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5bf5bf77b8-zwmpn        3m           66Mi
        service1-7755b7b4b5-n4w5b        1m           31Mi
        service2-677597bc9b-7zdj8        1m           9Mi
        ubuntu-client-76886f6bbd-plnpn   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.058459, 16.18229, 16.175172, 16.544393, 15.817511, 16.527734, 16.03606, 16.401654]
    [exp] Throughput: 1233.2045916553996
[test.py] Finished running 7th optmization experiment: groundtruth->1439.4404117821582, slowdown->1233.2045916553996, predicted->1449.347921611982, err->0.6882889870763992
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00064', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   366.41ms  211.30ms   1.10s    64.11%
        Req/Sec   189.27    112.71   540.00     70.50%
        Latency Distribution
        50%  375.62ms
        75%  496.23ms
        90%  626.42ms
        99%  940.73ms
        3993 requests in 3.03s, 620.01KB read
        Requests/sec:   1318.10
        Transfer/sec:    204.67KB
        [run.sh] Speed is 1318.10, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   396.29ms  437.35ms   2.92s    87.16%
        Req/Sec   183.90     86.88   600.00     71.02%
        Latency Distribution
        50%  227.11ms
        75%  541.42ms
        90%  957.74ms
        99%    2.06s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.996033
        stop time: 13.764093
        stop time: 14.212869
        stop time: 13.905110
        stop time: 13.679605
        stop time: 13.734618
        stop time: 13.754123
        stop time: 14.058681
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-hphzh        472m         63Mi
        service1-7755b7b4b5-5z77j        166m         40Mi
        service2-958786d58-9nbh7         91m          13Mi
        ubuntu-client-76886f6bbd-m8f5p   20m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.996033, 13.764093, 14.212869, 13.90511, 13.679605, 13.734618, 13.754123, 14.058681]
    [exp] Throughput: 1440.0774934500776
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '323.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   421.39ms  247.76ms   1.57s    68.55%
        Req/Sec   170.07    110.14   450.00     62.07%
        Latency Distribution
        50%  384.29ms
        75%  549.17ms
        90%  733.01ms
        99%    1.19s
        3590 requests in 3.03s, 557.43KB read
        Requests/sec:   1183.50
        Transfer/sec:    183.77KB
        [run.sh] Speed is 1183.50, duration is 25
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d25s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 25s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   426.04ms  454.90ms   3.39s    87.98%
        Req/Sec   169.22     82.69   480.00     67.56%
        Latency Distribution
        50%  297.04ms
        75%  578.84ms
        90%  947.60ms
        99%    2.29s
        20000 requests in 25.00s, 3.03MB read
        Requests/sec:    800.00
        Transfer/sec:    124.22KB
        ------------------------------
        stop time: 15.017940
        stop time: 14.839468
        stop time: 15.558811
        stop time: 15.655344
        stop time: 15.240853
        stop time: 15.570625
        stop time: 15.436650
        stop time: 15.087674
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7779556975-ggvjn        148m         66Mi
        service1-7755b7b4b5-rlvvx        1258m        37Mi
        service2-bcfd688d7-xtbj4         2m           9Mi
        ubuntu-client-76886f6bbd-54lqs   19m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.01794, 14.839468, 15.558811, 15.655344, 15.240853, 15.570625, 15.43665, 15.087674]
    [exp] Throughput: 1307.1108915709442
[test.py] Finished running 8th optmization experiment: groundtruth->1440.0774934500776, slowdown->1307.1108915709442, predicted->1461.7403398263075, err->1.504283378829218
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00072', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   360.45ms  230.95ms   1.59s    71.60%
        Req/Sec   185.85    106.71   410.00     62.68%
        Latency Distribution
        50%  314.02ms
        75%  501.04ms
        90%  638.78ms
        99%    1.07s
        4013 requests in 3.02s, 623.11KB read
        Requests/sec:   1329.33
        Transfer/sec:    206.41KB
        [run.sh] Speed is 1329.33, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   376.64ms  366.55ms   3.52s    85.78%
        Req/Sec   185.57     99.18   505.00     67.14%
        Latency Distribution
        50%  254.07ms
        75%  551.91ms
        90%  829.66ms
        99%    1.66s
        20001 requests in 22.00s, 3.03MB read
        Requests/sec:    909.13
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.041426
        stop time: 13.894706
        stop time: 13.094375
        stop time: 13.833675
        stop time: 13.381402
        stop time: 14.217492
        stop time: 14.170681
        stop time: 14.297488
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-dgwzh        636m         57Mi
        ubuntu-client-76886f6bbd-587tr   13m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.041426, 13.894706, 13.094375, 13.833675, 13.381402, 14.217492, 14.170681, 14.297488]
    [exp] Throughput: 1442.3348444344963
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '40.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '163.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   373.58ms  253.62ms   1.78s    70.07%
        Req/Sec   173.37    107.58   555.00     76.96%
        Latency Distribution
        50%  318.91ms
        75%  487.93ms
        90%  710.99ms
        99%    1.14s
        3842 requests in 3.02s, 596.56KB read
        Requests/sec:   1271.42
        Transfer/sec:    197.42KB
        [run.sh] Speed is 1271.42, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   379.34ms  329.29ms   2.88s    78.31%
        Req/Sec   179.32     93.50   616.00     69.70%
        Latency Distribution
        50%  308.37ms
        75%  534.44ms
        90%  789.21ms
        99%    1.57s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.774895
        stop time: 13.992736
        stop time: 14.608317
        stop time: 14.465390
        stop time: 14.476087
        stop time: 14.702970
        stop time: 14.563977
        stop time: 14.802270
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-c888f8587-cgxlv         1678m        61Mi
        service1-7755b7b4b5-vkmj9        1297m        33Mi
        service2-5c548c8f45-5l5xr        592m         11Mi
        ubuntu-client-76886f6bbd-r2m2v   45m          17Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.774895, 13.992736, 14.608317, 14.46539, 14.476087, 14.70297, 14.563977, 14.80227]
    [exp] Throughput: 1386.6423116811043
[test.py] Finished running 9th optmization experiment: groundtruth->1442.3348444344963, slowdown->1386.6423116811043, predicted->1470.0769241639316, err->1.923414652047202
[test.py] Baseline throughput:  1438.4708177739865
[test.py] Groundtruth:  [1426.7935291810177, 1433.6306471237601, 1424.0023390662423, 1458.5133134963976, 1435.1866137274164, 1452.3831860684863, 1428.3264450802678, 1439.4404117821582, 1440.0774934500776, 1442.3348444344963]
[test.py] Slowdown:  [914.6881927709024, 948.9663624104554, 1000.4247365745673, 1019.901874348255, 1071.594659032912, 1125.6242377853061, 1184.3654463808966, 1233.2045916553996, 1307.1108915709442, 1386.6423116811043]
[test.py] Predicted:  [1444.3796870854321, 1443.317741502532, 1473.5234859520858, 1429.4771427364287, 1444.5467223650176, 1454.6175242318823, 1463.2633380705872, 1449.347921611982, 1461.7403398263075, 1470.0769241639316]
[test.py] Error percentage:  [1.2325650169235727, 0.6757036338618161, 3.4776029173039107, -1.9908060139925883, 0.6521875655801561, 0.15383944022680068, 2.4460019703938225, 0.6882889870763992, 1.504283378829218, 1.923414652047202]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 2...
[test.py] Actual processing time range: [0, 80, 160, 240, 320, 400, 480, 560, 640, 720]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   313.13ms  226.96ms   1.23s    62.61%
        Req/Sec   183.15    107.28   470.00     70.35%
        Latency Distribution
        50%  297.43ms
        75%  453.97ms
        90%  607.72ms
        99%  886.01ms
        4152 requests in 3.03s, 644.70KB read
        Requests/sec:   1369.69
        Transfer/sec:    212.68KB
        [run.sh] Speed is 1369.69, duration is 21
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d21s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 21s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   379.52ms  375.00ms   3.11s    84.99%
        Req/Sec   186.01     91.22   676.00     66.41%
        Latency Distribution
        50%  263.59ms
        75%  558.32ms
        90%  866.77ms
        99%    1.78s
        20000 requests in 21.00s, 3.03MB read
        Requests/sec:    952.37
        Transfer/sec:    147.88KB
        ------------------------------
        stop time: 13.855093
        stop time: 13.856694
        stop time: 13.231310
        stop time: 13.460250
        stop time: 14.030020
        stop time: 13.929836
        stop time: 14.281329
        stop time: 14.234188
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.855093, 13.856694, 13.23131, 13.46025, 14.03002, 13.929836, 14.281329, 14.234188]
    [exp] Throughput: 1443.0181012190617
[test.py] Baseline throughput: 1443.0181012190617
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-g5jzv cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   401.84ms  363.41ms   1.97s    82.36%
        Req/Sec   175.15     98.37   540.00     78.90%
        Latency Distribution
        50%  275.86ms
        75%  514.41ms
        90%  923.34ms
        99%    1.56s
        4040 requests in 3.03s, 627.30KB read
        Requests/sec:   1332.05
        Transfer/sec:    206.83KB
        [run.sh] Speed is 1332.05, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   399.08ms  427.36ms   3.15s    85.71%
        Req/Sec   181.17     94.95   800.00     72.47%
        Latency Distribution
        50%  233.32ms
        75%  567.07ms
        90%  972.68ms
        99%    1.93s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.542204
        stop time: 14.206348
        stop time: 13.620492
        stop time: 14.300731
        stop time: 14.263892
        stop time: 14.333764
        stop time: 13.951246
        stop time: 13.953341
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-g5jzv        531m         57Mi
        service1-7755b7b4b5-whx8f        110m         22Mi
        service2-958786d58-khbd4         223m         10Mi
        ubuntu-client-76886f6bbd-cwwjz   46m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [13.542204, 14.206348, 13.620492, 14.300731, 14.263892, 14.333764, 13.951246, 13.953341]
    [exp] Throughput: 1426.3806861351109
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '400.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1603.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-788678d7df-7vgx2 cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   526.46ms  316.97ms   1.71s    67.97%
        Req/Sec   119.63     89.02   353.00     55.49%
        Latency Distribution
        50%  502.89ms
        75%  693.27ms
        90%  998.10ms
        99%    1.47s
        2402 requests in 3.03s, 372.97KB read
        Requests/sec:    792.01
        Transfer/sec:    122.98KB
        [run.sh] Speed is 792.01, duration is 37
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d37s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 37s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   683.90ms  892.78ms   7.96s    88.35%
        Req/Sec   137.60     82.89     0.92k    68.89%
        Latency Distribution
        50%  341.52ms
        75%  824.70ms
        90%    1.81s
        99%    4.48s
        20000 requests in 37.00s, 3.03MB read
        Requests/sec:    540.54
        Transfer/sec:     83.93KB
        ------------------------------
        stop time: 21.093565
        stop time: 21.101394
        stop time: 20.116700
        stop time: 21.605992
        stop time: 22.162665
        stop time: 22.226600
        stop time: 21.678952
        stop time: 22.130843
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
        > error: metrics not available yet
    [exp] Times: [21.093565, 21.101394, 20.1167, 21.605992, 22.162665, 22.2266, 21.678952, 22.130843]
    [exp] Throughput: 929.601774693452
[test.py] Finished running 0th optmization experiment: groundtruth->1426.3806861351109, slowdown->929.601774693452, predicted->1481.921790632774, err->3.8938486084073434
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '8e-05', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   376.75ms  409.66ms   2.13s    82.87%
        Req/Sec   174.16     76.63   434.00     74.57%
        Latency Distribution
        50%  175.79ms
        75%  586.70ms
        90%  951.27ms
        99%    1.68s
        4095 requests in 3.02s, 635.84KB read
        Requests/sec:   1357.90
        Transfer/sec:    210.85KB
        [run.sh] Speed is 1357.90, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   395.52ms  439.47ms   3.95s    86.89%
        Req/Sec   183.72     92.18   545.00     69.79%
        Latency Distribution
        50%  250.43ms
        75%  575.14ms
        90%  987.81ms
        99%    1.91s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.333302
        stop time: 13.534469
        stop time: 13.724197
        stop time: 14.191695
        stop time: 14.033170
        stop time: 14.081771
        stop time: 13.683522
        stop time: 14.184656
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-l9q5t        648m         62Mi
        service1-7755b7b4b5-9dkgz        146m         25Mi
        service2-958786d58-64nvd         215m         8Mi
        ubuntu-client-76886f6bbd-sl6pl   7m           12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.333302, 13.534469, 13.724197, 14.191695, 14.03317, 14.081771, 13.683522, 14.184656]
    [exp] Throughput: 1444.4763774034711
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '360.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1443.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   521.43ms  313.60ms   1.61s    64.37%
        Req/Sec   131.53     85.23   343.00     63.10%
        Latency Distribution
        50%  505.42ms
        75%  693.95ms
        90%  944.61ms
        99%    1.33s
        2652 requests in 3.03s, 411.79KB read
        Requests/sec:    875.17
        Transfer/sec:    135.89KB
        [run.sh] Speed is 875.17, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   554.26ms  534.97ms   3.87s    86.95%
        Req/Sec   130.01     77.56   373.00     64.07%
        Latency Distribution
        50%  410.86ms
        75%  769.32ms
        90%    1.15s
        99%    2.74s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 21.181069
        stop time: 21.046696
        stop time: 19.863413
        stop time: 20.281583
        stop time: 20.850628
        stop time: 21.183115
        stop time: 21.187760
        stop time: 20.902572
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d789b6d66-gdxfq        1308m        62Mi
        service1-7755b7b4b5-sjrt9        873m         30Mi
        service2-55fb5cdf7f-kr47n        405m         12Mi
        ubuntu-client-76886f6bbd-zx4ps   18m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.181069, 21.046696, 19.863413, 20.281583, 20.850628, 21.183115, 21.18776, 20.902572]
    [exp] Throughput: 960.9792224520111
[test.py] Finished running 1th optmization experiment: groundtruth->1444.4763774034711, slowdown->960.9792224520111, predicted->1471.2909389922224, err->1.856351686204243
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00016', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   353.51ms  229.48ms   1.38s    64.21%
        Req/Sec   184.57    108.25   540.00     70.75%
        Latency Distribution
        50%  316.65ms
        75%  480.53ms
        90%  707.36ms
        99%  925.40ms
        3993 requests in 3.04s, 620.01KB read
        Requests/sec:   1314.71
        Transfer/sec:    204.14KB
        [run.sh] Speed is 1314.71, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   395.06ms  409.15ms   3.26s    87.20%
        Req/Sec   182.48     94.54   700.00     73.42%
        Latency Distribution
        50%  268.18ms
        75%  521.30ms
        90%  931.66ms
        99%    1.99s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.218292
        stop time: 14.077529
        stop time: 14.166164
        stop time: 13.988948
        stop time: 14.042705
        stop time: 14.155076
        stop time: 14.149264
        stop time: 13.502738
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-8mm25        312m         66Mi
        service1-7755b7b4b5-nxdzv        128m         33Mi
        service2-958786d58-bjzjv         116m         12Mi
        ubuntu-client-76886f6bbd-vrs58   20m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.218292, 14.077529, 14.166164, 13.988948, 14.042705, 14.155076, 14.149264, 13.502738]
    [exp] Throughput: 1424.7460363476223
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '320.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1283.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   512.76ms  302.23ms   2.26s    73.02%
        Req/Sec   113.72     75.06   340.00     65.64%
        Latency Distribution
        50%  486.43ms
        75%  650.45ms
        90%  868.25ms
        99%    1.57s
        2543 requests in 3.02s, 394.86KB read
        Requests/sec:    840.73
        Transfer/sec:    130.54KB
        [run.sh] Speed is 840.73, duration is 35
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d35s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d5685b766-jbn4l        1355m        75Mi
        service1-7755b7b4b5-t57fn        969m         35Mi
        service2-6f89f64dfc-dnj26        445m         10Mi
        ubuntu-client-76886f6bbd-8gpjs   37m          20Mi
        Running 35s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   520.08ms  451.92ms   3.70s    75.28%
        Req/Sec   133.94     78.77   464.00     67.23%
        Latency Distribution
        50%  416.82ms
        75%  736.97ms
        90%    1.11s
        99%    2.07s
        20000 requests in 35.00s, 3.03MB read
        Requests/sec:    571.43
        Transfer/sec:     88.73KB
        ------------------------------
        stop time: 19.446040
        stop time: 20.172787
        stop time: 19.868828
        stop time: 20.337690
        stop time: 20.454860
        stop time: 19.948047
        stop time: 20.363534
        stop time: 20.224301
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.44604, 20.172787, 19.868828, 20.33769, 20.45486, 19.948047, 20.363534, 20.224301]
    [exp] Throughput: 994.9253397764863
[test.py] Finished running 2th optmization experiment: groundtruth->1424.7460363476223, slowdown->994.9253397764863, predicted->1461.623873075433, err->2.5883796681651523
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00024', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   365.64ms  214.69ms   1.15s    68.61%
        Req/Sec   188.66    127.98   636.00     72.33%
        Latency Distribution
        50%  340.74ms
        75%  484.68ms
        90%  664.32ms
        99%  977.23ms
        4064 requests in 3.03s, 631.03KB read
        Requests/sec:   1341.99
        Transfer/sec:    208.38KB
        [run.sh] Speed is 1341.99, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   396.46ms  424.39ms   3.01s    88.25%
        Req/Sec   184.88     96.86   570.00     71.17%
        Latency Distribution
        50%  256.32ms
        75%  544.89ms
        90%  897.99ms
        99%    2.12s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.582673
        stop time: 14.148627
        stop time: 14.193297
        stop time: 14.262221
        stop time: 13.980436
        stop time: 13.989668
        stop time: 13.716069
        stop time: 13.843479
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        ubuntu-client-76886f6bbd-qngbb   3m           7Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.582673, 14.148627, 14.193297, 14.262221, 13.980436, 13.989668, 13.716069, 13.843479]
    [exp] Throughput: 1432.1970610063136
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '280.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1123.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   534.73ms  490.86ms   2.88s    83.97%
        Req/Sec   131.34     86.87   400.00     62.79%
        Latency Distribution
        50%  360.58ms
        75%  735.12ms
        90%    1.11s
        99%    2.24s
        2619 requests in 3.03s, 406.66KB read
        Requests/sec:    864.27
        Transfer/sec:    134.20KB
        [run.sh] Speed is 864.27, duration is 34
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d34s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 34s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   499.03ms  422.54ms   3.26s    75.51%
        Req/Sec   140.37     78.41   484.00     66.07%
        Latency Distribution
        50%  393.99ms
        75%  717.06ms
        90%    1.04s
        99%    1.92s
        20000 requests in 34.00s, 3.03MB read
        Requests/sec:    588.23
        Transfer/sec:     91.34KB
        ------------------------------
        stop time: 18.609047
        stop time: 18.907593
        stop time: 19.070305
        stop time: 19.313603
        stop time: 19.201128
        stop time: 19.626975
        stop time: 19.601742
        stop time: 19.752844
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-75ddd887-nq286          1264m        68Mi
        service1-7755b7b4b5-zk87r        954m         34Mi
        service2-dc56fbc74-g2bt4         415m         10Mi
        ubuntu-client-76886f6bbd-xdn5f   38m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.609047, 18.907593, 19.070305, 19.313603, 19.201128, 19.626975, 19.601742, 19.752844]
    [exp] Throughput: 1038.3997838778528
[test.py] Finished running 3th optmization experiment: groundtruth->1432.1970610063136, slowdown->1038.3997838778528, predicted->1466.0816915196067, err->2.365919567624623
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00032', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   347.26ms  392.34ms   1.95s    84.88%
        Req/Sec   184.89     80.64   444.00     69.30%
        Latency Distribution
        50%  137.88ms
        75%  543.70ms
        90%  953.42ms
        99%    1.48s
        4010 requests in 3.02s, 622.65KB read
        Requests/sec:   1328.21
        Transfer/sec:    206.23KB
        [run.sh] Speed is 1328.21, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   362.45ms  293.59ms   2.61s    75.89%
        Req/Sec   186.64    100.02   570.00     68.32%
        Latency Distribution
        50%  292.90ms
        75%  506.95ms
        90%  717.56ms
        99%    1.39s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.619216
        stop time: 14.101977
        stop time: 13.691150
        stop time: 14.070304
        stop time: 14.027773
        stop time: 14.043209
        stop time: 13.929797
        stop time: 14.179760
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.619216, 14.101977, 13.69115, 14.070304, 14.027773, 14.043209, 13.929797, 14.17976]
    [exp] Throughput: 1432.880483994071
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '240.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '963.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   484.92ms  428.82ms   2.47s    74.53%
        Req/Sec   139.03     87.54   393.00     61.98%
        Latency Distribution
        50%  358.76ms
        75%  706.23ms
        90%    1.04s
        99%    1.92s
        2946 requests in 3.02s, 457.44KB read
        Requests/sec:    975.96
        Transfer/sec:    151.54KB
        [run.sh] Speed is 975.96, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   491.07ms  428.54ms   3.22s    77.72%
        Req/Sec   139.56     77.38   414.00     65.96%
        Latency Distribution
        50%  379.92ms
        75%  681.24ms
        90%    1.07s
        99%    2.01s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.144770
        stop time: 17.951154
        stop time: 18.627664
        stop time: 18.929404
        stop time: 18.976607
        stop time: 18.729226
        stop time: 18.744971
        stop time: 18.800034
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-686fb79d75-5bzmv        469m         63Mi
        service1-7755b7b4b5-k8mdk        363m         30Mi
        service2-5d558db67c-9m9xj        149m         10Mi
        ubuntu-client-76886f6bbd-ls2c4   27m          16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.14477, 17.951154, 18.627664, 18.929404, 18.976607, 18.729226, 18.744971, 18.800034]
    [exp] Throughput: 1074.5190368844105
[test.py] Finished running 4th optmization experiment: groundtruth->1432.880483994071, slowdown->1074.5190368844105, predicted->1449.8659463007712, err->1.1854067730306537
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0004', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   376.82ms  265.10ms   1.66s    65.89%
        Req/Sec   185.80    102.83   515.00     64.02%
        Latency Distribution
        50%  376.14ms
        75%  533.74ms
        90%  732.38ms
        99%    1.12s
        4015 requests in 3.03s, 623.42KB read
        Requests/sec:   1326.34
        Transfer/sec:    205.95KB
        [run.sh] Speed is 1326.34, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   363.12ms  292.82ms   2.40s    78.90%
        Req/Sec   185.03    101.12   590.00     68.34%
        Latency Distribution
        50%  293.83ms
        75%  482.95ms
        90%  728.59ms
        99%    1.45s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.492645
        stop time: 13.354260
        stop time: 13.799119
        stop time: 14.043362
        stop time: 14.031261
        stop time: 14.164148
        stop time: 14.080938
        stop time: 14.178709
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-5lwxm        3m           66Mi
        service1-7755b7b4b5-5rd48        1m           36Mi
        service2-958786d58-wlsfb         1m           13Mi
        ubuntu-client-76886f6bbd-25nbd   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.492645, 13.35426, 13.799119, 14.043362, 14.031261, 14.164148, 14.080938, 14.178709]
    [exp] Throughput: 1439.5681612221329
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '200.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '803.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   467.39ms  288.75ms   1.41s    67.91%
        Req/Sec   144.21     94.55   390.00     61.24%
        Latency Distribution
        50%  415.72ms
        75%  648.38ms
        90%  842.61ms
        99%    1.26s
        3165 requests in 3.02s, 491.44KB read
        Requests/sec:   1047.65
        Transfer/sec:    162.67KB
        [run.sh] Speed is 1047.65, duration is 28
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d28s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 28s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   488.52ms  504.81ms   4.15s    88.48%
        Req/Sec   148.10     78.11   666.00     68.30%
        Latency Distribution
        50%  345.04ms
        75%  627.97ms
        90%    1.09s
        99%    2.60s
        20000 requests in 28.00s, 3.03MB read
        Requests/sec:    714.28
        Transfer/sec:    110.91KB
        ------------------------------
        stop time: 17.371000
        stop time: 17.351521
        stop time: 17.130020
        stop time: 17.322279
        stop time: 17.808868
        stop time: 17.323238
        stop time: 17.821968
        stop time: 18.092422
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-9994fb58c-zxg7k         416m         65Mi
        service1-7755b7b4b5-kbrq5        258m         30Mi
        service2-559ddfcfcb-jr78k        158m         9Mi
        ubuntu-client-76886f6bbd-n4kdv   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.371, 17.351521, 17.13002, 17.322279, 17.808868, 17.323238, 17.821968, 18.092422]
    [exp] Throughput: 1141.0533331465808
[test.py] Finished running 5th optmization experiment: groundtruth->1439.5681612221329, slowdown->1141.0533331465808, predicted->1480.4874164306493, err->2.8424673670038474
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   357.34ms  224.30ms   1.11s    61.69%
        Req/Sec   192.71    133.93   535.00     58.76%
        Latency Distribution
        50%  326.90ms
        75%  520.84ms
        90%  674.85ms
        99%  890.79ms
        3848 requests in 3.02s, 597.49KB read
        Requests/sec:   1275.48
        Transfer/sec:    198.05KB
        [run.sh] Speed is 1275.48, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   371.76ms  336.86ms   2.68s    85.15%
        Req/Sec   183.85    107.20   590.00     70.52%
        Latency Distribution
        50%  282.66ms
        75%  477.50ms
        90%  753.09ms
        99%    1.85s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 14.242261
        stop time: 14.248120
        stop time: 13.186716
        stop time: 14.228222
        stop time: 13.875696
        stop time: 14.155545
        stop time: 13.866043
        stop time: 14.171466
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-7sbrk        3m           66Mi
        service1-7755b7b4b5-dvx4d        1m           35Mi
        service2-958786d58-5vlgw         1m           14Mi
        ubuntu-client-76886f6bbd-54fwb   32m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.242261, 14.24812, 13.186716, 14.228222, 13.875696, 14.155545, 13.866043, 14.171466]
    [exp] Throughput: 1428.9022577182577
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '160.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '643.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   500.44ms  480.34ms   2.49s    81.15%
        Req/Sec   150.20     83.88   530.00     74.63%
        Latency Distribution
        50%  314.61ms
        75%  814.36ms
        90%    1.27s
        99%    1.86s
        3223 requests in 3.03s, 500.45KB read
        Requests/sec:   1064.89
        Transfer/sec:    165.35KB
        [run.sh] Speed is 1064.89, duration is 28
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d28s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 28s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   437.16ms  344.28ms   3.38s    74.22%
        Req/Sec   153.19     87.24   700.00     68.12%
        Latency Distribution
        50%  371.08ms
        75%  608.41ms
        90%  885.80ms
        99%    1.56s
        20000 requests in 28.00s, 3.03MB read
        Requests/sec:    714.28
        Transfer/sec:    110.91KB
        ------------------------------
        stop time: 16.736183
        stop time: 16.667912
        stop time: 17.278055
        stop time: 17.251938
        stop time: 16.813555
        stop time: 16.763330
        stop time: 17.155504
        stop time: 17.146852
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f464877cb-tlgz2         529m         52Mi
        service1-7755b7b4b5-wdfg9        373m         26Mi
        service2-756d446d74-h8tw5        168m         8Mi
        ubuntu-client-76886f6bbd-2mc29   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.736183, 16.667912, 17.278055, 17.251938, 16.813555, 16.76333, 17.155504, 17.146852]
    [exp] Throughput: 1178.0876087648217
[test.py] Finished running 6th optmization experiment: groundtruth->1428.9022577182577, slowdown->1178.0876087648217, predicted->1453.6926787739217, err->1.7349276986412308
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00056', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   345.34ms  354.99ms   2.19s    84.12%
        Req/Sec   182.79     85.05   500.00     75.00%
        Latency Distribution
        50%  154.61ms
        75%  575.63ms
        90%  867.11ms
        99%    1.41s
        3967 requests in 3.04s, 615.97KB read
        Requests/sec:   1306.57
        Transfer/sec:    202.88KB
        [run.sh] Speed is 1306.57, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   407.18ms  462.91ms   3.62s    86.20%
        Req/Sec   183.45     91.71   676.00     71.48%
        Latency Distribution
        50%  223.70ms
        75%  578.34ms
        90%    1.04s
        99%    2.04s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.893135
        stop time: 13.819136
        stop time: 13.990882
        stop time: 14.096602
        stop time: 14.123936
        stop time: 14.016755
        stop time: 14.079096
        stop time: 13.098385
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pf5zm        690m         63Mi
        service1-7755b7b4b5-9jp55        344m         32Mi
        service2-958786d58-x9qcp         247m         13Mi
        ubuntu-client-76886f6bbd-xz8fq   48m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.893135, 13.819136, 13.990882, 14.096602, 14.123936, 14.016755, 14.079096, 13.098385]
    [exp] Throughput: 1439.9116714983352
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '120.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '483.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   423.01ms  244.25ms   1.67s    63.14%
        Req/Sec   151.88     85.16   370.00     61.79%
        Latency Distribution
        50%  391.46ms
        75%  586.82ms
        90%  725.12ms
        99%    1.16s
        3324 requests in 3.02s, 516.13KB read
        Requests/sec:   1099.91
        Transfer/sec:    170.79KB
        [run.sh] Speed is 1099.91, duration is 27
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d27s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 27s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   454.14ms  502.12ms   3.34s    87.12%
        Req/Sec   159.28     72.92   570.00     72.79%
        Latency Distribution
        50%  264.40ms
        75%  634.16ms
        90%    1.12s
        99%    2.33s
        20000 requests in 27.00s, 3.03MB read
        Requests/sec:    740.74
        Transfer/sec:    115.02KB
        ------------------------------
        stop time: 16.097340
        stop time: 15.640129
        stop time: 15.892708
        stop time: 16.430253
        stop time: 16.350683
        stop time: 16.131391
        stop time: 16.099454
        stop time: 15.801438
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-5bf5bf77b8-8mvhl   159m         50Mi
        service2-677597bc9b-lm4jf   23m          8Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.09734, 15.640129, 15.892708, 16.430253, 16.350683, 16.131391, 16.099454, 15.801438]
    [exp] Throughput: 1245.6849085491324
[test.py] Finished running 7th optmization experiment: groundtruth->1439.9116714983352, slowdown->1245.6849085491324, predicted->1466.6170998974135, err->1.8546574020953186
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00064', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   341.82ms  260.94ms   1.37s    66.51%
        Req/Sec   187.12    105.36   484.00     69.08%
        Latency Distribution
        50%  289.54ms
        75%  533.35ms
        90%  700.46ms
        99%    1.11s
        4027 requests in 3.03s, 625.29KB read
        Requests/sec:   1329.48
        Transfer/sec:    206.43KB
        [run.sh] Speed is 1329.48, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   378.38ms  358.56ms   2.65s    83.18%
        Req/Sec   177.61     83.98   550.00     71.69%
        Latency Distribution
        50%  264.03ms
        75%  559.98ms
        90%  869.96ms
        99%    1.69s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.655597
        stop time: 14.427359
        stop time: 14.463783
        stop time: 14.278783
        stop time: 14.562773
        stop time: 14.274709
        stop time: 13.668460
        stop time: 13.747486
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-8dk46        884m         70Mi
        service1-7755b7b4b5-vtftc        541m         36Mi
        service2-958786d58-vjnxb         248m         12Mi
        ubuntu-client-76886f6bbd-rq25g   32m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.655597, 14.427359, 14.463783, 14.278783, 14.562773, 14.274709, 13.66846, 13.747486]
    [exp] Throughput: 1402.5374532286633
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '323.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   424.14ms  344.56ms   1.67s    63.96%
        Req/Sec   170.23    101.70   505.00     71.01%
        Latency Distribution
        50%  360.83ms
        75%  659.74ms
        90%  933.34ms
        99%    1.34s
        3608 requests in 3.01s, 560.23KB read
        Requests/sec:   1196.78
        Transfer/sec:    185.83KB
        [run.sh] Speed is 1196.78, duration is 25
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d25s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 25s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   414.65ms  392.43ms   3.02s    86.35%
        Req/Sec   170.15     99.93   707.00     65.63%
        Latency Distribution
        50%  309.26ms
        75%  527.18ms
        90%  875.02ms
        99%    2.03s
        20000 requests in 25.00s, 3.03MB read
        Requests/sec:    800.00
        Transfer/sec:    124.22KB
        ------------------------------
        stop time: 14.174117
        stop time: 15.174583
        stop time: 14.732152
        stop time: 15.335546
        stop time: 15.390600
        stop time: 15.472928
        stop time: 15.582940
        stop time: 15.687879
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [14.174117, 15.174583, 14.732152, 15.335546, 15.3906, 15.472928, 15.58294, 15.687879]
    [exp] Throughput: 1316.3226601367192
[test.py] Finished running 8th optmization experiment: groundtruth->1402.5374532286633, slowdown->1316.3226601367192, predicted->1473.2701150057674, err->5.043192366398231
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00072', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   348.79ms  262.34ms   1.42s    68.25%
        Req/Sec   174.80    105.61   520.00     64.19%
        Latency Distribution
        50%  283.82ms
        75%  521.35ms
        90%  685.83ms
        99%    1.10s
        3822 requests in 3.03s, 593.46KB read
        Requests/sec:   1259.86
        Transfer/sec:    195.62KB
        [run.sh] Speed is 1259.86, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   390.18ms  418.62ms   3.13s    86.27%
        Req/Sec   183.40     90.02   595.00     70.20%
        Latency Distribution
        50%  244.92ms
        75%  543.75ms
        90%  952.51ms
        99%    1.95s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.860593
        stop time: 13.485693
        stop time: 14.073468
        stop time: 14.164153
        stop time: 14.215889
        stop time: 14.207164
        stop time: 13.828265
        stop time: 14.127830
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-2cvrl        207m         69Mi
        service1-7755b7b4b5-pgsp5        97m          36Mi
        service2-958786d58-slmkg         96m          10Mi
        ubuntu-client-76886f6bbd-lmb58   5m           17Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.860593, 13.485693, 14.073468, 14.164153, 14.215889, 14.207164, 13.828265, 14.12783]
    [exp] Throughput: 1429.042821312798
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '40.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '163.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   383.81ms  268.83ms   1.54s    72.11%
        Req/Sec   176.85     85.71   440.00     68.06%
        Latency Distribution
        50%  327.23ms
        75%  520.89ms
        90%  759.31ms
        99%    1.20s
        3843 requests in 3.02s, 596.72KB read
        Requests/sec:   1271.65
        Transfer/sec:    197.45KB
        [run.sh] Speed is 1271.65, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   399.26ms  414.40ms   3.09s    86.24%
        Req/Sec   176.35     82.06   565.00     69.08%
        Latency Distribution
        50%  258.09ms
        75%  585.71ms
        90%  986.95ms
        99%    1.85s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 14.536676
        stop time: 14.229380
        stop time: 14.032815
        stop time: 14.716685
        stop time: 14.780180
        stop time: 14.677038
        stop time: 14.425642
        stop time: 14.636352
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-c888f8587-757q4         3m           64Mi
        service1-7755b7b4b5-7zkx2        1m           33Mi
        service2-5c548c8f45-4n727        1m           10Mi
        ubuntu-client-76886f6bbd-zhfcl   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.536676, 14.22938, 14.032815, 14.716685, 14.78018, 14.677038, 14.425642, 14.636352]
    [exp] Throughput: 1378.8970560961523
[test.py] Finished running 9th optmization experiment: groundtruth->1429.042821312798, slowdown->1378.8970560961523, predicted->1461.3744840800057, err->2.2624698354039565
[test.py] Baseline throughput:  1443.0181012190617
[test.py] Groundtruth:  [1426.3806861351109, 1444.4763774034711, 1424.7460363476223, 1432.1970610063136, 1432.880483994071, 1439.5681612221329, 1428.9022577182577, 1439.9116714983352, 1402.5374532286633, 1429.042821312798]
[test.py] Slowdown:  [929.601774693452, 960.9792224520111, 994.9253397764863, 1038.3997838778528, 1074.5190368844105, 1141.0533331465808, 1178.0876087648217, 1245.6849085491324, 1316.3226601367192, 1378.8970560961523]
[test.py] Predicted:  [1481.921790632774, 1471.2909389922224, 1461.623873075433, 1466.0816915196067, 1449.8659463007712, 1480.4874164306493, 1453.6926787739217, 1466.6170998974135, 1473.2701150057674, 1461.3744840800057]
[test.py] Error percentage:  [3.8938486084073434, 1.856351686204243, 2.5883796681651523, 2.365919567624623, 1.1854067730306537, 2.8424673670038474, 1.7349276986412308, 1.8546574020953186, 5.043192366398231, 2.2624698354039565]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 3...
[test.py] Actual processing time range: [0, 80, 160, 240, 320, 400, 480, 560, 640, 720]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   364.18ms  217.17ms   1.25s    68.14%
        Req/Sec   189.89    103.95   505.00     64.11%
        Latency Distribution
        50%  325.63ms
        75%  506.88ms
        90%  672.31ms
        99%  959.96ms
        4063 requests in 3.02s, 630.88KB read
        Requests/sec:   1344.33
        Transfer/sec:    208.74KB
        [run.sh] Speed is 1344.33, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   371.53ms  337.70ms   3.01s    78.97%
        Req/Sec   183.18     89.42   515.00     68.00%
        Latency Distribution
        50%  280.70ms
        75%  546.32ms
        90%  813.36ms
        99%    1.50s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.080928
        stop time: 13.787646
        stop time: 14.104064
        stop time: 14.287455
        stop time: 13.884895
        stop time: 14.205925
        stop time: 13.959136
        stop time: 14.355407
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-tks9d        650m         64Mi
        service1-7755b7b4b5-w86qj        447m         34Mi
        service2-958786d58-xn56w         199m         9Mi
        ubuntu-client-76886f6bbd-wh2wz   21m          7Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.080928, 13.787646, 14.104064, 14.287455, 13.884895, 14.205925, 13.959136, 14.355407]
    [exp] Throughput: 1420.1336033291338
[test.py] Baseline throughput: 1420.1336033291338
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   364.44ms  242.09ms   1.26s    72.06%
        Req/Sec   182.94    117.99   555.00     69.27%
        Latency Distribution
        50%  308.73ms
        75%  499.61ms
        90%  696.23ms
        99%    1.18s
        3989 requests in 3.02s, 619.39KB read
        Requests/sec:   1321.66
        Transfer/sec:    205.22KB
        [run.sh] Speed is 1321.66, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   363.30ms  357.60ms   2.92s    84.13%
        Req/Sec   185.80     89.87   560.00     69.35%
        Latency Distribution
        50%  253.35ms
        75%  567.22ms
        90%  842.08ms
        99%    1.45s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.623873
        stop time: 13.620473
        stop time: 13.769125
        stop time: 14.093629
        stop time: 13.861637
        stop time: 13.938856
        stop time: 14.123911
        stop time: 14.208722
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-v5knk        791m         64Mi
        service1-7755b7b4b5-q4hzz        113m         31Mi
        service2-958786d58-gfhqh         299m         12Mi
        ubuntu-client-76886f6bbd-sxmt7   20m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.623873, 13.620473, 13.769125, 14.093629, 13.861637, 13.938856, 14.123911, 14.208722]
    [exp] Throughput: 1438.3286132482326
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '400.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1603.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   580.62ms  317.68ms   2.00s    72.57%
        Req/Sec   118.72     91.06   340.00     65.95%
        Latency Distribution
        50%  528.91ms
        75%  792.85ms
        90%  942.56ms
        99%    1.66s
        2388 requests in 3.03s, 370.79KB read
        Requests/sec:    788.85
        Transfer/sec:    122.49KB
        [run.sh] Speed is 788.85, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-788678d7df-49wnc        86m          47Mi
        service1-7755b7b4b5-vcnrz        67m          35Mi
        service2-7cbc657d97-b7p4t        2m           11Mi
        ubuntu-client-76886f6bbd-dxg5r   4m           0Mi
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   571.76ms  572.44ms   4.10s    86.24%
        Req/Sec   130.65     75.64   404.00     67.15%
        Latency Distribution
        50%  395.50ms
        75%  811.44ms
        90%    1.30s
        99%    2.77s
        20001 requests in 38.00s, 3.03MB read
        Requests/sec:    526.34
        Transfer/sec:     81.73KB
        ------------------------------
        stop time: 20.935699
        stop time: 21.040516
        stop time: 21.656098
        stop time: 22.159585
        stop time: 21.984100
        stop time: 21.781543
        stop time: 22.157831
        stop time: 21.970744
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.935699, 21.040516, 21.656098, 22.159585, 21.9841, 21.781543, 22.157831, 21.970744]
    [exp] Throughput: 921.2020147885626
[test.py] Finished running 0th optmization experiment: groundtruth->1438.3286132482326, slowdown->921.2020147885626, predicted->1460.6894329965144, err->1.5546391514650786
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '8e-05', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-5nzms cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   317.58ms  370.15ms   1.84s    84.47%
        Req/Sec   181.46     97.70   550.00     77.31%
        Latency Distribution
        50%  156.98ms
        75%  464.12ms
        90%  850.62ms
        99%    1.56s
        4040 requests in 3.02s, 627.30KB read
        Requests/sec:   1336.07
        Transfer/sec:    207.46KB
        [run.sh] Speed is 1336.07, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   393.59ms  431.10ms   3.04s    86.23%
        Req/Sec   187.06    110.69     0.94k    72.56%
        Latency Distribution
        50%  244.54ms
        75%  549.62ms
        90%  955.53ms
        99%    2.02s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.962685
        stop time: 13.477551
        stop time: 13.252236
        stop time: 13.713556
        stop time: 14.045240
        stop time: 13.981701
        stop time: 13.932547
        stop time: 14.158469
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-5nzms        1857m        68Mi
        service1-7755b7b4b5-vhkr5        403m         33Mi
        service2-958786d58-bzxvv         559m         12Mi
        ubuntu-client-76886f6bbd-fkr79   49m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [13.962685, 13.477551, 13.252236, 13.713556, 14.04524, 13.981701, 13.932547, 14.158469]
    [exp] Throughput: 1447.6495757911734
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '360.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1443.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   432.72ms  312.70ms   1.49s    66.71%
        Req/Sec   126.31     78.56   330.00     70.56%
        Latency Distribution
        50%  365.50ms
        75%  647.26ms
        90%  930.05ms
        99%    1.17s
        2788 requests in 3.03s, 432.90KB read
        Requests/sec:    921.65
        Transfer/sec:    143.11KB
        [run.sh] Speed is 921.65, duration is 32
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d32s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 32s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   568.42ms  547.32ms   6.24s    84.98%
        Req/Sec   126.23     75.44   464.00     66.47%
        Latency Distribution
        50%  434.24ms
        75%  741.87ms
        90%    1.26s
        99%    2.56s
        20000 requests in 32.00s, 3.03MB read
        Requests/sec:    624.99
        Transfer/sec:     97.05KB
        ------------------------------
        stop time: 20.523530
        stop time: 20.256207
        stop time: 20.655217
        stop time: 21.052965
        stop time: 20.822182
        stop time: 21.120545
        stop time: 20.983910
        stop time: 20.501894
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [20.52353, 20.256207, 20.655217, 21.052965, 20.822182, 21.120545, 20.98391, 20.501894]
    [exp] Throughput: 964.3407871853575
[test.py] Finished running 1th optmization experiment: groundtruth->1447.6495757911734, slowdown->964.3407871853575, predicted->1479.1853201950862, err->2.1784100884136794
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00016', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   426.71ms  471.88ms   2.55s    85.76%
        Req/Sec   165.20     94.44   490.00     68.33%
        Latency Distribution
        50%  251.82ms
        75%  659.14ms
        90%    1.12s
        99%    2.08s
        3952 requests in 3.02s, 613.64KB read
        Requests/sec:   1307.36
        Transfer/sec:    203.00KB
        [run.sh] Speed is 1307.36, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   354.52ms  282.52ms   2.15s    68.77%
        Req/Sec   187.66    107.56   550.00     65.69%
        Latency Distribution
        50%  298.08ms
        75%  519.83ms
        90%  749.29ms
        99%    1.19s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.385739
        stop time: 13.795370
        stop time: 13.663902
        stop time: 14.060321
        stop time: 13.944808
        stop time: 14.139765
        stop time: 14.238263
        stop time: 14.284367
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-rcbbm        699m         65Mi
        service1-7755b7b4b5-zzx8d        190m         29Mi
        service2-958786d58-xbdvj         180m         10Mi
        ubuntu-client-76886f6bbd-5rxvn   17m          16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.385739, 13.79537, 13.663902, 14.060321, 13.944808, 14.139765, 14.238263, 14.284367]
    [exp] Throughput: 1434.8162742421737
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '320.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1283.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   489.31ms  411.60ms   2.48s    74.16%
        Req/Sec   118.78     76.46   390.00     69.12%
        Latency Distribution
        50%  402.39ms
        75%  703.12ms
        90%    1.04s
        99%    1.73s
        2731 requests in 3.04s, 424.05KB read
        Requests/sec:    899.48
        Transfer/sec:    139.66KB
        [run.sh] Speed is 899.48, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   527.43ms  440.16ms   3.50s    77.66%
        Req/Sec   129.10     75.87     0.87k    69.12%
        Latency Distribution
        50%  433.81ms
        75%  728.60ms
        90%    1.09s
        99%    2.14s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 19.743041
        stop time: 20.396011
        stop time: 20.250766
        stop time: 20.025372
        stop time: 20.341335
        stop time: 20.483428
        stop time: 20.361289
        stop time: 20.307979
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d5685b766-bqw29        1m           60Mi
        service1-7755b7b4b5-4jfcs        1m           33Mi
        service2-6f89f64dfc-kszjc        55m          12Mi
        ubuntu-client-76886f6bbd-r8jzl   5m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.743041, 20.396011, 20.250766, 20.025372, 20.341335, 20.483428, 20.361289, 20.307979]
    [exp] Throughput: 988.2080774139479
[test.py] Finished running 2th optmization experiment: groundtruth->1434.8162742421737, slowdown->988.2080774139479, predicted->1447.1724922248625, err->0.8611707439138843
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00024', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   396.00ms  288.83ms   1.42s    68.85%
        Req/Sec   195.35    132.25   590.00     72.45%
        Latency Distribution
        50%  373.99ms
        75%  561.99ms
        90%  790.87ms
        99%    1.28s
        3977 requests in 3.02s, 617.52KB read
        Requests/sec:   1317.04
        Transfer/sec:    204.50KB
        [run.sh] Speed is 1317.04, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   394.41ms  454.93ms   3.26s    86.51%
        Req/Sec   185.55    104.36     1.06k    72.03%
        Latency Distribution
        50%  226.04ms
        75%  573.50ms
        90%    1.02s
        99%    2.04s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.148915
        stop time: 13.295764
        stop time: 13.610803
        stop time: 13.554383
        stop time: 13.704790
        stop time: 13.731096
        stop time: 14.017517
        stop time: 14.169236
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-xntmn        445m         58Mi
        service1-7755b7b4b5-skst5        139m         36Mi
        service2-958786d58-kv6tj         192m         12Mi
        ubuntu-client-76886f6bbd-dmwsp   20m          9Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.148915, 13.295764, 13.610803, 13.554383, 13.70479, 13.731096, 14.017517, 14.169236]
    [exp] Throughput: 1464.7654694430516
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '280.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1123.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   486.78ms  295.91ms   1.76s    70.66%
        Req/Sec   127.93     79.31   363.00     65.83%
        Latency Distribution
        50%  441.41ms
        75%  663.44ms
        90%  886.66ms
        99%    1.37s
        2838 requests in 3.02s, 440.67KB read
        Requests/sec:    939.71
        Transfer/sec:    145.91KB
        [run.sh] Speed is 939.71, duration is 31
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d31s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 31s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   524.11ms  539.08ms   3.93s    87.18%
        Req/Sec   143.88     83.98   590.00     70.20%
        Latency Distribution
        50%  358.05ms
        75%  705.16ms
        90%    1.23s
        99%    2.46s
        20000 requests in 31.00s, 3.03MB read
        Requests/sec:    645.16
        Transfer/sec:    100.18KB
        ------------------------------
        stop time: 19.073086
        stop time: 18.600218
        stop time: 19.262560
        stop time: 18.793104
        stop time: 19.435851
        stop time: 19.459108
        stop time: 18.939417
        stop time: 19.534814
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-75ddd887-8np4c          700m         64Mi
        service1-7755b7b4b5-p66lh        512m         33Mi
        service2-dc56fbc74-m24mb         276m         13Mi
        ubuntu-client-76886f6bbd-d8s5m   27m          21Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [19.073086, 18.600218, 19.26256, 18.793104, 19.435851, 19.459108, 18.939417, 19.534814]
    [exp] Throughput: 1045.0811563650557
[test.py] Finished running 3th optmization experiment: groundtruth->1464.7654694430516, slowdown->1045.0811563650557, predicted->1479.4355043697994, err->1.0015279055100743
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00032', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-j8dw4 cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   304.75ms  281.47ms   2.08s    79.04%
        Req/Sec   180.47     88.67   464.00     65.74%
        Latency Distribution
        50%  240.97ms
        75%  447.52ms
        90%  663.23ms
        99%    1.19s
        3925 requests in 3.02s, 609.45KB read
        Requests/sec:   1299.17
        Transfer/sec:    201.73KB
        [run.sh] Speed is 1299.17, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   385.95ms  402.57ms   2.95s    87.65%
        Req/Sec   181.94     90.40   626.00     70.33%
        Latency Distribution
        50%  255.09ms
        75%  494.65ms
        90%  881.57ms
        99%    1.97s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.821887
        stop time: 13.606509
        stop time: 13.884897
        stop time: 13.711721
        stop time: 14.005945
        stop time: 13.995097
        stop time: 14.135858
        stop time: 13.996466
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-j8dw4        627m         66Mi
        service1-7755b7b4b5-p57jr        245m         35Mi
        service2-958786d58-5vnvz         199m         12Mi
        ubuntu-client-76886f6bbd-572s4   18m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [13.821887, 13.606509, 13.884897, 13.711721, 14.005945, 13.995097, 14.135858, 13.996466]
    [exp] Throughput: 1439.3876557035107
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '240.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '963.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   474.54ms  309.37ms   2.27s    68.06%
        Req/Sec   143.28     75.79   330.00     66.33%
        Latency Distribution
        50%  436.99ms
        75%  638.69ms
        90%  884.90ms
        99%    1.63s
        2981 requests in 3.03s, 462.87KB read
        Requests/sec:    984.77
        Transfer/sec:    152.91KB
        [run.sh] Speed is 984.77, duration is 30
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d30s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 30s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   488.90ms  427.99ms   3.62s    81.23%
        Req/Sec   144.52     86.64   474.00     66.62%
        Latency Distribution
        50%  393.11ms
        75%  650.74ms
        90%    1.04s
        99%    2.05s
        20000 requests in 30.00s, 3.03MB read
        Requests/sec:    666.66
        Transfer/sec:    103.52KB
        ------------------------------
        stop time: 18.676725
        stop time: 18.685579
        stop time: 18.692919
        stop time: 18.762520
        stop time: 18.811840
        stop time: 18.966846
        stop time: 18.682600
        stop time: 18.324199
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-686fb79d75-g9ckc        1477m        65Mi
        service1-7755b7b4b5-87bh6        1051m        36Mi
        service2-5d558db67c-b8vdw        482m         12Mi
        ubuntu-client-76886f6bbd-ql74s   37m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.676725, 18.685579, 18.692919, 18.76252, 18.81184, 18.966846, 18.6826, 18.324199]
    [exp] Throughput: 1069.4956394924848
[test.py] Finished running 4th optmization experiment: groundtruth->1439.3876557035107, slowdown->1069.4956394924848, predicted->1440.7349880726952, err->0.09360455217506337
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0004', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-9t2n8 cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   378.02ms  251.26ms   1.50s    70.32%
        Req/Sec   173.02     91.33   424.00     65.44%
        Latency Distribution
        50%  332.81ms
        75%  518.54ms
        90%  734.98ms
        99%    1.10s
        3850 requests in 3.02s, 597.80KB read
        Requests/sec:   1275.79
        Transfer/sec:    198.10KB
        [run.sh] Speed is 1275.79, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   386.20ms  441.84ms   3.50s    87.94%
        Req/Sec   186.09     95.53   740.00     72.73%
        Latency Distribution
        50%  217.12ms
        75%  529.64ms
        90%  917.55ms
        99%    2.18s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 13.798626
        stop time: 13.664587
        stop time: 13.716144
        stop time: 14.076241
        stop time: 13.521436
        stop time: 13.842111
        stop time: 13.927663
        stop time: 13.968632
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-9t2n8   3m           3Mi
        service1-7755b7b4b5-s8lc5   2m           3Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [13.798626, 13.664587, 13.716144, 14.076241, 13.521436, 13.842111, 13.927663, 13.968632]
    [exp] Throughput: 1447.7615073513712
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '200.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '803.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-9994fb58c-rpfnb cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   560.90ms  545.48ms   2.51s    84.96%
        Req/Sec   143.83     84.74   414.00     67.34%
        Latency Distribution
        50%  370.30ms
        75%  736.14ms
        90%    1.32s
        99%    2.41s
        3131 requests in 3.03s, 486.16KB read
        Requests/sec:   1033.67
        Transfer/sec:    160.50KB
        [run.sh] Speed is 1033.67, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   467.58ms  448.59ms   3.95s    82.28%
        Req/Sec   148.10     81.67   565.00     68.69%
        Latency Distribution
        50%  351.54ms
        75%  682.40ms
        90%    1.02s
        99%    2.07s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 17.124340
        stop time: 17.441937
        stop time: 17.589316
        stop time: 17.804028
        stop time: 17.912064
        stop time: 17.882444
        stop time: 17.898509
        stop time: 17.768176
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-9994fb58c-rpfnb         1533m        68Mi
        service1-7755b7b4b5-zzbhl        1092m        32Mi
        service2-559ddfcfcb-62swq        496m         10Mi
        ubuntu-client-76886f6bbd-mjps2   41m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [17.12434, 17.441937, 17.589316, 17.804028, 17.912064, 17.882444, 17.898509, 17.768176]
    [exp] Throughput: 1131.3751878135845
[test.py] Finished running 5th optmization experiment: groundtruth->1447.7615073513712, slowdown->1131.3751878135845, predicted->1464.2358472499645, err->1.137918076626626
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   356.96ms  237.40ms   1.18s    62.78%
        Req/Sec   199.20     97.51   470.00     73.87%
        Latency Distribution
        50%  326.65ms
        75%  522.69ms
        90%  690.09ms
        99%  974.18ms
        4115 requests in 3.02s, 638.95KB read
        Requests/sec:   1361.66
        Transfer/sec:    211.43KB
        [run.sh] Speed is 1361.66, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   393.81ms  441.21ms   4.04s    85.89%
        Req/Sec   183.39     90.50   595.00     68.56%
        Latency Distribution
        50%  241.21ms
        75%  526.10ms
        90%  991.33ms
        99%    2.03s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.050314
        stop time: 13.572697
        stop time: 13.243166
        stop time: 13.933706
        stop time: 14.069847
        stop time: 14.142229
        stop time: 14.182433
        stop time: 14.182904
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [14.050314, 13.572697, 13.243166, 13.933706, 14.069847, 14.142229, 14.182433, 14.182904]
    [exp] Throughput: 1436.558488545098
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '160.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '643.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   456.70ms  365.72ms   1.89s    67.16%
        Req/Sec   140.55     84.53   333.00     58.77%
        Latency Distribution
        50%  369.92ms
        75%  651.18ms
        90%    1.00s
        99%    1.49s
        3114 requests in 3.03s, 483.52KB read
        Requests/sec:   1027.92
        Transfer/sec:    159.61KB
        [run.sh] Speed is 1027.92, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   455.46ms  429.97ms   3.10s    85.25%
        Req/Sec   153.02     87.09   474.00     67.06%
        Latency Distribution
        50%  341.88ms
        75%  611.90ms
        90%    1.00s
        99%    2.11s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 17.102008
        stop time: 16.939237
        stop time: 16.162591
        stop time: 17.256464
        stop time: 17.004980
        stop time: 17.228380
        stop time: 16.919561
        stop time: 17.177643
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f464877cb-9qhvv         369m         69Mi
        service1-7755b7b4b5-lnnh5        291m         30Mi
        service2-756d446d74-4f74r        318m         9Mi
        ubuntu-client-76886f6bbd-rkbpl   20m          17Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [17.102008, 16.939237, 16.162591, 17.256464, 17.00498, 17.22838, 16.919561, 17.177643]
    [exp] Throughput: 1178.2825094919494
[test.py] Finished running 6th optmization experiment: groundtruth->1436.558488545098, slowdown->1178.2825094919494, predicted->1453.9894489801648, err->1.213383274962946
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00056', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   422.80ms  414.48ms   1.87s    84.82%
        Req/Sec   184.58     99.20   430.00     69.41%
        Latency Distribution
        50%  244.29ms
        75%  623.17ms
        90%    1.10s
        99%    1.71s
        4094 requests in 3.03s, 635.69KB read
        Requests/sec:   1351.49
        Transfer/sec:    209.85KB
        [run.sh] Speed is 1351.49, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   409.16ms  463.75ms   3.33s    85.82%
        Req/Sec   183.28     97.33   690.00     69.67%
        Latency Distribution
        50%  224.11ms
        75%  572.84ms
        90%    1.04s
        99%    2.03s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.250119
        stop time: 13.739069
        stop time: 14.165369
        stop time: 13.326668
        stop time: 14.179001
        stop time: 13.333600
        stop time: 14.129132
        stop time: 13.760259
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-9cmpb        2m           67Mi
        service1-7755b7b4b5-kftfh        1m           34Mi
        service2-958786d58-vsv4f         61m          14Mi
        ubuntu-client-76886f6bbd-rkxrg   4m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.250119, 13.739069, 14.165369, 13.326668, 14.179001, 13.3336, 14.129132, 13.760259]
    [exp] Throughput: 1442.9595779134006
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '120.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '483.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   427.83ms  221.96ms   1.53s    69.89%
        Req/Sec   159.77    103.87   424.00     67.15%
        Latency Distribution
        50%  383.98ms
        75%  558.65ms
        90%  726.50ms
        99%    1.11s
        3442 requests in 3.02s, 534.45KB read
        Requests/sec:   1138.92
        Transfer/sec:    176.84KB
        [run.sh] Speed is 1138.92, duration is 26
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d26s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 26s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   427.77ms  413.04ms   2.89s    85.40%
        Req/Sec   164.91     90.52   580.00     67.09%
        Latency Distribution
        50%  331.74ms
        75%  594.31ms
        90%  922.69ms
        99%    1.98s
        20000 requests in 26.00s, 3.03MB read
        Requests/sec:    769.22
        Transfer/sec:    119.44KB
        ------------------------------
        stop time: 15.446303
        stop time: 15.334249
        stop time: 15.293394
        stop time: 16.133038
        stop time: 16.469279
        stop time: 16.247805
        stop time: 16.376325
        stop time: 15.992913
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5bf5bf77b8-ncx87        561m         67Mi
        service1-7755b7b4b5-lbt8r        387m         32Mi
        service2-677597bc9b-ct25t        170m         8Mi
        ubuntu-client-76886f6bbd-zk4hm   14m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.446303, 15.334249, 15.293394, 16.133038, 16.469279, 16.247805, 16.376325, 15.992913]
    [exp] Throughput: 1256.9396225752828
[test.py] Finished running 7th optmization experiment: groundtruth->1442.9595779134006, slowdown->1256.9396225752828, predicted->1482.2431073981663, err->2.722427577740735
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00064', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   361.82ms  226.68ms   1.40s    63.85%
        Req/Sec   185.15    104.51   470.00     63.38%
        Latency Distribution
        50%  335.34ms
        75%  522.31ms
        90%  663.60ms
        99%  988.63ms
        4003 requests in 3.02s, 621.56KB read
        Requests/sec:   1324.26
        Transfer/sec:    205.62KB
        [run.sh] Speed is 1324.26, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   375.70ms  342.38ms   2.29s    83.44%
        Req/Sec   183.07     98.00   570.00     69.17%
        Latency Distribution
        50%  288.21ms
        75%  495.86ms
        90%  775.40ms
        99%    1.70s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.423156
        stop time: 13.987366
        stop time: 13.895245
        stop time: 14.005287
        stop time: 14.218405
        stop time: 13.773704
        stop time: 14.001539
        stop time: 14.135507
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-2dbql        1043m        67Mi
        service1-7755b7b4b5-b2m4b        641m         33Mi
        service2-958786d58-xjjmd         453m         10Mi
        ubuntu-client-76886f6bbd-rqp7v   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.423156, 13.987366, 13.895245, 14.005287, 14.218405, 13.773704, 14.001539, 14.135507]
    [exp] Throughput: 1435.7474867980552
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '323.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7779556975-d8jvx cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   398.57ms  261.43ms   1.74s    68.77%
        Req/Sec   162.06    103.22   444.00     65.85%
        Latency Distribution
        50%  344.22ms
        75%  557.08ms
        90%  797.69ms
        99%    1.16s
        3391 requests in 3.03s, 526.53KB read
        Requests/sec:   1119.33
        Transfer/sec:    173.80KB
        [run.sh] Speed is 1119.33, duration is 26
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d26s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 26s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   425.29ms  444.88ms   4.31s    87.12%
        Req/Sec   166.32     77.78   470.00     70.13%
        Latency Distribution
        50%  291.36ms
        75%  569.36ms
        90%  989.16ms
        99%    2.13s
        20000 requests in 26.00s, 3.03MB read
        Requests/sec:    769.23
        Transfer/sec:    119.44KB
        ------------------------------
        stop time: 15.145615
        stop time: 15.709999
        stop time: 15.458799
        stop time: 15.297105
        stop time: 15.352915
        stop time: 14.890010
        stop time: 15.599821
        stop time: 15.566707
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7779556975-d8jvx        3m           60Mi
        service1-7755b7b4b5-b4qdm        2m           29Mi
        ubuntu-client-76886f6bbd-qgc28   22m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [15.145615, 15.709999, 15.458799, 15.297105, 15.352915, 14.89001, 15.599821, 15.566707]
    [exp] Throughput: 1300.5912626067632
[test.py] Finished running 8th optmization experiment: groundtruth->1435.7474867980552, slowdown->1300.5912626067632, predicted->1453.5917529963135, err->1.2428554716159634
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00072', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-wgq5h cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   319.44ms  316.30ms   1.72s    85.94%
        Req/Sec   188.06     87.10   460.00     72.69%
        Latency Distribution
        50%  246.15ms
        75%  484.96ms
        90%  800.45ms
        99%    1.27s
        4120 requests in 3.03s, 639.73KB read
        Requests/sec:   1358.01
        Transfer/sec:    210.86KB
        [run.sh] Speed is 1358.01, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   374.08ms  365.45ms   2.58s    85.61%
        Req/Sec   188.89    109.50   630.00     69.20%
        Latency Distribution
        50%  270.64ms
        75%  525.47ms
        90%  839.79ms
        99%    1.76s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.199905
        stop time: 13.192056
        stop time: 13.095797
        stop time: 14.251919
        stop time: 14.144129
        stop time: 14.260129
        stop time: 14.315852
        stop time: 14.335123
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-wgq5h        1941m        66Mi
        service1-7755b7b4b5-qzbt4        1238m        38Mi
        service2-958786d58-9jg9m         612m         12Mi
        ubuntu-client-76886f6bbd-64mrp   36m          18Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [12.199905, 13.192056, 13.095797, 14.251919, 14.144129, 14.260129, 14.315852, 14.335123]
    [exp] Throughput: 1457.2624541520186
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '40.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '163.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   395.74ms  322.26ms   2.11s    74.78%
        Req/Sec   167.50     84.39   370.00     65.49%
        Latency Distribution
        50%  312.81ms
        75%  555.48ms
        90%  816.62ms
        99%    1.50s
        3805 requests in 3.02s, 590.82KB read
        Requests/sec:   1259.39
        Transfer/sec:    195.55KB
        [run.sh] Speed is 1259.39, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   368.98ms  288.05ms   2.32s    73.04%
        Req/Sec   176.59     85.68   525.00     66.01%
        Latency Distribution
        50%  312.23ms
        75%  519.70ms
        90%  735.66ms
        99%    1.32s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 14.033165
        stop time: 14.448366
        stop time: 14.478380
        stop time: 14.737786
        stop time: 14.519033
        stop time: 14.696024
        stop time: 14.692579
        stop time: 14.664991
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [14.033165, 14.448366, 14.47838, 14.737786, 14.519033, 14.696024, 14.692579, 14.664991]
    [exp] Throughput: 1376.1035016983355
[test.py] Finished running 9th optmization experiment: groundtruth->1457.2624541520186, slowdown->1376.1035016983355, predicted->1458.2371276578333, err->0.06688386865644583
[test.py] Baseline throughput:  1420.1336033291338
[test.py] Groundtruth:  [1438.3286132482326, 1447.6495757911734, 1434.8162742421737, 1464.7654694430516, 1439.3876557035107, 1447.7615073513712, 1436.558488545098, 1442.9595779134006, 1435.7474867980552, 1457.2624541520186]
[test.py] Slowdown:  [921.2020147885626, 964.3407871853575, 988.2080774139479, 1045.0811563650557, 1069.4956394924848, 1131.3751878135845, 1178.2825094919494, 1256.9396225752828, 1300.5912626067632, 1376.1035016983355]
[test.py] Predicted:  [1460.6894329965144, 1479.1853201950862, 1447.1724922248625, 1479.4355043697994, 1440.7349880726952, 1464.2358472499645, 1453.9894489801648, 1482.2431073981663, 1453.5917529963135, 1458.2371276578333]
[test.py] Error percentage:  [1.5546391514650786, 2.1784100884136794, 0.8611707439138843, 1.0015279055100743, 0.09360455217506337, 1.137918076626626, 1.213383274962946, 2.722427577740735, 1.2428554716159634, 0.06688386865644583]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 4...
[test.py] Actual processing time range: [0, 80, 160, 240, 320, 400, 480, 560, 640, 720]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   313.59ms  283.65ms   1.95s    81.83%
        Req/Sec   177.54     81.57   464.00     76.79%
        Latency Distribution
        50%  206.46ms
        75%  485.83ms
        90%  699.96ms
        99%    1.34s
        4010 requests in 3.02s, 622.65KB read
        Requests/sec:   1326.59
        Transfer/sec:    205.98KB
        [run.sh] Speed is 1326.59, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   362.84ms  283.89ms   1.78s    73.32%
        Req/Sec   184.63    102.75   540.00     65.56%
        Latency Distribution
        50%  287.49ms
        75%  523.68ms
        90%  752.86ms
        99%    1.27s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.221297
        stop time: 13.898091
        stop time: 13.951481
        stop time: 14.207943
        stop time: 13.945415
        stop time: 13.751557
        stop time: 14.321883
        stop time: 14.055452
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-b45ng        1308m        72Mi
        service1-7755b7b4b5-5nlfx        862m         36Mi
        service2-958786d58-s649c         298m         10Mi
        ubuntu-client-76886f6bbd-lrfhx   53m          17Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.221297, 13.898091, 13.951481, 14.207943, 13.945415, 13.751557, 14.321883, 14.055452]
    [exp] Throughput: 1424.0815157076324
[test.py] Baseline throughput: 1424.0815157076324
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   394.15ms  383.10ms   2.00s    84.97%
        Req/Sec   184.47    102.34   535.00     70.14%
        Latency Distribution
        50%  270.02ms
        75%  571.09ms
        90%  955.21ms
        99%    1.61s
        4099 requests in 3.03s, 636.47KB read
        Requests/sec:   1353.03
        Transfer/sec:    210.09KB
        [run.sh] Speed is 1353.03, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   370.84ms  342.56ms   2.33s    83.12%
        Req/Sec   188.31    107.56   650.00     68.90%
        Latency Distribution
        50%  267.15ms
        75%  510.65ms
        90%  787.94ms
        99%    1.71s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.216601
        stop time: 13.957842
        stop time: 13.701227
        stop time: 14.067333
        stop time: 13.349849
        stop time: 14.189341
        stop time: 14.084463
        stop time: 14.179498
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [13.216601, 13.957842, 13.701227, 14.067333, 13.349849, 14.189341, 14.084463, 14.179498]
    [exp] Throughput: 1444.7454310693265
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '400.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1603.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   554.93ms  363.94ms   1.99s    65.75%
        Req/Sec   111.56     98.60   450.00     79.91%
        Latency Distribution
        50%  482.80ms
        75%  761.44ms
        90%    1.18s
        99%    1.46s
        2478 requests in 3.03s, 384.77KB read
        Requests/sec:    818.01
        Transfer/sec:    127.01KB
        [run.sh] Speed is 818.01, duration is 36
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d36s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-788678d7df-z9dg4        120m         67Mi
        service1-7755b7b4b5-4qdwp        46m          33Mi
        service2-7cbc657d97-w5b9d        61m          10Mi
        ubuntu-client-76886f6bbd-zkxs6   20m          15Mi
        Running 36s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   596.12ms  639.23ms   4.79s    85.37%
        Req/Sec   126.80     73.05   414.00     62.33%
        Latency Distribution
        50%  361.50ms
        75%  895.66ms
        90%    1.53s
        99%    2.66s
        20000 requests in 36.00s, 3.03MB read
        Requests/sec:    555.55
        Transfer/sec:     86.26KB
        ------------------------------
        stop time: 21.272039
        stop time: 20.239300
        stop time: 21.822692
        stop time: 21.533656
        stop time: 22.017122
        stop time: 22.190203
        stop time: 22.130191
        stop time: 22.051904
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [21.272039, 20.2393, 21.822692, 21.533656, 22.017122, 22.190203, 22.130191, 22.051904]
    [exp] Throughput: 923.4830407274434
[test.py] Finished running 0th optmization experiment: groundtruth->1444.7454310693265, slowdown->923.4830407274434, predicted->1466.4327987418962, err->1.5011203500756432
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '8e-05', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   363.70ms  211.49ms   1.35s    72.22%
        Req/Sec   191.06    123.01   530.00     62.50%
        Latency Distribution
        50%  337.54ms
        75%  471.44ms
        90%  626.06ms
        99%    1.09s
        4075 requests in 3.02s, 632.74KB read
        Requests/sec:   1349.54
        Transfer/sec:    209.55KB
        [run.sh] Speed is 1349.54, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   370.32ms  359.31ms   3.08s    84.23%
        Req/Sec   187.21    102.35   636.00     71.70%
        Latency Distribution
        50%  256.56ms
        75%  532.84ms
        90%  845.22ms
        99%    1.60s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.403897
        stop time: 13.770034
        stop time: 13.573235
        stop time: 13.651746
        stop time: 14.096478
        stop time: 14.022786
        stop time: 14.021575
        stop time: 14.045743
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-vd6sc        2m           67Mi
        service1-7755b7b4b5-8sxwb        1m           36Mi
        service2-958786d58-9gjxh         1m           13Mi
        ubuntu-client-76886f6bbd-z6chn   21m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.403897, 13.770034, 13.573235, 13.651746, 14.096478, 14.022786, 14.021575, 14.045743]
    [exp] Throughput: 1446.8443754476511
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '360.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1443.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   516.15ms  251.66ms   1.77s    71.46%
        Req/Sec   113.23     87.30   414.00     68.59%
        Latency Distribution
        50%  519.98ms
        75%  657.59ms
        90%  819.45ms
        99%    1.29s
        2375 requests in 3.02s, 368.77KB read
        Requests/sec:    785.72
        Transfer/sec:    122.00KB
        [run.sh] Speed is 785.72, duration is 38
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d38s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6d789b6d66-77wvk        425m         65Mi
        service1-7755b7b4b5-llb8b        295m         30Mi
        service2-55fb5cdf7f-g4w7z        130m         9Mi
        ubuntu-client-76886f6bbd-w4jcm   8m           0Mi
        Running 38s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   545.51ms  442.65ms   3.38s    73.43%
        Req/Sec   124.28     78.04   474.00     68.46%
        Latency Distribution
        50%  451.52ms
        75%  756.27ms
        90%    1.13s
        99%    2.06s
        20000 requests in 38.00s, 3.03MB read
        Requests/sec:    526.31
        Transfer/sec:     81.72KB
        ------------------------------
        stop time: 20.599373
        stop time: 21.296100
        stop time: 21.072069
        stop time: 21.345496
        stop time: 21.366906
        stop time: 21.344812
        stop time: 21.078124
        stop time: 21.335577
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [20.599373, 21.2961, 21.072069, 21.345496, 21.366906, 21.344812, 21.078124, 21.335577]
    [exp] Throughput: 944.295662465812
[test.py] Finished running 1th optmization experiment: groundtruth->1446.8443754476511, slowdown->944.295662465812, predicted->1432.5408842467843, err->-0.988599150232818
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00016', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   351.12ms  245.88ms   1.38s    63.57%
        Req/Sec   193.07     95.57   505.00     69.23%
        Latency Distribution
        50%  307.96ms
        75%  527.29ms
        90%  697.04ms
        99%  975.36ms
        4067 requests in 3.03s, 631.50KB read
        Requests/sec:   1344.02
        Transfer/sec:    208.69KB
        [run.sh] Speed is 1344.02, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   385.74ms  419.99ms   3.18s    85.92%
        Req/Sec   188.51    104.62   660.00     73.52%
        Latency Distribution
        50%  247.58ms
        75%  565.40ms
        90%  957.13ms
        99%    1.88s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.141449
        stop time: 13.063561
        stop time: 13.662912
        stop time: 13.754083
        stop time: 14.149632
        stop time: 14.170599
        stop time: 14.089526
        stop time: 13.999044
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-8h6pj        1372m        65Mi
        service1-7755b7b4b5-zbxfj        404m         32Mi
        service2-958786d58-p8v88         601m         12Mi
        ubuntu-client-76886f6bbd-f9gjf   50m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.141449, 13.063561, 13.662912, 13.754083, 14.149632, 14.170599, 14.089526, 13.999044]
    [exp] Throughput: 1454.1382165281968
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '320.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1283.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   418.94ms  323.46ms   1.42s    61.49%
        Req/Sec   150.60     88.70   424.00     70.31%
        Latency Distribution
        50%  328.36ms
        75%  679.45ms
        90%  918.03ms
        99%    1.13s
        3100 requests in 3.03s, 481.35KB read
        Requests/sec:   1022.28
        Transfer/sec:    158.73KB
        [run.sh] Speed is 1022.28, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   531.69ms  402.79ms   3.07s    75.53%
        Req/Sec   127.95     75.97   440.00     67.20%
        Latency Distribution
        50%  467.03ms
        75%  711.84ms
        90%    1.02s
        99%    2.00s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 20.382740
        stop time: 20.317561
        stop time: 20.102966
        stop time: 20.054652
        stop time: 19.846751
        stop time: 20.620465
        stop time: 20.449988
        stop time: 20.431501
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [20.38274, 20.317561, 20.102966, 20.054652, 19.846751, 20.620465, 20.449988, 20.431501]
    [exp] Throughput: 986.3962152371781
[test.py] Finished running 2th optmization experiment: groundtruth->1454.1382165281968, slowdown->986.3962152371781, predicted->1443.2901010216478, err->-0.7460168079791774
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00024', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   376.30ms  296.60ms   2.16s    74.98%
        Req/Sec   177.26    108.14   490.00     67.57%
        Latency Distribution
        50%  318.69ms
        75%  515.62ms
        90%  726.21ms
        99%    1.49s
        3992 requests in 3.03s, 619.85KB read
        Requests/sec:   1318.39
        Transfer/sec:    204.71KB
        [run.sh] Speed is 1318.39, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   387.81ms  454.33ms   3.09s    86.14%
        Req/Sec   181.70     87.33   606.00     71.67%
        Latency Distribution
        50%  212.62ms
        75%  568.05ms
        90%    1.04s
        99%    1.97s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 14.114397
        stop time: 13.593509
        stop time: 13.850866
        stop time: 14.017195
        stop time: 13.948055
        stop time: 13.863128
        stop time: 14.254684
        stop time: 14.153535
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-gdhnt        1937m        61Mi
        service1-7755b7b4b5-q6nk2        646m         29Mi
        service2-958786d58-wlnk8         584m         10Mi
        ubuntu-client-76886f6bbd-q7ldh   22m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.114397, 13.593509, 13.850866, 14.017195, 13.948055, 13.863128, 14.254684, 14.153535]
    [exp] Throughput: 1431.1862953822354
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '280.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '1123.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   562.61ms  481.60ms   2.72s    83.46%
        Req/Sec   133.71     92.88   404.00     67.03%
        Latency Distribution
        50%  473.89ms
        75%  700.19ms
        90%    1.28s
        99%    2.12s
        2669 requests in 3.02s, 414.42KB read
        Requests/sec:    883.85
        Transfer/sec:    137.24KB
        [run.sh] Speed is 883.85, duration is 33
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d33s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 33s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   481.75ms  349.46ms   2.65s    68.05%
        Req/Sec   135.91     91.10   505.00     67.04%
        Latency Distribution
        50%  424.73ms
        75%  692.82ms
        90%  941.76ms
        99%    1.55s
        20000 requests in 33.00s, 3.03MB read
        Requests/sec:    606.06
        Transfer/sec:     94.10KB
        ------------------------------
        stop time: 18.605936
        stop time: 18.932348
        stop time: 19.132126
        stop time: 19.257187
        stop time: 19.414375
        stop time: 19.340859
        stop time: 19.355373
        stop time: 19.396628
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [18.605936, 18.932348, 19.132126, 19.257187, 19.414375, 19.340859, 19.355373, 19.396628]
    [exp] Throughput: 1042.7879896267623
[test.py] Finished running 3th optmization experiment: groundtruth->1431.1862953822354, slowdown->1042.7879896267623, predicted->1474.8442453863556, err->3.0504728940588604
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00032', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   390.99ms  448.38ms   2.69s    85.23%
        Req/Sec   170.10     77.11   363.00     63.71%
        Latency Distribution
        50%  192.35ms
        75%  589.47ms
        90%    1.06s
        99%    1.94s
        4025 requests in 3.03s, 624.98KB read
        Requests/sec:   1328.85
        Transfer/sec:    206.34KB
        [run.sh] Speed is 1328.85, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   405.57ms  450.25ms   3.15s    88.36%
        Req/Sec   182.70     98.43   590.00     72.84%
        Latency Distribution
        50%  246.41ms
        75%  531.00ms
        90%  947.15ms
        99%    2.11s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.858159
        stop time: 13.716257
        stop time: 13.289326
        stop time: 13.919203
        stop time: 13.913337
        stop time: 13.988448
        stop time: 14.107825
        stop time: 14.287292
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-btkgt        637m         65Mi
        service1-7755b7b4b5-l4bnm        373m         24Mi
        service2-958786d58-fxbcr         190m         8Mi
        ubuntu-client-76886f6bbd-4l6xs   15m          16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.858159, 13.716257, 13.289326, 13.919203, 13.913337, 13.988448, 14.107825, 14.287292]
    [exp] Throughput: 1440.4052969212319
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '240.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '963.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   508.43ms  470.81ms   2.54s    82.33%
        Req/Sec   138.77     75.04   373.00     62.15%
        Latency Distribution
        50%  354.62ms
        75%  652.88ms
        90%    1.22s
        99%    2.05s
        3069 requests in 3.03s, 476.53KB read
        Requests/sec:   1014.08
        Transfer/sec:    157.46KB
        [run.sh] Speed is 1014.08, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   485.72ms  402.77ms   3.75s    76.93%
        Req/Sec   142.57     77.84   484.00     67.09%
        Latency Distribution
        50%  406.63ms
        75%  664.50ms
        90%  960.62ms
        99%    2.02s
        20000 requests in 29.00s, 3.03MB read
        Requests/sec:    689.65
        Transfer/sec:    107.08KB
        ------------------------------
        stop time: 18.507511
        stop time: 18.723294
        stop time: 18.686768
        stop time: 18.610703
        stop time: 18.487003
        stop time: 18.583503
        stop time: 18.742439
        stop time: 18.567524
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-686fb79d75-n895n        805m         64Mi
        service1-7755b7b4b5-5qm8b        636m         28Mi
        service2-5d558db67c-l8pmv        1m           10Mi
        ubuntu-client-76886f6bbd-nbhh5   15m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [18.507511, 18.723294, 18.686768, 18.610703, 18.487003, 18.583503, 18.742439, 18.567524]
    [exp] Throughput: 1074.4835704578668
[test.py] Finished running 4th optmization experiment: groundtruth->1440.4052969212319, slowdown->1074.4835704578668, predicted->1449.801374946318, err->0.6523218183916432
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.0004', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   355.49ms  284.26ms   1.70s    70.02%
        Req/Sec   187.59     93.22   404.00     64.65%
        Latency Distribution
        50%  290.46ms
        75%  492.00ms
        90%  765.03ms
        99%    1.24s
        4059 requests in 3.02s, 630.25KB read
        Requests/sec:   1344.02
        Transfer/sec:    208.69KB
        [run.sh] Speed is 1344.02, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   377.45ms  382.40ms   2.78s    86.65%
        Req/Sec   184.16     93.28   555.00     70.96%
        Latency Distribution
        50%  269.15ms
        75%  537.66ms
        90%  872.99ms
        99%    1.83s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.09
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.537044
        stop time: 14.227121
        stop time: 13.722446
        stop time: 14.207881
        stop time: 14.295846
        stop time: 13.661194
        stop time: 13.800014
        stop time: 14.189882
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-28t8n        651m         68Mi
        service1-7755b7b4b5-9pxk8        283m         34Mi
        service2-958786d58-899pc         130m         12Mi
        ubuntu-client-76886f6bbd-7sw4b   20m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.537044, 14.227121, 13.722446, 14.207881, 14.295846, 13.661194, 13.800014, 14.189882]
    [exp] Throughput: 1433.1597406654455
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '200.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '803.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   470.93ms  274.55ms   1.50s    70.60%
        Req/Sec   133.01    101.91   480.00     65.32%
        Latency Distribution
        50%  448.06ms
        75%  629.37ms
        90%  795.53ms
        99%    1.25s
        3093 requests in 3.03s, 480.26KB read
        Requests/sec:   1020.94
        Transfer/sec:    158.52KB
        [run.sh] Speed is 1020.94, duration is 29
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d29s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 29s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   471.88ms  466.40ms   3.48s    87.24%
        Req/Sec   148.28     85.44   565.00     68.90%
        Latency Distribution
        50%  338.14ms
        75%  649.43ms
        90%    1.05s
        99%    2.28s
        20001 requests in 29.00s, 3.03MB read
        Requests/sec:    689.69
        Transfer/sec:    107.09KB
        ------------------------------
        stop time: 16.847297
        stop time: 17.706926
        stop time: 17.277388
        stop time: 17.826417
        stop time: 17.717660
        stop time: 17.651487
        stop time: 17.931411
        stop time: 17.876359
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-9994fb58c-mdfqg         1556m        69Mi
        service1-7755b7b4b5-jq4l9        1100m        29Mi
        service2-559ddfcfcb-qtxs7        147m         10Mi
        ubuntu-client-76886f6bbd-5nfrc   35m          20Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.847297, 17.706926, 17.277388, 17.826417, 17.71766, 17.651487, 17.931411, 17.876359]
    [exp] Throughput: 1136.0816734795471
[test.py] Finished running 5th optmization experiment: groundtruth->1433.1597406654455, slowdown->1136.0816734795471, predicted->1472.128761214228, err->2.7190981886421395
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00048', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   378.49ms  382.74ms   1.88s    84.08%
        Req/Sec   183.95     95.75   620.00     73.58%
        Latency Distribution
        50%  285.56ms
        75%  611.76ms
        90%  945.42ms
        99%    1.48s
        4025 requests in 3.02s, 624.98KB read
        Requests/sec:   1331.82
        Transfer/sec:    206.80KB
        [run.sh] Speed is 1331.82, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   390.76ms  406.92ms   3.14s    87.10%
        Req/Sec   183.70     91.97   590.00     67.16%
        Latency Distribution
        50%  265.07ms
        75%  538.85ms
        90%  916.58ms
        99%    1.88s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 13.415896
        stop time: 13.241352
        stop time: 13.637177
        stop time: 14.119777
        stop time: 13.926597
        stop time: 13.933654
        stop time: 14.202634
        stop time: 14.077388
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-pzc5j        2m           70Mi
        service2-958786d58-hnrbc         212m         13Mi
        ubuntu-client-76886f6bbd-j8489   3m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [13.415896, 13.241352, 13.637177, 14.119777, 13.926597, 13.933654, 14.202634, 14.077388]
    [exp] Throughput: 1447.2503261401223
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '160.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '643.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   529.32ms  563.03ms   2.86s    83.83%
        Req/Sec   151.30     75.77   353.00     64.62%
        Latency Distribution
        50%  284.73ms
        75%  779.92ms
        90%    1.41s
        99%    2.30s
        3280 requests in 3.02s, 509.30KB read
        Requests/sec:   1085.02
        Transfer/sec:    168.48KB
        [run.sh] Speed is 1085.02, duration is 27
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d27s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 27s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   469.66ms  484.68ms   4.95s    87.98%
        Req/Sec   155.36     81.65   525.00     68.01%
        Latency Distribution
        50%  340.10ms
        75%  684.02ms
        90%    1.03s
        99%    2.32s
        20000 requests in 27.00s, 3.03MB read
        Requests/sec:    740.74
        Transfer/sec:    115.02KB
        ------------------------------
        stop time: 16.697893
        stop time: 17.013974
        stop time: 16.935041
        stop time: 17.152676
        stop time: 17.054735
        stop time: 17.213383
        stop time: 16.729632
        stop time: 17.003686
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-f464877cb-bv698         1642m        67Mi
        service1-7755b7b4b5-6ncbg        1162m        33Mi
        service2-756d446d74-8gtxf        485m         10Mi
        ubuntu-client-76886f6bbd-mgnqf   46m          19Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [16.697893, 17.013974, 16.935041, 17.152676, 17.054735, 17.213383, 16.729632, 17.003686]
    [exp] Throughput: 1178.1943905870517
[test.py] Finished running 6th optmization experiment: groundtruth->1447.2503261401223, slowdown->1178.1943905870517, predicted->1453.8552697982834, err->0.4563787990828637
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00056', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   357.25ms  242.62ms   1.15s    66.39%
        Req/Sec   187.55    110.09   490.00     62.50%
        Latency Distribution
        50%  320.12ms
        75%  507.17ms
        90%  713.15ms
        99%    1.00s
        3825 requests in 3.02s, 593.92KB read
        Requests/sec:   1266.32
        Transfer/sec:    196.63KB
        [run.sh] Speed is 1266.32, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   367.05ms  335.85ms   2.56s    84.74%
        Req/Sec   184.82     95.73   585.00     67.77%
        Latency Distribution
        50%  268.27ms
        75%  494.00ms
        90%  759.45ms
        99%    1.73s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 14.055305
        stop time: 13.544042
        stop time: 14.065331
        stop time: 13.699888
        stop time: 13.914813
        stop time: 14.121175
        stop time: 13.932203
        stop time: 14.074318
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [14.055305, 13.544042, 14.065331, 13.699888, 13.914813, 14.121175, 13.932203, 14.074318]
    [exp] Throughput: 1436.1744978943213
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '120.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '483.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-5bf5bf77b8-f9fjj cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   420.09ms  230.10ms   1.50s    70.79%
        Req/Sec   167.13    108.45   494.00     69.65%
        Latency Distribution
        50%  388.21ms
        75%  566.50ms
        90%  709.84ms
        99%    1.01s
        3425 requests in 3.03s, 531.81KB read
        Requests/sec:   1132.09
        Transfer/sec:    175.78KB
        [run.sh] Speed is 1132.09, duration is 26
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d26s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 26s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   417.59ms  300.72ms   2.95s    72.16%
        Req/Sec   157.30     87.68   474.00     67.28%
        Latency Distribution
        50%  370.15ms
        75%  569.77ms
        90%  796.54ms
        99%    1.39s
        20000 requests in 26.00s, 3.03MB read
        Requests/sec:    769.23
        Transfer/sec:    119.44KB
        ------------------------------
        stop time: 16.432243
        stop time: 16.204372
        stop time: 16.229187
        stop time: 16.303873
        stop time: 16.502779
        stop time: 16.352383
        stop time: 16.067764
        stop time: 16.258137
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5bf5bf77b8-f9fjj        816m         70Mi
        service1-7755b7b4b5-n7rqq        495m         37Mi
        service2-677597bc9b-ptxvr        111m         13Mi
        ubuntu-client-76886f6bbd-dn7xs   26m          16Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [16.432243, 16.204372, 16.229187, 16.303873, 16.502779, 16.352383, 16.067764, 16.258137]
    [exp] Throughput: 1227.457569131676
[test.py] Finished running 7th optmization experiment: groundtruth->1436.1744978943213, slowdown->1227.457569131676, predicted->1441.4162750924222, err->0.3649819159013204
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00064', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   375.08ms  291.85ms   2.01s    77.72%
        Req/Sec   171.72     83.42   464.00     68.81%
        Latency Distribution
        50%  312.77ms
        75%  507.99ms
        90%  757.72ms
        99%    1.43s
        3805 requests in 3.02s, 590.82KB read
        Requests/sec:   1258.45
        Transfer/sec:    195.40KB
        [run.sh] Speed is 1258.45, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   407.33ms  465.91ms   3.12s    86.48%
        Req/Sec   183.59    100.30   580.00     66.51%
        Latency Distribution
        50%  236.57ms
        75%  533.97ms
        90%    1.04s
        99%    2.17s
        20000 requests in 23.00s, 3.03MB read
        Requests/sec:    869.56
        Transfer/sec:    135.02KB
        ------------------------------
        stop time: 12.965583
        stop time: 14.174269
        stop time: 13.756196
        stop time: 13.985423
        stop time: 14.304692
        stop time: 14.098643
        stop time: 13.852783
        stop time: 14.065282
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [12.965583, 14.174269, 13.756196, 13.985423, 14.304692, 14.098643, 13.852783, 14.065282]
    [exp] Throughput: 1438.811773124095
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '323.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7779556975-89bkq cannot connect to service2
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   348.15ms  302.93ms   1.52s    77.52%
        Req/Sec   167.05     82.57   420.00     71.30%
        Latency Distribution
        50%  264.55ms
        75%  498.85ms
        90%  786.22ms
        99%    1.33s
        3624 requests in 3.02s, 562.71KB read
        Requests/sec:   1199.01
        Transfer/sec:    186.17KB
        [run.sh] Speed is 1199.01, duration is 25
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d25s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 25s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   400.31ms  340.43ms   3.27s    77.84%
        Req/Sec   167.07     87.81   616.00     68.64%
        Latency Distribution
        50%  331.50ms
        75%  549.70ms
        90%  830.46ms
        99%    1.65s
        20000 requests in 25.00s, 3.03MB read
        Requests/sec:    800.00
        Transfer/sec:    124.22KB
        ------------------------------
        stop time: 15.146585
        stop time: 14.967713
        stop time: 15.410655
        stop time: 15.119473
        stop time: 15.404615
        stop time: 15.625274
        stop time: 15.625746
        stop time: 15.579012
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7779556975-89bkq        234m         67Mi
        service1-7755b7b4b5-hn4qh        246m         39Mi
        service2-bcfd688d7-tv2lx         188m         21Mi
        ubuntu-client-76886f6bbd-67v75   11m          14Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [15.146585, 14.967713, 15.410655, 15.119473, 15.404615, 15.625274, 15.625746, 15.579012]
    [exp] Throughput: 1302.0931562528958
[test.py] Finished running 8th optmization experiment: groundtruth->1438.811773124095, slowdown->1302.0931562528958, predicted->1455.4680492788368, err->1.1576410803600814
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00072', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-7b65886d58-86w5d cannot connect to service1
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   398.58ms  384.59ms   2.17s    81.59%
        Req/Sec   177.23     90.17   444.00     64.16%
        Latency Distribution
        50%  246.59ms
        75%  605.15ms
        90%  906.52ms
        99%    1.70s
        4088 requests in 3.04s, 634.76KB read
        Requests/sec:   1346.36
        Transfer/sec:    209.05KB
        [run.sh] Speed is 1346.36, duration is 22
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d22s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 22s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   384.15ms  392.72ms   2.87s    87.26%
        Req/Sec   186.82     97.63   757.00     70.53%
        Latency Distribution
        50%  242.93ms
        75%  536.09ms
        90%  902.27ms
        99%    1.81s
        20000 requests in 22.00s, 3.03MB read
        Requests/sec:    909.08
        Transfer/sec:    141.16KB
        ------------------------------
        stop time: 12.850059
        stop time: 13.104695
        stop time: 13.360001
        stop time: 13.880059
        stop time: 13.885378
        stop time: 14.209424
        stop time: 14.164234
        stop time: 14.187356
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7b65886d58-86w5d        2m           65Mi
        service1-7755b7b4b5-v5m8h        42m          34Mi
        service2-958786d58-tr77j         173m         10Mi
        ubuntu-client-76886f6bbd-hrqtb   5m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [12.850059, 13.104695, 13.360001, 13.880059, 13.885378, 14.209424, 14.164234, 14.187356]
    [exp] Throughput: 1459.3053637151709
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00112131', 'PROCESSING_TIME_SERVICE1': '0.00080186', 'PROCESSING_TIME_SERVICE2': '0.00154809', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '40.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '163.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-http-async 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   353.37ms  265.78ms   1.57s    68.39%
        Req/Sec   168.78     79.65   414.00     66.52%
        Latency Distribution
        50%  305.41ms
        75%  510.73ms
        90%  707.39ms
        99%    1.11s
        3777 requests in 3.03s, 586.47KB read
        Requests/sec:   1247.32
        Transfer/sec:    193.68KB
        [run.sh] Speed is 1247.32, duration is 24
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d24s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 24s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   415.24ms  488.22ms   4.47s    85.53%
        Req/Sec   176.48     84.01   470.00     69.27%
        Latency Distribution
        50%  231.38ms
        75%  645.80ms
        90%    1.07s
        99%    2.13s
        20000 requests in 24.00s, 3.03MB read
        Requests/sec:    833.33
        Transfer/sec:    129.39KB
        ------------------------------
        stop time: 14.026212
        stop time: 14.839389
        stop time: 14.284361
        stop time: 14.881012
        stop time: 14.591282
        stop time: 14.845088
        stop time: 14.490506
        stop time: 14.603825
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-c888f8587-thxw6         603m         62Mi
        service1-7755b7b4b5-2sqbc        420m         29Mi
        service2-5c548c8f45-vrk75        111m         7Mi
        ubuntu-client-76886f6bbd-wqtvw   25m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [14.026212, 14.839389, 14.284361, 14.881012, 14.591282, 14.845088, 14.490506, 14.603825]
    [exp] Throughput: 1372.6638708649307
[test.py] Finished running 9th optmization experiment: groundtruth->1459.3053637151709, slowdown->1372.6638708649307, predicted->1454.3752265359851, err->-0.3378413662946023
[test.py] Baseline throughput:  1424.0815157076324
[test.py] Groundtruth:  [1444.7454310693265, 1446.8443754476511, 1454.1382165281968, 1431.1862953822354, 1440.4052969212319, 1433.1597406654455, 1447.2503261401223, 1436.1744978943213, 1438.811773124095, 1459.3053637151709]
[test.py] Slowdown:  [923.4830407274434, 944.295662465812, 986.3962152371781, 1042.7879896267623, 1074.4835704578668, 1136.0816734795471, 1178.1943905870517, 1227.457569131676, 1302.0931562528958, 1372.6638708649307]
[test.py] Predicted:  [1466.4327987418962, 1432.5408842467843, 1443.2901010216478, 1474.8442453863556, 1449.801374946318, 1472.128761214228, 1453.8552697982834, 1441.4162750924222, 1455.4680492788368, 1454.3752265359851]
[test.py] Error percentage:  [1.5011203500756432, -0.988599150232818, -0.7460168079791774, 3.0504728940588604, 0.6523218183916432, 2.7190981886421395, 0.4563787990828637, 0.3649819159013204, 1.1576410803600814, -0.3378413662946023]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1431.7815723429699
    Groundtruth: [1423.5123546325865, 1435.2385730700228, 1443.5500649326864, 1436.255407827012, 1434.5505713102134, 1436.0312519173262, 1444.47927244468, 1449.0371637097192, 1439.912202793347, 1421.8770410322875]
    Slowdown:    [929.4966129840544, 947.4983130976908, 989.0119657961584, 1032.0408299089252, 1086.8689519988402, 1132.4954405379658, 1182.9789469746913, 1230.2773091190152, 1293.8387125567322, 1385.9191000562041]
    Predicted:   [1481.654560684607, 1439.9245133973097, 1448.897152915283, 1453.4378556210427, 1472.441508641483, 1466.1127912458255, 1461.147543455281, 1445.3062685281484, 1445.1621742024136, 1469.2640880432996]
    Error Perc:  [4.084418787290911, 0.3264920839790133, 0.3704123682642011, 1.1963365081442492, 2.6413106717222865, 2.0947691276450784, 1.153929400620003, -0.25747408520697934, 0.36460357783494934, 3.3327106102373625]
[test.py] Result for the experiment 1: 
    Baseline throughput: 1438.4708177739865
    Groundtruth: [1426.7935291810177, 1433.6306471237601, 1424.0023390662423, 1458.5133134963976, 1435.1866137274164, 1452.3831860684863, 1428.3264450802678, 1439.4404117821582, 1440.0774934500776, 1442.3348444344963]
    Slowdown:    [914.6881927709024, 948.9663624104554, 1000.4247365745673, 1019.901874348255, 1071.594659032912, 1125.6242377853061, 1184.3654463808966, 1233.2045916553996, 1307.1108915709442, 1386.6423116811043]
    Predicted:   [1444.3796870854321, 1443.317741502532, 1473.5234859520858, 1429.4771427364287, 1444.5467223650176, 1454.6175242318823, 1463.2633380705872, 1449.347921611982, 1461.7403398263075, 1470.0769241639316]
    Error Perc:  [1.2325650169235727, 0.6757036338618161, 3.4776029173039107, -1.9908060139925883, 0.6521875655801561, 0.15383944022680068, 2.4460019703938225, 0.6882889870763992, 1.504283378829218, 1.923414652047202]
[test.py] Result for the experiment 2: 
    Baseline throughput: 1443.0181012190617
    Groundtruth: [1426.3806861351109, 1444.4763774034711, 1424.7460363476223, 1432.1970610063136, 1432.880483994071, 1439.5681612221329, 1428.9022577182577, 1439.9116714983352, 1402.5374532286633, 1429.042821312798]
    Slowdown:    [929.601774693452, 960.9792224520111, 994.9253397764863, 1038.3997838778528, 1074.5190368844105, 1141.0533331465808, 1178.0876087648217, 1245.6849085491324, 1316.3226601367192, 1378.8970560961523]
    Predicted:   [1481.921790632774, 1471.2909389922224, 1461.623873075433, 1466.0816915196067, 1449.8659463007712, 1480.4874164306493, 1453.6926787739217, 1466.6170998974135, 1473.2701150057674, 1461.3744840800057]
    Error Perc:  [3.8938486084073434, 1.856351686204243, 2.5883796681651523, 2.365919567624623, 1.1854067730306537, 2.8424673670038474, 1.7349276986412308, 1.8546574020953186, 5.043192366398231, 2.2624698354039565]
[test.py] Result for the experiment 3: 
    Baseline throughput: 1420.1336033291338
    Groundtruth: [1438.3286132482326, 1447.6495757911734, 1434.8162742421737, 1464.7654694430516, 1439.3876557035107, 1447.7615073513712, 1436.558488545098, 1442.9595779134006, 1435.7474867980552, 1457.2624541520186]
    Slowdown:    [921.2020147885626, 964.3407871853575, 988.2080774139479, 1045.0811563650557, 1069.4956394924848, 1131.3751878135845, 1178.2825094919494, 1256.9396225752828, 1300.5912626067632, 1376.1035016983355]
    Predicted:   [1460.6894329965144, 1479.1853201950862, 1447.1724922248625, 1479.4355043697994, 1440.7349880726952, 1464.2358472499645, 1453.9894489801648, 1482.2431073981663, 1453.5917529963135, 1458.2371276578333]
    Error Perc:  [1.5546391514650786, 2.1784100884136794, 0.8611707439138843, 1.0015279055100743, 0.09360455217506337, 1.137918076626626, 1.213383274962946, 2.722427577740735, 1.2428554716159634, 0.06688386865644583]
[test.py] Result for the experiment 4: 
    Baseline throughput: 1424.0815157076324
    Groundtruth: [1444.7454310693265, 1446.8443754476511, 1454.1382165281968, 1431.1862953822354, 1440.4052969212319, 1433.1597406654455, 1447.2503261401223, 1436.1744978943213, 1438.811773124095, 1459.3053637151709]
    Slowdown:    [923.4830407274434, 944.295662465812, 986.3962152371781, 1042.7879896267623, 1074.4835704578668, 1136.0816734795471, 1178.1943905870517, 1227.457569131676, 1302.0931562528958, 1372.6638708649307]
    Predicted:   [1466.4327987418962, 1432.5408842467843, 1443.2901010216478, 1474.8442453863556, 1449.801374946318, 1472.128761214228, 1453.8552697982834, 1441.4162750924222, 1455.4680492788368, 1454.3752265359851]
    Error Perc:  [1.5011203500756432, -0.988599150232818, -0.7460168079791774, 3.0504728940588604, 0.6523218183916432, 2.7190981886421395, 0.4563787990828637, 0.3649819159013204, 1.1576410803600814, -0.3378413662946023]
