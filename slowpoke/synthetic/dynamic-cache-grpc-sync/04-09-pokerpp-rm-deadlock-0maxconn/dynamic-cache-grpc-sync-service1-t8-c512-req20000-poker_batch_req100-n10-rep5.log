[config.py] Random numbers for execution time: [243.1852228229995, 265.3472596363038, 431.399959404726]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service1
request_type                     : dynamic-cache-grpc-sync
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 27597
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.25}
baseline_service_processing_time : {'service0': 431.4, 'service1': 265.35, 'service2': 972.74}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2}
target_processing_time_range     : [0, 265.35]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 26, 52, 78, 104, 130, 156, 182, 208, 234]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.97ms   83.06ms 684.42ms   72.36%
        Req/Sec   414.73    142.11   727.00     65.52%
        Latency Distribution
        50%  140.53ms
        75%  198.64ms
        90%  270.12ms
        99%  414.86ms
        9688 requests in 3.02s, 1.47MB read
        Requests/sec:   3210.94
        Transfer/sec:    498.57KB
        [run.sh] Speed is 3210.94, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.29ms  109.62ms   1.08s    77.89%
        Req/Sec   403.50    138.26   770.00     69.26%
        Latency Distribution
        50%  138.78ms
        75%  208.21ms
        90%  285.70ms
        99%  581.74ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.202319
        stop time: 6.120212
        stop time: 6.258758
        stop time: 6.218136
        stop time: 6.158365
        stop time: 6.209556
        stop time: 6.298391
        stop time: 6.289087
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-rzssq        0m           45Mi
        service1-745795666b-npjbk        0m           16Mi
        service2-8f7c6f8f5-5rhz7         0m           10Mi
        ubuntu-client-76886f6bbd-kjt9c   2m           4Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.202319, 6.120212, 6.258758, 6.218136, 6.158365, 6.209556, 6.298391, 6.289087]
    [exp] Throughput: 3215.7685855747372
[test.py] Baseline throughput: 3215.7685855747372
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.14ms  100.41ms 635.79ms   72.85%
        Req/Sec   401.61    173.15     0.97k    66.38%
        Latency Distribution
        50%  149.43ms
        75%  213.30ms
        90%  285.42ms
        99%  518.77ms
        9419 requests in 3.03s, 1.43MB read
        Requests/sec:   3113.09
        Transfer/sec:    483.38KB
        [run.sh] Speed is 3113.09, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.78ms   92.00ms 745.35ms   73.45%
        Req/Sec   408.59    155.64   840.00     66.74%
        Latency Distribution
        50%  139.20ms
        75%  202.02ms
        90%  270.06ms
        99%  457.62ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.117308
        stop time: 6.053461
        stop time: 6.176570
        stop time: 6.210018
        stop time: 6.197943
        stop time: 6.207666
        stop time: 6.103140
        stop time: 6.159182
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-2m45x        517m         44Mi
        service1-745795666b-6l2bt        151m         10Mi
        service2-8f7c6f8f5-td2hg         288m         9Mi
        ubuntu-client-76886f6bbd-fpj89   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.117308, 6.053461, 6.17657, 6.210018, 6.197943, 6.207666, 6.10314, 6.159182]
    [exp] Throughput: 3250.361887166613
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '132.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '530.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   224.34ms  115.53ms 668.95ms   65.12%
        Req/Sec   282.75    181.79   650.00     58.10%
        Latency Distribution
        50%  211.11ms
        75%  300.43ms
        90%  384.57ms
        99%  495.42ms
        6165 requests in 3.03s, 0.93MB read
        Requests/sec:   2036.78
        Transfer/sec:    316.26KB
        [run.sh] Speed is 2036.78, duration is 14
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d14s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 14s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   218.81ms  131.42ms   1.00s    69.26%
        Req/Sec   292.20    168.62   777.00     65.32%
        Latency Distribution
        50%  208.81ms
        75%  292.80ms
        90%  390.88ms
        99%  605.11ms
        20000 requests in 14.00s, 3.03MB read
        Requests/sec:   1428.56
        Transfer/sec:    221.82KB
        ------------------------------
        stop time: 8.439810
        stop time: 8.447367
        stop time: 8.610486
        stop time: 8.589605
        stop time: 8.798508
        stop time: 8.719095
        stop time: 8.700150
        stop time: 8.670496
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-848bfcb77d-w45vz        270m         43Mi
        service1-745795666b-7bvzv        75m          12Mi
        service2-567796f7b-xrftq         70m          10Mi
        ubuntu-client-76886f6bbd-cqjmz   46m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.43981, 8.447367, 8.610486, 8.589605, 8.798508, 8.719095, 8.70015, 8.670496]
    [exp] Throughput: 2319.663656888574
[test.py] Finished running 0th optmization experiment: groundtruth->3250.361887166613, slowdown->2319.663656888574, predicted->3350.959590212828, err->3.0949693153677553
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '2.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.51ms   96.06ms 798.85ms   75.14%
        Req/Sec   409.48    202.87     0.87k    64.94%
        Latency Distribution
        50%  149.58ms
        75%  206.24ms
        90%  284.16ms
        99%  494.89ms
        9496 requests in 3.03s, 1.44MB read
        Requests/sec:   3136.08
        Transfer/sec:    486.95KB
        [run.sh] Speed is 3136.08, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.11ms   97.17ms 768.83ms   77.07%
        Req/Sec   409.34    154.59   797.00     66.67%
        Latency Distribution
        50%  132.43ms
        75%  201.43ms
        90%  285.38ms
        99%  496.26ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.893117
        stop time: 6.000438
        stop time: 6.219062
        stop time: 6.120753
        stop time: 6.198142
        stop time: 6.239598
        stop time: 6.132619
        stop time: 6.231319
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-745795666b-vxbhc   0m           11Mi
        service2-8f7c6f8f5-7tsgt    0m           9Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.893117, 6.000438, 6.219062, 6.120753, 6.198142, 6.239598, 6.132619, 6.231319]
    [exp] Throughput: 3262.972231616863
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '119.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '478.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   216.51ms  130.49ms 796.99ms   66.07%
        Req/Sec   301.24    160.70   636.00     61.74%
        Latency Distribution
        50%  206.10ms
        75%  294.12ms
        90%  401.28ms
        99%  551.83ms
        6983 requests in 3.02s, 1.06MB read
        Requests/sec:   2311.75
        Transfer/sec:    358.95KB
        [run.sh] Speed is 2311.75, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   214.23ms  121.38ms 952.41ms   70.38%
        Req/Sec   300.32    152.13     1.11k    68.00%
        Latency Distribution
        50%  198.99ms
        75%  277.15ms
        90%  372.74ms
        99%  570.53ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.64
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 8.349857
        stop time: 8.271453
        stop time: 8.408615
        stop time: 8.437627
        stop time: 8.477818
        stop time: 8.535841
        stop time: 8.534384
        stop time: 8.523305
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7579bf5b9c-c4pjs        955m         45Mi
        service1-745795666b-c49hs        573m         12Mi
        service2-67d6df6559-r5bf2        421m         9Mi
        ubuntu-client-76886f6bbd-9kpfp   64m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.349857, 8.271453, 8.408615, 8.437627, 8.477818, 8.535841, 8.534384, 8.523305]
    [exp] Throughput: 2369.0051214929476
[test.py] Finished running 1th optmization experiment: groundtruth->3262.972231616863, slowdown->2369.0051214929476, predicted->3306.406783093517, err->1.3311345728226163
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '5.2e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.55ms  107.11ms 709.72ms   68.30%
        Req/Sec   407.98    164.62   777.00     65.78%
        Latency Distribution
        50%  156.13ms
        75%  225.64ms
        90%  306.56ms
        99%  493.96ms
        9493 requests in 3.02s, 1.44MB read
        Requests/sec:   3138.52
        Transfer/sec:    487.33KB
        [run.sh] Speed is 3138.52, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   151.85ms   89.15ms 760.96ms   71.52%
        Req/Sec   417.34    161.95     0.86k    67.51%
        Latency Distribution
        50%  131.68ms
        75%  198.58ms
        90%  282.26ms
        99%  416.04ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.874223
        stop time: 5.983063
        stop time: 6.097402
        stop time: 6.091528
        stop time: 6.110955
        stop time: 6.081126
        stop time: 6.118693
        stop time: 5.941964
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [5.874223, 5.983063, 6.097402, 6.091528, 6.110955, 6.081126, 6.118693, 5.941964]
    [exp] Throughput: 3312.7011404843265
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '106.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '426.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   214.16ms  110.38ms 713.72ms   68.30%
        Req/Sec   303.44    169.34   720.00     62.61%
        Latency Distribution
        50%  209.76ms
        75%  278.53ms
        90%  361.89ms
        99%  515.68ms
        6876 requests in 3.03s, 1.04MB read
        Requests/sec:   2271.05
        Transfer/sec:    352.63KB
        [run.sh] Speed is 2271.05, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   204.32ms  115.41ms 911.37ms   70.67%
        Req/Sec   316.61    154.30     0.88k    69.32%
        Latency Distribution
        50%  188.15ms
        75%  268.00ms
        90%  350.04ms
        99%  543.67ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.44
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 7.808073
        stop time: 7.817458
        stop time: 8.093895
        stop time: 7.977634
        stop time: 8.228414
        stop time: 8.209328
        stop time: 8.161757
        stop time: 8.118003
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d9fd768c7-zg5c2        1016m        46Mi
        service1-745795666b-864nx        812m         12Mi
        service2-7668ff8dd-hjfbq         550m         9Mi
        ubuntu-client-76886f6bbd-npx52   22m          13Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.808073, 7.817458, 8.093895, 7.977634, 8.228414, 8.209328, 8.161757, 8.118003]
    [exp] Throughput: 2483.9103928083837
[test.py] Finished running 2th optmization experiment: groundtruth->3312.7011404843265, slowdown->2483.9103928083837, predicted->3379.337236777614, err->2.0115335935056695
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '7.8e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.90ms   82.28ms 585.19ms   70.27%
        Req/Sec   408.46    173.05   808.00     64.22%
        Latency Distribution
        50%  147.58ms
        75%  209.50ms
        90%  266.23ms
        99%  399.85ms
        9461 requests in 3.03s, 1.43MB read
        Requests/sec:   3124.73
        Transfer/sec:    485.19KB
        [run.sh] Speed is 3124.73, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.22ms   97.71ms 654.55ms   74.83%
        Req/Sec   408.09    179.46     0.93k    65.98%
        Latency Distribution
        50%  140.43ms
        75%  202.31ms
        90%  283.26ms
        99%  504.10ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.010714
        stop time: 6.137118
        stop time: 6.062422
        stop time: 6.228241
        stop time: 6.211895
        stop time: 6.223060
        stop time: 6.149100
        stop time: 6.136341
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.010714, 6.137118, 6.062422, 6.228241, 6.211895, 6.22306, 6.1491, 6.136341]
    [exp] Throughput: 3254.7520244099887
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '93.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '374.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   199.88ms   95.31ms 646.91ms   68.71%
        Req/Sec   327.95    170.17   727.00     66.52%
        Latency Distribution
        50%  189.14ms
        75%  251.98ms
        90%  319.91ms
        99%  499.85ms
        7575 requests in 3.03s, 1.15MB read
        Requests/sec:   2502.61
        Transfer/sec:    388.59KB
        [run.sh] Speed is 2502.61, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   202.02ms  112.73ms 723.87ms   67.31%
        Req/Sec   316.63    169.80     0.85k    68.71%
        Latency Distribution
        50%  190.43ms
        75%  274.88ms
        90%  352.83ms
        99%  509.31ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.820439
        stop time: 7.830245
        stop time: 8.078261
        stop time: 8.005902
        stop time: 8.063811
        stop time: 7.974510
        stop time: 8.059418
        stop time: 8.052493
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f496748d4-gcjs7        287m         45Mi
        service1-745795666b-sf4bt        336m         14Mi
        service2-6b7dfdd958-j6b59        232m         10Mi
        ubuntu-client-76886f6bbd-49gks   31m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.820439, 7.830245, 8.078261, 8.005902, 8.063811, 7.97451, 8.059418, 8.052493]
    [exp] Throughput: 2504.497176875996
[test.py] Finished running 3th optmization experiment: groundtruth->3254.7520244099887, slowdown->2504.497176875996, predicted->3272.1791009233903, err->0.5354348467318534
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000104', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.48ms   99.96ms 571.39ms   67.17%
        Req/Sec   391.59    178.58     0.88k    67.67%
        Latency Distribution
        50%  151.72ms
        75%  225.05ms
        90%  299.18ms
        99%  452.76ms
        9172 requests in 3.02s, 1.39MB read
        Requests/sec:   3034.27
        Transfer/sec:    471.14KB
        [run.sh] Speed is 3034.27, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   149.98ms   88.43ms 564.37ms   68.88%
        Req/Sec   418.14    160.83   787.00     65.25%
        Latency Distribution
        50%  132.95ms
        75%  201.12ms
        90%  277.00ms
        99%  396.91ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.799759
        stop time: 5.993434
        stop time: 6.000436
        stop time: 5.994227
        stop time: 6.042230
        stop time: 6.079635
        stop time: 6.014635
        stop time: 6.041288
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-4fgtn        0m           44Mi
        service1-745795666b-6gs7t        0m           10Mi
        service2-8f7c6f8f5-gg5tf         0m           10Mi
        ubuntu-client-76886f6bbd-gbh2q   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.799759, 5.993434, 6.000436, 5.994227, 6.04223, 6.079635, 6.014635, 6.041288]
    [exp] Throughput: 3335.7208755500083
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '322.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   206.51ms  110.04ms 840.81ms   73.50%
        Req/Sec   320.41    175.56   696.00     62.45%
        Latency Distribution
        50%  191.35ms
        75%  266.93ms
        90%  336.32ms
        99%  550.65ms
        7407 requests in 3.04s, 1.12MB read
        Requests/sec:   2436.44
        Transfer/sec:    378.31KB
        [run.sh] Speed is 2436.44, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   194.76ms  106.95ms   1.05s    70.66%
        Req/Sec   326.13    159.95   750.00     63.86%
        Latency Distribution
        50%  178.03ms
        75%  252.77ms
        90%  344.45ms
        99%  499.14ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 7.687659
        stop time: 7.591541
        stop time: 7.754627
        stop time: 7.746564
        stop time: 7.706004
        stop time: 7.744271
        stop time: 7.786741
        stop time: 7.787628
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7c6d788d76-slh9t        14m          44Mi
        service1-745795666b-lkmkd        76m          12Mi
        service2-76b4546649-hgnmk        38m          9Mi
        ubuntu-client-76886f6bbd-2hl66   30m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.687659, 7.591541, 7.754627, 7.746564, 7.706004, 7.744271, 7.786741, 7.787628]
    [exp] Throughput: 2588.7858489199143
[test.py] Finished running 4th optmization experiment: groundtruth->3335.7208755500083, slowdown->2588.7858489199143, predicted->3272.182045393959, err->-1.9048005671509516
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00013', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.83ms   92.89ms 638.05ms   71.33%
        Req/Sec   396.91    188.36   848.00     65.95%
        Latency Distribution
        50%  144.41ms
        75%  213.70ms
        90%  286.17ms
        99%  455.32ms
        9235 requests in 3.02s, 1.40MB read
        Requests/sec:   3052.93
        Transfer/sec:    474.04KB
        [run.sh] Speed is 3052.93, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.72ms   81.14ms 613.40ms   73.50%
        Req/Sec   407.82    169.75     0.86k    65.29%
        Latency Distribution
        50%  142.70ms
        75%  197.88ms
        90%  261.22ms
        99%  419.40ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.066654
        stop time: 6.152007
        stop time: 6.123466
        stop time: 6.142114
        stop time: 6.096741
        stop time: 6.109222
        stop time: 6.176724
        stop time: 6.206506
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-7m2pp        355m         46Mi
        service1-745795666b-s6j7d        97m          11Mi
        service2-8f7c6f8f5-thck4         136m         9Mi
        ubuntu-client-76886f6bbd-4j5hs   2m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.066654, 6.152007, 6.123466, 6.142114, 6.096741, 6.109222, 6.176724, 6.206506]
    [exp] Throughput: 3260.419884208633
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '67.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '270.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   187.42ms   94.27ms 736.19ms   69.56%
        Req/Sec   336.06    165.26   686.00     64.66%
        Latency Distribution
        50%  181.80ms
        75%  247.56ms
        90%  306.99ms
        99%  467.18ms
        7804 requests in 3.02s, 1.18MB read
        Requests/sec:   2582.28
        Transfer/sec:    400.96KB
        [run.sh] Speed is 2582.28, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   187.42ms  106.47ms 801.84ms   67.00%
        Req/Sec   339.34    180.62   818.00     63.08%
        Latency Distribution
        50%  170.98ms
        75%  255.48ms
        90%  334.24ms
        99%  473.30ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.233392
        stop time: 7.446727
        stop time: 7.364561
        stop time: 7.354399
        stop time: 7.433824
        stop time: 7.429457
        stop time: 7.424003
        stop time: 7.426553
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        ubuntu-client-76886f6bbd-5brxp   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.233392, 7.446727, 7.364561, 7.354399, 7.433824, 7.429457, 7.424003, 7.426553]
    [exp] Throughput: 2706.684271843399
[test.py] Finished running 5th optmization experiment: groundtruth->3260.419884208633, slowdown->2706.684271843399, predicted->3313.6642507569036, err->1.633052442298978
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000156', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.36ms  103.63ms 780.12ms   74.91%
        Req/Sec   405.76    171.51   797.00     65.95%
        Latency Distribution
        50%  145.82ms
        75%  213.95ms
        90%  293.29ms
        99%  525.51ms
        9438 requests in 3.03s, 1.43MB read
        Requests/sec:   3115.84
        Transfer/sec:    483.81KB
        [run.sh] Speed is 3115.84, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.70ms  105.21ms 770.21ms   71.85%
        Req/Sec   416.60    181.36     0.87k    65.05%
        Latency Distribution
        50%  131.04ms
        75%  213.12ms
        90%  301.99ms
        99%  515.53ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.787828
        stop time: 5.830231
        stop time: 6.157129
        stop time: 6.152646
        stop time: 6.203078
        stop time: 6.218398
        stop time: 6.125930
        stop time: 6.129020
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-zfnfp        1211m        44Mi
        service1-745795666b-89xnp        611m         12Mi
        service2-8f7c6f8f5-r97zw         612m         10Mi
        ubuntu-client-76886f6bbd-srbzj   37m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.787828, 5.830231, 6.157129, 6.152646, 6.203078, 6.218398, 6.12593, 6.12902]
    [exp] Throughput: 3291.8925213551242
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '54.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '218.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   186.47ms  111.27ms 836.20ms   71.27%
        Req/Sec   332.26    163.47   780.00     66.25%
        Latency Distribution
        50%  172.30ms
        75%  245.75ms
        90%  328.38ms
        99%  513.45ms
        7940 requests in 3.03s, 1.20MB read
        Requests/sec:   2623.48
        Transfer/sec:    407.36KB
        [run.sh] Speed is 2623.48, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   180.95ms  105.40ms 893.13ms   72.96%
        Req/Sec   351.98    152.13   750.00     65.66%
        Latency Distribution
        50%  162.00ms
        75%  236.17ms
        90%  314.62ms
        99%  578.62ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.116709
        stop time: 7.093651
        stop time: 7.136850
        stop time: 7.186771
        stop time: 7.027412
        stop time: 7.157531
        stop time: 7.112618
        stop time: 7.143038
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [7.116709, 7.093651, 7.13685, 7.186771, 7.027412, 7.157531, 7.112618, 7.143038]
    [exp] Throughput: 2808.2699337142985
[test.py] Finished running 6th optmization experiment: groundtruth->3291.8925213551242, slowdown->2808.2699337142985, predicted->3317.6725365970387, err->0.7831366022637344
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000182', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.36ms   85.79ms 568.46ms   66.73%
        Req/Sec   408.39    181.43     0.87k    70.69%
        Latency Distribution
        50%  147.71ms
        75%  211.27ms
        90%  274.11ms
        99%  378.40ms
        9502 requests in 3.02s, 1.44MB read
        Requests/sec:   3147.54
        Transfer/sec:    488.73KB
        [run.sh] Speed is 3147.54, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.11ms   86.61ms 622.46ms   69.77%
        Req/Sec   398.73    164.27     0.89k    67.81%
        Latency Distribution
        50%  143.72ms
        75%  205.96ms
        90%  277.90ms
        99%  418.08ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.240414
        stop time: 6.172581
        stop time: 6.388320
        stop time: 6.204272
        stop time: 6.359096
        stop time: 6.349346
        stop time: 6.342528
        stop time: 6.351493
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-ndtw7        821m         43Mi
        service1-745795666b-m62z4        537m         13Mi
        service2-8f7c6f8f5-j6wk2         424m         9Mi
        ubuntu-client-76886f6bbd-4qvpj   73m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.240414, 6.172581, 6.38832, 6.204272, 6.359096, 6.349346, 6.342528, 6.351493]
    [exp] Throughput: 3174.0962009044188
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '41.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '166.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   178.00ms   97.83ms 800.39ms   71.03%
        Req/Sec   360.83    167.09   710.00     62.07%
        Latency Distribution
        50%  161.21ms
        75%  228.79ms
        90%  314.47ms
        99%  460.76ms
        8377 requests in 3.02s, 1.27MB read
        Requests/sec:   2775.29
        Transfer/sec:    430.93KB
        [run.sh] Speed is 2775.29, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   173.13ms   91.69ms 778.29ms   73.01%
        Req/Sec   369.04    157.84   740.00     63.62%
        Latency Distribution
        50%  160.84ms
        75%  222.10ms
        90%  285.21ms
        99%  479.56ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.705973
        stop time: 6.794813
        stop time: 6.887574
        stop time: 6.736846
        stop time: 6.718769
        stop time: 6.923044
        stop time: 6.870864
        stop time: 6.927421
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.705973, 6.794813, 6.887574, 6.736846, 6.718769, 6.923044, 6.870864, 6.927421]
    [exp] Throughput: 2932.2662620921164
[test.py] Finished running 7th optmization experiment: groundtruth->3174.0962009044188, slowdown->2932.2662620921164, predicted->3340.480290915748, err->5.241935955309738
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000208', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.35ms   86.25ms 651.18ms   71.10%
        Req/Sec   406.25    193.52     0.93k    65.80%
        Latency Distribution
        50%  146.22ms
        75%  211.38ms
        90%  276.97ms
        99%  425.34ms
        9383 requests in 3.02s, 1.42MB read
        Requests/sec:   3102.24
        Transfer/sec:    481.70KB
        [run.sh] Speed is 3102.24, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.00ms   95.30ms 773.68ms   74.96%
        Req/Sec   404.45    139.33   830.00     69.33%
        Latency Distribution
        50%  139.96ms
        75%  205.22ms
        90%  275.33ms
        99%  497.71ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.222511
        stop time: 6.103034
        stop time: 6.222702
        stop time: 6.222610
        stop time: 6.203354
        stop time: 6.211092
        stop time: 6.246555
        stop time: 6.282123
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-x2dwq        94m          45Mi
        service1-745795666b-dw99g        1m           13Mi
        service2-8f7c6f8f5-rrcjq         37m          9Mi
        ubuntu-client-76886f6bbd-rmt64   27m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.222511, 6.103034, 6.222702, 6.22261, 6.203354, 6.211092, 6.246555, 6.282123]
    [exp] Throughput: 3218.410531234664
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '28.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '114.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   178.00ms  103.54ms 710.00ms   70.23%
        Req/Sec   380.43    191.83   760.00     61.43%
        Latency Distribution
        50%  166.38ms
        75%  235.14ms
        90%  308.24ms
        99%  567.66ms
        8631 requests in 3.01s, 1.31MB read
        Requests/sec:   2863.67
        Transfer/sec:    444.65KB
        [run.sh] Speed is 2863.67, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   167.48ms   84.10ms 657.34ms   69.26%
        Req/Sec   381.32    171.66   780.00     66.48%
        Latency Distribution
        50%  156.49ms
        75%  216.54ms
        90%  276.87ms
        99%  435.33ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.480974
        stop time: 6.599595
        stop time: 6.600185
        stop time: 6.636125
        stop time: 6.622673
        stop time: 6.635118
        stop time: 6.720312
        stop time: 6.719206
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74f5db548b-zbbfd        0m           45Mi
        service1-745795666b-4b25d        0m           12Mi
        service2-96f84c786-98q7l         0m           9Mi
        ubuntu-client-76886f6bbd-gv466   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.480974, 6.599595, 6.600185, 6.636125, 6.622673, 6.635118, 6.720312, 6.719206]
    [exp] Throughput: 3018.0599955619427
[test.py] Finished running 8th optmization experiment: groundtruth->3218.410531234664, slowdown->3018.0599955619427, predicted->3303.997415613221, err->2.6592904649029867
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000234', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.02ms   79.83ms 511.33ms   71.04%
        Req/Sec   397.10    188.96     0.89k    67.24%
        Latency Distribution
        50%  148.76ms
        75%  207.68ms
        90%  265.67ms
        99%  404.64ms
        9229 requests in 3.02s, 1.40MB read
        Requests/sec:   3053.11
        Transfer/sec:    474.07KB
        [run.sh] Speed is 3053.11, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.52ms   83.77ms 724.21ms   71.75%
        Req/Sec   405.37    151.11   770.00     65.17%
        Latency Distribution
        50%  142.12ms
        75%  199.46ms
        90%  269.22ms
        99%  417.83ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.054967
        stop time: 6.149156
        stop time: 6.162172
        stop time: 6.161540
        stop time: 6.276161
        stop time: 6.228280
        stop time: 6.241191
        stop time: 6.228315
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-9672h        579m         43Mi
        service1-745795666b-tg6xs        365m         14Mi
        service2-8f7c6f8f5-c5mz7         279m         9Mi
        ubuntu-client-76886f6bbd-tvcg4   25m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.054967, 6.149156, 6.162172, 6.16154, 6.276161, 6.22828, 6.241191, 6.228315]
    [exp] Throughput: 3232.206872875809
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '15.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '62.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   168.61ms   93.51ms 561.04ms   70.33%
        Req/Sec   381.46    178.22   830.00     63.36%
        Latency Distribution
        50%  153.50ms
        75%  221.67ms
        90%  301.71ms
        99%  430.63ms
        8860 requests in 3.03s, 1.34MB read
        Requests/sec:   2922.02
        Transfer/sec:    453.71KB
        [run.sh] Speed is 2922.02, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.94ms  102.43ms 673.15ms   68.43%
        Req/Sec   394.64    158.17   820.00     66.87%
        Latency Distribution
        50%  140.08ms
        75%  222.21ms
        90%  307.15ms
        99%  449.59ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.400621
        stop time: 6.342075
        stop time: 6.282320
        stop time: 6.438470
        stop time: 6.407429
        stop time: 6.413522
        stop time: 6.289533
        stop time: 6.374461
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5867c84794-xf56w        0m           45Mi
        service1-745795666b-lhg2f        0m           13Mi
        service2-69d7667f8d-8dgvg        0m           9Mi
        ubuntu-client-76886f6bbd-hjrk2   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.400621, 6.342075, 6.28232, 6.43847, 6.407429, 6.413522, 6.289533, 6.374461]
    [exp] Throughput: 3140.4303696810603
[test.py] Finished running 9th optmization experiment: groundtruth->3232.206872875809, slowdown->3140.4303696810603, predicted->3303.025937155679, err->2.1910436758913185
[test.py] Baseline throughput:  3215.7685855747372
[test.py] Groundtruth:  [3250.361887166613, 3262.972231616863, 3312.7011404843265, 3254.7520244099887, 3335.7208755500083, 3260.419884208633, 3291.8925213551242, 3174.0962009044188, 3218.410531234664, 3232.206872875809]
[test.py] Slowdown:  [2319.663656888574, 2369.0051214929476, 2483.9103928083837, 2504.497176875996, 2588.7858489199143, 2706.684271843399, 2808.2699337142985, 2932.2662620921164, 3018.0599955619427, 3140.4303696810603]
[test.py] Predicted:  [3350.959590212828, 3306.406783093517, 3379.337236777614, 3272.1791009233903, 3272.182045393959, 3313.6642507569036, 3317.6725365970387, 3340.480290915748, 3303.997415613221, 3303.025937155679]
[test.py] Error percentage:  [3.0949693153677553, 1.3311345728226163, 2.0115335935056695, 0.5354348467318534, -1.9048005671509516, 1.633052442298978, 0.7831366022637344, 5.241935955309738, 2.6592904649029867, 2.1910436758913185]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 1...
[test.py] Actual processing time range: [0, 26, 52, 78, 104, 130, 156, 182, 208, 234]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.69ms   85.09ms 502.63ms   70.17%
        Req/Sec   411.60    146.12   780.00     69.70%
        Latency Distribution
        50%  145.50ms
        75%  211.40ms
        90%  282.01ms
        99%  396.98ms
        9510 requests in 3.03s, 1.44MB read
        Requests/sec:   3143.40
        Transfer/sec:    488.09KB
        [run.sh] Speed is 3143.40, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.16ms   93.91ms 672.11ms   69.74%
        Req/Sec   403.00    172.69     0.95k    69.59%
        Latency Distribution
        50%  141.86ms
        75%  213.76ms
        90%  281.12ms
        99%  437.39ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.172033
        stop time: 6.230377
        stop time: 6.171361
        stop time: 6.192736
        stop time: 6.240689
        stop time: 6.247775
        stop time: 6.272744
        stop time: 6.294203
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-rgmw4        595m         30Mi
        service1-745795666b-7597t        410m         10Mi
        service2-8f7c6f8f5-zdz65         297m         8Mi
        ubuntu-client-76886f6bbd-5g87v   37m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.172033, 6.230377, 6.171361, 6.192736, 6.240689, 6.247775, 6.272744, 6.294203]
    [exp] Throughput: 3211.4379859884157
[test.py] Baseline throughput: 3211.4379859884157
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.41ms  100.92ms 777.76ms   71.62%
        Req/Sec   403.13    191.84   777.00     60.34%
        Latency Distribution
        50%  150.74ms
        75%  215.47ms
        90%  294.59ms
        99%  528.13ms
        9363 requests in 3.02s, 1.42MB read
        Requests/sec:   3103.78
        Transfer/sec:    481.93KB
        [run.sh] Speed is 3103.78, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   153.99ms   81.59ms 657.32ms   73.85%
        Req/Sec   412.23    169.13     0.97k    64.09%
        Latency Distribution
        50%  137.29ms
        75%  199.23ms
        90%  255.82ms
        99%  413.35ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.011854
        stop time: 6.091451
        stop time: 6.083520
        stop time: 6.072013
        stop time: 6.061973
        stop time: 6.130536
        stop time: 6.165735
        stop time: 6.119595
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-7kdhz        2m           45Mi
        service1-745795666b-wcbdr        0m           9Mi
        service2-8f7c6f8f5-5mhwj         0m           10Mi
        ubuntu-client-76886f6bbd-xd9tp   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.011854, 6.091451, 6.08352, 6.072013, 6.061973, 6.130536, 6.165735, 6.119595]
    [exp] Throughput: 3282.948486619225
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '132.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '530.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   229.45ms  134.87ms 737.04ms   67.30%
        Req/Sec   275.45    171.70   740.00     60.36%
        Latency Distribution
        50%  221.29ms
        75%  322.76ms
        90%  403.64ms
        99%  577.24ms
        6386 requests in 3.02s, 0.97MB read
        Requests/sec:   2111.74
        Transfer/sec:    327.90KB
        [run.sh] Speed is 2111.74, duration is 14
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d14s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 14s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   218.24ms  110.45ms 825.72ms   69.78%
        Req/Sec   291.74    146.53     0.86k    63.64%
        Latency Distribution
        50%  208.99ms
        75%  289.14ms
        90%  363.50ms
        99%  526.09ms
        20001 requests in 14.00s, 3.03MB read
        Requests/sec:   1428.63
        Transfer/sec:    221.83KB
        ------------------------------
        stop time: 8.294527
        stop time: 8.580528
        stop time: 8.779528
        stop time: 8.716385
        stop time: 8.774119
        stop time: 8.766195
        stop time: 8.774493
        stop time: 8.702982
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-848bfcb77d-nmh7m        0m           38Mi
        service1-745795666b-zwwgn        0m           14Mi
        service2-567796f7b-zrnjv         0m           10Mi
        ubuntu-client-76886f6bbd-fgb5q   6m           8Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.294527, 8.580528, 8.779528, 8.716385, 8.774119, 8.766195, 8.774493, 8.702982]
    [exp] Throughput: 2305.849058515344
[test.py] Finished running 0th optmization experiment: groundtruth->3282.948486619225, slowdown->2305.849058515344, predicted->3322.2069163073993, err->1.1958283795248463
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '2.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.39ms   90.84ms 698.45ms   70.17%
        Req/Sec   411.75    176.79   848.00     68.97%
        Latency Distribution
        50%  139.44ms
        75%  208.88ms
        90%  286.03ms
        99%  424.49ms
        9575 requests in 3.02s, 1.45MB read
        Requests/sec:   3168.58
        Transfer/sec:    492.00KB
        [run.sh] Speed is 3168.58, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.23ms   98.02ms 765.78ms   74.81%
        Req/Sec   412.31    166.72   808.00     65.62%
        Latency Distribution
        50%  137.78ms
        75%  198.73ms
        90%  287.88ms
        99%  471.35ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.008541
        stop time: 5.999100
        stop time: 6.098061
        stop time: 6.220940
        stop time: 6.126373
        stop time: 6.127984
        stop time: 6.166962
        stop time: 6.200989
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-9shh5        648m         44Mi
        service1-745795666b-zj6v2        170m         11Mi
        service2-8f7c6f8f5-js9lv         339m         9Mi
        ubuntu-client-76886f6bbd-q2hs9   25m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.008541, 5.9991, 6.098061, 6.22094, 6.126373, 6.127984, 6.166962, 6.200989]
    [exp] Throughput: 3268.7115862546593
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '119.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '478.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   218.33ms  118.22ms 887.02ms   73.52%
        Req/Sec   299.65    186.88   707.00     60.18%
        Latency Distribution
        50%  204.62ms
        75%  281.64ms
        90%  351.00ms
        99%  639.46ms
        6858 requests in 3.02s, 1.04MB read
        Requests/sec:   2272.32
        Transfer/sec:    352.83KB
        [run.sh] Speed is 2272.32, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   211.47ms  124.65ms 899.07ms   72.26%
        Req/Sec   304.36    148.75   707.00     63.55%
        Latency Distribution
        50%  191.72ms
        75%  280.36ms
        90%  366.00ms
        99%  617.48ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.44
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 8.198661
        stop time: 8.187938
        stop time: 8.137720
        stop time: 8.348339
        stop time: 8.239684
        stop time: 8.375165
        stop time: 8.423669
        stop time: 8.344338
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [8.198661, 8.187938, 8.13772, 8.348339, 8.239684, 8.375165, 8.423669, 8.344338]
    [exp] Throughput: 2414.893347593681
[test.py] Finished running 1th optmization experiment: groundtruth->3268.7115862546593, slowdown->2414.893347593681, predicted->3396.4857495982487, err->3.909006957998244
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '5.2e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.76ms   89.66ms 647.98ms   72.21%
        Req/Sec   406.07    195.25     0.88k    66.81%
        Latency Distribution
        50%  154.79ms
        75%  210.27ms
        90%  265.36ms
        99%  463.10ms
        9443 requests in 3.04s, 1.43MB read
        Requests/sec:   3109.00
        Transfer/sec:    482.75KB
        [run.sh] Speed is 3109.00, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.82ms   96.04ms 702.41ms   72.84%
        Req/Sec   410.36    167.13   780.00     67.29%
        Latency Distribution
        50%  133.80ms
        75%  205.98ms
        90%  283.34ms
        99%  498.62ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.994514
        stop time: 6.081802
        stop time: 6.072453
        stop time: 6.088916
        stop time: 6.081641
        stop time: 6.131786
        stop time: 6.174488
        stop time: 6.147575
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-2thgp        1203m        42Mi
        service1-745795666b-dhwgg        397m         10Mi
        service2-8f7c6f8f5-jz7nk         586m         10Mi
        ubuntu-client-76886f6bbd-v9r2h   14m          11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.994514, 6.081802, 6.072453, 6.088916, 6.081641, 6.131786, 6.174488, 6.147575]
    [exp] Throughput: 3280.491786724977
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '106.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '426.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   208.82ms  113.05ms 748.15ms   69.59%
        Req/Sec   313.17    180.83   737.00     61.64%
        Latency Distribution
        50%  200.41ms
        75%  277.65ms
        90%  357.21ms
        99%  507.81ms
        7211 requests in 3.02s, 1.09MB read
        Requests/sec:   2385.03
        Transfer/sec:    370.33KB
        [run.sh] Speed is 2385.03, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   205.64ms  111.61ms 881.56ms   67.93%
        Req/Sec   311.46    161.05   696.00     64.17%
        Latency Distribution
        50%  196.00ms
        75%  275.40ms
        90%  349.80ms
        99%  514.36ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 8.064972
        stop time: 8.070193
        stop time: 8.183854
        stop time: 8.085568
        stop time: 8.164783
        stop time: 8.146633
        stop time: 8.146863
        stop time: 8.130039
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [8.064972, 8.070193, 8.183854, 8.085568, 8.164783, 8.146633, 8.146863, 8.130039]
    [exp] Throughput: 2461.807177260349
[test.py] Finished running 2th optmization experiment: groundtruth->3280.491786724977, slowdown->2461.807177260349, predicted->3338.556435323138, err->1.769998292119759
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '7.8e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.52ms   74.69ms 507.99ms   69.19%
        Req/Sec   407.36    162.28   810.00     67.10%
        Latency Distribution
        50%  146.39ms
        75%  199.38ms
        90%  257.05ms
        99%  366.49ms
        9478 requests in 3.03s, 1.44MB read
        Requests/sec:   3124.68
        Transfer/sec:    485.18KB
        [run.sh] Speed is 3124.68, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.52ms  107.93ms 917.78ms   77.56%
        Req/Sec   405.48    183.51     0.90k    67.69%
        Latency Distribution
        50%  133.95ms
        75%  207.29ms
        90%  297.44ms
        99%  532.83ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.068621
        stop time: 6.097528
        stop time: 6.167970
        stop time: 6.238464
        stop time: 6.239283
        stop time: 6.244163
        stop time: 6.213664
        stop time: 6.237665
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-cpg6c        594m         44Mi
        service1-745795666b-cxf4l        229m         10Mi
        service2-8f7c6f8f5-g94vh         225m         10Mi
        ubuntu-client-76886f6bbd-bc9xf   37m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.068621, 6.097528, 6.16797, 6.238464, 6.239283, 6.244163, 6.213664, 6.237665]
    [exp] Throughput: 3231.842830312213
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '93.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '374.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   203.10ms  103.64ms 706.77ms   67.98%
        Req/Sec   317.19    154.31   727.00     64.89%
        Latency Distribution
        50%  195.87ms
        75%  264.80ms
        90%  347.67ms
        99%  457.82ms
        7299 requests in 3.03s, 1.11MB read
        Requests/sec:   2412.61
        Transfer/sec:    374.61KB
        [run.sh] Speed is 2412.61, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   199.93ms  100.26ms 669.88ms   66.16%
        Req/Sec   322.21    190.03   810.00     60.76%
        Latency Distribution
        50%  189.59ms
        75%  267.77ms
        90%  334.35ms
        99%  467.14ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 7.804869
        stop time: 7.934289
        stop time: 7.945304
        stop time: 7.953473
        stop time: 8.035369
        stop time: 7.921942
        stop time: 7.922105
        stop time: 7.959349
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f496748d4-8g7c8        2m           45Mi
        service1-745795666b-jkwds        0m           14Mi
        service2-6b7dfdd958-pn6bh        0m           10Mi
        ubuntu-client-76886f6bbd-2plhh   2m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.804869, 7.934289, 7.945304, 7.953473, 8.035369, 7.921942, 7.922105, 7.959349]
    [exp] Throughput: 2520.6099245865016
[test.py] Finished running 3th optmization experiment: groundtruth->3231.842830312213, slowdown->2520.6099245865016, predicted->3299.7378770723903, err->2.100815241489269
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000104', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   166.67ms   98.90ms 691.09ms   69.83%
        Req/Sec   398.75    199.46     0.90k    61.21%
        Latency Distribution
        50%  151.15ms
        75%  216.85ms
        90%  295.20ms
        99%  458.74ms
        9379 requests in 3.03s, 1.42MB read
        Requests/sec:   3099.06
        Transfer/sec:    481.20KB
        [run.sh] Speed is 3099.06, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.77ms   96.02ms 776.17ms   75.71%
        Req/Sec   409.90    166.76   830.00     65.01%
        Latency Distribution
        50%  135.34ms
        75%  202.25ms
        90%  281.55ms
        99%  478.40ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.969556
        stop time: 6.049276
        stop time: 6.179648
        stop time: 6.190440
        stop time: 6.142390
        stop time: 6.134998
        stop time: 6.123280
        stop time: 6.172678
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-v6pjn        153m         43Mi
        service1-745795666b-pcxvs        86m          10Mi
        service2-8f7c6f8f5-sslbs         35m          9Mi
        ubuntu-client-76886f6bbd-q7c2x   13m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.969556, 6.049276, 6.179648, 6.19044, 6.14239, 6.134998, 6.12328, 6.172678]
    [exp] Throughput: 3267.822612621728
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '322.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   197.59ms  117.48ms 935.16ms   72.33%
        Req/Sec   335.75    162.81   777.00     70.69%
        Latency Distribution
        50%  180.55ms
        75%  252.36ms
        90%  334.88ms
        99%  624.24ms
        7785 requests in 3.03s, 1.18MB read
        Requests/sec:   2569.31
        Transfer/sec:    398.95KB
        [run.sh] Speed is 2569.31, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   192.06ms  104.43ms 746.45ms   66.52%
        Req/Sec   331.77    162.65   757.00     66.95%
        Latency Distribution
        50%  182.80ms
        75%  256.44ms
        90%  331.32ms
        99%  478.70ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.498546
        stop time: 7.505929
        stop time: 7.427973
        stop time: 7.512200
        stop time: 7.682900
        stop time: 7.676125
        stop time: 7.684737
        stop time: 7.683847
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7c6d788d76-92wlx        427m         45Mi
        service1-745795666b-mc6kw        272m         11Mi
        service2-76b4546649-jfb7f        248m         9Mi
        ubuntu-client-76886f6bbd-5tm28   25m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.498546, 7.505929, 7.427973, 7.5122, 7.6829, 7.676125, 7.684737, 7.683847]
    [exp] Throughput: 2637.119631135529
[test.py] Finished running 4th optmization experiment: groundtruth->3267.822612621728, slowdown->2637.119631135529, predicted->3349.785175136295, err->2.5081704924249193
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00013', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.87ms   77.84ms 512.64ms   68.62%
        Req/Sec   402.11    185.93   818.00     66.81%
        Latency Distribution
        50%  151.02ms
        75%  213.96ms
        90%  261.10ms
        99%  387.19ms
        9327 requests in 3.02s, 1.41MB read
        Requests/sec:   3083.59
        Transfer/sec:    478.80KB
        [run.sh] Speed is 3083.59, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.76ms   87.59ms 725.75ms   74.77%
        Req/Sec   409.76    150.16   787.00     66.53%
        Latency Distribution
        50%  140.36ms
        75%  198.16ms
        90%  263.63ms
        99%  468.14ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.021348
        stop time: 5.977146
        stop time: 6.168792
        stop time: 6.174396
        stop time: 6.204231
        stop time: 6.140019
        stop time: 6.203154
        stop time: 6.201358
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.021348, 5.977146, 6.168792, 6.174396, 6.204231, 6.140019, 6.203154, 6.201358]
    [exp] Throughput: 3259.290138015456
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '67.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '270.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   187.72ms  104.62ms 595.91ms   66.69%
        Req/Sec   343.05    176.36   750.00     66.38%
        Latency Distribution
        50%  174.72ms
        75%  252.90ms
        90%  333.55ms
        99%  468.05ms
        7976 requests in 3.03s, 1.21MB read
        Requests/sec:   2635.79
        Transfer/sec:    409.27KB
        [run.sh] Speed is 2635.79, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   184.70ms  107.64ms 865.12ms   71.62%
        Req/Sec   346.81    165.68   818.00     64.45%
        Latency Distribution
        50%  169.59ms
        75%  243.30ms
        90%  318.81ms
        99%  517.77ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.327220
        stop time: 7.352394
        stop time: 7.346289
        stop time: 7.344830
        stop time: 7.360287
        stop time: 7.338800
        stop time: 7.417289
        stop time: 7.411078
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-d6dd5547-ctdm6          1210m        42Mi
        service1-745795666b-xb977        819m         12Mi
        service2-7854f4f79c-lp6lb        594m         10Mi
        ubuntu-client-76886f6bbd-mprr9   74m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.32722, 7.352394, 7.346289, 7.34483, 7.360287, 7.3388, 7.417289, 7.411078]
    [exp] Throughput: 2716.5522089839537
[test.py] Finished running 5th optmization experiment: groundtruth->3259.290138015456, slowdown->2716.5522089839537, predicted->3328.46635275207, err->2.1224319347873393
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000156', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.05ms   94.37ms 543.96ms   69.88%
        Req/Sec   381.20    196.19     0.93k    64.44%
        Latency Distribution
        50%  151.92ms
        75%  216.49ms
        90%  308.84ms
        99%  406.34ms
        9100 requests in 3.02s, 1.38MB read
        Requests/sec:   3009.29
        Transfer/sec:    467.26KB
        [run.sh] Speed is 3009.29, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.17ms  109.50ms   1.02s    78.08%
        Req/Sec   408.65    145.93     0.99k    70.87%
        Latency Distribution
        50%  135.66ms
        75%  203.15ms
        90%  294.00ms
        99%  553.89ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.980776
        stop time: 6.124613
        stop time: 6.148542
        stop time: 6.147781
        stop time: 6.220494
        stop time: 6.197053
        stop time: 6.135474
        stop time: 6.236028
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [5.980776, 6.124613, 6.148542, 6.147781, 6.220494, 6.197053, 6.135474, 6.236028]
    [exp] Throughput: 3252.643316495957
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '54.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '218.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   182.54ms   86.95ms 783.80ms   63.69%
        Req/Sec   351.17    181.98   818.00     62.93%
        Latency Distribution
        50%  174.69ms
        75%  247.97ms
        90%  298.16ms
        99%  398.39ms
        8153 requests in 3.03s, 1.24MB read
        Requests/sec:   2689.40
        Transfer/sec:    417.59KB
        [run.sh] Speed is 2689.40, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   181.99ms  105.35ms 854.67ms   68.15%
        Req/Sec   353.15    176.89     0.87k    63.64%
        Latency Distribution
        50%  166.40ms
        75%  246.67ms
        90%  324.68ms
        99%  476.38ms
        20001 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.25
        Transfer/sec:    282.33KB
        ------------------------------
        stop time: 7.020273
        stop time: 7.123501
        stop time: 7.126049
        stop time: 7.228519
        stop time: 7.172395
        stop time: 7.200759
        stop time: 7.292390
        stop time: 7.285996
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5d9cf6f69-5pxft         800m         44Mi
        service1-745795666b-pp448        598m         12Mi
        service2-67685bd7bc-n6w9f        355m         9Mi
        ubuntu-client-76886f6bbd-jjr6m   43m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.020273, 7.123501, 7.126049, 7.228519, 7.172395, 7.200759, 7.29239, 7.285996]
    [exp] Throughput: 2785.036181623489
[test.py] Finished running 6th optmization experiment: groundtruth->3252.643316495957, slowdown->2785.036181623489, predicted->3285.293985148254, err->1.0038195238533227
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000182', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.22ms   78.44ms 621.83ms   68.72%
        Req/Sec   396.16    185.99     0.85k    64.68%
        Latency Distribution
        50%  150.45ms
        75%  202.71ms
        90%  261.59ms
        99%  380.69ms
        9348 requests in 3.03s, 1.42MB read
        Requests/sec:   3081.62
        Transfer/sec:    478.49KB
        [run.sh] Speed is 3081.62, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.72ms   88.08ms 784.39ms   70.52%
        Req/Sec   407.84    174.54   830.00     66.67%
        Latency Distribution
        50%  144.17ms
        75%  205.65ms
        90%  273.80ms
        99%  412.38ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.052098
        stop time: 6.028162
        stop time: 6.208189
        stop time: 6.206890
        stop time: 6.199157
        stop time: 6.251740
        stop time: 6.185503
        stop time: 6.258797
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.052098, 6.028162, 6.208189, 6.20689, 6.199157, 6.25174, 6.185503, 6.258797]
    [exp] Throughput: 3239.487014273342
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '41.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '166.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   182.07ms   93.25ms 676.47ms   67.60%
        Req/Sec   351.22    210.41     0.88k    61.64%
        Latency Distribution
        50%  172.67ms
        75%  241.68ms
        90%  301.38ms
        99%  417.70ms
        8145 requests in 3.03s, 1.24MB read
        Requests/sec:   2689.00
        Transfer/sec:    417.53KB
        [run.sh] Speed is 2689.00, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   170.26ms  107.51ms 784.05ms   69.26%
        Req/Sec   372.82    185.77     0.94k    69.30%
        Latency Distribution
        50%  153.45ms
        75%  230.32ms
        90%  317.57ms
        99%  483.08ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 6.630611
        stop time: 6.716477
        stop time: 6.738350
        stop time: 6.778942
        stop time: 6.796473
        stop time: 6.747464
        stop time: 6.738729
        stop time: 6.839551
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-b697cbc5-s7gzr          7m           45Mi
        service1-745795666b-9ff7j        10m          15Mi
        service2-54d55b9855-gdp9f        55m          9Mi
        ubuntu-client-76886f6bbd-s5htk   12m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.630611, 6.716477, 6.73835, 6.778942, 6.796473, 6.747464, 6.738729, 6.839551]
    [exp] Throughput: 2963.69856392319
[test.py] Finished running 7th optmization experiment: groundtruth->3239.487014273342, slowdown->2963.69856392319, predicted->3381.3344043146503, err->4.378699140213297
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000208', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.71ms   91.56ms 517.76ms   68.12%
        Req/Sec   401.73    180.89   848.00     67.24%
        Latency Distribution
        50%  151.56ms
        75%  219.53ms
        90%  293.18ms
        99%  426.12ms
        9333 requests in 3.03s, 1.42MB read
        Requests/sec:   3084.01
        Transfer/sec:    478.87KB
        [run.sh] Speed is 3084.01, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.57ms   97.36ms 770.66ms   77.77%
        Req/Sec   409.17    150.60   808.00     68.19%
        Latency Distribution
        50%  136.68ms
        75%  201.12ms
        90%  273.92ms
        99%  499.56ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.197984
        stop time: 6.034730
        stop time: 6.101978
        stop time: 6.177241
        stop time: 6.019741
        stop time: 6.202410
        stop time: 6.165325
        stop time: 6.204063
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-nk5vt        0m           45Mi
        service1-745795666b-5ndm4        0m           14Mi
        service2-8f7c6f8f5-2wz7b         0m           9Mi
        ubuntu-client-76886f6bbd-r2xrl   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.197984, 6.03473, 6.101978, 6.177241, 6.019741, 6.20241, 6.165325, 6.204063]
    [exp] Throughput: 3258.425391996721
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '28.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '114.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   170.45ms   90.18ms 700.84ms   67.18%
        Req/Sec   378.18    183.79     0.87k    66.67%
        Latency Distribution
        50%  163.43ms
        75%  230.02ms
        90%  286.99ms
        99%  405.56ms
        8819 requests in 3.02s, 1.34MB read
        Requests/sec:   2923.35
        Transfer/sec:    453.92KB
        [run.sh] Speed is 2923.35, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.30ms   88.00ms 650.26ms   69.43%
        Req/Sec   378.98    159.41   800.00     66.99%
        Latency Distribution
        50%  153.28ms
        75%  214.50ms
        90%  285.12ms
        99%  422.36ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.554517
        stop time: 6.654481
        stop time: 6.599424
        stop time: 6.718609
        stop time: 6.642652
        stop time: 6.674145
        stop time: 6.712590
        stop time: 6.622504
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74f5db548b-zrrs5        562m         43Mi
        service1-745795666b-7jnzp        386m         13Mi
        service2-96f84c786-g7tnk         282m         9Mi
        ubuntu-client-76886f6bbd-vqqcf   35m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.554517, 6.654481, 6.599424, 6.718609, 6.642652, 6.674145, 6.71259, 6.622504]
    [exp] Throughput: 3008.710857282891
[test.py] Finished running 8th optmization experiment: groundtruth->3258.425391996721, slowdown->3008.710857282891, predicted->3292.796131754816, err->1.0548266608318204
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000234', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.43ms  114.61ms 804.17ms   81.05%
        Req/Sec   416.06    166.17   780.00     67.24%
        Latency Distribution
        50%  136.21ms
        75%  206.14ms
        90%  293.19ms
        99%  608.87ms
        9661 requests in 3.02s, 1.46MB read
        Requests/sec:   3194.15
        Transfer/sec:    495.97KB
        [run.sh] Speed is 3194.15, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.97ms   95.77ms 815.83ms   72.95%
        Req/Sec   415.22    189.08     1.06k    66.32%
        Latency Distribution
        50%  137.07ms
        75%  202.31ms
        90%  280.95ms
        99%  478.38ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.040316
        stop time: 5.965393
        stop time: 5.974849
        stop time: 5.960231
        stop time: 6.174211
        stop time: 6.183544
        stop time: 6.205269
        stop time: 6.217063
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-5nmhh        0m           43Mi
        service1-745795666b-mwh7j        0m           12Mi
        service2-8f7c6f8f5-w4pjb         0m           9Mi
        ubuntu-client-76886f6bbd-qxwd7   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.040316, 5.965393, 5.974849, 5.960231, 6.174211, 6.183544, 6.205269, 6.217063]
    [exp] Throughput: 3284.0132020614733
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '15.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '62.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   163.42ms   87.19ms 666.74ms   71.54%
        Req/Sec   390.51    148.99   696.00     70.00%
        Latency Distribution
        50%  148.34ms
        75%  208.77ms
        90%  279.15ms
        99%  430.05ms
        9333 requests in 3.04s, 1.42MB read
        Requests/sec:   3070.85
        Transfer/sec:    476.82KB
        [run.sh] Speed is 3070.85, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.44ms   96.58ms 967.05ms   75.01%
        Req/Sec   399.48    174.51   787.00     61.05%
        Latency Distribution
        50%  146.87ms
        75%  205.49ms
        90%  274.27ms
        99%  506.06ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.194616
        stop time: 6.200035
        stop time: 6.268418
        stop time: 6.191331
        stop time: 6.268142
        stop time: 6.381193
        stop time: 6.396953
        stop time: 6.318366
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5867c84794-4w424        573m         44Mi
        service1-745795666b-nh6jq        409m         12Mi
        service2-69d7667f8d-qv9zx        206m         9Mi
        ubuntu-client-76886f6bbd-n8dw7   14m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.194616, 6.200035, 6.268418, 6.191331, 6.268142, 6.381193, 6.396953, 6.318366]
    [exp] Throughput: 3186.041696444541
[test.py] Finished running 9th optmization experiment: groundtruth->3284.0132020614733, slowdown->3186.041696444541, predicted->3353.5205489277187, err->2.116536767349581
[test.py] Baseline throughput:  3211.4379859884157
[test.py] Groundtruth:  [3282.948486619225, 3268.7115862546593, 3280.491786724977, 3231.842830312213, 3267.822612621728, 3259.290138015456, 3252.643316495957, 3239.487014273342, 3258.425391996721, 3284.0132020614733]
[test.py] Slowdown:  [2305.849058515344, 2414.893347593681, 2461.807177260349, 2520.6099245865016, 2637.119631135529, 2716.5522089839537, 2785.036181623489, 2963.69856392319, 3008.710857282891, 3186.041696444541]
[test.py] Predicted:  [3322.2069163073993, 3396.4857495982487, 3338.556435323138, 3299.7378770723903, 3349.785175136295, 3328.46635275207, 3285.293985148254, 3381.3344043146503, 3292.796131754816, 3353.5205489277187]
[test.py] Error percentage:  [1.1958283795248463, 3.909006957998244, 1.769998292119759, 2.100815241489269, 2.5081704924249193, 2.1224319347873393, 1.0038195238533227, 4.378699140213297, 1.0548266608318204, 2.116536767349581]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 2...
[test.py] Actual processing time range: [0, 26, 52, 78, 104, 130, 156, 182, 208, 234]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   166.92ms   99.79ms 753.23ms   74.27%
        Req/Sec   393.70    165.72   780.00     68.97%
        Latency Distribution
        50%  148.24ms
        75%  212.05ms
        90%  293.52ms
        99%  520.50ms
        9156 requests in 3.03s, 1.39MB read
        Requests/sec:   3024.93
        Transfer/sec:    469.69KB
        [run.sh] Speed is 3024.93, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.07ms  108.26ms 895.48ms   76.18%
        Req/Sec   403.21    158.69   797.00     70.23%
        Latency Distribution
        50%  135.46ms
        75%  212.27ms
        90%  301.06ms
        99%  556.38ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.210919
        stop time: 6.233100
        stop time: 6.124096
        stop time: 6.237344
        stop time: 6.184262
        stop time: 6.286292
        stop time: 6.204994
        stop time: 6.305262
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-wx924        2m           43Mi
        service1-745795666b-7xc9f        0m           13Mi
        service2-8f7c6f8f5-4cs8k         0m           10Mi
        ubuntu-client-76886f6bbd-hdch9   16m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.210919, 6.2331, 6.124096, 6.237344, 6.184262, 6.286292, 6.204994, 6.305262]
    [exp] Throughput: 3213.7375066205504
[test.py] Baseline throughput: 3213.7375066205504
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.40ms   92.17ms 544.91ms   68.62%
        Req/Sec   405.40    168.77   767.00     62.07%
        Latency Distribution
        50%  151.54ms
        75%  214.69ms
        90%  295.14ms
        99%  417.02ms
        9452 requests in 3.02s, 1.43MB read
        Requests/sec:   3131.78
        Transfer/sec:    486.28KB
        [run.sh] Speed is 3131.78, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.55ms   79.51ms 560.09ms   70.46%
        Req/Sec   407.26    163.42     0.88k    66.26%
        Latency Distribution
        50%  142.22ms
        75%  204.66ms
        90%  260.47ms
        99%  390.23ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.161135
        stop time: 6.120086
        stop time: 6.107555
        stop time: 6.227295
        stop time: 6.152319
        stop time: 6.111616
        stop time: 6.208339
        stop time: 6.218215
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-bjpbv   0m           41Mi
        service1-745795666b-7slps   0m           10Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.161135, 6.120086, 6.107555, 6.227295, 6.152319, 6.111616, 6.208339, 6.218215]
    [exp] Throughput: 3245.00431585574
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '132.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '530.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   221.09ms  113.78ms 720.96ms   65.50%
        Req/Sec   286.72    153.14   750.00     69.33%
        Latency Distribution
        50%  205.15ms
        75%  302.98ms
        90%  372.38ms
        99%  499.30ms
        6750 requests in 3.03s, 1.02MB read
        Requests/sec:   2231.04
        Transfer/sec:    346.42KB
        [run.sh] Speed is 2231.04, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   219.10ms  102.41ms 676.15ms   66.13%
        Req/Sec   291.58    154.63   660.00     66.27%
        Latency Distribution
        50%  211.41ms
        75%  283.92ms
        90%  358.96ms
        99%  487.86ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.44
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 8.621959
        stop time: 8.505494
        stop time: 8.624697
        stop time: 8.660176
        stop time: 8.756195
        stop time: 8.754069
        stop time: 8.743295
        stop time: 8.737815
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-848bfcb77d-dsdb2        757m         45Mi
        service1-745795666b-zjppx        515m         12Mi
        service2-567796f7b-5v9hk         447m         11Mi
        ubuntu-client-76886f6bbd-ncr6r   65m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.621959, 8.505494, 8.624697, 8.660176, 8.756195, 8.754069, 8.743295, 8.737815]
    [exp] Throughput: 2305.352596475404
[test.py] Finished running 0th optmization experiment: groundtruth->3245.00431585574, slowdown->2305.352596475404, predicted->3321.176443725779, err->2.3473659957198385
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '2.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.50ms   85.64ms 758.31ms   71.75%
        Req/Sec   412.68    164.40   828.00     69.40%
        Latency Distribution
        50%  142.76ms
        75%  206.80ms
        90%  261.75ms
        99%  412.42ms
        9606 requests in 3.03s, 1.46MB read
        Requests/sec:   3167.34
        Transfer/sec:    491.80KB
        [run.sh] Speed is 3167.34, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   154.37ms   81.00ms 514.47ms   69.39%
        Req/Sec   408.91    180.04   840.00     62.06%
        Latency Distribution
        50%  141.11ms
        75%  199.48ms
        90%  264.99ms
        99%  391.49ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.005327
        stop time: 6.193773
        stop time: 6.039246
        stop time: 6.178794
        stop time: 6.138185
        stop time: 6.186159
        stop time: 6.181054
        stop time: 6.183573
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.005327, 6.193773, 6.039246, 6.178794, 6.138185, 6.186159, 6.181054, 6.183573]
    [exp] Throughput: 3258.2502817215554
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '119.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '478.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   218.12ms   97.02ms 706.75ms   67.60%
        Req/Sec   284.68    141.08   636.00     63.79%
        Latency Distribution
        50%  203.27ms
        75%  287.25ms
        90%  351.26ms
        99%  469.39ms
        6638 requests in 3.03s, 1.01MB read
        Requests/sec:   2192.24
        Transfer/sec:    340.40KB
        [run.sh] Speed is 2192.24, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   212.84ms  119.33ms 901.32ms   68.29%
        Req/Sec   298.58    173.72   808.00     62.95%
        Latency Distribution
        50%  200.96ms
        75%  278.24ms
        90%  373.95ms
        99%  553.69ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.44
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 8.051153
        stop time: 8.448701
        stop time: 8.364225
        stop time: 8.531793
        stop time: 8.441602
        stop time: 8.548527
        stop time: 8.433079
        stop time: 8.509780
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7579bf5b9c-d7r8g        1180m        45Mi
        service1-745795666b-l9m5v        831m         13Mi
        service2-67d6df6559-6hrbx        498m         10Mi
        ubuntu-client-76886f6bbd-m4bcs   48m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.051153, 8.448701, 8.364225, 8.531793, 8.441602, 8.548527, 8.433079, 8.50978]
    [exp] Throughput: 2376.395501126857
[test.py] Finished running 1th optmization experiment: groundtruth->3258.2502817215554, slowdown->2376.395501126857, predicted->3320.820757454309, err->1.920370454159625
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '5.2e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.69ms   87.23ms 798.04ms   68.97%
        Req/Sec   406.36    149.69   757.00     65.52%
        Latency Distribution
        50%  140.38ms
        75%  208.47ms
        90%  275.88ms
        99%  405.71ms
        9553 requests in 3.03s, 1.45MB read
        Requests/sec:   3155.99
        Transfer/sec:    490.04KB
        [run.sh] Speed is 3155.99, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.42ms   81.27ms 595.46ms   71.55%
        Req/Sec   406.24    159.50     0.85k    69.06%
        Latency Distribution
        50%  141.53ms
        75%  200.18ms
        90%  266.65ms
        99%  407.32ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.045956
        stop time: 6.228267
        stop time: 6.225977
        stop time: 6.044905
        stop time: 6.221494
        stop time: 6.149270
        stop time: 6.234456
        stop time: 6.233603
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.045956, 6.228267, 6.225977, 6.044905, 6.221494, 6.14927, 6.234456, 6.233603]
    [exp] Throughput: 3239.9204858714356
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '106.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '426.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   210.63ms  100.24ms 725.54ms   65.71%
        Req/Sec   295.42    147.27   616.00     62.76%
        Latency Distribution
        50%  207.10ms
        75%  274.18ms
        90%  344.33ms
        99%  469.09ms
        7048 requests in 3.03s, 1.07MB read
        Requests/sec:   2328.64
        Transfer/sec:    361.58KB
        [run.sh] Speed is 2328.64, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   204.16ms  100.38ms 762.78ms   67.68%
        Req/Sec   309.75    177.12     0.90k    64.57%
        Latency Distribution
        50%  197.92ms
        75%  269.10ms
        90%  333.83ms
        99%  468.65ms
        20001 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.73
        Transfer/sec:    258.80KB
        ------------------------------
        stop time: 8.025088
        stop time: 8.021843
        stop time: 8.029174
        stop time: 8.030984
        stop time: 8.113375
        stop time: 8.153602
        stop time: 8.105299
        stop time: 8.169333
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d9fd768c7-jj9cv        459m         46Mi
        service1-745795666b-bcq2n        317m         13Mi
        service2-7668ff8dd-nkcmh         224m         10Mi
        ubuntu-client-76886f6bbd-gs6pw   12m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.025088, 8.021843, 8.029174, 8.030984, 8.113375, 8.153602, 8.105299, 8.169333]
    [exp] Throughput: 2474.9144986647684
[test.py] Finished running 2th optmization experiment: groundtruth->3239.9204858714356, slowdown->2474.9144986647684, predicted->3362.708130090904, err->3.7898351133899006
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '7.8e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.39ms  101.21ms 627.91ms   66.54%
        Req/Sec   407.67    185.50   830.00     62.93%
        Latency Distribution
        50%  140.03ms
        75%  227.82ms
        90%  294.99ms
        99%  444.70ms
        9485 requests in 3.05s, 1.44MB read
        Requests/sec:   3110.05
        Transfer/sec:    482.91KB
        [run.sh] Speed is 3110.05, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.41ms   94.92ms 688.96ms   70.87%
        Req/Sec   408.94    180.45     0.86k    62.14%
        Latency Distribution
        50%  139.11ms
        75%  210.47ms
        90%  287.52ms
        99%  452.03ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.072332
        stop time: 6.026465
        stop time: 6.156053
        stop time: 6.231037
        stop time: 6.292432
        stop time: 6.116378
        stop time: 6.228361
        stop time: 6.212771
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-fddfs        0m           45Mi
        service1-745795666b-7lzwq        0m           11Mi
        service2-8f7c6f8f5-qwk8f         0m           10Mi
        ubuntu-client-76886f6bbd-jpvwc   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.072332, 6.026465, 6.156053, 6.231037, 6.292432, 6.116378, 6.228361, 6.212771]
    [exp] Throughput: 3243.079182879444
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '93.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '374.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   204.95ms  115.87ms 729.05ms   72.73%
        Req/Sec   297.11    158.36   646.00     59.17%
        Latency Distribution
        50%  190.25ms
        75%  267.19ms
        90%  355.02ms
        99%  546.54ms
        7101 requests in 3.03s, 1.08MB read
        Requests/sec:   2346.96
        Transfer/sec:    364.42KB
        [run.sh] Speed is 2346.96, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   199.20ms   97.90ms 711.24ms   69.29%
        Req/Sec   318.04    148.61   790.00     68.16%
        Latency Distribution
        50%  187.81ms
        75%  258.56ms
        90%  332.88ms
        99%  467.50ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 7.944203
        stop time: 7.715224
        stop time: 7.938753
        stop time: 7.930101
        stop time: 7.918583
        stop time: 7.942934
        stop time: 7.951996
        stop time: 7.934532
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f496748d4-67ltb        408m         43Mi
        service1-745795666b-lqbw2        277m         11Mi
        service2-6b7dfdd958-t7kp2        88m          10Mi
        ubuntu-client-76886f6bbd-cx725   30m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.944203, 7.715224, 7.938753, 7.930101, 7.918583, 7.942934, 7.951996, 7.934532]
    [exp] Throughput: 2528.591814891402
[test.py] Finished running 3th optmization experiment: groundtruth->3243.079182879444, slowdown->2528.591814891402, predicted->3313.4302481307805, err->2.16926757825486
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000104', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
