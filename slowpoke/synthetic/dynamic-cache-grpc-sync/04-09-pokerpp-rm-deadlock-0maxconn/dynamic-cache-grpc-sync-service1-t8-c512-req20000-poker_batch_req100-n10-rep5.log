[config.py] Random numbers for execution time: [243.1852228229995, 265.3472596363038, 431.399959404726]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service1
request_type                     : dynamic-cache-grpc-sync
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 27597
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.25}
baseline_service_processing_time : {'service0': 431.4, 'service1': 265.35, 'service2': 972.74}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2}
target_processing_time_range     : [0, 265.35]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 26, 52, 78, 104, 130, 156, 182, 208, 234]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.97ms   83.06ms 684.42ms   72.36%
        Req/Sec   414.73    142.11   727.00     65.52%
        Latency Distribution
        50%  140.53ms
        75%  198.64ms
        90%  270.12ms
        99%  414.86ms
        9688 requests in 3.02s, 1.47MB read
        Requests/sec:   3210.94
        Transfer/sec:    498.57KB
        [run.sh] Speed is 3210.94, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.29ms  109.62ms   1.08s    77.89%
        Req/Sec   403.50    138.26   770.00     69.26%
        Latency Distribution
        50%  138.78ms
        75%  208.21ms
        90%  285.70ms
        99%  581.74ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.202319
        stop time: 6.120212
        stop time: 6.258758
        stop time: 6.218136
        stop time: 6.158365
        stop time: 6.209556
        stop time: 6.298391
        stop time: 6.289087
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-rzssq        0m           45Mi
        service1-745795666b-npjbk        0m           16Mi
        service2-8f7c6f8f5-5rhz7         0m           10Mi
        ubuntu-client-76886f6bbd-kjt9c   2m           4Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.202319, 6.120212, 6.258758, 6.218136, 6.158365, 6.209556, 6.298391, 6.289087]
    [exp] Throughput: 3215.7685855747372
[test.py] Baseline throughput: 3215.7685855747372
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.14ms  100.41ms 635.79ms   72.85%
        Req/Sec   401.61    173.15     0.97k    66.38%
        Latency Distribution
        50%  149.43ms
        75%  213.30ms
        90%  285.42ms
        99%  518.77ms
        9419 requests in 3.03s, 1.43MB read
        Requests/sec:   3113.09
        Transfer/sec:    483.38KB
        [run.sh] Speed is 3113.09, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.78ms   92.00ms 745.35ms   73.45%
        Req/Sec   408.59    155.64   840.00     66.74%
        Latency Distribution
        50%  139.20ms
        75%  202.02ms
        90%  270.06ms
        99%  457.62ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.117308
        stop time: 6.053461
        stop time: 6.176570
        stop time: 6.210018
        stop time: 6.197943
        stop time: 6.207666
        stop time: 6.103140
        stop time: 6.159182
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-2m45x        517m         44Mi
        service1-745795666b-6l2bt        151m         10Mi
        service2-8f7c6f8f5-td2hg         288m         9Mi
        ubuntu-client-76886f6bbd-fpj89   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.117308, 6.053461, 6.17657, 6.210018, 6.197943, 6.207666, 6.10314, 6.159182]
    [exp] Throughput: 3250.361887166613
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '132.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '530.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   224.34ms  115.53ms 668.95ms   65.12%
        Req/Sec   282.75    181.79   650.00     58.10%
        Latency Distribution
        50%  211.11ms
        75%  300.43ms
        90%  384.57ms
        99%  495.42ms
        6165 requests in 3.03s, 0.93MB read
        Requests/sec:   2036.78
        Transfer/sec:    316.26KB
        [run.sh] Speed is 2036.78, duration is 14
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d14s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 14s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   218.81ms  131.42ms   1.00s    69.26%
        Req/Sec   292.20    168.62   777.00     65.32%
        Latency Distribution
        50%  208.81ms
        75%  292.80ms
        90%  390.88ms
        99%  605.11ms
        20000 requests in 14.00s, 3.03MB read
        Requests/sec:   1428.56
        Transfer/sec:    221.82KB
        ------------------------------
        stop time: 8.439810
        stop time: 8.447367
        stop time: 8.610486
        stop time: 8.589605
        stop time: 8.798508
        stop time: 8.719095
        stop time: 8.700150
        stop time: 8.670496
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-848bfcb77d-w45vz        270m         43Mi
        service1-745795666b-7bvzv        75m          12Mi
        service2-567796f7b-xrftq         70m          10Mi
        ubuntu-client-76886f6bbd-cqjmz   46m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.43981, 8.447367, 8.610486, 8.589605, 8.798508, 8.719095, 8.70015, 8.670496]
    [exp] Throughput: 2319.663656888574
[test.py] Finished running 0th optmization experiment: groundtruth->3250.361887166613, slowdown->2319.663656888574, predicted->3350.959590212828, err->3.0949693153677553
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '2.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.51ms   96.06ms 798.85ms   75.14%
        Req/Sec   409.48    202.87     0.87k    64.94%
        Latency Distribution
        50%  149.58ms
        75%  206.24ms
        90%  284.16ms
        99%  494.89ms
        9496 requests in 3.03s, 1.44MB read
        Requests/sec:   3136.08
        Transfer/sec:    486.95KB
        [run.sh] Speed is 3136.08, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.11ms   97.17ms 768.83ms   77.07%
        Req/Sec   409.34    154.59   797.00     66.67%
        Latency Distribution
        50%  132.43ms
        75%  201.43ms
        90%  285.38ms
        99%  496.26ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.893117
        stop time: 6.000438
        stop time: 6.219062
        stop time: 6.120753
        stop time: 6.198142
        stop time: 6.239598
        stop time: 6.132619
        stop time: 6.231319
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-745795666b-vxbhc   0m           11Mi
        service2-8f7c6f8f5-7tsgt    0m           9Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.893117, 6.000438, 6.219062, 6.120753, 6.198142, 6.239598, 6.132619, 6.231319]
    [exp] Throughput: 3262.972231616863
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '119.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '478.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   216.51ms  130.49ms 796.99ms   66.07%
        Req/Sec   301.24    160.70   636.00     61.74%
        Latency Distribution
        50%  206.10ms
        75%  294.12ms
        90%  401.28ms
        99%  551.83ms
        6983 requests in 3.02s, 1.06MB read
        Requests/sec:   2311.75
        Transfer/sec:    358.95KB
        [run.sh] Speed is 2311.75, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   214.23ms  121.38ms 952.41ms   70.38%
        Req/Sec   300.32    152.13     1.11k    68.00%
        Latency Distribution
        50%  198.99ms
        75%  277.15ms
        90%  372.74ms
        99%  570.53ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.64
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 8.349857
        stop time: 8.271453
        stop time: 8.408615
        stop time: 8.437627
        stop time: 8.477818
        stop time: 8.535841
        stop time: 8.534384
        stop time: 8.523305
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7579bf5b9c-c4pjs        955m         45Mi
        service1-745795666b-c49hs        573m         12Mi
        service2-67d6df6559-r5bf2        421m         9Mi
        ubuntu-client-76886f6bbd-9kpfp   64m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.349857, 8.271453, 8.408615, 8.437627, 8.477818, 8.535841, 8.534384, 8.523305]
    [exp] Throughput: 2369.0051214929476
[test.py] Finished running 1th optmization experiment: groundtruth->3262.972231616863, slowdown->2369.0051214929476, predicted->3306.406783093517, err->1.3311345728226163
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '5.2e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.55ms  107.11ms 709.72ms   68.30%
        Req/Sec   407.98    164.62   777.00     65.78%
        Latency Distribution
        50%  156.13ms
        75%  225.64ms
        90%  306.56ms
        99%  493.96ms
        9493 requests in 3.02s, 1.44MB read
        Requests/sec:   3138.52
        Transfer/sec:    487.33KB
        [run.sh] Speed is 3138.52, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   151.85ms   89.15ms 760.96ms   71.52%
        Req/Sec   417.34    161.95     0.86k    67.51%
        Latency Distribution
        50%  131.68ms
        75%  198.58ms
        90%  282.26ms
        99%  416.04ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.874223
        stop time: 5.983063
        stop time: 6.097402
        stop time: 6.091528
        stop time: 6.110955
        stop time: 6.081126
        stop time: 6.118693
        stop time: 5.941964
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [5.874223, 5.983063, 6.097402, 6.091528, 6.110955, 6.081126, 6.118693, 5.941964]
    [exp] Throughput: 3312.7011404843265
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '106.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '426.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   214.16ms  110.38ms 713.72ms   68.30%
        Req/Sec   303.44    169.34   720.00     62.61%
        Latency Distribution
        50%  209.76ms
        75%  278.53ms
        90%  361.89ms
        99%  515.68ms
        6876 requests in 3.03s, 1.04MB read
        Requests/sec:   2271.05
        Transfer/sec:    352.63KB
        [run.sh] Speed is 2271.05, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   204.32ms  115.41ms 911.37ms   70.67%
        Req/Sec   316.61    154.30     0.88k    69.32%
        Latency Distribution
        50%  188.15ms
        75%  268.00ms
        90%  350.04ms
        99%  543.67ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.44
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 7.808073
        stop time: 7.817458
        stop time: 8.093895
        stop time: 7.977634
        stop time: 8.228414
        stop time: 8.209328
        stop time: 8.161757
        stop time: 8.118003
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d9fd768c7-zg5c2        1016m        46Mi
        service1-745795666b-864nx        812m         12Mi
        service2-7668ff8dd-hjfbq         550m         9Mi
        ubuntu-client-76886f6bbd-npx52   22m          13Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.808073, 7.817458, 8.093895, 7.977634, 8.228414, 8.209328, 8.161757, 8.118003]
    [exp] Throughput: 2483.9103928083837
[test.py] Finished running 2th optmization experiment: groundtruth->3312.7011404843265, slowdown->2483.9103928083837, predicted->3379.337236777614, err->2.0115335935056695
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '7.8e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.90ms   82.28ms 585.19ms   70.27%
        Req/Sec   408.46    173.05   808.00     64.22%
        Latency Distribution
        50%  147.58ms
        75%  209.50ms
        90%  266.23ms
        99%  399.85ms
        9461 requests in 3.03s, 1.43MB read
        Requests/sec:   3124.73
        Transfer/sec:    485.19KB
        [run.sh] Speed is 3124.73, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.22ms   97.71ms 654.55ms   74.83%
        Req/Sec   408.09    179.46     0.93k    65.98%
        Latency Distribution
        50%  140.43ms
        75%  202.31ms
        90%  283.26ms
        99%  504.10ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.010714
        stop time: 6.137118
        stop time: 6.062422
        stop time: 6.228241
        stop time: 6.211895
        stop time: 6.223060
        stop time: 6.149100
        stop time: 6.136341
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.010714, 6.137118, 6.062422, 6.228241, 6.211895, 6.22306, 6.1491, 6.136341]
    [exp] Throughput: 3254.7520244099887
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '93.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '374.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   199.88ms   95.31ms 646.91ms   68.71%
        Req/Sec   327.95    170.17   727.00     66.52%
        Latency Distribution
        50%  189.14ms
        75%  251.98ms
        90%  319.91ms
        99%  499.85ms
        7575 requests in 3.03s, 1.15MB read
        Requests/sec:   2502.61
        Transfer/sec:    388.59KB
        [run.sh] Speed is 2502.61, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   202.02ms  112.73ms 723.87ms   67.31%
        Req/Sec   316.63    169.80     0.85k    68.71%
        Latency Distribution
        50%  190.43ms
        75%  274.88ms
        90%  352.83ms
        99%  509.31ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.820439
        stop time: 7.830245
        stop time: 8.078261
        stop time: 8.005902
        stop time: 8.063811
        stop time: 7.974510
        stop time: 8.059418
        stop time: 8.052493
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f496748d4-gcjs7        287m         45Mi
        service1-745795666b-sf4bt        336m         14Mi
        service2-6b7dfdd958-j6b59        232m         10Mi
        ubuntu-client-76886f6bbd-49gks   31m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.820439, 7.830245, 8.078261, 8.005902, 8.063811, 7.97451, 8.059418, 8.052493]
    [exp] Throughput: 2504.497176875996
[test.py] Finished running 3th optmization experiment: groundtruth->3254.7520244099887, slowdown->2504.497176875996, predicted->3272.1791009233903, err->0.5354348467318534
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000104', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.48ms   99.96ms 571.39ms   67.17%
        Req/Sec   391.59    178.58     0.88k    67.67%
        Latency Distribution
        50%  151.72ms
        75%  225.05ms
        90%  299.18ms
        99%  452.76ms
        9172 requests in 3.02s, 1.39MB read
        Requests/sec:   3034.27
        Transfer/sec:    471.14KB
        [run.sh] Speed is 3034.27, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   149.98ms   88.43ms 564.37ms   68.88%
        Req/Sec   418.14    160.83   787.00     65.25%
        Latency Distribution
        50%  132.95ms
        75%  201.12ms
        90%  277.00ms
        99%  396.91ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.799759
        stop time: 5.993434
        stop time: 6.000436
        stop time: 5.994227
        stop time: 6.042230
        stop time: 6.079635
        stop time: 6.014635
        stop time: 6.041288
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-4fgtn        0m           44Mi
        service1-745795666b-6gs7t        0m           10Mi
        service2-8f7c6f8f5-gg5tf         0m           10Mi
        ubuntu-client-76886f6bbd-gbh2q   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.799759, 5.993434, 6.000436, 5.994227, 6.04223, 6.079635, 6.014635, 6.041288]
    [exp] Throughput: 3335.7208755500083
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '322.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   206.51ms  110.04ms 840.81ms   73.50%
        Req/Sec   320.41    175.56   696.00     62.45%
        Latency Distribution
        50%  191.35ms
        75%  266.93ms
        90%  336.32ms
        99%  550.65ms
        7407 requests in 3.04s, 1.12MB read
        Requests/sec:   2436.44
        Transfer/sec:    378.31KB
        [run.sh] Speed is 2436.44, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   194.76ms  106.95ms   1.05s    70.66%
        Req/Sec   326.13    159.95   750.00     63.86%
        Latency Distribution
        50%  178.03ms
        75%  252.77ms
        90%  344.45ms
        99%  499.14ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 7.687659
        stop time: 7.591541
        stop time: 7.754627
        stop time: 7.746564
        stop time: 7.706004
        stop time: 7.744271
        stop time: 7.786741
        stop time: 7.787628
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7c6d788d76-slh9t        14m          44Mi
        service1-745795666b-lkmkd        76m          12Mi
        service2-76b4546649-hgnmk        38m          9Mi
        ubuntu-client-76886f6bbd-2hl66   30m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.687659, 7.591541, 7.754627, 7.746564, 7.706004, 7.744271, 7.786741, 7.787628]
    [exp] Throughput: 2588.7858489199143
[test.py] Finished running 4th optmization experiment: groundtruth->3335.7208755500083, slowdown->2588.7858489199143, predicted->3272.182045393959, err->-1.9048005671509516
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00013', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.83ms   92.89ms 638.05ms   71.33%
        Req/Sec   396.91    188.36   848.00     65.95%
        Latency Distribution
        50%  144.41ms
        75%  213.70ms
        90%  286.17ms
        99%  455.32ms
        9235 requests in 3.02s, 1.40MB read
        Requests/sec:   3052.93
        Transfer/sec:    474.04KB
        [run.sh] Speed is 3052.93, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.72ms   81.14ms 613.40ms   73.50%
        Req/Sec   407.82    169.75     0.86k    65.29%
        Latency Distribution
        50%  142.70ms
        75%  197.88ms
        90%  261.22ms
        99%  419.40ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.066654
        stop time: 6.152007
        stop time: 6.123466
        stop time: 6.142114
        stop time: 6.096741
        stop time: 6.109222
        stop time: 6.176724
        stop time: 6.206506
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-7m2pp        355m         46Mi
        service1-745795666b-s6j7d        97m          11Mi
        service2-8f7c6f8f5-thck4         136m         9Mi
        ubuntu-client-76886f6bbd-4j5hs   2m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.066654, 6.152007, 6.123466, 6.142114, 6.096741, 6.109222, 6.176724, 6.206506]
    [exp] Throughput: 3260.419884208633
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '67.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '270.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   187.42ms   94.27ms 736.19ms   69.56%
        Req/Sec   336.06    165.26   686.00     64.66%
        Latency Distribution
        50%  181.80ms
        75%  247.56ms
        90%  306.99ms
        99%  467.18ms
        7804 requests in 3.02s, 1.18MB read
        Requests/sec:   2582.28
        Transfer/sec:    400.96KB
        [run.sh] Speed is 2582.28, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   187.42ms  106.47ms 801.84ms   67.00%
        Req/Sec   339.34    180.62   818.00     63.08%
        Latency Distribution
        50%  170.98ms
        75%  255.48ms
        90%  334.24ms
        99%  473.30ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.233392
        stop time: 7.446727
        stop time: 7.364561
        stop time: 7.354399
        stop time: 7.433824
        stop time: 7.429457
        stop time: 7.424003
        stop time: 7.426553
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        ubuntu-client-76886f6bbd-5brxp   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.233392, 7.446727, 7.364561, 7.354399, 7.433824, 7.429457, 7.424003, 7.426553]
    [exp] Throughput: 2706.684271843399
[test.py] Finished running 5th optmization experiment: groundtruth->3260.419884208633, slowdown->2706.684271843399, predicted->3313.6642507569036, err->1.633052442298978
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000156', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.36ms  103.63ms 780.12ms   74.91%
        Req/Sec   405.76    171.51   797.00     65.95%
        Latency Distribution
        50%  145.82ms
        75%  213.95ms
        90%  293.29ms
        99%  525.51ms
        9438 requests in 3.03s, 1.43MB read
        Requests/sec:   3115.84
        Transfer/sec:    483.81KB
        [run.sh] Speed is 3115.84, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.70ms  105.21ms 770.21ms   71.85%
        Req/Sec   416.60    181.36     0.87k    65.05%
        Latency Distribution
        50%  131.04ms
        75%  213.12ms
        90%  301.99ms
        99%  515.53ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.787828
        stop time: 5.830231
        stop time: 6.157129
        stop time: 6.152646
        stop time: 6.203078
        stop time: 6.218398
        stop time: 6.125930
        stop time: 6.129020
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-zfnfp        1211m        44Mi
        service1-745795666b-89xnp        611m         12Mi
        service2-8f7c6f8f5-r97zw         612m         10Mi
        ubuntu-client-76886f6bbd-srbzj   37m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.787828, 5.830231, 6.157129, 6.152646, 6.203078, 6.218398, 6.12593, 6.12902]
    [exp] Throughput: 3291.8925213551242
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '54.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '218.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   186.47ms  111.27ms 836.20ms   71.27%
        Req/Sec   332.26    163.47   780.00     66.25%
        Latency Distribution
        50%  172.30ms
        75%  245.75ms
        90%  328.38ms
        99%  513.45ms
        7940 requests in 3.03s, 1.20MB read
        Requests/sec:   2623.48
        Transfer/sec:    407.36KB
        [run.sh] Speed is 2623.48, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   180.95ms  105.40ms 893.13ms   72.96%
        Req/Sec   351.98    152.13   750.00     65.66%
        Latency Distribution
        50%  162.00ms
        75%  236.17ms
        90%  314.62ms
        99%  578.62ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.116709
        stop time: 7.093651
        stop time: 7.136850
        stop time: 7.186771
        stop time: 7.027412
        stop time: 7.157531
        stop time: 7.112618
        stop time: 7.143038
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [7.116709, 7.093651, 7.13685, 7.186771, 7.027412, 7.157531, 7.112618, 7.143038]
    [exp] Throughput: 2808.2699337142985
[test.py] Finished running 6th optmization experiment: groundtruth->3291.8925213551242, slowdown->2808.2699337142985, predicted->3317.6725365970387, err->0.7831366022637344
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000182', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.36ms   85.79ms 568.46ms   66.73%
        Req/Sec   408.39    181.43     0.87k    70.69%
        Latency Distribution
        50%  147.71ms
        75%  211.27ms
        90%  274.11ms
        99%  378.40ms
        9502 requests in 3.02s, 1.44MB read
        Requests/sec:   3147.54
        Transfer/sec:    488.73KB
        [run.sh] Speed is 3147.54, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.11ms   86.61ms 622.46ms   69.77%
        Req/Sec   398.73    164.27     0.89k    67.81%
        Latency Distribution
        50%  143.72ms
        75%  205.96ms
        90%  277.90ms
        99%  418.08ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.240414
        stop time: 6.172581
        stop time: 6.388320
        stop time: 6.204272
        stop time: 6.359096
        stop time: 6.349346
        stop time: 6.342528
        stop time: 6.351493
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-ndtw7        821m         43Mi
        service1-745795666b-m62z4        537m         13Mi
        service2-8f7c6f8f5-j6wk2         424m         9Mi
        ubuntu-client-76886f6bbd-4qvpj   73m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.240414, 6.172581, 6.38832, 6.204272, 6.359096, 6.349346, 6.342528, 6.351493]
    [exp] Throughput: 3174.0962009044188
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '41.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '166.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   178.00ms   97.83ms 800.39ms   71.03%
        Req/Sec   360.83    167.09   710.00     62.07%
        Latency Distribution
        50%  161.21ms
        75%  228.79ms
        90%  314.47ms
        99%  460.76ms
        8377 requests in 3.02s, 1.27MB read
        Requests/sec:   2775.29
        Transfer/sec:    430.93KB
        [run.sh] Speed is 2775.29, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   173.13ms   91.69ms 778.29ms   73.01%
        Req/Sec   369.04    157.84   740.00     63.62%
        Latency Distribution
        50%  160.84ms
        75%  222.10ms
        90%  285.21ms
        99%  479.56ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.705973
        stop time: 6.794813
        stop time: 6.887574
        stop time: 6.736846
        stop time: 6.718769
        stop time: 6.923044
        stop time: 6.870864
        stop time: 6.927421
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.705973, 6.794813, 6.887574, 6.736846, 6.718769, 6.923044, 6.870864, 6.927421]
    [exp] Throughput: 2932.2662620921164
[test.py] Finished running 7th optmization experiment: groundtruth->3174.0962009044188, slowdown->2932.2662620921164, predicted->3340.480290915748, err->5.241935955309738
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000208', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.35ms   86.25ms 651.18ms   71.10%
        Req/Sec   406.25    193.52     0.93k    65.80%
        Latency Distribution
        50%  146.22ms
        75%  211.38ms
        90%  276.97ms
        99%  425.34ms
        9383 requests in 3.02s, 1.42MB read
        Requests/sec:   3102.24
        Transfer/sec:    481.70KB
        [run.sh] Speed is 3102.24, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.00ms   95.30ms 773.68ms   74.96%
        Req/Sec   404.45    139.33   830.00     69.33%
        Latency Distribution
        50%  139.96ms
        75%  205.22ms
        90%  275.33ms
        99%  497.71ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.222511
        stop time: 6.103034
        stop time: 6.222702
        stop time: 6.222610
        stop time: 6.203354
        stop time: 6.211092
        stop time: 6.246555
        stop time: 6.282123
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-x2dwq        94m          45Mi
        service1-745795666b-dw99g        1m           13Mi
        service2-8f7c6f8f5-rrcjq         37m          9Mi
        ubuntu-client-76886f6bbd-rmt64   27m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.222511, 6.103034, 6.222702, 6.22261, 6.203354, 6.211092, 6.246555, 6.282123]
    [exp] Throughput: 3218.410531234664
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '28.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '114.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   178.00ms  103.54ms 710.00ms   70.23%
        Req/Sec   380.43    191.83   760.00     61.43%
        Latency Distribution
        50%  166.38ms
        75%  235.14ms
        90%  308.24ms
        99%  567.66ms
        8631 requests in 3.01s, 1.31MB read
        Requests/sec:   2863.67
        Transfer/sec:    444.65KB
        [run.sh] Speed is 2863.67, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   167.48ms   84.10ms 657.34ms   69.26%
        Req/Sec   381.32    171.66   780.00     66.48%
        Latency Distribution
        50%  156.49ms
        75%  216.54ms
        90%  276.87ms
        99%  435.33ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.480974
        stop time: 6.599595
        stop time: 6.600185
        stop time: 6.636125
        stop time: 6.622673
        stop time: 6.635118
        stop time: 6.720312
        stop time: 6.719206
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74f5db548b-zbbfd        0m           45Mi
        service1-745795666b-4b25d        0m           12Mi
        service2-96f84c786-98q7l         0m           9Mi
        ubuntu-client-76886f6bbd-gv466   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.480974, 6.599595, 6.600185, 6.636125, 6.622673, 6.635118, 6.720312, 6.719206]
    [exp] Throughput: 3018.0599955619427
[test.py] Finished running 8th optmization experiment: groundtruth->3218.410531234664, slowdown->3018.0599955619427, predicted->3303.997415613221, err->2.6592904649029867
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000234', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.02ms   79.83ms 511.33ms   71.04%
        Req/Sec   397.10    188.96     0.89k    67.24%
        Latency Distribution
        50%  148.76ms
        75%  207.68ms
        90%  265.67ms
        99%  404.64ms
        9229 requests in 3.02s, 1.40MB read
        Requests/sec:   3053.11
        Transfer/sec:    474.07KB
        [run.sh] Speed is 3053.11, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.52ms   83.77ms 724.21ms   71.75%
        Req/Sec   405.37    151.11   770.00     65.17%
        Latency Distribution
        50%  142.12ms
        75%  199.46ms
        90%  269.22ms
        99%  417.83ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.054967
        stop time: 6.149156
        stop time: 6.162172
        stop time: 6.161540
        stop time: 6.276161
        stop time: 6.228280
        stop time: 6.241191
        stop time: 6.228315
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-9672h        579m         43Mi
        service1-745795666b-tg6xs        365m         14Mi
        service2-8f7c6f8f5-c5mz7         279m         9Mi
        ubuntu-client-76886f6bbd-tvcg4   25m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.054967, 6.149156, 6.162172, 6.16154, 6.276161, 6.22828, 6.241191, 6.228315]
    [exp] Throughput: 3232.206872875809
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '15.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '62.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   168.61ms   93.51ms 561.04ms   70.33%
        Req/Sec   381.46    178.22   830.00     63.36%
        Latency Distribution
        50%  153.50ms
        75%  221.67ms
        90%  301.71ms
        99%  430.63ms
        8860 requests in 3.03s, 1.34MB read
        Requests/sec:   2922.02
        Transfer/sec:    453.71KB
        [run.sh] Speed is 2922.02, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.94ms  102.43ms 673.15ms   68.43%
        Req/Sec   394.64    158.17   820.00     66.87%
        Latency Distribution
        50%  140.08ms
        75%  222.21ms
        90%  307.15ms
        99%  449.59ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.400621
        stop time: 6.342075
        stop time: 6.282320
        stop time: 6.438470
        stop time: 6.407429
        stop time: 6.413522
        stop time: 6.289533
        stop time: 6.374461
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5867c84794-xf56w        0m           45Mi
        service1-745795666b-lhg2f        0m           13Mi
        service2-69d7667f8d-8dgvg        0m           9Mi
        ubuntu-client-76886f6bbd-hjrk2   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.400621, 6.342075, 6.28232, 6.43847, 6.407429, 6.413522, 6.289533, 6.374461]
    [exp] Throughput: 3140.4303696810603
[test.py] Finished running 9th optmization experiment: groundtruth->3232.206872875809, slowdown->3140.4303696810603, predicted->3303.025937155679, err->2.1910436758913185
[test.py] Baseline throughput:  3215.7685855747372
[test.py] Groundtruth:  [3250.361887166613, 3262.972231616863, 3312.7011404843265, 3254.7520244099887, 3335.7208755500083, 3260.419884208633, 3291.8925213551242, 3174.0962009044188, 3218.410531234664, 3232.206872875809]
[test.py] Slowdown:  [2319.663656888574, 2369.0051214929476, 2483.9103928083837, 2504.497176875996, 2588.7858489199143, 2706.684271843399, 2808.2699337142985, 2932.2662620921164, 3018.0599955619427, 3140.4303696810603]
[test.py] Predicted:  [3350.959590212828, 3306.406783093517, 3379.337236777614, 3272.1791009233903, 3272.182045393959, 3313.6642507569036, 3317.6725365970387, 3340.480290915748, 3303.997415613221, 3303.025937155679]
[test.py] Error percentage:  [3.0949693153677553, 1.3311345728226163, 2.0115335935056695, 0.5354348467318534, -1.9048005671509516, 1.633052442298978, 0.7831366022637344, 5.241935955309738, 2.6592904649029867, 2.1910436758913185]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 1...
[test.py] Actual processing time range: [0, 26, 52, 78, 104, 130, 156, 182, 208, 234]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.69ms   85.09ms 502.63ms   70.17%
        Req/Sec   411.60    146.12   780.00     69.70%
        Latency Distribution
        50%  145.50ms
        75%  211.40ms
        90%  282.01ms
        99%  396.98ms
        9510 requests in 3.03s, 1.44MB read
        Requests/sec:   3143.40
        Transfer/sec:    488.09KB
        [run.sh] Speed is 3143.40, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.16ms   93.91ms 672.11ms   69.74%
        Req/Sec   403.00    172.69     0.95k    69.59%
        Latency Distribution
        50%  141.86ms
        75%  213.76ms
        90%  281.12ms
        99%  437.39ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.172033
        stop time: 6.230377
        stop time: 6.171361
        stop time: 6.192736
        stop time: 6.240689
        stop time: 6.247775
        stop time: 6.272744
        stop time: 6.294203
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-rgmw4        595m         30Mi
        service1-745795666b-7597t        410m         10Mi
        service2-8f7c6f8f5-zdz65         297m         8Mi
        ubuntu-client-76886f6bbd-5g87v   37m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.172033, 6.230377, 6.171361, 6.192736, 6.240689, 6.247775, 6.272744, 6.294203]
    [exp] Throughput: 3211.4379859884157
[test.py] Baseline throughput: 3211.4379859884157
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.41ms  100.92ms 777.76ms   71.62%
        Req/Sec   403.13    191.84   777.00     60.34%
        Latency Distribution
        50%  150.74ms
        75%  215.47ms
        90%  294.59ms
        99%  528.13ms
        9363 requests in 3.02s, 1.42MB read
        Requests/sec:   3103.78
        Transfer/sec:    481.93KB
        [run.sh] Speed is 3103.78, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   153.99ms   81.59ms 657.32ms   73.85%
        Req/Sec   412.23    169.13     0.97k    64.09%
        Latency Distribution
        50%  137.29ms
        75%  199.23ms
        90%  255.82ms
        99%  413.35ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.011854
        stop time: 6.091451
        stop time: 6.083520
        stop time: 6.072013
        stop time: 6.061973
        stop time: 6.130536
        stop time: 6.165735
        stop time: 6.119595
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-7kdhz        2m           45Mi
        service1-745795666b-wcbdr        0m           9Mi
        service2-8f7c6f8f5-5mhwj         0m           10Mi
        ubuntu-client-76886f6bbd-xd9tp   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.011854, 6.091451, 6.08352, 6.072013, 6.061973, 6.130536, 6.165735, 6.119595]
    [exp] Throughput: 3282.948486619225
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '132.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '530.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   229.45ms  134.87ms 737.04ms   67.30%
        Req/Sec   275.45    171.70   740.00     60.36%
        Latency Distribution
        50%  221.29ms
        75%  322.76ms
        90%  403.64ms
        99%  577.24ms
        6386 requests in 3.02s, 0.97MB read
        Requests/sec:   2111.74
        Transfer/sec:    327.90KB
        [run.sh] Speed is 2111.74, duration is 14
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d14s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 14s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   218.24ms  110.45ms 825.72ms   69.78%
        Req/Sec   291.74    146.53     0.86k    63.64%
        Latency Distribution
        50%  208.99ms
        75%  289.14ms
        90%  363.50ms
        99%  526.09ms
        20001 requests in 14.00s, 3.03MB read
        Requests/sec:   1428.63
        Transfer/sec:    221.83KB
        ------------------------------
        stop time: 8.294527
        stop time: 8.580528
        stop time: 8.779528
        stop time: 8.716385
        stop time: 8.774119
        stop time: 8.766195
        stop time: 8.774493
        stop time: 8.702982
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-848bfcb77d-nmh7m        0m           38Mi
        service1-745795666b-zwwgn        0m           14Mi
        service2-567796f7b-zrnjv         0m           10Mi
        ubuntu-client-76886f6bbd-fgb5q   6m           8Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.294527, 8.580528, 8.779528, 8.716385, 8.774119, 8.766195, 8.774493, 8.702982]
    [exp] Throughput: 2305.849058515344
[test.py] Finished running 0th optmization experiment: groundtruth->3282.948486619225, slowdown->2305.849058515344, predicted->3322.2069163073993, err->1.1958283795248463
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '2.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.39ms   90.84ms 698.45ms   70.17%
        Req/Sec   411.75    176.79   848.00     68.97%
        Latency Distribution
        50%  139.44ms
        75%  208.88ms
        90%  286.03ms
        99%  424.49ms
        9575 requests in 3.02s, 1.45MB read
        Requests/sec:   3168.58
        Transfer/sec:    492.00KB
        [run.sh] Speed is 3168.58, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.23ms   98.02ms 765.78ms   74.81%
        Req/Sec   412.31    166.72   808.00     65.62%
        Latency Distribution
        50%  137.78ms
        75%  198.73ms
        90%  287.88ms
        99%  471.35ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.008541
        stop time: 5.999100
        stop time: 6.098061
        stop time: 6.220940
        stop time: 6.126373
        stop time: 6.127984
        stop time: 6.166962
        stop time: 6.200989
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-9shh5        648m         44Mi
        service1-745795666b-zj6v2        170m         11Mi
        service2-8f7c6f8f5-js9lv         339m         9Mi
        ubuntu-client-76886f6bbd-q2hs9   25m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.008541, 5.9991, 6.098061, 6.22094, 6.126373, 6.127984, 6.166962, 6.200989]
    [exp] Throughput: 3268.7115862546593
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '119.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '478.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   218.33ms  118.22ms 887.02ms   73.52%
        Req/Sec   299.65    186.88   707.00     60.18%
        Latency Distribution
        50%  204.62ms
        75%  281.64ms
        90%  351.00ms
        99%  639.46ms
        6858 requests in 3.02s, 1.04MB read
        Requests/sec:   2272.32
        Transfer/sec:    352.83KB
        [run.sh] Speed is 2272.32, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   211.47ms  124.65ms 899.07ms   72.26%
        Req/Sec   304.36    148.75   707.00     63.55%
        Latency Distribution
        50%  191.72ms
        75%  280.36ms
        90%  366.00ms
        99%  617.48ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.44
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 8.198661
        stop time: 8.187938
        stop time: 8.137720
        stop time: 8.348339
        stop time: 8.239684
        stop time: 8.375165
        stop time: 8.423669
        stop time: 8.344338
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [8.198661, 8.187938, 8.13772, 8.348339, 8.239684, 8.375165, 8.423669, 8.344338]
    [exp] Throughput: 2414.893347593681
[test.py] Finished running 1th optmization experiment: groundtruth->3268.7115862546593, slowdown->2414.893347593681, predicted->3396.4857495982487, err->3.909006957998244
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '5.2e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.76ms   89.66ms 647.98ms   72.21%
        Req/Sec   406.07    195.25     0.88k    66.81%
        Latency Distribution
        50%  154.79ms
        75%  210.27ms
        90%  265.36ms
        99%  463.10ms
        9443 requests in 3.04s, 1.43MB read
        Requests/sec:   3109.00
        Transfer/sec:    482.75KB
        [run.sh] Speed is 3109.00, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.82ms   96.04ms 702.41ms   72.84%
        Req/Sec   410.36    167.13   780.00     67.29%
        Latency Distribution
        50%  133.80ms
        75%  205.98ms
        90%  283.34ms
        99%  498.62ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.994514
        stop time: 6.081802
        stop time: 6.072453
        stop time: 6.088916
        stop time: 6.081641
        stop time: 6.131786
        stop time: 6.174488
        stop time: 6.147575
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-2thgp        1203m        42Mi
        service1-745795666b-dhwgg        397m         10Mi
        service2-8f7c6f8f5-jz7nk         586m         10Mi
        ubuntu-client-76886f6bbd-v9r2h   14m          11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.994514, 6.081802, 6.072453, 6.088916, 6.081641, 6.131786, 6.174488, 6.147575]
    [exp] Throughput: 3280.491786724977
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '106.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '426.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   208.82ms  113.05ms 748.15ms   69.59%
        Req/Sec   313.17    180.83   737.00     61.64%
        Latency Distribution
        50%  200.41ms
        75%  277.65ms
        90%  357.21ms
        99%  507.81ms
        7211 requests in 3.02s, 1.09MB read
        Requests/sec:   2385.03
        Transfer/sec:    370.33KB
        [run.sh] Speed is 2385.03, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   205.64ms  111.61ms 881.56ms   67.93%
        Req/Sec   311.46    161.05   696.00     64.17%
        Latency Distribution
        50%  196.00ms
        75%  275.40ms
        90%  349.80ms
        99%  514.36ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 8.064972
        stop time: 8.070193
        stop time: 8.183854
        stop time: 8.085568
        stop time: 8.164783
        stop time: 8.146633
        stop time: 8.146863
        stop time: 8.130039
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [8.064972, 8.070193, 8.183854, 8.085568, 8.164783, 8.146633, 8.146863, 8.130039]
    [exp] Throughput: 2461.807177260349
[test.py] Finished running 2th optmization experiment: groundtruth->3280.491786724977, slowdown->2461.807177260349, predicted->3338.556435323138, err->1.769998292119759
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '7.8e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.52ms   74.69ms 507.99ms   69.19%
        Req/Sec   407.36    162.28   810.00     67.10%
        Latency Distribution
        50%  146.39ms
        75%  199.38ms
        90%  257.05ms
        99%  366.49ms
        9478 requests in 3.03s, 1.44MB read
        Requests/sec:   3124.68
        Transfer/sec:    485.18KB
        [run.sh] Speed is 3124.68, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.52ms  107.93ms 917.78ms   77.56%
        Req/Sec   405.48    183.51     0.90k    67.69%
        Latency Distribution
        50%  133.95ms
        75%  207.29ms
        90%  297.44ms
        99%  532.83ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.068621
        stop time: 6.097528
        stop time: 6.167970
        stop time: 6.238464
        stop time: 6.239283
        stop time: 6.244163
        stop time: 6.213664
        stop time: 6.237665
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-cpg6c        594m         44Mi
        service1-745795666b-cxf4l        229m         10Mi
        service2-8f7c6f8f5-g94vh         225m         10Mi
        ubuntu-client-76886f6bbd-bc9xf   37m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.068621, 6.097528, 6.16797, 6.238464, 6.239283, 6.244163, 6.213664, 6.237665]
    [exp] Throughput: 3231.842830312213
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '93.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '374.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   203.10ms  103.64ms 706.77ms   67.98%
        Req/Sec   317.19    154.31   727.00     64.89%
        Latency Distribution
        50%  195.87ms
        75%  264.80ms
        90%  347.67ms
        99%  457.82ms
        7299 requests in 3.03s, 1.11MB read
        Requests/sec:   2412.61
        Transfer/sec:    374.61KB
        [run.sh] Speed is 2412.61, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   199.93ms  100.26ms 669.88ms   66.16%
        Req/Sec   322.21    190.03   810.00     60.76%
        Latency Distribution
        50%  189.59ms
        75%  267.77ms
        90%  334.35ms
        99%  467.14ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 7.804869
        stop time: 7.934289
        stop time: 7.945304
        stop time: 7.953473
        stop time: 8.035369
        stop time: 7.921942
        stop time: 7.922105
        stop time: 7.959349
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f496748d4-8g7c8        2m           45Mi
        service1-745795666b-jkwds        0m           14Mi
        service2-6b7dfdd958-pn6bh        0m           10Mi
        ubuntu-client-76886f6bbd-2plhh   2m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.804869, 7.934289, 7.945304, 7.953473, 8.035369, 7.921942, 7.922105, 7.959349]
    [exp] Throughput: 2520.6099245865016
[test.py] Finished running 3th optmization experiment: groundtruth->3231.842830312213, slowdown->2520.6099245865016, predicted->3299.7378770723903, err->2.100815241489269
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000104', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   166.67ms   98.90ms 691.09ms   69.83%
        Req/Sec   398.75    199.46     0.90k    61.21%
        Latency Distribution
        50%  151.15ms
        75%  216.85ms
        90%  295.20ms
        99%  458.74ms
        9379 requests in 3.03s, 1.42MB read
        Requests/sec:   3099.06
        Transfer/sec:    481.20KB
        [run.sh] Speed is 3099.06, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.77ms   96.02ms 776.17ms   75.71%
        Req/Sec   409.90    166.76   830.00     65.01%
        Latency Distribution
        50%  135.34ms
        75%  202.25ms
        90%  281.55ms
        99%  478.40ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.969556
        stop time: 6.049276
        stop time: 6.179648
        stop time: 6.190440
        stop time: 6.142390
        stop time: 6.134998
        stop time: 6.123280
        stop time: 6.172678
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-v6pjn        153m         43Mi
        service1-745795666b-pcxvs        86m          10Mi
        service2-8f7c6f8f5-sslbs         35m          9Mi
        ubuntu-client-76886f6bbd-q7c2x   13m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.969556, 6.049276, 6.179648, 6.19044, 6.14239, 6.134998, 6.12328, 6.172678]
    [exp] Throughput: 3267.822612621728
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '322.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   197.59ms  117.48ms 935.16ms   72.33%
        Req/Sec   335.75    162.81   777.00     70.69%
        Latency Distribution
        50%  180.55ms
        75%  252.36ms
        90%  334.88ms
        99%  624.24ms
        7785 requests in 3.03s, 1.18MB read
        Requests/sec:   2569.31
        Transfer/sec:    398.95KB
        [run.sh] Speed is 2569.31, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   192.06ms  104.43ms 746.45ms   66.52%
        Req/Sec   331.77    162.65   757.00     66.95%
        Latency Distribution
        50%  182.80ms
        75%  256.44ms
        90%  331.32ms
        99%  478.70ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.498546
        stop time: 7.505929
        stop time: 7.427973
        stop time: 7.512200
        stop time: 7.682900
        stop time: 7.676125
        stop time: 7.684737
        stop time: 7.683847
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7c6d788d76-92wlx        427m         45Mi
        service1-745795666b-mc6kw        272m         11Mi
        service2-76b4546649-jfb7f        248m         9Mi
        ubuntu-client-76886f6bbd-5tm28   25m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.498546, 7.505929, 7.427973, 7.5122, 7.6829, 7.676125, 7.684737, 7.683847]
    [exp] Throughput: 2637.119631135529
[test.py] Finished running 4th optmization experiment: groundtruth->3267.822612621728, slowdown->2637.119631135529, predicted->3349.785175136295, err->2.5081704924249193
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00013', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.87ms   77.84ms 512.64ms   68.62%
        Req/Sec   402.11    185.93   818.00     66.81%
        Latency Distribution
        50%  151.02ms
        75%  213.96ms
        90%  261.10ms
        99%  387.19ms
        9327 requests in 3.02s, 1.41MB read
        Requests/sec:   3083.59
        Transfer/sec:    478.80KB
        [run.sh] Speed is 3083.59, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.76ms   87.59ms 725.75ms   74.77%
        Req/Sec   409.76    150.16   787.00     66.53%
        Latency Distribution
        50%  140.36ms
        75%  198.16ms
        90%  263.63ms
        99%  468.14ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.021348
        stop time: 5.977146
        stop time: 6.168792
        stop time: 6.174396
        stop time: 6.204231
        stop time: 6.140019
        stop time: 6.203154
        stop time: 6.201358
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.021348, 5.977146, 6.168792, 6.174396, 6.204231, 6.140019, 6.203154, 6.201358]
    [exp] Throughput: 3259.290138015456
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '67.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '270.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   187.72ms  104.62ms 595.91ms   66.69%
        Req/Sec   343.05    176.36   750.00     66.38%
        Latency Distribution
        50%  174.72ms
        75%  252.90ms
        90%  333.55ms
        99%  468.05ms
        7976 requests in 3.03s, 1.21MB read
        Requests/sec:   2635.79
        Transfer/sec:    409.27KB
        [run.sh] Speed is 2635.79, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   184.70ms  107.64ms 865.12ms   71.62%
        Req/Sec   346.81    165.68   818.00     64.45%
        Latency Distribution
        50%  169.59ms
        75%  243.30ms
        90%  318.81ms
        99%  517.77ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.327220
        stop time: 7.352394
        stop time: 7.346289
        stop time: 7.344830
        stop time: 7.360287
        stop time: 7.338800
        stop time: 7.417289
        stop time: 7.411078
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-d6dd5547-ctdm6          1210m        42Mi
        service1-745795666b-xb977        819m         12Mi
        service2-7854f4f79c-lp6lb        594m         10Mi
        ubuntu-client-76886f6bbd-mprr9   74m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.32722, 7.352394, 7.346289, 7.34483, 7.360287, 7.3388, 7.417289, 7.411078]
    [exp] Throughput: 2716.5522089839537
[test.py] Finished running 5th optmization experiment: groundtruth->3259.290138015456, slowdown->2716.5522089839537, predicted->3328.46635275207, err->2.1224319347873393
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000156', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.05ms   94.37ms 543.96ms   69.88%
        Req/Sec   381.20    196.19     0.93k    64.44%
        Latency Distribution
        50%  151.92ms
        75%  216.49ms
        90%  308.84ms
        99%  406.34ms
        9100 requests in 3.02s, 1.38MB read
        Requests/sec:   3009.29
        Transfer/sec:    467.26KB
        [run.sh] Speed is 3009.29, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.17ms  109.50ms   1.02s    78.08%
        Req/Sec   408.65    145.93     0.99k    70.87%
        Latency Distribution
        50%  135.66ms
        75%  203.15ms
        90%  294.00ms
        99%  553.89ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.980776
        stop time: 6.124613
        stop time: 6.148542
        stop time: 6.147781
        stop time: 6.220494
        stop time: 6.197053
        stop time: 6.135474
        stop time: 6.236028
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [5.980776, 6.124613, 6.148542, 6.147781, 6.220494, 6.197053, 6.135474, 6.236028]
    [exp] Throughput: 3252.643316495957
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '54.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '218.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   182.54ms   86.95ms 783.80ms   63.69%
        Req/Sec   351.17    181.98   818.00     62.93%
        Latency Distribution
        50%  174.69ms
        75%  247.97ms
        90%  298.16ms
        99%  398.39ms
        8153 requests in 3.03s, 1.24MB read
        Requests/sec:   2689.40
        Transfer/sec:    417.59KB
        [run.sh] Speed is 2689.40, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   181.99ms  105.35ms 854.67ms   68.15%
        Req/Sec   353.15    176.89     0.87k    63.64%
        Latency Distribution
        50%  166.40ms
        75%  246.67ms
        90%  324.68ms
        99%  476.38ms
        20001 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.25
        Transfer/sec:    282.33KB
        ------------------------------
        stop time: 7.020273
        stop time: 7.123501
        stop time: 7.126049
        stop time: 7.228519
        stop time: 7.172395
        stop time: 7.200759
        stop time: 7.292390
        stop time: 7.285996
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5d9cf6f69-5pxft         800m         44Mi
        service1-745795666b-pp448        598m         12Mi
        service2-67685bd7bc-n6w9f        355m         9Mi
        ubuntu-client-76886f6bbd-jjr6m   43m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.020273, 7.123501, 7.126049, 7.228519, 7.172395, 7.200759, 7.29239, 7.285996]
    [exp] Throughput: 2785.036181623489
[test.py] Finished running 6th optmization experiment: groundtruth->3252.643316495957, slowdown->2785.036181623489, predicted->3285.293985148254, err->1.0038195238533227
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000182', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.22ms   78.44ms 621.83ms   68.72%
        Req/Sec   396.16    185.99     0.85k    64.68%
        Latency Distribution
        50%  150.45ms
        75%  202.71ms
        90%  261.59ms
        99%  380.69ms
        9348 requests in 3.03s, 1.42MB read
        Requests/sec:   3081.62
        Transfer/sec:    478.49KB
        [run.sh] Speed is 3081.62, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.72ms   88.08ms 784.39ms   70.52%
        Req/Sec   407.84    174.54   830.00     66.67%
        Latency Distribution
        50%  144.17ms
        75%  205.65ms
        90%  273.80ms
        99%  412.38ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.052098
        stop time: 6.028162
        stop time: 6.208189
        stop time: 6.206890
        stop time: 6.199157
        stop time: 6.251740
        stop time: 6.185503
        stop time: 6.258797
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.052098, 6.028162, 6.208189, 6.20689, 6.199157, 6.25174, 6.185503, 6.258797]
    [exp] Throughput: 3239.487014273342
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '41.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '166.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   182.07ms   93.25ms 676.47ms   67.60%
        Req/Sec   351.22    210.41     0.88k    61.64%
        Latency Distribution
        50%  172.67ms
        75%  241.68ms
        90%  301.38ms
        99%  417.70ms
        8145 requests in 3.03s, 1.24MB read
        Requests/sec:   2689.00
        Transfer/sec:    417.53KB
        [run.sh] Speed is 2689.00, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   170.26ms  107.51ms 784.05ms   69.26%
        Req/Sec   372.82    185.77     0.94k    69.30%
        Latency Distribution
        50%  153.45ms
        75%  230.32ms
        90%  317.57ms
        99%  483.08ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 6.630611
        stop time: 6.716477
        stop time: 6.738350
        stop time: 6.778942
        stop time: 6.796473
        stop time: 6.747464
        stop time: 6.738729
        stop time: 6.839551
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-b697cbc5-s7gzr          7m           45Mi
        service1-745795666b-9ff7j        10m          15Mi
        service2-54d55b9855-gdp9f        55m          9Mi
        ubuntu-client-76886f6bbd-s5htk   12m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.630611, 6.716477, 6.73835, 6.778942, 6.796473, 6.747464, 6.738729, 6.839551]
    [exp] Throughput: 2963.69856392319
[test.py] Finished running 7th optmization experiment: groundtruth->3239.487014273342, slowdown->2963.69856392319, predicted->3381.3344043146503, err->4.378699140213297
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000208', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.71ms   91.56ms 517.76ms   68.12%
        Req/Sec   401.73    180.89   848.00     67.24%
        Latency Distribution
        50%  151.56ms
        75%  219.53ms
        90%  293.18ms
        99%  426.12ms
        9333 requests in 3.03s, 1.42MB read
        Requests/sec:   3084.01
        Transfer/sec:    478.87KB
        [run.sh] Speed is 3084.01, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.57ms   97.36ms 770.66ms   77.77%
        Req/Sec   409.17    150.60   808.00     68.19%
        Latency Distribution
        50%  136.68ms
        75%  201.12ms
        90%  273.92ms
        99%  499.56ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.197984
        stop time: 6.034730
        stop time: 6.101978
        stop time: 6.177241
        stop time: 6.019741
        stop time: 6.202410
        stop time: 6.165325
        stop time: 6.204063
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-nk5vt        0m           45Mi
        service1-745795666b-5ndm4        0m           14Mi
        service2-8f7c6f8f5-2wz7b         0m           9Mi
        ubuntu-client-76886f6bbd-r2xrl   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.197984, 6.03473, 6.101978, 6.177241, 6.019741, 6.20241, 6.165325, 6.204063]
    [exp] Throughput: 3258.425391996721
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '28.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '114.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   170.45ms   90.18ms 700.84ms   67.18%
        Req/Sec   378.18    183.79     0.87k    66.67%
        Latency Distribution
        50%  163.43ms
        75%  230.02ms
        90%  286.99ms
        99%  405.56ms
        8819 requests in 3.02s, 1.34MB read
        Requests/sec:   2923.35
        Transfer/sec:    453.92KB
        [run.sh] Speed is 2923.35, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.30ms   88.00ms 650.26ms   69.43%
        Req/Sec   378.98    159.41   800.00     66.99%
        Latency Distribution
        50%  153.28ms
        75%  214.50ms
        90%  285.12ms
        99%  422.36ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.554517
        stop time: 6.654481
        stop time: 6.599424
        stop time: 6.718609
        stop time: 6.642652
        stop time: 6.674145
        stop time: 6.712590
        stop time: 6.622504
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74f5db548b-zrrs5        562m         43Mi
        service1-745795666b-7jnzp        386m         13Mi
        service2-96f84c786-g7tnk         282m         9Mi
        ubuntu-client-76886f6bbd-vqqcf   35m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.554517, 6.654481, 6.599424, 6.718609, 6.642652, 6.674145, 6.71259, 6.622504]
    [exp] Throughput: 3008.710857282891
[test.py] Finished running 8th optmization experiment: groundtruth->3258.425391996721, slowdown->3008.710857282891, predicted->3292.796131754816, err->1.0548266608318204
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000234', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.43ms  114.61ms 804.17ms   81.05%
        Req/Sec   416.06    166.17   780.00     67.24%
        Latency Distribution
        50%  136.21ms
        75%  206.14ms
        90%  293.19ms
        99%  608.87ms
        9661 requests in 3.02s, 1.46MB read
        Requests/sec:   3194.15
        Transfer/sec:    495.97KB
        [run.sh] Speed is 3194.15, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.97ms   95.77ms 815.83ms   72.95%
        Req/Sec   415.22    189.08     1.06k    66.32%
        Latency Distribution
        50%  137.07ms
        75%  202.31ms
        90%  280.95ms
        99%  478.38ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.040316
        stop time: 5.965393
        stop time: 5.974849
        stop time: 5.960231
        stop time: 6.174211
        stop time: 6.183544
        stop time: 6.205269
        stop time: 6.217063
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-5nmhh        0m           43Mi
        service1-745795666b-mwh7j        0m           12Mi
        service2-8f7c6f8f5-w4pjb         0m           9Mi
        ubuntu-client-76886f6bbd-qxwd7   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.040316, 5.965393, 5.974849, 5.960231, 6.174211, 6.183544, 6.205269, 6.217063]
    [exp] Throughput: 3284.0132020614733
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '15.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '62.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   163.42ms   87.19ms 666.74ms   71.54%
        Req/Sec   390.51    148.99   696.00     70.00%
        Latency Distribution
        50%  148.34ms
        75%  208.77ms
        90%  279.15ms
        99%  430.05ms
        9333 requests in 3.04s, 1.42MB read
        Requests/sec:   3070.85
        Transfer/sec:    476.82KB
        [run.sh] Speed is 3070.85, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.44ms   96.58ms 967.05ms   75.01%
        Req/Sec   399.48    174.51   787.00     61.05%
        Latency Distribution
        50%  146.87ms
        75%  205.49ms
        90%  274.27ms
        99%  506.06ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.194616
        stop time: 6.200035
        stop time: 6.268418
        stop time: 6.191331
        stop time: 6.268142
        stop time: 6.381193
        stop time: 6.396953
        stop time: 6.318366
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5867c84794-4w424        573m         44Mi
        service1-745795666b-nh6jq        409m         12Mi
        service2-69d7667f8d-qv9zx        206m         9Mi
        ubuntu-client-76886f6bbd-n8dw7   14m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.194616, 6.200035, 6.268418, 6.191331, 6.268142, 6.381193, 6.396953, 6.318366]
    [exp] Throughput: 3186.041696444541
[test.py] Finished running 9th optmization experiment: groundtruth->3284.0132020614733, slowdown->3186.041696444541, predicted->3353.5205489277187, err->2.116536767349581
[test.py] Baseline throughput:  3211.4379859884157
[test.py] Groundtruth:  [3282.948486619225, 3268.7115862546593, 3280.491786724977, 3231.842830312213, 3267.822612621728, 3259.290138015456, 3252.643316495957, 3239.487014273342, 3258.425391996721, 3284.0132020614733]
[test.py] Slowdown:  [2305.849058515344, 2414.893347593681, 2461.807177260349, 2520.6099245865016, 2637.119631135529, 2716.5522089839537, 2785.036181623489, 2963.69856392319, 3008.710857282891, 3186.041696444541]
[test.py] Predicted:  [3322.2069163073993, 3396.4857495982487, 3338.556435323138, 3299.7378770723903, 3349.785175136295, 3328.46635275207, 3285.293985148254, 3381.3344043146503, 3292.796131754816, 3353.5205489277187]
[test.py] Error percentage:  [1.1958283795248463, 3.909006957998244, 1.769998292119759, 2.100815241489269, 2.5081704924249193, 2.1224319347873393, 1.0038195238533227, 4.378699140213297, 1.0548266608318204, 2.116536767349581]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 2...
[test.py] Actual processing time range: [0, 26, 52, 78, 104, 130, 156, 182, 208, 234]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   166.92ms   99.79ms 753.23ms   74.27%
        Req/Sec   393.70    165.72   780.00     68.97%
        Latency Distribution
        50%  148.24ms
        75%  212.05ms
        90%  293.52ms
        99%  520.50ms
        9156 requests in 3.03s, 1.39MB read
        Requests/sec:   3024.93
        Transfer/sec:    469.69KB
        [run.sh] Speed is 3024.93, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.07ms  108.26ms 895.48ms   76.18%
        Req/Sec   403.21    158.69   797.00     70.23%
        Latency Distribution
        50%  135.46ms
        75%  212.27ms
        90%  301.06ms
        99%  556.38ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.210919
        stop time: 6.233100
        stop time: 6.124096
        stop time: 6.237344
        stop time: 6.184262
        stop time: 6.286292
        stop time: 6.204994
        stop time: 6.305262
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-wx924        2m           43Mi
        service1-745795666b-7xc9f        0m           13Mi
        service2-8f7c6f8f5-4cs8k         0m           10Mi
        ubuntu-client-76886f6bbd-hdch9   16m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.210919, 6.2331, 6.124096, 6.237344, 6.184262, 6.286292, 6.204994, 6.305262]
    [exp] Throughput: 3213.7375066205504
[test.py] Baseline throughput: 3213.7375066205504
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.40ms   92.17ms 544.91ms   68.62%
        Req/Sec   405.40    168.77   767.00     62.07%
        Latency Distribution
        50%  151.54ms
        75%  214.69ms
        90%  295.14ms
        99%  417.02ms
        9452 requests in 3.02s, 1.43MB read
        Requests/sec:   3131.78
        Transfer/sec:    486.28KB
        [run.sh] Speed is 3131.78, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.55ms   79.51ms 560.09ms   70.46%
        Req/Sec   407.26    163.42     0.88k    66.26%
        Latency Distribution
        50%  142.22ms
        75%  204.66ms
        90%  260.47ms
        99%  390.23ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.161135
        stop time: 6.120086
        stop time: 6.107555
        stop time: 6.227295
        stop time: 6.152319
        stop time: 6.111616
        stop time: 6.208339
        stop time: 6.218215
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-bjpbv   0m           41Mi
        service1-745795666b-7slps   0m           10Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.161135, 6.120086, 6.107555, 6.227295, 6.152319, 6.111616, 6.208339, 6.218215]
    [exp] Throughput: 3245.00431585574
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '132.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '530.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   221.09ms  113.78ms 720.96ms   65.50%
        Req/Sec   286.72    153.14   750.00     69.33%
        Latency Distribution
        50%  205.15ms
        75%  302.98ms
        90%  372.38ms
        99%  499.30ms
        6750 requests in 3.03s, 1.02MB read
        Requests/sec:   2231.04
        Transfer/sec:    346.42KB
        [run.sh] Speed is 2231.04, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   219.10ms  102.41ms 676.15ms   66.13%
        Req/Sec   291.58    154.63   660.00     66.27%
        Latency Distribution
        50%  211.41ms
        75%  283.92ms
        90%  358.96ms
        99%  487.86ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.44
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 8.621959
        stop time: 8.505494
        stop time: 8.624697
        stop time: 8.660176
        stop time: 8.756195
        stop time: 8.754069
        stop time: 8.743295
        stop time: 8.737815
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-848bfcb77d-dsdb2        757m         45Mi
        service1-745795666b-zjppx        515m         12Mi
        service2-567796f7b-5v9hk         447m         11Mi
        ubuntu-client-76886f6bbd-ncr6r   65m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.621959, 8.505494, 8.624697, 8.660176, 8.756195, 8.754069, 8.743295, 8.737815]
    [exp] Throughput: 2305.352596475404
[test.py] Finished running 0th optmization experiment: groundtruth->3245.00431585574, slowdown->2305.352596475404, predicted->3321.176443725779, err->2.3473659957198385
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '2.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.50ms   85.64ms 758.31ms   71.75%
        Req/Sec   412.68    164.40   828.00     69.40%
        Latency Distribution
        50%  142.76ms
        75%  206.80ms
        90%  261.75ms
        99%  412.42ms
        9606 requests in 3.03s, 1.46MB read
        Requests/sec:   3167.34
        Transfer/sec:    491.80KB
        [run.sh] Speed is 3167.34, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   154.37ms   81.00ms 514.47ms   69.39%
        Req/Sec   408.91    180.04   840.00     62.06%
        Latency Distribution
        50%  141.11ms
        75%  199.48ms
        90%  264.99ms
        99%  391.49ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.005327
        stop time: 6.193773
        stop time: 6.039246
        stop time: 6.178794
        stop time: 6.138185
        stop time: 6.186159
        stop time: 6.181054
        stop time: 6.183573
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.005327, 6.193773, 6.039246, 6.178794, 6.138185, 6.186159, 6.181054, 6.183573]
    [exp] Throughput: 3258.2502817215554
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '119.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '478.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   218.12ms   97.02ms 706.75ms   67.60%
        Req/Sec   284.68    141.08   636.00     63.79%
        Latency Distribution
        50%  203.27ms
        75%  287.25ms
        90%  351.26ms
        99%  469.39ms
        6638 requests in 3.03s, 1.01MB read
        Requests/sec:   2192.24
        Transfer/sec:    340.40KB
        [run.sh] Speed is 2192.24, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   212.84ms  119.33ms 901.32ms   68.29%
        Req/Sec   298.58    173.72   808.00     62.95%
        Latency Distribution
        50%  200.96ms
        75%  278.24ms
        90%  373.95ms
        99%  553.69ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.44
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 8.051153
        stop time: 8.448701
        stop time: 8.364225
        stop time: 8.531793
        stop time: 8.441602
        stop time: 8.548527
        stop time: 8.433079
        stop time: 8.509780
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7579bf5b9c-d7r8g        1180m        45Mi
        service1-745795666b-l9m5v        831m         13Mi
        service2-67d6df6559-6hrbx        498m         10Mi
        ubuntu-client-76886f6bbd-m4bcs   48m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.051153, 8.448701, 8.364225, 8.531793, 8.441602, 8.548527, 8.433079, 8.50978]
    [exp] Throughput: 2376.395501126857
[test.py] Finished running 1th optmization experiment: groundtruth->3258.2502817215554, slowdown->2376.395501126857, predicted->3320.820757454309, err->1.920370454159625
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '5.2e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.69ms   87.23ms 798.04ms   68.97%
        Req/Sec   406.36    149.69   757.00     65.52%
        Latency Distribution
        50%  140.38ms
        75%  208.47ms
        90%  275.88ms
        99%  405.71ms
        9553 requests in 3.03s, 1.45MB read
        Requests/sec:   3155.99
        Transfer/sec:    490.04KB
        [run.sh] Speed is 3155.99, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.42ms   81.27ms 595.46ms   71.55%
        Req/Sec   406.24    159.50     0.85k    69.06%
        Latency Distribution
        50%  141.53ms
        75%  200.18ms
        90%  266.65ms
        99%  407.32ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.045956
        stop time: 6.228267
        stop time: 6.225977
        stop time: 6.044905
        stop time: 6.221494
        stop time: 6.149270
        stop time: 6.234456
        stop time: 6.233603
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.045956, 6.228267, 6.225977, 6.044905, 6.221494, 6.14927, 6.234456, 6.233603]
    [exp] Throughput: 3239.9204858714356
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '106.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '426.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   210.63ms  100.24ms 725.54ms   65.71%
        Req/Sec   295.42    147.27   616.00     62.76%
        Latency Distribution
        50%  207.10ms
        75%  274.18ms
        90%  344.33ms
        99%  469.09ms
        7048 requests in 3.03s, 1.07MB read
        Requests/sec:   2328.64
        Transfer/sec:    361.58KB
        [run.sh] Speed is 2328.64, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   204.16ms  100.38ms 762.78ms   67.68%
        Req/Sec   309.75    177.12     0.90k    64.57%
        Latency Distribution
        50%  197.92ms
        75%  269.10ms
        90%  333.83ms
        99%  468.65ms
        20001 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.73
        Transfer/sec:    258.80KB
        ------------------------------
        stop time: 8.025088
        stop time: 8.021843
        stop time: 8.029174
        stop time: 8.030984
        stop time: 8.113375
        stop time: 8.153602
        stop time: 8.105299
        stop time: 8.169333
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d9fd768c7-jj9cv        459m         46Mi
        service1-745795666b-bcq2n        317m         13Mi
        service2-7668ff8dd-nkcmh         224m         10Mi
        ubuntu-client-76886f6bbd-gs6pw   12m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.025088, 8.021843, 8.029174, 8.030984, 8.113375, 8.153602, 8.105299, 8.169333]
    [exp] Throughput: 2474.9144986647684
[test.py] Finished running 2th optmization experiment: groundtruth->3239.9204858714356, slowdown->2474.9144986647684, predicted->3362.708130090904, err->3.7898351133899006
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '7.8e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.39ms  101.21ms 627.91ms   66.54%
        Req/Sec   407.67    185.50   830.00     62.93%
        Latency Distribution
        50%  140.03ms
        75%  227.82ms
        90%  294.99ms
        99%  444.70ms
        9485 requests in 3.05s, 1.44MB read
        Requests/sec:   3110.05
        Transfer/sec:    482.91KB
        [run.sh] Speed is 3110.05, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.41ms   94.92ms 688.96ms   70.87%
        Req/Sec   408.94    180.45     0.86k    62.14%
        Latency Distribution
        50%  139.11ms
        75%  210.47ms
        90%  287.52ms
        99%  452.03ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.072332
        stop time: 6.026465
        stop time: 6.156053
        stop time: 6.231037
        stop time: 6.292432
        stop time: 6.116378
        stop time: 6.228361
        stop time: 6.212771
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-fddfs        0m           45Mi
        service1-745795666b-7lzwq        0m           11Mi
        service2-8f7c6f8f5-qwk8f         0m           10Mi
        ubuntu-client-76886f6bbd-jpvwc   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.072332, 6.026465, 6.156053, 6.231037, 6.292432, 6.116378, 6.228361, 6.212771]
    [exp] Throughput: 3243.079182879444
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '93.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '374.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   204.95ms  115.87ms 729.05ms   72.73%
        Req/Sec   297.11    158.36   646.00     59.17%
        Latency Distribution
        50%  190.25ms
        75%  267.19ms
        90%  355.02ms
        99%  546.54ms
        7101 requests in 3.03s, 1.08MB read
        Requests/sec:   2346.96
        Transfer/sec:    364.42KB
        [run.sh] Speed is 2346.96, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   199.20ms   97.90ms 711.24ms   69.29%
        Req/Sec   318.04    148.61   790.00     68.16%
        Latency Distribution
        50%  187.81ms
        75%  258.56ms
        90%  332.88ms
        99%  467.50ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 7.944203
        stop time: 7.715224
        stop time: 7.938753
        stop time: 7.930101
        stop time: 7.918583
        stop time: 7.942934
        stop time: 7.951996
        stop time: 7.934532
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f496748d4-67ltb        408m         43Mi
        service1-745795666b-lqbw2        277m         11Mi
        service2-6b7dfdd958-t7kp2        88m          10Mi
        ubuntu-client-76886f6bbd-cx725   30m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.944203, 7.715224, 7.938753, 7.930101, 7.918583, 7.942934, 7.951996, 7.934532]
    [exp] Throughput: 2528.591814891402
[test.py] Finished running 3th optmization experiment: groundtruth->3243.079182879444, slowdown->2528.591814891402, predicted->3313.4302481307805, err->2.16926757825486
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000104', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.66ms   89.98ms 580.42ms   67.15%
        Req/Sec   406.70    196.83     0.87k    69.13%
        Latency Distribution
        50%  149.62ms
        75%  217.93ms
        90%  281.03ms
        99%  418.30ms
        9435 requests in 3.03s, 1.43MB read
        Requests/sec:   3111.46
        Transfer/sec:    483.13KB
        [run.sh] Speed is 3111.46, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   153.99ms   88.73ms 647.27ms   73.36%
        Req/Sec   413.49    179.21     0.87k    62.42%
        Latency Distribution
        50%  136.05ms
        75%  200.85ms
        90%  268.53ms
        99%  446.89ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.941545
        stop time: 6.083117
        stop time: 6.051769
        stop time: 6.052186
        stop time: 6.112970
        stop time: 6.097706
        stop time: 6.139977
        stop time: 6.065206
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-p6z5h        2m           44Mi
        service1-745795666b-wp4lh        0m           12Mi
        service2-8f7c6f8f5-xnvdf         74m          9Mi
        ubuntu-client-76886f6bbd-5c6g2   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.941545, 6.083117, 6.051769, 6.052186, 6.11297, 6.097706, 6.139977, 6.065206]
    [exp] Throughput: 3295.9465872079863
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '322.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   196.34ms  100.84ms 844.63ms   74.19%
        Req/Sec   323.81    150.72   747.00     67.67%
        Latency Distribution
        50%  178.77ms
        75%  246.17ms
        90%  325.07ms
        99%  533.17ms
        7688 requests in 3.03s, 1.17MB read
        Requests/sec:   2538.10
        Transfer/sec:    394.10KB
        [run.sh] Speed is 2538.10, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   190.93ms  104.30ms 624.99ms   68.42%
        Req/Sec   331.33    182.98   838.00     65.09%
        Latency Distribution
        50%  179.40ms
        75%  252.83ms
        90%  328.23ms
        99%  490.56ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.290661
        stop time: 7.303667
        stop time: 7.534701
        stop time: 7.645378
        stop time: 7.655064
        stop time: 7.682548
        stop time: 7.679208
        stop time: 7.654750
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        ubuntu-client-76886f6bbd-p85s5   32m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.290661, 7.303667, 7.534701, 7.645378, 7.655064, 7.682548, 7.679208, 7.65475]
    [exp] Throughput: 2646.991709638509
[test.py] Finished running 4th optmization experiment: groundtruth->3295.9465872079863, slowdown->2646.991709638509, predicted->3365.730098274901, err->2.1172524863647375
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00013', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.24ms   94.94ms 789.91ms   75.27%
        Req/Sec   407.23    167.87   797.00     68.97%
        Latency Distribution
        50%  133.93ms
        75%  210.94ms
        90%  280.44ms
        99%  465.84ms
        9493 requests in 3.02s, 1.44MB read
        Requests/sec:   3144.00
        Transfer/sec:    488.18KB
        [run.sh] Speed is 3144.00, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.58ms   99.32ms 739.95ms   75.54%
        Req/Sec   411.85    175.01   820.00     67.01%
        Latency Distribution
        50%  133.78ms
        75%  195.08ms
        90%  294.77ms
        99%  526.99ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.887642
        stop time: 6.078881
        stop time: 6.152982
        stop time: 6.128762
        stop time: 6.089233
        stop time: 6.114550
        stop time: 6.180385
        stop time: 6.193564
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-csslt        827m         44Mi
        service1-745795666b-kb7wz        401m         10Mi
        service2-8f7c6f8f5-wbz55         563m         9Mi
        ubuntu-client-76886f6bbd-rhn7n   2m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.887642, 6.078881, 6.152982, 6.128762, 6.089233, 6.11455, 6.180385, 6.193564]
    [exp] Throughput: 3276.9426796572047
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '67.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '270.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   200.30ms  132.35ms 793.31ms   76.37%
        Req/Sec   324.82    177.39   760.00     66.95%
        Latency Distribution
        50%  169.99ms
        75%  266.83ms
        90%  374.39ms
        99%  640.70ms
        7756 requests in 3.03s, 1.18MB read
        Requests/sec:   2559.99
        Transfer/sec:    397.50KB
        [run.sh] Speed is 2559.99, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   187.44ms  121.97ms 862.77ms   73.23%
        Req/Sec   344.71    151.17   787.00     66.78%
        Latency Distribution
        50%  165.95ms
        75%  245.96ms
        90%  343.63ms
        99%  637.14ms
        20001 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.25
        Transfer/sec:    282.33KB
        ------------------------------
        stop time: 7.265543
        stop time: 7.299087
        stop time: 7.313163
        stop time: 7.339232
        stop time: 7.410850
        stop time: 7.284529
        stop time: 7.393110
        stop time: 7.393332
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [7.265543, 7.299087, 7.313163, 7.339232, 7.41085, 7.284529, 7.39311, 7.393332]
    [exp] Throughput: 2725.777607280388
[test.py] Finished running 5th optmization experiment: groundtruth->3276.9426796572047, slowdown->2725.777607280388, predicted->3342.326559259053, err->1.995270775034972
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000156', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.61ms   80.91ms 528.96ms   68.41%
        Req/Sec   414.46    171.93   780.00     66.07%
        Latency Distribution
        50%  147.59ms
        75%  209.62ms
        90%  276.20ms
        99%  386.60ms
        9430 requests in 3.03s, 1.43MB read
        Requests/sec:   3112.58
        Transfer/sec:    483.30KB
        [run.sh] Speed is 3112.58, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.22ms  111.43ms 873.43ms   77.55%
        Req/Sec   408.30    156.73     0.95k    69.42%
        Latency Distribution
        50%  136.04ms
        75%  207.56ms
        90%  293.06ms
        99%  609.81ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.982042
        stop time: 6.114325
        stop time: 6.155905
        stop time: 6.155036
        stop time: 6.120527
        stop time: 6.148657
        stop time: 6.194965
        stop time: 6.200159
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-4c5lg        1202m        43Mi
        service1-745795666b-92xl8        622m         14Mi
        service2-8f7c6f8f5-m8n7d         517m         9Mi
        ubuntu-client-76886f6bbd-rk86s   50m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.982042, 6.114325, 6.155905, 6.155036, 6.120527, 6.148657, 6.194965, 6.200159]
    [exp] Throughput: 3260.5406758970407
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '54.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '218.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   189.95ms  113.17ms 827.94ms   75.67%
        Req/Sec   351.68    148.86   656.00     65.09%
        Latency Distribution
        50%  167.03ms
        75%  240.06ms
        90%  333.79ms
        99%  634.59ms
        8158 requests in 3.03s, 1.24MB read
        Requests/sec:   2691.85
        Transfer/sec:    417.97KB
        [run.sh] Speed is 2691.85, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   180.04ms  104.32ms 905.17ms   70.88%
        Req/Sec   352.90    165.14   747.00     65.19%
        Latency Distribution
        50%  166.17ms
        75%  232.83ms
        90%  323.30ms
        99%  495.22ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.114111
        stop time: 7.096363
        stop time: 7.086328
        stop time: 7.078884
        stop time: 7.074032
        stop time: 7.227639
        stop time: 7.256784
        stop time: 7.086931
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [7.114111, 7.096363, 7.086328, 7.078884, 7.074032, 7.227639, 7.256784, 7.086931]
    [exp] Throughput: 2805.9802172782724
[test.py] Finished running 6th optmization experiment: groundtruth->3260.5406758970407, slowdown->2805.9802172782724, predicted->3314.4772721321738, err->1.6542224617484333
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000182', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.64ms   91.16ms 553.26ms   70.97%
        Req/Sec   394.37    190.70     0.92k    62.93%
        Latency Distribution
        50%  140.04ms
        75%  217.95ms
        90%  281.28ms
        99%  454.19ms
        9201 requests in 3.02s, 1.40MB read
        Requests/sec:   3042.45
        Transfer/sec:    472.41KB
        [run.sh] Speed is 3042.45, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.35ms   89.22ms 837.89ms   73.65%
        Req/Sec   406.91    148.31   737.00     63.60%
        Latency Distribution
        50%  140.87ms
        75%  205.04ms
        90%  267.18ms
        99%  445.26ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.055646
        stop time: 6.124101
        stop time: 6.178313
        stop time: 6.195159
        stop time: 6.241220
        stop time: 6.231425
        stop time: 6.229733
        stop time: 6.214534
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-gjfht        362m         45Mi
        service1-745795666b-htj54        175m         11Mi
        service2-8f7c6f8f5-47wdj         17m          9Mi
        ubuntu-client-76886f6bbd-68cgd   72m          11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.055646, 6.124101, 6.178313, 6.195159, 6.24122, 6.231425, 6.229733, 6.214534]
    [exp] Throughput: 3234.2748394986056
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '41.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '166.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   176.53ms   76.98ms 602.47ms   68.52%
        Req/Sec   347.72    155.77   820.00     63.33%
        Latency Distribution
        50%  171.29ms
        75%  222.51ms
        90%  273.52ms
        99%  390.08ms
        8313 requests in 3.03s, 1.26MB read
        Requests/sec:   2744.01
        Transfer/sec:    426.07KB
        [run.sh] Speed is 2744.01, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   171.95ms   88.16ms 636.14ms   67.63%
        Req/Sec   368.07    160.40   757.00     67.47%
        Latency Distribution
        50%  157.05ms
        75%  226.63ms
        90%  294.20ms
        99%  420.90ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.807273
        stop time: 6.743846
        stop time: 6.747784
        stop time: 6.804362
        stop time: 6.849574
        stop time: 6.856459
        stop time: 6.794526
        stop time: 6.839021
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-b697cbc5-w9856          0m           45Mi
        service1-745795666b-f9lgm        0m           12Mi
        service2-54d55b9855-l6d4k        0m           9Mi
        ubuntu-client-76886f6bbd-98hdp   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.807273, 6.743846, 6.747784, 6.804362, 6.849574, 6.856459, 6.794526, 6.839021]
    [exp] Throughput: 2938.861846767927
[test.py] Finished running 7th optmization experiment: groundtruth->3234.2748394986056, slowdown->2938.861846767927, predicted->3349.042786010086, err->3.5484908428274493
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000208', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   163.00ms   88.61ms 655.38ms   69.25%
        Req/Sec   404.56    136.06   727.00     75.00%
        Latency Distribution
        50%  149.05ms
        75%  216.24ms
        90%  283.00ms
        99%  422.99ms
        9430 requests in 3.03s, 1.43MB read
        Requests/sec:   3113.82
        Transfer/sec:    483.49KB
        [run.sh] Speed is 3113.82, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.03ms   96.60ms 687.07ms   67.35%
        Req/Sec   395.20    188.21   810.00     62.40%
        Latency Distribution
        50%  138.63ms
        75%  218.62ms
        90%  302.48ms
        99%  419.84ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.335923
        stop time: 6.393906
        stop time: 6.359698
        stop time: 6.278730
        stop time: 6.327814
        stop time: 6.352314
        stop time: 6.405347
        stop time: 6.403498
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-wc4x2        369m         45Mi
        service1-745795666b-rmqkr        260m         14Mi
        service2-8f7c6f8f5-rkh2w         297m         9Mi
        ubuntu-client-76886f6bbd-xtg24   37m          11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.335923, 6.393906, 6.359698, 6.27873, 6.327814, 6.352314, 6.405347, 6.403498]
    [exp] Throughput: 3146.062025006081
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '28.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '114.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   173.25ms  100.03ms 749.43ms   74.83%
        Req/Sec   385.89    177.25   780.00     66.81%
        Latency Distribution
        50%  154.49ms
        75%  220.48ms
        90%  294.05ms
        99%  571.38ms
        8930 requests in 3.03s, 1.35MB read
        Requests/sec:   2950.25
        Transfer/sec:    458.10KB
        [run.sh] Speed is 2950.25, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   168.41ms   95.75ms 666.68ms   66.72%
        Req/Sec   377.68    181.22   838.00     64.82%
        Latency Distribution
        50%  157.01ms
        75%  227.57ms
        90%  301.63ms
        99%  419.04ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.574271
        stop time: 6.649265
        stop time: 6.619853
        stop time: 6.717664
        stop time: 6.766368
        stop time: 6.788513
        stop time: 6.756829
        stop time: 6.624763
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74f5db548b-bklhk        0m           44Mi
        service1-745795666b-q9z6w        0m           12Mi
        service2-96f84c786-7lwfs         0m           9Mi
        ubuntu-client-76886f6bbd-xfrbb   2m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.574271, 6.649265, 6.619853, 6.717664, 6.766368, 6.788513, 6.756829, 6.624763]
    [exp] Throughput: 2990.792508797509
[test.py] Finished running 8th optmization experiment: groundtruth->3146.062025006081, slowdown->2990.792508797509, predicted->3271.346363078636, err->3.9822589979710497
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000234', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   170.49ms  101.25ms 806.29ms   71.45%
        Req/Sec   389.45    157.18   666.00     66.81%
        Latency Distribution
        50%  150.35ms
        75%  229.08ms
        90%  304.11ms
        99%  496.74ms
        9015 requests in 3.03s, 1.37MB read
        Requests/sec:   2975.05
        Transfer/sec:    461.95KB
        [run.sh] Speed is 2975.05, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.24ms   79.48ms 598.61ms   70.42%
        Req/Sec   407.41    148.15   810.00     66.60%
        Latency Distribution
        50%  140.13ms
        75%  203.10ms
        90%  267.51ms
        99%  385.80ms
        20001 requests in 10.00s, 3.03MB read
        Requests/sec:   2000.07
        Transfer/sec:    310.56KB
        ------------------------------
        stop time: 6.154641
        stop time: 6.106365
        stop time: 6.313480
        stop time: 6.171155
        stop time: 6.279244
        stop time: 6.197826
        stop time: 6.154033
        stop time: 6.189665
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-sgzvk        575m         43Mi
        service1-745795666b-hngqh        358m         14Mi
        service2-8f7c6f8f5-qj9sv         283m         9Mi
        ubuntu-client-76886f6bbd-zddhz   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.154641, 6.106365, 6.31348, 6.171155, 6.279244, 6.197826, 6.154033, 6.189665]
    [exp] Throughput: 3227.9925705329997
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '15.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '62.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   163.96ms   90.55ms 547.24ms   68.94%
        Req/Sec   389.92    190.36   820.00     68.10%
        Latency Distribution
        50%  153.18ms
        75%  220.15ms
        90%  289.10ms
        99%  413.22ms
        9070 requests in 3.03s, 1.38MB read
        Requests/sec:   2997.04
        Transfer/sec:    465.36KB
        [run.sh] Speed is 2997.04, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.49ms   92.14ms 657.51ms   69.04%
        Req/Sec   390.55    183.19   840.00     62.87%
        Latency Distribution
        50%  148.11ms
        75%  216.27ms
        90%  284.60ms
        99%  435.20ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.405942
        stop time: 6.424856
        stop time: 6.430697
        stop time: 6.510778
        stop time: 6.475680
        stop time: 6.486672
        stop time: 6.499551
        stop time: 6.499763
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5867c84794-4rg25        0m           46Mi
        service1-745795666b-bv64w        0m           16Mi
        service2-69d7667f8d-f5lw5        0m           9Mi
        ubuntu-client-76886f6bbd-wdpqb   29m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.405942, 6.424856, 6.430697, 6.510778, 6.47568, 6.486672, 6.499551, 6.499763]
    [exp] Throughput: 3092.747296895371
[test.py] Finished running 9th optmization experiment: groundtruth->3227.9925705329997, slowdown->3092.747296895371, predicted->3250.3189019918955, err->0.6916475478507463
[test.py] Baseline throughput:  3213.7375066205504
[test.py] Groundtruth:  [3245.00431585574, 3258.2502817215554, 3239.9204858714356, 3243.079182879444, 3295.9465872079863, 3276.9426796572047, 3260.5406758970407, 3234.2748394986056, 3146.062025006081, 3227.9925705329997]
[test.py] Slowdown:  [2305.352596475404, 2376.395501126857, 2474.9144986647684, 2528.591814891402, 2646.991709638509, 2725.777607280388, 2805.9802172782724, 2938.861846767927, 2990.792508797509, 3092.747296895371]
[test.py] Predicted:  [3321.176443725779, 3320.820757454309, 3362.708130090904, 3313.4302481307805, 3365.730098274901, 3342.326559259053, 3314.4772721321738, 3349.042786010086, 3271.346363078636, 3250.3189019918955]
[test.py] Error percentage:  [2.3473659957198385, 1.920370454159625, 3.7898351133899006, 2.16926757825486, 2.1172524863647375, 1.995270775034972, 1.6542224617484333, 3.5484908428274493, 3.9822589979710497, 0.6916475478507463]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 3...
[test.py] Actual processing time range: [0, 26, 52, 78, 104, 130, 156, 182, 208, 234]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.08ms   83.05ms 529.68ms   71.19%
        Req/Sec   404.70    165.03   760.00     65.52%
        Latency Distribution
        50%  144.71ms
        75%  209.92ms
        90%  281.10ms
        99%  428.61ms
        9382 requests in 3.03s, 1.42MB read
        Requests/sec:   3099.07
        Transfer/sec:    481.20KB
        [run.sh] Speed is 3099.07, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   154.81ms   86.57ms 703.53ms   72.27%
        Req/Sec   411.85    141.63     0.86k    70.27%
        Latency Distribution
        50%  137.16ms
        75%  201.02ms
        90%  270.88ms
        99%  428.90ms
        20002 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.41
        Transfer/sec:    345.08KB
        ------------------------------
        stop time: 5.972793
        stop time: 5.997790
        stop time: 6.037605
        stop time: 6.161923
        stop time: 6.212070
        stop time: 6.193968
        stop time: 6.162137
        stop time: 6.194596
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-x6jzt   199m         45Mi
        service1-745795666b-6kwfr   61m          13Mi
        service2-8f7c6f8f5-lz26f    0m           8Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.972793, 5.99779, 6.037605, 6.161923, 6.21207, 6.193968, 6.162137, 6.194596]
    [exp] Throughput: 3269.7849270353627
[test.py] Baseline throughput: 3269.7849270353627
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.37ms   91.46ms 572.59ms   70.52%
        Req/Sec   403.60    165.15     0.87k    68.10%
        Latency Distribution
        50%  151.01ms
        75%  210.37ms
        90%  281.07ms
        99%  447.00ms
        9424 requests in 3.03s, 1.43MB read
        Requests/sec:   3111.44
        Transfer/sec:    483.12KB
        [run.sh] Speed is 3111.44, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.93ms   91.75ms 749.66ms   76.55%
        Req/Sec   409.34    140.62   830.00     68.20%
        Latency Distribution
        50%  139.67ms
        75%  196.73ms
        90%  267.13ms
        99%  508.75ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.035034
        stop time: 6.217138
        stop time: 6.211889
        stop time: 6.204011
        stop time: 6.203789
        stop time: 6.038033
        stop time: 6.041310
        stop time: 6.031216
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-p9nqb        167m         46Mi
        service1-745795666b-5jqs4        63m          10Mi
        service2-8f7c6f8f5-lhqcm         274m         10Mi
        ubuntu-client-76886f6bbd-wnzkd   71m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.035034, 6.217138, 6.211889, 6.204011, 6.203789, 6.038033, 6.04131, 6.031216]
    [exp] Throughput: 3266.478054779653
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '132.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '530.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   221.90ms   96.99ms 739.05ms   66.90%
        Req/Sec   286.78    158.47   626.00     58.62%
        Latency Distribution
        50%  207.35ms
        75%  288.54ms
        90%  348.96ms
        99%  462.11ms
        6691 requests in 3.03s, 1.01MB read
        Requests/sec:   2210.00
        Transfer/sec:    343.16KB
        [run.sh] Speed is 2210.00, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   219.43ms  130.55ms   1.02s    70.12%
        Req/Sec   290.76    157.53   780.00     63.72%
        Latency Distribution
        50%  203.82ms
        75%  289.58ms
        90%  388.00ms
        99%  608.29ms
        20001 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.52
        Transfer/sec:    238.89KB
        ------------------------------
        stop time: 8.489860
        stop time: 8.474697
        stop time: 8.481262
        stop time: 8.743365
        stop time: 8.690860
        stop time: 8.749323
        stop time: 8.686422
        stop time: 8.791951
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [8.48986, 8.474697, 8.481262, 8.743365, 8.69086, 8.749323, 8.686422, 8.791951]
    [exp] Throughput: 2315.2254725736943
[test.py] Finished running 0th optmization experiment: groundtruth->3266.478054779653, slowdown->2315.2254725736943, predicted->3341.7056984854134, err->2.3030200247536934
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '2.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.08ms   90.31ms 481.48ms   64.29%
        Req/Sec   401.79    222.55   820.00     57.14%
        Latency Distribution
        50%  148.07ms
        75%  210.00ms
        90%  280.36ms
        99%  394.83ms
        9368 requests in 3.02s, 1.42MB read
        Requests/sec:   3096.90
        Transfer/sec:    480.87KB
        [run.sh] Speed is 3096.90, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.65ms   95.80ms 746.67ms   70.14%
        Req/Sec   407.31    170.80     0.89k    67.76%
        Latency Distribution
        50%  140.38ms
        75%  211.69ms
        90%  281.08ms
        99%  498.89ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.103401
        stop time: 6.101050
        stop time: 6.093042
        stop time: 6.220917
        stop time: 6.222469
        stop time: 6.201824
        stop time: 6.241840
        stop time: 6.245405
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-kpckd        1163m        47Mi
        service1-745795666b-fdkbp        354m         12Mi
        service2-8f7c6f8f5-t455b         579m         10Mi
        ubuntu-client-76886f6bbd-ms978   36m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.103401, 6.10105, 6.093042, 6.220917, 6.222469, 6.201824, 6.24184, 6.245405]
    [exp] Throughput: 3236.9040728102727
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '119.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '478.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   221.45ms  112.31ms   1.07s    68.90%
        Req/Sec   284.58    194.64   737.00     64.22%
        Latency Distribution
        50%  216.65ms
        75%  290.10ms
        90%  347.65ms
        99%  549.13ms
        6662 requests in 3.03s, 1.01MB read
        Requests/sec:   2199.70
        Transfer/sec:    341.56KB
        [run.sh] Speed is 2199.70, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   214.57ms  124.51ms   1.06s    72.32%
        Req/Sec   299.60    178.83   840.00     61.01%
        Latency Distribution
        50%  199.14ms
        75%  284.44ms
        90%  372.62ms
        99%  591.06ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.44
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 8.203329
        stop time: 8.532183
        stop time: 8.542018
        stop time: 8.439473
        stop time: 8.529996
        stop time: 8.567766
        stop time: 8.515401
        stop time: 8.442627
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [8.203329, 8.532183, 8.542018, 8.439473, 8.529996, 8.567766, 8.515401, 8.442627]
    [exp] Throughput: 2360.8293670293324
[test.py] Finished running 1th optmization experiment: groundtruth->3236.9040728102727, slowdown->2360.8293670293324, predicted->3290.5024397738816, err->1.655852807435066
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '5.2e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   163.62ms  108.83ms 771.40ms   75.07%
        Req/Sec   410.23    179.44     0.88k    68.97%
        Latency Distribution
        50%  142.67ms
        75%  215.94ms
        90%  301.10ms
        99%  558.80ms
        9524 requests in 3.03s, 1.44MB read
        Requests/sec:   3138.15
        Transfer/sec:    487.27KB
        [run.sh] Speed is 3138.15, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.93ms  105.76ms 867.72ms   74.42%
        Req/Sec   406.03    175.17     0.89k    68.38%
        Latency Distribution
        50%  139.91ms
        75%  212.11ms
        90%  286.99ms
        99%  518.21ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.976128
        stop time: 6.065266
        stop time: 6.190158
        stop time: 6.270237
        stop time: 6.260698
        stop time: 6.288771
        stop time: 6.338724
        stop time: 6.319835
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-vvk72        601m         44Mi
        service1-745795666b-tlnnt        200m         11Mi
        service2-8f7c6f8f5-bldgg         292m         9Mi
        ubuntu-client-76886f6bbd-j6n8t   25m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.976128, 6.065266, 6.190158, 6.270237, 6.260698, 6.288771, 6.338724, 6.319835]
    [exp] Throughput: 3218.6801250948083
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '106.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '426.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   206.29ms  101.78ms 594.53ms   68.60%
        Req/Sec   307.88    149.51   690.00     63.79%
        Latency Distribution
        50%  194.56ms
        75%  267.15ms
        90%  343.04ms
        99%  499.72ms
        7160 requests in 3.02s, 1.09MB read
        Requests/sec:   2369.17
        Transfer/sec:    367.87KB
        [run.sh] Speed is 2369.17, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   203.89ms  106.08ms 747.53ms   68.76%
        Req/Sec   311.91    167.15     0.91k    63.09%
        Latency Distribution
        50%  193.81ms
        75%  267.21ms
        90%  343.58ms
        99%  509.95ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 7.766702
        stop time: 7.982573
        stop time: 8.000809
        stop time: 8.148004
        stop time: 8.207529
        stop time: 8.117674
        stop time: 8.128384
        stop time: 8.106589
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d9fd768c7-k4j7n        0m           44Mi
        service1-745795666b-rv6jg        0m           12Mi
        service2-7668ff8dd-phjcb         0m           10Mi
        ubuntu-client-76886f6bbd-gmph7   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.766702, 7.982573, 8.000809, 8.148004, 8.207529, 8.117674, 8.128384, 8.106589]
    [exp] Throughput: 2482.2263286519787
[test.py] Finished running 2th optmization experiment: groundtruth->3218.6801250948083, slowdown->2482.2263286519787, predicted->3376.2209047833117, err->4.89457708022051
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '7.8e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   157.44ms   83.74ms 532.52ms   68.98%
        Req/Sec   418.28    211.87   808.00     62.93%
        Latency Distribution
        50%  141.88ms
        75%  207.92ms
        90%  268.71ms
        99%  383.92ms
        9720 requests in 3.04s, 1.47MB read
        Requests/sec:   3199.95
        Transfer/sec:    496.87KB
        [run.sh] Speed is 3199.95, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.80ms   96.33ms 759.42ms   74.37%
        Req/Sec   413.88    184.31     1.00k    67.08%
        Latency Distribution
        50%  137.04ms
        75%  201.68ms
        90%  278.42ms
        99%  513.10ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.945978
        stop time: 6.046014
        stop time: 6.124406
        stop time: 6.151333
        stop time: 6.103594
        stop time: 6.137842
        stop time: 6.141872
        stop time: 6.188218
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-7hgzh        611m         41Mi
        service1-745795666b-8srx2        199m         10Mi
        service2-8f7c6f8f5-hhsxw         185m         9Mi
        ubuntu-client-76886f6bbd-bp2v9   37m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.945978, 6.046014, 6.124406, 6.151333, 6.103594, 6.137842, 6.141872, 6.188218]
    [exp] Throughput: 3276.0531144034394
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '93.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '374.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   211.04ms  119.48ms   1.06s    72.55%
        Req/Sec   311.82    158.23   750.00     65.52%
        Latency Distribution
        50%  193.78ms
        75%  272.63ms
        90%  365.92ms
        99%  628.42ms
        7248 requests in 3.03s, 1.10MB read
        Requests/sec:   2395.69
        Transfer/sec:    371.99KB
        [run.sh] Speed is 2395.69, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   198.18ms   94.44ms 652.83ms   67.91%
        Req/Sec   321.76    172.56     0.89k    65.19%
        Latency Distribution
        50%  190.79ms
        75%  259.82ms
        90%  326.52ms
        99%  431.47ms
        20001 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.73
        Transfer/sec:    258.80KB
        ------------------------------
        stop time: 7.771018
        stop time: 7.784122
        stop time: 7.789994
        stop time: 7.783655
        stop time: 7.988852
        stop time: 7.941543
        stop time: 7.767070
        stop time: 7.934498
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f496748d4-2bsvb        38m          47Mi
        service1-745795666b-8c42q        91m          12Mi
        service2-6b7dfdd958-65xlb        190m         10Mi
        ubuntu-client-76886f6bbd-hrw8p   2m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.771018, 7.784122, 7.789994, 7.783655, 7.988852, 7.941543, 7.76707, 7.934498]
    [exp] Throughput: 2549.363971929463
[test.py] Finished running 3th optmization experiment: groundtruth->3276.0531144034394, slowdown->2549.363971929463, predicted->3349.189512883829, err->2.232454600898853
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000104', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.02ms  100.50ms 707.10ms   75.00%
        Req/Sec   402.93    146.13   730.00     65.04%
        Latency Distribution
        50%  139.41ms
        75%  223.53ms
        90%  274.40ms
        99%  535.96ms
        9359 requests in 3.04s, 1.42MB read
        Requests/sec:   3081.12
        Transfer/sec:    478.42KB
        [run.sh] Speed is 3081.12, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.85ms  104.28ms 772.78ms   76.50%
        Req/Sec   410.49    169.43   808.00     66.53%
        Latency Distribution
        50%  134.33ms
        75%  205.75ms
        90%  280.56ms
        99%  577.62ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.047942
        stop time: 6.067712
        stop time: 6.020582
        stop time: 6.201042
        stop time: 6.162562
        stop time: 6.134715
        stop time: 6.165099
        stop time: 6.193808
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-bkvgn        0m           43Mi
        ubuntu-client-76886f6bbd-x4wlm   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.047942, 6.067712, 6.020582, 6.201042, 6.162562, 6.134715, 6.165099, 6.193808]
    [exp] Throughput: 3265.7418657207772
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '322.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   196.97ms   90.83ms 548.82ms   66.86%
        Req/Sec   318.78    169.74   660.00     64.22%
        Latency Distribution
        50%  191.54ms
        75%  252.29ms
        90%  323.60ms
        99%  435.69ms
        7415 requests in 3.03s, 1.12MB read
        Requests/sec:   2448.80
        Transfer/sec:    380.23KB
        [run.sh] Speed is 2448.80, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   192.87ms   99.10ms 727.55ms   67.48%
        Req/Sec   332.23    161.94     0.87k    61.45%
        Latency Distribution
        50%  179.39ms
        75%  255.90ms
        90%  323.52ms
        99%  463.85ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.64
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 7.485802
        stop time: 7.547820
        stop time: 7.542034
        stop time: 7.693805
        stop time: 7.707081
        stop time: 7.649743
        stop time: 7.677229
        stop time: 7.753344
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7c6d788d76-znb4z        793m         47Mi
        service1-745795666b-vtp57        609m         12Mi
        service2-76b4546649-xhkm5        575m         10Mi
        ubuntu-client-76886f6bbd-tx8km   35m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.485802, 7.54782, 7.542034, 7.693805, 7.707081, 7.649743, 7.677229, 7.753344]
    [exp] Throughput: 2620.5082482298712
[test.py] Finished running 4th optmization experiment: groundtruth->3265.7418657207772, slowdown->2620.5082482298712, predicted->3323.0279314205127, err->1.7541516768684324
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00013', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.64ms   90.33ms 606.34ms   71.23%
        Req/Sec   407.65    178.75     0.92k    70.26%
        Latency Distribution
        50%  139.54ms
        75%  209.17ms
        90%  282.35ms
        99%  410.48ms
        9517 requests in 3.02s, 1.44MB read
        Requests/sec:   3154.27
        Transfer/sec:    489.77KB
        [run.sh] Speed is 3154.27, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.77ms   99.23ms 828.39ms   78.15%
        Req/Sec   410.34    157.73     0.96k    71.96%
        Latency Distribution
        50%  139.39ms
        75%  198.51ms
        90%  272.93ms
        99%  511.95ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.132602
        stop time: 6.107403
        stop time: 6.236308
        stop time: 6.143264
        stop time: 6.131045
        stop time: 6.173586
        stop time: 6.209995
        stop time: 6.126507
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.132602, 6.107403, 6.236308, 6.143264, 6.131045, 6.173586, 6.209995, 6.126507]
    [exp] Throughput: 3248.0246427629645
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '67.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '270.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   189.21ms  100.87ms 693.50ms   65.20%
        Req/Sec   336.44    186.27   848.00     70.31%
        Latency Distribution
        50%  175.27ms
        75%  254.79ms
        90%  327.08ms
        99%  444.85ms
        7810 requests in 3.02s, 1.18MB read
        Requests/sec:   2582.25
        Transfer/sec:    400.96KB
        [run.sh] Speed is 2582.25, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   184.73ms   91.11ms 679.62ms   69.85%
        Req/Sec   344.20    173.16   800.00     64.34%
        Latency Distribution
        50%  177.82ms
        75%  238.07ms
        90%  298.69ms
        99%  449.12ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.246330
        stop time: 7.277426
        stop time: 7.367660
        stop time: 7.278130
        stop time: 7.373756
        stop time: 7.358793
        stop time: 7.329432
        stop time: 7.311524
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-d6dd5547-j8psk          1208m        45Mi
        service1-745795666b-gk544        799m         12Mi
        service2-7854f4f79c-pfstb        423m         9Mi
        ubuntu-client-76886f6bbd-5xd5f   72m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.24633, 7.277426, 7.36766, 7.27813, 7.373756, 7.358793, 7.329432, 7.311524]
    [exp] Throughput: 2733.0314574824606
[test.py] Finished running 5th optmization experiment: groundtruth->3248.0246427629645, slowdown->2733.0314574824606, predicted->3353.239630824245, err->3.2393531340876276
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000156', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.10ms   79.93ms 520.97ms   68.60%
        Req/Sec   420.91    187.57   770.00     58.19%
        Latency Distribution
        50%  141.83ms
        75%  203.93ms
        90%  265.47ms
        99%  376.85ms
        9778 requests in 3.03s, 1.48MB read
        Requests/sec:   3229.41
        Transfer/sec:    501.44KB
        [run.sh] Speed is 3229.41, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   153.82ms   80.82ms 613.16ms   70.08%
        Req/Sec   411.85    169.13     0.90k    63.07%
        Latency Distribution
        50%  140.37ms
        75%  200.46ms
        90%  265.33ms
        99%  386.20ms
        20001 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.30
        Transfer/sec:    345.06KB
        ------------------------------
        stop time: 6.106141
        stop time: 5.991662
        stop time: 6.064042
        stop time: 6.062565
        stop time: 6.088879
        stop time: 6.198059
        stop time: 6.135355
        stop time: 6.115666
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [6.106141, 5.991662, 6.064042, 6.062565, 6.088879, 6.198059, 6.135355, 6.115666]
    [exp] Throughput: 3281.2187611311506
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '54.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '218.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   181.28ms   99.35ms 790.34ms   74.97%
        Req/Sec   357.00    153.33   750.00     66.38%
        Latency Distribution
        50%  168.13ms
        75%  231.22ms
        90%  295.51ms
        99%  539.41ms
        8288 requests in 3.04s, 1.26MB read
        Requests/sec:   2729.46
        Transfer/sec:    423.81KB
        [run.sh] Speed is 2729.46, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   180.47ms  103.44ms 958.13ms   69.54%
        Req/Sec   353.18    178.91     0.90k    66.84%
        Latency Distribution
        50%  169.86ms
        75%  239.82ms
        90%  312.37ms
        99%  482.52ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 7.015577
        stop time: 7.057676
        stop time: 7.041450
        stop time: 7.057967
        stop time: 7.194831
        stop time: 7.111805
        stop time: 7.144927
        stop time: 7.173290
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5d9cf6f69-fvckb         605m         46Mi
        service1-745795666b-jsg76        345m         12Mi
        service2-67685bd7bc-5gt86        88m          9Mi
        ubuntu-client-76886f6bbd-kg6tv   44m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.015577, 7.057676, 7.04145, 7.057967, 7.194831, 7.111805, 7.144927, 7.17329]
    [exp] Throughput: 2817.0242564979458
[test.py] Finished running 6th optmization experiment: groundtruth->3281.2187611311506, slowdown->2817.0242564979458, predicted->3329.897780670996, err->1.483565195850091
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000182', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.35ms   86.14ms 575.69ms   70.20%
        Req/Sec   400.70    165.25   820.00     67.97%
        Latency Distribution
        50%  145.73ms
        75%  211.90ms
        90%  283.39ms
        99%  409.46ms
        9362 requests in 3.03s, 1.42MB read
        Requests/sec:   3093.79
        Transfer/sec:    480.38KB
        [run.sh] Speed is 3093.79, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.42ms  110.29ms 941.69ms   77.56%
        Req/Sec   408.18    171.80     0.94k    69.40%
        Latency Distribution
        50%  136.26ms
        75%  206.44ms
        90%  295.59ms
        99%  532.79ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.926640
        stop time: 6.140668
        stop time: 6.128700
        stop time: 6.126319
        stop time: 6.212108
        stop time: 6.212956
        stop time: 6.245004
        stop time: 6.214601
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [5.92664, 6.140668, 6.1287, 6.126319, 6.212108, 6.212956, 6.245004, 6.214601]
    [exp] Throughput: 3251.570162909355
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '41.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '166.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   181.62ms  101.96ms 765.18ms   70.09%
        Req/Sec   359.59    162.96   686.00     64.22%
        Latency Distribution
        50%  171.08ms
        75%  235.95ms
        90%  320.06ms
        99%  480.51ms
        8335 requests in 3.03s, 1.26MB read
        Requests/sec:   2747.82
        Transfer/sec:    426.66KB
        [run.sh] Speed is 2747.82, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   174.62ms  114.98ms   1.04s    74.61%
        Req/Sec   369.57    162.41   737.00     64.18%
        Latency Distribution
        50%  154.13ms
        75%  222.86ms
        90%  321.77ms
        99%  573.95ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.637580
        stop time: 6.710910
        stop time: 6.764979
        stop time: 6.832186
        stop time: 6.799015
        stop time: 6.883873
        stop time: 6.875251
        stop time: 6.892078
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-b697cbc5-9qmw9          220m         44Mi
        service1-745795666b-lhzc9        236m         10Mi
        service2-54d55b9855-855sq        265m         9Mi
        ubuntu-client-76886f6bbd-np4kp   13m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.63758, 6.71091, 6.764979, 6.832186, 6.799015, 6.883873, 6.875251, 6.892078]
    [exp] Throughput: 2941.399670916205
[test.py] Finished running 7th optmization experiment: groundtruth->3251.570162909355, slowdown->2941.399670916205, predicted->3352.338859775689, err->3.099078039766813
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000208', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   161.35ms   99.10ms 693.50ms   74.88%
        Req/Sec   404.73    163.91   800.00     67.95%
        Latency Distribution
        50%  144.46ms
        75%  209.86ms
        90%  287.51ms
        99%  520.91ms
        9509 requests in 3.03s, 1.44MB read
        Requests/sec:   3134.71
        Transfer/sec:    486.74KB
        [run.sh] Speed is 3134.71, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.43ms  108.68ms 789.28ms   74.32%
        Req/Sec   407.74    160.40     0.88k    67.56%
        Latency Distribution
        50%  136.75ms
        75%  202.62ms
        90%  297.59ms
        99%  587.43ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.055961
        stop time: 6.142686
        stop time: 6.134587
        stop time: 6.166597
        stop time: 6.180279
        stop time: 6.202553
        stop time: 6.125562
        stop time: 6.206572
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-hg8k8        0m           46Mi
        service1-745795666b-kdfzb        0m           12Mi
        service2-8f7c6f8f5-t58nn         0m           9Mi
        ubuntu-client-76886f6bbd-jb9g2   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.055961, 6.142686, 6.134587, 6.166597, 6.180279, 6.202553, 6.125562, 6.206572]
    [exp] Throughput: 3251.0547589985995
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '28.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '114.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   169.12ms   91.11ms 646.90ms   67.01%
        Req/Sec   383.54    190.75   838.00     62.45%
        Latency Distribution
        50%  163.23ms
        75%  226.29ms
        90%  290.87ms
        99%  408.96ms
        9067 requests in 3.03s, 1.37MB read
        Requests/sec:   2995.14
        Transfer/sec:    465.07KB
        [run.sh] Speed is 2995.14, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   166.93ms   86.61ms 590.00ms   68.62%
        Req/Sec   379.74    159.38   787.00     60.27%
        Latency Distribution
        50%  155.27ms
        75%  216.97ms
        90%  287.19ms
        99%  420.26ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.441981
        stop time: 6.676835
        stop time: 6.685887
        stop time: 6.592197
        stop time: 6.534342
        stop time: 6.677506
        stop time: 6.666382
        stop time: 6.652837
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74f5db548b-9gkqr        582m         45Mi
        service1-745795666b-4tckx        390m         11Mi
        service2-96f84c786-cmxb9         290m         9Mi
        ubuntu-client-76886f6bbd-kjtlw   34m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.441981, 6.676835, 6.685887, 6.592197, 6.534342, 6.677506, 6.666382, 6.652837]
    [exp] Throughput: 3022.976491804418
[test.py] Finished running 8th optmization experiment: groundtruth->3251.0547589985995, slowdown->3022.976491804418, predicted->3309.8905508148155, err->1.809744719105832
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000234', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.97ms  112.23ms 785.45ms   75.91%
        Req/Sec   396.80    136.42   727.00     69.17%
        Latency Distribution
        50%  144.13ms
        75%  213.97ms
        90%  302.23ms
        99%  567.42ms
        9485 requests in 3.02s, 1.44MB read
        Requests/sec:   3141.29
        Transfer/sec:    487.76KB
        [run.sh] Speed is 3141.29, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.32ms   82.24ms 611.56ms   70.79%
        Req/Sec   408.59    158.09   767.00     65.15%
        Latency Distribution
        50%  145.29ms
        75%  198.77ms
        90%  264.94ms
        99%  406.85ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.104991
        stop time: 6.198934
        stop time: 6.235523
        stop time: 6.164257
        stop time: 6.178835
        stop time: 6.247487
        stop time: 6.225073
        stop time: 6.138327
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-mm9l8        0m           44Mi
        service1-745795666b-zd25z        0m           13Mi
        service2-8f7c6f8f5-gt4n9         0m           9Mi
        ubuntu-client-76886f6bbd-sz789   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.104991, 6.198934, 6.235523, 6.164257, 6.178835, 6.247487, 6.225073, 6.138327]
    [exp] Throughput: 3232.7525026707085
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '15.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '62.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   166.79ms  102.36ms 766.35ms   66.03%
        Req/Sec   395.01    189.66   818.00     66.24%
        Latency Distribution
        50%  157.25ms
        75%  234.42ms
        90%  305.03ms
        99%  443.82ms
        9326 requests in 3.03s, 1.41MB read
        Requests/sec:   3080.90
        Transfer/sec:    478.38KB
        [run.sh] Speed is 3080.90, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.33ms  119.51ms 920.47ms   76.69%
        Req/Sec   393.92    170.99     1.07k    65.07%
        Latency Distribution
        50%  136.88ms
        75%  213.80ms
        90%  320.89ms
        99%  589.81ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.240341
        stop time: 6.377759
        stop time: 6.192065
        stop time: 6.368212
        stop time: 6.379488
        stop time: 6.383190
        stop time: 6.388375
        stop time: 6.368951
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5867c84794-mdhhn        593m         44Mi
        service1-745795666b-k9l8c        390m         13Mi
        service2-69d7667f8d-ktrzr        88m          9Mi
        ubuntu-client-76886f6bbd-fnflk   36m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.240341, 6.377759, 6.192065, 6.368212, 6.379488, 6.38319, 6.388375, 6.368951]
    [exp] Throughput: 3155.9193182125478
[test.py] Finished running 9th optmization experiment: groundtruth->3232.7525026707085, slowdown->3155.9193182125478, predicted->3320.1646610762423, err->2.703954550597951
[test.py] Baseline throughput:  3269.7849270353627
[test.py] Groundtruth:  [3266.478054779653, 3236.9040728102727, 3218.6801250948083, 3276.0531144034394, 3265.7418657207772, 3248.0246427629645, 3281.2187611311506, 3251.570162909355, 3251.0547589985995, 3232.7525026707085]
[test.py] Slowdown:  [2315.2254725736943, 2360.8293670293324, 2482.2263286519787, 2549.363971929463, 2620.5082482298712, 2733.0314574824606, 2817.0242564979458, 2941.399670916205, 3022.976491804418, 3155.9193182125478]
[test.py] Predicted:  [3341.7056984854134, 3290.5024397738816, 3376.2209047833117, 3349.189512883829, 3323.0279314205127, 3353.239630824245, 3329.897780670996, 3352.338859775689, 3309.8905508148155, 3320.1646610762423]
[test.py] Error percentage:  [2.3030200247536934, 1.655852807435066, 4.89457708022051, 2.232454600898853, 1.7541516768684324, 3.2393531340876276, 1.483565195850091, 3.099078039766813, 1.809744719105832, 2.703954550597951]
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 4...
[test.py] Actual processing time range: [0, 26, 52, 78, 104, 130, 156, 182, 208, 234]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   163.40ms  108.90ms 839.90ms   73.49%
        Req/Sec   408.93    151.04   730.00     67.53%
        Latency Distribution
        50%  137.52ms
        75%  222.46ms
        90%  298.67ms
        99%  491.28ms
        9462 requests in 3.03s, 1.43MB read
        Requests/sec:   3120.67
        Transfer/sec:    484.56KB
        [run.sh] Speed is 3120.67, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   154.11ms   93.33ms 814.75ms   73.20%
        Req/Sec   411.96    156.45     0.89k    66.67%
        Latency Distribution
        50%  135.82ms
        75%  203.49ms
        90%  271.09ms
        99%  445.43ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.992715
        stop time: 6.026908
        stop time: 6.095780
        stop time: 6.162451
        stop time: 6.046776
        stop time: 6.137045
        stop time: 6.147936
        stop time: 6.139988
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-jgr9q        2m           44Mi
        service1-745795666b-wvmvx        0m           12Mi
        service2-8f7c6f8f5-m2cht         77m          9Mi
        ubuntu-client-76886f6bbd-5jzt6   2m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.992715, 6.026908, 6.09578, 6.162451, 6.046776, 6.137045, 6.147936, 6.139988]
    [exp] Throughput: 3282.078279249025
[test.py] Baseline throughput: 3282.078279249025
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.0', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   166.38ms  108.48ms 683.44ms   71.70%
        Req/Sec   399.71    163.63     0.94k    68.53%
        Latency Distribution
        50%  141.99ms
        75%  214.14ms
        90%  331.04ms
        99%  495.19ms
        9440 requests in 3.03s, 1.43MB read
        Requests/sec:   3113.07
        Transfer/sec:    483.38KB
        [run.sh] Speed is 3113.07, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   160.52ms  111.91ms 974.36ms   80.78%
        Req/Sec   406.64    162.93     1.01k    65.84%
        Latency Distribution
        50%  133.76ms
        75%  203.45ms
        90%  292.78ms
        99%  575.76ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.946423
        stop time: 6.238389
        stop time: 6.225202
        stop time: 6.212375
        stop time: 6.189625
        stop time: 6.114380
        stop time: 6.127669
        stop time: 6.176683
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-sppsz   0m           2Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.946423, 6.238389, 6.225202, 6.212375, 6.189625, 6.11438, 6.127669, 6.176683]
    [exp] Throughput: 3250.0015335944745
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '132.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '530.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   221.32ms   94.25ms 572.55ms   65.39%
        Req/Sec   292.86    163.05   610.00     60.81%
        Latency Distribution
        50%  219.03ms
        75%  281.38ms
        90%  350.87ms
        99%  476.82ms
        6644 requests in 3.03s, 1.01MB read
        Requests/sec:   2189.76
        Transfer/sec:    340.01KB
        [run.sh] Speed is 2189.76, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   221.71ms  129.58ms 953.75ms   68.50%
        Req/Sec   295.55    158.72   848.00     66.31%
        Latency Distribution
        50%  206.18ms
        75%  302.00ms
        90%  389.24ms
        99%  585.41ms
        20001 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.52
        Transfer/sec:    238.89KB
        ------------------------------
        stop time: 8.695313
        stop time: 8.748445
        stop time: 8.625585
        stop time: 8.736578
        stop time: 8.661869
        stop time: 8.717403
        stop time: 8.801000
        stop time: 8.846044
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-848bfcb77d-vnvt2        788m         41Mi
        service1-745795666b-hqsm4        644m         12Mi
        service2-567796f7b-x8f56         581m         10Mi
        ubuntu-client-76886f6bbd-4nh6r   56m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.695313, 8.748445, 8.625585, 8.736578, 8.661869, 8.717403, 8.801, 8.846044]
    [exp] Throughput: 2291.20542135862
[test.py] Finished running 0th optmization experiment: groundtruth->3250.0015335944745, slowdown->2291.20542135862, predicted->3291.8940791108394, err->1.289000792255998
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '2.6e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   163.27ms   94.70ms 746.41ms   75.72%
        Req/Sec   402.89    141.73   720.00     64.22%
        Latency Distribution
        50%  149.06ms
        75%  207.59ms
        90%  277.52ms
        99%  473.54ms
        9380 requests in 3.02s, 1.42MB read
        Requests/sec:   3101.38
        Transfer/sec:    481.56KB
        [run.sh] Speed is 3101.38, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.74ms  108.02ms 798.88ms   74.28%
        Req/Sec   411.40    176.47     0.88k    62.47%
        Latency Distribution
        50%  127.04ms
        75%  207.92ms
        90%  305.91ms
        99%  543.54ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.900301
        stop time: 6.034273
        stop time: 6.095546
        stop time: 6.116325
        stop time: 6.145567
        stop time: 6.108598
        stop time: 6.194871
        stop time: 6.108722
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [5.900301, 6.034273, 6.095546, 6.116325, 6.145567, 6.108598, 6.194871, 6.108722]
    [exp] Throughput: 3285.1374243820396
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '119.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '478.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   217.63ms  104.98ms 657.64ms   68.44%
        Req/Sec   303.81    189.23   770.00     62.50%
        Latency Distribution
        50%  206.83ms
        75%  286.29ms
        90%  362.90ms
        99%  479.79ms
        6901 requests in 3.02s, 1.05MB read
        Requests/sec:   2288.25
        Transfer/sec:    355.30KB
        [run.sh] Speed is 2288.25, duration is 13
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d13s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 13s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   210.90ms  114.20ms 825.95ms   68.75%
        Req/Sec   302.08    147.05   717.00     66.26%
        Latency Distribution
        50%  198.47ms
        75%  276.61ms
        90%  367.35ms
        99%  522.46ms
        20000 requests in 13.00s, 3.03MB read
        Requests/sec:   1538.45
        Transfer/sec:    238.88KB
        ------------------------------
        stop time: 8.234359
        stop time: 8.110677
        stop time: 8.131745
        stop time: 8.470151
        stop time: 8.394766
        stop time: 8.411601
        stop time: 8.461620
        stop time: 8.455785
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7579bf5b9c-9btsn        262m         44Mi
        service1-745795666b-cv4bt        712m         13Mi
        service2-67d6df6559-sg9xq        355m         10Mi
        ubuntu-client-76886f6bbd-kl9v2   57m          13Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.234359, 8.110677, 8.131745, 8.470151, 8.394766, 8.411601, 8.46162, 8.455785]
    [exp] Throughput: 2399.854664801499
[test.py] Finished running 1th optmization experiment: groundtruth->3285.1374243820396, slowdown->2399.854664801499, predicted->3366.811787477412, err->2.4861779750579545
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '5.2e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   154.86ms   82.69ms 604.61ms   70.08%
        Req/Sec   404.94    173.65   750.00     65.96%
        Latency Distribution
        50%  141.37ms
        75%  202.46ms
        90%  263.36ms
        99%  383.65ms
        9523 requests in 3.02s, 1.44MB read
        Requests/sec:   3152.45
        Transfer/sec:    489.49KB
        [run.sh] Speed is 3152.45, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.02ms  101.26ms 955.72ms   77.24%
        Req/Sec   414.44    155.12     0.91k    69.67%
        Latency Distribution
        50%  133.49ms
        75%  195.20ms
        90%  283.12ms
        99%  528.13ms
        20001 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.30
        Transfer/sec:    345.06KB
        ------------------------------
        stop time: 5.855699
        stop time: 5.965902
        stop time: 6.140878
        stop time: 6.150286
        stop time: 5.993509
        stop time: 6.154339
        stop time: 6.126624
        stop time: 6.141378
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-94pfm        0m           39Mi
        service1-745795666b-thv4m        0m           10Mi
        service2-8f7c6f8f5-nk9qv         0m           9Mi
        ubuntu-client-76886f6bbd-nn2sm   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.855699, 5.965902, 6.140878, 6.150286, 5.993509, 6.154339, 6.126624, 6.141378]
    [exp] Throughput: 3297.0238281063657
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '106.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '426.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   205.52ms   98.98ms 637.55ms   65.87%
        Req/Sec   318.95    191.72   777.00     66.82%
        Latency Distribution
        50%  203.62ms
        75%  269.44ms
        90%  333.76ms
        99%  448.45ms
        7239 requests in 3.03s, 1.10MB read
        Requests/sec:   2390.56
        Transfer/sec:    371.19KB
        [run.sh] Speed is 2390.56, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   209.97ms  103.00ms 688.01ms   69.14%
        Req/Sec   303.58    172.78   750.00     65.69%
        Latency Distribution
        50%  201.72ms
        75%  268.62ms
        90%  341.08ms
        99%  515.40ms
        20001 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.73
        Transfer/sec:    258.80KB
        ------------------------------
        stop time: 8.236434
        stop time: 8.244381
        stop time: 8.288079
        stop time: 8.307345
        stop time: 8.439997
        stop time: 8.426512
        stop time: 8.439348
        stop time: 8.282467
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d9fd768c7-vh5zn        468m         44Mi
        service1-745795666b-hmsxw        321m         14Mi
        service2-7668ff8dd-8cxfb         0m           9Mi
        ubuntu-client-76886f6bbd-9j6rr   12m          11Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [8.236434, 8.244381, 8.288079, 8.307345, 8.439997, 8.426512, 8.439348, 8.282467]
    [exp] Throughput: 2400.0757343897985
[test.py] Finished running 2th optmization experiment: groundtruth->3297.0238281063657, slowdown->2400.0757343897985, predicted->3226.0299972802545, err->-2.1532701772096767
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '7.8e-05', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   165.97ms  107.75ms 892.22ms   80.12%
        Req/Sec   407.16    179.56   787.00     66.81%
        Latency Distribution
        50%  145.75ms
        75%  216.29ms
        90%  281.75ms
        99%  597.29ms
        9447 requests in 3.02s, 1.43MB read
        Requests/sec:   3126.21
        Transfer/sec:    485.42KB
        [run.sh] Speed is 3126.21, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   159.75ms  105.17ms 876.13ms   74.64%
        Req/Sec   403.45    180.02   830.00     64.15%
        Latency Distribution
        50%  136.70ms
        75%  213.49ms
        90%  297.40ms
        99%  511.04ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.219993
        stop time: 6.063659
        stop time: 6.098540
        stop time: 6.271544
        stop time: 6.249093
        stop time: 6.270706
        stop time: 6.254823
        stop time: 6.231324
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-7kcs2        0m           44Mi
        service1-745795666b-77kjr        0m           11Mi
        service2-8f7c6f8f5-cmdnh         0m           9Mi
        ubuntu-client-76886f6bbd-6hjmw   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.219993, 6.063659, 6.09854, 6.271544, 6.249093, 6.270706, 6.254823, 6.231324]
    [exp] Throughput: 3221.9296128396477
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '93.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '374.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   203.67ms   99.82ms 620.32ms   65.86%
        Req/Sec   312.39    150.57   676.00     68.58%
        Latency Distribution
        50%  195.55ms
        75%  268.64ms
        90%  347.01ms
        99%  442.29ms
        7160 requests in 3.03s, 1.09MB read
        Requests/sec:   2365.30
        Transfer/sec:    367.27KB
        [run.sh] Speed is 2365.30, duration is 12
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d12s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 12s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   201.51ms  107.47ms 808.17ms   71.63%
        Req/Sec   320.07    169.65   747.00     63.00%
        Latency Distribution
        50%  190.48ms
        75%  258.30ms
        90%  341.01ms
        99%  551.32ms
        20000 requests in 12.00s, 3.03MB read
        Requests/sec:   1666.65
        Transfer/sec:    258.79KB
        ------------------------------
        stop time: 7.848465
        stop time: 7.847631
        stop time: 7.927220
        stop time: 8.006641
        stop time: 8.102182
        stop time: 8.088659
        stop time: 8.035138
        stop time: 8.077309
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6f496748d4-978g7        478m         43Mi
        service1-745795666b-l2vzx        230m         12Mi
        service2-6b7dfdd958-w2wkt        230m         9Mi
        ubuntu-client-76886f6bbd-rtx5p   10m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.848465, 7.847631, 7.92722, 8.006641, 8.102182, 8.088659, 8.035138, 8.077309]
    [exp] Throughput: 2502.6103398943696
[test.py] Finished running 3th optmization experiment: groundtruth->3221.9296128396477, slowdown->2502.6103398943696, predicted->3268.9590173672646, err->1.4596657959317583
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000104', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   166.55ms   96.37ms 664.12ms   74.03%
        Req/Sec   394.64    143.02   797.00     76.72%
        Latency Distribution
        50%  145.49ms
        75%  214.94ms
        90%  292.51ms
        99%  497.71ms
        9165 requests in 3.02s, 1.39MB read
        Requests/sec:   3033.00
        Transfer/sec:    470.94KB
        [run.sh] Speed is 3033.00, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   155.39ms   90.90ms 614.11ms   69.13%
        Req/Sec   410.04    162.31     1.09k    71.64%
        Latency Distribution
        50%  139.24ms
        75%  207.12ms
        90%  284.96ms
        99%  412.79ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.923641
        stop time: 6.079051
        stop time: 6.106026
        stop time: 6.111530
        stop time: 6.187531
        stop time: 6.181906
        stop time: 6.213488
        stop time: 6.241410
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-gpq6x        1m           43Mi
        service1-745795666b-2jz9f        0m           11Mi
        service2-8f7c6f8f5-nxzkw         72m          10Mi
        ubuntu-client-76886f6bbd-jpxg5   6m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.923641, 6.079051, 6.106026, 6.11153, 6.187531, 6.181906, 6.213488, 6.24141]
    [exp] Throughput: 3262.337861043696
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '80.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '322.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   197.07ms   99.48ms 701.02ms   67.47%
        Req/Sec   328.40    167.51   686.00     61.21%
        Latency Distribution
        50%  189.48ms
        75%  260.15ms
        90%  326.59ms
        99%  482.88ms
        7609 requests in 3.03s, 1.15MB read
        Requests/sec:   2510.01
        Transfer/sec:    389.74KB
        [run.sh] Speed is 2510.01, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   192.35ms   88.88ms 650.62ms   69.39%
        Req/Sec   331.31    174.36   790.00     63.83%
        Latency Distribution
        50%  182.69ms
        75%  243.04ms
        90%  314.11ms
        99%  435.22ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.532588
        stop time: 7.583182
        stop time: 7.548213
        stop time: 7.534656
        stop time: 7.656805
        stop time: 7.656672
        stop time: 7.675327
        stop time: 7.669314
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-7c6d788d76-c74p4   0m           43Mi
        service1-745795666b-czdj7   0m           15Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [7.532588, 7.583182, 7.548213, 7.534656, 7.656805, 7.656672, 7.675327, 7.669314]
    [exp] Throughput: 2629.124650858408
[test.py] Finished running 4th optmization experiment: groundtruth->3262.337861043696, slowdown->2629.124650858408, predicted->3336.8956780256053, err->2.285410652042532
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00013', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   162.25ms   87.70ms 505.86ms   67.68%
        Req/Sec   400.30    158.00   770.00     65.95%
        Latency Distribution
        50%  150.26ms
        75%  212.18ms
        90%  288.10ms
        99%  403.34ms
        9318 requests in 3.03s, 1.41MB read
        Requests/sec:   3078.36
        Transfer/sec:    477.99KB
        [run.sh] Speed is 3078.36, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.30ms   91.38ms 802.75ms   74.95%
        Req/Sec   405.65    165.51     1.12k    68.85%
        Latency Distribution
        50%  140.05ms
        75%  205.70ms
        90%  266.88ms
        99%  445.51ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 5.995199
        stop time: 6.145333
        stop time: 6.219211
        stop time: 6.317463
        stop time: 6.279881
        stop time: 6.287424
        stop time: 6.241941
        stop time: 6.175315
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-9dh6s        518m         47Mi
        service1-745795666b-gc2zx        337m         11Mi
        service2-8f7c6f8f5-w8qdp         569m         9Mi
        ubuntu-client-76886f6bbd-76dck   65m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [5.995199, 6.145333, 6.219211, 6.317463, 6.279881, 6.287424, 6.241941, 6.175315]
    [exp] Throughput: 3221.7943433225
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '67.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '270.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   194.00ms  117.68ms 878.57ms   73.13%
        Req/Sec   334.71    145.08   646.00     67.67%
        Latency Distribution
        50%  168.94ms
        75%  261.38ms
        90%  341.46ms
        99%  585.04ms
        7767 requests in 3.04s, 1.18MB read
        Requests/sec:   2551.65
        Transfer/sec:    396.20KB
        [run.sh] Speed is 2551.65, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   190.07ms  101.45ms 656.96ms   67.31%
        Req/Sec   333.32    175.56   767.00     62.31%
        Latency Distribution
        50%  178.75ms
        75%  252.14ms
        90%  330.23ms
        99%  469.08ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.453708
        stop time: 7.478557
        stop time: 7.452933
        stop time: 7.565494
        stop time: 7.622657
        stop time: 7.650566
        stop time: 7.667544
        stop time: 7.587042
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [7.453708, 7.478557, 7.452933, 7.565494, 7.622657, 7.650566, 7.667544, 7.587042]
    [exp] Throughput: 2645.5682160508572
[test.py] Finished running 5th optmization experiment: groundtruth->3221.7943433225, slowdown->2645.5682160508572, predicted->3222.525388011694, err->0.0226906068883319
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000156', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.89ms   88.83ms 585.82ms   65.02%
        Req/Sec   392.57    209.26   848.00     58.19%
        Latency Distribution
        50%  152.19ms
        75%  224.49ms
        90%  288.04ms
        99%  396.98ms
        9128 requests in 3.03s, 1.38MB read
        Requests/sec:   3011.56
        Transfer/sec:    467.61KB
        [run.sh] Speed is 3011.56, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   156.86ms   83.61ms 820.74ms   70.73%
        Req/Sec   407.07    167.01   840.00     63.62%
        Latency Distribution
        50%  143.55ms
        75%  202.20ms
        90%  269.62ms
        99%  412.31ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.18
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.096638
        stop time: 6.180167
        stop time: 6.192332
        stop time: 6.202132
        stop time: 6.177486
        stop time: 6.161096
        stop time: 6.192090
        stop time: 6.224670
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-msfp2        1218m        44Mi
        service1-745795666b-chsth        631m         10Mi
        service2-8f7c6f8f5-97f6h         605m         9Mi
        ubuntu-client-76886f6bbd-mwn8z   70m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.096638, 6.180167, 6.192332, 6.202132, 6.177486, 6.161096, 6.19209, 6.22467]
    [exp] Throughput: 3237.1226099236305
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '54.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '218.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   187.35ms   94.92ms 634.26ms   68.44%
        Req/Sec   340.65    166.26   686.00     63.60%
        Latency Distribution
        50%  177.99ms
        75%  241.12ms
        90%  313.73ms
        99%  458.66ms
        7749 requests in 3.02s, 1.18MB read
        Requests/sec:   2566.20
        Transfer/sec:    398.46KB
        [run.sh] Speed is 2566.20, duration is 11
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d11s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 11s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   183.72ms   97.92ms 766.49ms   69.23%
        Req/Sec   345.43    170.42   790.00     64.79%
        Latency Distribution
        50%  168.64ms
        75%  240.10ms
        90%  316.78ms
        99%  471.27ms
        20000 requests in 11.00s, 3.03MB read
        Requests/sec:   1818.16
        Transfer/sec:    282.31KB
        ------------------------------
        stop time: 7.271478
        stop time: 7.115713
        stop time: 7.276591
        stop time: 7.266041
        stop time: 7.278071
        stop time: 7.250818
        stop time: 7.234846
        stop time: 7.259322
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [7.271478, 7.115713, 7.276591, 7.266041, 7.278071, 7.250818, 7.234846, 7.259322]
    [exp] Throughput: 2760.8636533680465
[test.py] Finished running 6th optmization experiment: groundtruth->3237.1226099236305, slowdown->2760.8636533680465, predicted->3251.709992992565, err->0.45062806778512565
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000182', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   169.78ms  111.72ms 895.76ms   77.30%
        Req/Sec   402.04    171.46   770.00     62.50%
        Latency Distribution
        50%  143.93ms
        75%  220.27ms
        90%  305.59ms
        99%  591.15ms
        9386 requests in 3.03s, 1.42MB read
        Requests/sec:   3095.35
        Transfer/sec:    480.63KB
        [run.sh] Speed is 3095.35, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.99ms   90.03ms 511.02ms   68.06%
        Req/Sec   399.07    184.69   818.00     66.33%
        Latency Distribution
        50%  143.00ms
        75%  209.36ms
        90%  287.11ms
        99%  406.49ms
        20000 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.19
        Transfer/sec:    345.05KB
        ------------------------------
        stop time: 6.153694
        stop time: 6.220837
        stop time: 6.159910
        stop time: 6.355935
        stop time: 6.355578
        stop time: 6.384807
        stop time: 6.359087
        stop time: 6.328097
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-c4bdb        1081m        44Mi
        service1-745795666b-f988q        496m         11Mi
        service2-8f7c6f8f5-m5sxr         207m         10Mi
        ubuntu-client-76886f6bbd-688z5   21m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.153694, 6.220837, 6.15991, 6.355935, 6.355578, 6.384807, 6.359087, 6.328097]
    [exp] Throughput: 3179.7800963453496
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '41.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '166.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   177.15ms   90.40ms 609.83ms   69.21%
        Req/Sec   371.17    182.99   787.00     66.96%
        Latency Distribution
        50%  169.25ms
        75%  229.11ms
        90%  294.05ms
        99%  431.99ms
        8505 requests in 3.02s, 1.29MB read
        Requests/sec:   2817.18
        Transfer/sec:    437.43KB
        [run.sh] Speed is 2817.18, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   174.68ms   88.03ms 733.30ms   68.89%
        Req/Sec   358.40    157.22   740.00     64.62%
        Latency Distribution
        50%  163.30ms
        75%  225.23ms
        90%  291.92ms
        99%  430.87ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 7.055850
        stop time: 6.995505
        stop time: 6.975037
        stop time: 7.029886
        stop time: 7.037283
        stop time: 7.008755
        stop time: 7.037148
        stop time: 7.050914
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [7.05585, 6.995505, 6.975037, 7.029886, 7.037283, 7.008755, 7.037148, 7.050914]
    [exp] Throughput: 2847.4626029388874
[test.py] Finished running 7th optmization experiment: groundtruth->3179.7800963453496, slowdown->2847.4626029388874, predicted->3230.8626213385796, err->1.6064798019190447
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000208', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   164.18ms   85.00ms 589.87ms   67.22%
        Req/Sec   394.32    195.21     0.91k    57.33%
        Latency Distribution
        50%  151.46ms
        75%  209.43ms
        90%  283.04ms
        99%  402.62ms
        9184 requests in 3.03s, 1.39MB read
        Requests/sec:   3031.21
        Transfer/sec:    470.67KB
        [run.sh] Speed is 3031.21, duration is 9
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d9s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 9s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   163.42ms  107.62ms 792.17ms   74.86%
        Req/Sec   392.69    162.12     0.93k    66.80%
        Latency Distribution
        50%  142.92ms
        75%  211.15ms
        90%  297.70ms
        99%  549.61ms
        20001 requests in 9.00s, 3.03MB read
        Requests/sec:   2222.30
        Transfer/sec:    345.06KB
        ------------------------------
        stop time: 6.313842
        stop time: 6.186516
        stop time: 6.406787
        stop time: 6.411173
        stop time: 6.387945
        stop time: 6.336828
        stop time: 6.387981
        stop time: 6.380902
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-zwmjw        113m         48Mi
        service1-745795666b-2rr7k        24m          12Mi
        service2-8f7c6f8f5-wpp2q         261m         9Mi
        ubuntu-client-76886f6bbd-66b4h   36m          12Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.313842, 6.186516, 6.406787, 6.411173, 6.387945, 6.336828, 6.387981, 6.380902]
    [exp] Throughput: 3148.8640846742146
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '28.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '114.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   180.87ms  104.36ms 642.59ms   68.00%
        Req/Sec   356.55    189.76   790.00     67.24%
        Latency Distribution
        50%  163.63ms
        75%  253.65ms
        90%  311.35ms
        99%  477.97ms
        8252 requests in 3.03s, 1.25MB read
        Requests/sec:   2727.55
        Transfer/sec:    423.52KB
        [run.sh] Speed is 2727.55, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   170.11ms  108.31ms 796.96ms   71.06%
        Req/Sec   375.65    151.85   757.00     64.75%
        Latency Distribution
        50%  148.55ms
        75%  227.96ms
        90%  314.39ms
        99%  516.26ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.465487
        stop time: 6.506760
        stop time: 6.713468
        stop time: 6.834489
        stop time: 6.673324
        stop time: 6.701570
        stop time: 6.797884
        stop time: 6.691185
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-74f5db548b-bkjrh        0m           45Mi
        service1-745795666b-smxtb        0m           12Mi
        service2-96f84c786-ns5h7         0m           9Mi
        ubuntu-client-76886f6bbd-lp8ww   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.465487, 6.50676, 6.713468, 6.834489, 6.673324, 6.70157, 6.797884, 6.691185]
    [exp] Throughput: 2997.1433290323703
[test.py] Finished running 8th optmization experiment: groundtruth->3148.8640846742146, slowdown->2997.1433290323703, predicted->3278.9460696779734, err->4.131076524924612
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.000234', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   246.99ms  151.69ms 882.28ms   69.28%
        Req/Sec   249.74    161.93   710.00     62.61%
        Latency Distribution
        50%  215.99ms
        75%  328.20ms
        90%  461.16ms
        99%  684.11ms
        5782 requests in 3.03s, 0.88MB read
        Requests/sec:   1907.31
        Transfer/sec:    296.16KB
        [run.sh] Speed is 1907.31, duration is 15
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d15s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 15s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   158.67ms   81.66ms 546.50ms   68.65%
        Req/Sec   400.59    127.87   790.00     69.09%
        Latency Distribution
        50%  145.51ms
        75%  208.42ms
        90%  274.12ms
        99%  387.10ms
        20000 requests in 15.00s, 3.03MB read
        Requests/sec:   1333.32
        Transfer/sec:    207.03KB
        ------------------------------
        stop time: 6.204194
        stop time: 6.205386
        stop time: 6.197690
        stop time: 6.318128
        stop time: 6.322645
        stop time: 6.377037
        stop time: 6.371090
        stop time: 6.295671
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-t7fj6        392m         44Mi
        service1-745795666b-46vr4        246m         13Mi
        service2-8f7c6f8f5-cfgtd         197m         8Mi
        ubuntu-client-76886f6bbd-h9zqz   26m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.204194, 6.205386, 6.19769, 6.318128, 6.322645, 6.377037, 6.37109, 6.295671]
    [exp] Throughput: 3181.430562464396
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.0004314', 'PROCESSING_TIME_SERVICE1': '0.00026535', 'PROCESSING_TIME_SERVICE2': '0.00097274', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '15.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'true', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '62.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'false'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   170.12ms   93.30ms 536.18ms   68.07%
        Req/Sec   387.30    170.67   707.00     63.64%
        Latency Distribution
        50%  157.39ms
        75%  230.40ms
        90%  295.53ms
        99%  433.33ms
        8962 requests in 3.02s, 1.36MB read
        Requests/sec:   2963.30
        Transfer/sec:    460.12KB
        [run.sh] Speed is 2963.30, duration is 10
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d10s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 10s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   166.12ms   90.09ms 638.11ms   70.02%
        Req/Sec   383.14    178.56   848.00     65.83%
        Latency Distribution
        50%  153.75ms
        75%  218.21ms
        90%  282.41ms
        99%  440.41ms
        20000 requests in 10.00s, 3.03MB read
        Requests/sec:   1999.97
        Transfer/sec:    310.54KB
        ------------------------------
        stop time: 6.544053
        stop time: 6.550484
        stop time: 6.549422
        stop time: 6.515908
        stop time: 6.644219
        stop time: 6.591240
        stop time: 6.529943
        stop time: 6.624636
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5867c84794-9nk26        0m           45Mi
        service1-745795666b-gxtl2        0m           11Mi
        service2-69d7667f8d-vnsp9        0m           9Mi
        ubuntu-client-76886f6bbd-bxpbz   2m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [6.544053, 6.550484, 6.549422, 6.515908, 6.644219, 6.59124, 6.529943, 6.624636]
    [exp] Throughput: 3044.7248191980557
[test.py] Finished running 9th optmization experiment: groundtruth->3181.430562464396, slowdown->3044.7248191980557, predicted->3197.320325834918, err->0.4994534080986949
[test.py] Baseline throughput:  3282.078279249025
[test.py] Groundtruth:  [3250.0015335944745, 3285.1374243820396, 3297.0238281063657, 3221.9296128396477, 3262.337861043696, 3221.7943433225, 3237.1226099236305, 3179.7800963453496, 3148.8640846742146, 3181.430562464396]
[test.py] Slowdown:  [2291.20542135862, 2399.854664801499, 2400.0757343897985, 2502.6103398943696, 2629.124650858408, 2645.5682160508572, 2760.8636533680465, 2847.4626029388874, 2997.1433290323703, 3044.7248191980557]
[test.py] Predicted:  [3291.8940791108394, 3366.811787477412, 3226.0299972802545, 3268.9590173672646, 3336.8956780256053, 3222.525388011694, 3251.709992992565, 3230.8626213385796, 3278.9460696779734, 3197.320325834918]
[test.py] Error percentage:  [1.289000792255998, 2.4861779750579545, -2.1532701772096767, 1.4596657959317583, 2.285410652042532, 0.0226906068883319, 0.45062806778512565, 1.6064798019190447, 4.131076524924612, 0.4994534080986949]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 3215.7685855747372
    Groundtruth: [3250.361887166613, 3262.972231616863, 3312.7011404843265, 3254.7520244099887, 3335.7208755500083, 3260.419884208633, 3291.8925213551242, 3174.0962009044188, 3218.410531234664, 3232.206872875809]
    Slowdown:    [2319.663656888574, 2369.0051214929476, 2483.9103928083837, 2504.497176875996, 2588.7858489199143, 2706.684271843399, 2808.2699337142985, 2932.2662620921164, 3018.0599955619427, 3140.4303696810603]
    Predicted:   [3350.959590212828, 3306.406783093517, 3379.337236777614, 3272.1791009233903, 3272.182045393959, 3313.6642507569036, 3317.6725365970387, 3340.480290915748, 3303.997415613221, 3303.025937155679]
    Error Perc:  [3.0949693153677553, 1.3311345728226163, 2.0115335935056695, 0.5354348467318534, -1.9048005671509516, 1.633052442298978, 0.7831366022637344, 5.241935955309738, 2.6592904649029867, 2.1910436758913185]
[test.py] Result for the experiment 1: 
    Baseline throughput: 3211.4379859884157
    Groundtruth: [3282.948486619225, 3268.7115862546593, 3280.491786724977, 3231.842830312213, 3267.822612621728, 3259.290138015456, 3252.643316495957, 3239.487014273342, 3258.425391996721, 3284.0132020614733]
    Slowdown:    [2305.849058515344, 2414.893347593681, 2461.807177260349, 2520.6099245865016, 2637.119631135529, 2716.5522089839537, 2785.036181623489, 2963.69856392319, 3008.710857282891, 3186.041696444541]
    Predicted:   [3322.2069163073993, 3396.4857495982487, 3338.556435323138, 3299.7378770723903, 3349.785175136295, 3328.46635275207, 3285.293985148254, 3381.3344043146503, 3292.796131754816, 3353.5205489277187]
    Error Perc:  [1.1958283795248463, 3.909006957998244, 1.769998292119759, 2.100815241489269, 2.5081704924249193, 2.1224319347873393, 1.0038195238533227, 4.378699140213297, 1.0548266608318204, 2.116536767349581]
[test.py] Result for the experiment 2: 
    Baseline throughput: 3213.7375066205504
    Groundtruth: [3245.00431585574, 3258.2502817215554, 3239.9204858714356, 3243.079182879444, 3295.9465872079863, 3276.9426796572047, 3260.5406758970407, 3234.2748394986056, 3146.062025006081, 3227.9925705329997]
    Slowdown:    [2305.352596475404, 2376.395501126857, 2474.9144986647684, 2528.591814891402, 2646.991709638509, 2725.777607280388, 2805.9802172782724, 2938.861846767927, 2990.792508797509, 3092.747296895371]
    Predicted:   [3321.176443725779, 3320.820757454309, 3362.708130090904, 3313.4302481307805, 3365.730098274901, 3342.326559259053, 3314.4772721321738, 3349.042786010086, 3271.346363078636, 3250.3189019918955]
    Error Perc:  [2.3473659957198385, 1.920370454159625, 3.7898351133899006, 2.16926757825486, 2.1172524863647375, 1.995270775034972, 1.6542224617484333, 3.5484908428274493, 3.9822589979710497, 0.6916475478507463]
[test.py] Result for the experiment 3: 
    Baseline throughput: 3269.7849270353627
    Groundtruth: [3266.478054779653, 3236.9040728102727, 3218.6801250948083, 3276.0531144034394, 3265.7418657207772, 3248.0246427629645, 3281.2187611311506, 3251.570162909355, 3251.0547589985995, 3232.7525026707085]
    Slowdown:    [2315.2254725736943, 2360.8293670293324, 2482.2263286519787, 2549.363971929463, 2620.5082482298712, 2733.0314574824606, 2817.0242564979458, 2941.399670916205, 3022.976491804418, 3155.9193182125478]
    Predicted:   [3341.7056984854134, 3290.5024397738816, 3376.2209047833117, 3349.189512883829, 3323.0279314205127, 3353.239630824245, 3329.897780670996, 3352.338859775689, 3309.8905508148155, 3320.1646610762423]
    Error Perc:  [2.3030200247536934, 1.655852807435066, 4.89457708022051, 2.232454600898853, 1.7541516768684324, 3.2393531340876276, 1.483565195850091, 3.099078039766813, 1.809744719105832, 2.703954550597951]
[test.py] Result for the experiment 4: 
    Baseline throughput: 3282.078279249025
    Groundtruth: [3250.0015335944745, 3285.1374243820396, 3297.0238281063657, 3221.9296128396477, 3262.337861043696, 3221.7943433225, 3237.1226099236305, 3179.7800963453496, 3148.8640846742146, 3181.430562464396]
    Slowdown:    [2291.20542135862, 2399.854664801499, 2400.0757343897985, 2502.6103398943696, 2629.124650858408, 2645.5682160508572, 2760.8636533680465, 2847.4626029388874, 2997.1433290323703, 3044.7248191980557]
    Predicted:   [3291.8940791108394, 3366.811787477412, 3226.0299972802545, 3268.9590173672646, 3336.8956780256053, 3222.525388011694, 3251.709992992565, 3230.8626213385796, 3278.9460696779734, 3197.320325834918]
    Error Perc:  [1.289000792255998, 2.4861779750579545, -2.1532701772096767, 1.4596657959317583, 2.285410652042532, 0.0226906068883319, 0.45062806778512565, 1.6064798019190447, 4.131076524924612, 0.4994534080986949]
