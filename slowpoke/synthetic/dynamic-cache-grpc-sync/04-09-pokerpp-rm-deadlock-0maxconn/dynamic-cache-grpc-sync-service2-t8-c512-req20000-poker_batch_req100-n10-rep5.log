[config.py] Random numbers for execution time: [786.0420416734107, 826.5145977008433, 958.0749646410659]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : dynamic-cache-grpc-sync
repetitions                      : 5
target_num_exp                   : 10
pre_run                          : False
num_req                          : 20000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
poker_batch_req                  : 100
client_cpu_quota                 : 2
random_seed                      : 13505
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.25}
baseline_service_processing_time : {'service0': 958.07, 'service1': 826.51, 'service2': 6288.34}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2}
target_processing_time_range     : [0, 6288.34]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 628, 1256, 1884, 2512, 3140, 3768, 4396, 5024, 5652]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   362.15ms  427.29ms   2.37s    84.34%
        Req/Sec   182.42     85.26   393.00     67.79%
        Latency Distribution
        50%  155.64ms
        75%  563.39ms
        90%    1.00s
        99%    1.74s
        3908 requests in 3.03s, 606.81KB read
        Requests/sec:   1290.53
        Transfer/sec:    200.39KB
        [run.sh] Speed is 1290.53, duration is 23
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d23s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 23s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   683.76ms    1.02s    6.23s    84.80%
        Req/Sec   168.29     88.89   510.00     65.18%
        Latency Distribution
        50%   98.58ms
        75%    1.01s
        90%    2.26s
        99%    4.24s
        20001 requests in 23.00s, 3.03MB read
        Requests/sec:    869.60
        Transfer/sec:    135.03KB
        ------------------------------
        stop time: 15.021795
        stop time: 15.769733
        stop time: 14.915117
        stop time: 16.470586
        stop time: 16.123035
        stop time: 15.824390
        stop time: 16.233525
        stop time: 15.502643
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-9wls5        515m         39Mi
        service1-76b89695f7-lxdl5        397m         25Mi
        service2-7bdbb95446-6x7w7        0m           23Mi
        ubuntu-client-76886f6bbd-vp25d   0m           0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [15.021795, 15.769733, 14.915117, 16.470586, 16.123035, 15.82439, 16.233525, 15.502643]
    [exp] Throughput: 1271.245451245417
[test.py] Baseline throughput: 1271.245451245417
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   314.88ms  134.05ms 994.85ms   70.12%
        Req/Sec   216.56     92.37   440.00     66.20%
        Latency Distribution
        50%  297.98ms
        75%  392.98ms
        90%  494.14ms
        99%  759.67ms
        4712 requests in 3.03s, 731.65KB read
        Requests/sec:   1554.17
        Transfer/sec:    241.32KB
        [run.sh] Speed is 1554.17, duration is 19
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d19s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 19s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   303.43ms  164.84ms   1.34s    75.98%
        Req/Sec   214.86    112.85   580.00     63.50%
        Latency Distribution
        50%  269.49ms
        75%  369.04ms
        90%  521.62ms
        99%  874.55ms
        20000 requests in 19.00s, 3.03MB read
        Requests/sec:   1052.62
        Transfer/sec:    163.44KB
        ------------------------------
        stop time: 11.827547
        stop time: 11.867262
        stop time: 11.822504
        stop time: 12.056466
        stop time: 12.080240
        stop time: 12.031108
        stop time: 12.125984
        stop time: 12.094669
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-s2rqq        1573m        49Mi
        service1-76b89695f7-5x25t        836m         18Mi
        service2-7bdbb95446-fbv9x        60m          7Mi
        ubuntu-client-76886f6bbd-g8wtz   57m          14Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [11.827547, 11.867262, 11.822504, 12.056466, 12.08024, 12.031108, 12.125984, 12.094669]
    [exp] Throughput: 1668.3040375668702
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '786.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '786.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   626.60ms  556.16ms   1.93s    76.05%
        Req/Sec   125.72    104.39   390.00     66.96%
        Latency Distribution
        50%  463.01ms
        75%    1.02s
        90%    1.73s
        99%    1.89s
        1900 requests in 3.03s, 295.02KB read
        Requests/sec:    627.14
        Transfer/sec:     97.38KB
        [run.sh] Speed is 627.14, duration is 47
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 47s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   706.03ms  487.17ms   3.71s    72.38%
        Req/Sec   130.19     98.02   575.00     64.09%
        Latency Distribution
        50%  652.53ms
        75%  946.15ms
        90%    1.23s
        99%    2.64s
        20000 requests in 47.00s, 3.03MB read
        Requests/sec:    425.53
        Transfer/sec:     66.07KB
        ------------------------------
        stop time: 26.266618
        stop time: 26.752937
        stop time: 27.267497
        stop time: 27.824923
        stop time: 27.744757
        stop time: 28.224335
        stop time: 28.318878
        stop time: 28.324535
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [26.266618, 26.752937, 27.267497, 27.824923, 27.744757, 28.224335, 28.318878, 28.324535]
    [exp] Throughput: 724.8856130502606
[test.py] Finished running 0th optmization experiment: groundtruth->1668.3040375668702, slowdown->724.8856130502606, predicted->1684.961132159084, err->0.9984447808750262
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.000628', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   307.04ms  203.19ms   1.44s    77.34%
        Req/Sec   205.62    102.84   440.00     67.86%
        Latency Distribution
        50%  242.16ms
        75%  400.74ms
        90%  573.16ms
        99%  967.23ms
        4624 requests in 3.02s, 717.98KB read
        Requests/sec:   1531.43
        Transfer/sec:    237.79KB
        [run.sh] Speed is 1531.43, duration is 19
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d19s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 19s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   316.34ms  178.34ms   1.47s    75.74%
        Req/Sec   204.27    111.83   595.00     64.95%
        Latency Distribution
        50%  275.17ms
        75%  395.49ms
        90%  554.18ms
        99%  887.05ms
        20000 requests in 19.00s, 3.03MB read
        Requests/sec:   1052.62
        Transfer/sec:    163.44KB
        ------------------------------
        stop time: 12.299048
        stop time: 12.040438
        stop time: 12.183674
        stop time: 12.521388
        stop time: 12.585717
        stop time: 12.633638
        stop time: 12.612502
        stop time: 12.584255
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6fb7cc7c7f-nk494        597m         43Mi
        service1-76b89695f7-99l5r        495m         12Mi
        service2-7bdbb95446-vx86k        110m         8Mi
        ubuntu-client-76886f6bbd-c2js4   23m          0Mi
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [12.299048, 12.040438, 12.183674, 12.521388, 12.585717, 12.633638, 12.612502, 12.584255]
    [exp] Throughput: 1608.676234402627
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '707.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '707.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   681.62ms  415.31ms   2.15s    64.39%
        Req/Sec   132.57     92.73   390.00     66.12%
        Latency Distribution
        50%  653.24ms
        75%    1.00s
        90%    1.31s
        99%    1.46s
        2021 requests in 3.03s, 313.81KB read
        Requests/sec:    667.40
        Transfer/sec:    103.63KB
        [run.sh] Speed is 667.40, duration is 44
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d44s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5cdf544684-rfllp        852m         49Mi
        service1-5f648644fd-hxmbv        747m         17Mi
        service2-7bdbb95446-fzf99        1274m        12Mi
        ubuntu-client-76886f6bbd-dlvrr   30m          20Mi
        Running 44s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   662.84ms  434.96ms   3.50s    74.16%
        Req/Sec   127.23     89.52   474.00     68.70%
        Latency Distribution
        50%  580.74ms
        75%  882.52ms
        90%    1.12s
        99%    2.12s
        20000 requests in 44.00s, 3.03MB read
        Requests/sec:    454.54
        Transfer/sec:     70.58KB
        ------------------------------
        stop time: 26.277480
        stop time: 25.432614
        stop time: 26.284654
        stop time: 25.525311
        stop time: 26.318317
        stop time: 26.284645
        stop time: 26.399750
        stop time: 26.295729
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.27748, 25.432614, 26.284654, 25.525311, 26.318317, 26.284645, 26.39975, 26.295729]
    [exp] Throughput: 766.2156370244973
[test.py] Finished running 1th optmization experiment: groundtruth->1608.676234402627, slowdown->766.2156370244973, predicted->1673.4353640820107, err->4.025616111835682
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.001256', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 --timeout 3s -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   325.83ms  162.89ms   1.02s    66.30%
        Req/Sec   206.09     94.14   434.00     66.32%
        Latency Distribution
        50%  303.57ms
        75%  448.72ms
        90%  542.43ms
        99%  740.19ms
        4427 requests in 3.02s, 687.40KB read
        Requests/sec:   1463.81
        Transfer/sec:    227.29KB
        [run.sh] Speed is 1463.81, duration is 20
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d20s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        Running 20s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   304.74ms  207.98ms   1.68s    79.41%
        Req/Sec   213.08     99.97   720.00     68.08%
        Latency Distribution
        50%  247.95ms
        75%  364.71ms
        90%  594.48ms
        99%    1.07s
        20000 requests in 20.00s, 3.03MB read
        Requests/sec:    999.99
        Transfer/sec:    155.27KB
        ------------------------------
        stop time: 11.736323
        stop time: 11.623826
        stop time: 11.788912
        stop time: 12.121653
        stop time: 12.108365
        stop time: 12.152641
        stop time: 12.031330
        stop time: 11.805192
        [run.sh] Checking the resource usage
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [11.736323, 11.623826, 11.788912, 12.121653, 12.108365, 12.152641, 12.03133, 11.805192]
    [exp] Throughput: 1677.7073441282475
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-cache-grpc-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00095807', 'PROCESSING_TIME_SERVICE1': '0.00082651', 'PROCESSING_TIME_SERVICE2': '0.00628834', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '629.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE0': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '629.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE1': 'false', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '100', 'SLOWPOKE_IS_TARGET_SERVICE_SERVICE2': 'true'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-cache-grpc-sync 8 512 20000`:
        [run.sh] Running benchmark synthetic with request dynamic-cache-grpc-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
