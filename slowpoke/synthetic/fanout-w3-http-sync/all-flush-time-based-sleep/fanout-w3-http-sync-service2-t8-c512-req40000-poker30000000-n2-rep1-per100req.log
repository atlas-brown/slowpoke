[config.py] Random numbers for execution time: [467.7110783366884, 525.184656690112, 990.1754468108787, 1144.090129435625]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : fanout-w3-http-sync
repetitions                      : 1
target_num_exp                   : 2
pre_run                          : False
num_req                          : 40000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 22197
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 1, 'service3': 1}
baseline_service_processing_time : {'service0': 1144.09, 'service1': 990.18, 'service2': 1050.37, 'service3': 467.71}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2}
target_processing_time_range     : [0, 1050.37]
baseline_throughputs             : []
poker_batch                      : 30000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 525]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.00105037', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   518.38ms  135.44ms   1.10s    79.38%
        Req/Sec   124.22     47.65   220.00     71.43%
        Latency Distribution
        50%  484.01ms
        75%  553.28ms
        90%  706.22ms
        99%  981.63ms
        2731 requests in 3.03s, 1.80MB read
        Requests/sec:    901.00
        Transfer/sec:    606.46KB
        [run.sh] Speed is 901.00, duration is 88
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d88s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f7bfff576-6j7gv        1758m        52Mi
        service1-96558989f-sb8z5         1219m        11Mi
        service2-b9b68cb9d-6bftv         1266m        17Mi
        service3-8798dc54d-s8fxr         663m         11Mi
        ubuntu-client-76886f6bbd-js9ql   54m          14Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   486.04ms   90.69ms   1.36s    86.75%
        Req/Sec   131.85     35.33   380.00     70.51%
        Latency Distribution
        50%  468.70ms
        75%  511.73ms
        90%  570.33ms
        99%  853.31ms
        40000 requests in 1.47m, 26.28MB read
        Requests/sec:    454.54
        Transfer/sec:    305.84KB
        ------------------------------
        stop time: 37.805058
        stop time: 37.950212
        stop time: 38.179995
        stop time: 38.260313
        stop time: 38.448031
        stop time: 38.368844
        stop time: 38.503121
        stop time: 38.379753
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [37.805058, 37.950212, 38.179995, 38.260313, 38.448031, 38.368844, 38.503121, 38.379753]
    [exp] Throughput: 1046.10947521928
[test.py] Baseline throughput: 1046.10947521928
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.0', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   466.58ms  199.65ms   1.51s    71.87%
        Req/Sec   144.07     48.42   260.00     72.60%
        Latency Distribution
        50%  424.57ms
        75%  562.35ms
        90%  744.02ms
        99%    1.21s
        3058 requests in 3.03s, 2.01MB read
        Requests/sec:   1010.33
        Transfer/sec:    680.24KB
        [run.sh] Speed is 1010.33, duration is 79
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d79s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service1-96558989f-j4cw2         406m         13Mi
        ubuntu-client-76886f6bbd-4tp5f   10m          0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   432.85ms  160.60ms   1.45s    75.66%
        Req/Sec   148.21     47.70   343.00     68.52%
        Latency Distribution
        50%  398.24ms
        75%  500.86ms
        90%  651.57ms
        99%  963.20ms
        40000 requests in 1.32m, 26.29MB read
        Requests/sec:    506.33
        Transfer/sec:    340.71KB
        ------------------------------
        stop time: 33.899540
        stop time: 34.170474
        stop time: 34.007937
        stop time: 33.911882
        stop time: 34.112425
        stop time: 34.030843
        stop time: 34.179241
        stop time: 34.226310
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [33.89954, 34.170474, 34.007937, 33.911882, 34.112425, 34.030843, 34.179241, 34.22631]
    [exp] Throughput: 1174.1453832390716
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.000525', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   452.18ms  195.69ms   1.52s    82.02%
        Req/Sec   141.79     48.13   280.00     71.04%
        Latency Distribution
        50%  401.22ms
        75%  503.79ms
        90%  680.84ms
        99%    1.20s
        3161 requests in 3.03s, 2.08MB read
        Requests/sec:   1041.57
        Transfer/sec:    701.49KB
        [run.sh] Speed is 1041.57, duration is 76
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d76s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   434.13ms  165.96ms   1.93s    76.80%
        Req/Sec   147.34     44.55   290.00     70.12%
        Latency Distribution
        50%  401.79ms
        75%  498.03ms
        90%  647.06ms
        99%  997.73ms
        40000 requests in 1.27m, 26.29MB read
        Requests/sec:    526.31
        Transfer/sec:    354.17KB
        ------------------------------
        stop time: 34.029605
        stop time: 33.759704
        stop time: 34.148296
        stop time: 34.303869
        stop time: 34.293923
        stop time: 34.304307
        stop time: 34.204158
        stop time: 34.139026
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [34.029605, 33.759704, 34.148296, 34.303869, 34.293923, 34.304307, 34.204158, 34.139026]
    [exp] Throughput: 1171.3764443401005
[test.py] Running slowdown experiment
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.00105037', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '525.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '52500000', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '525.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '52500000', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '525.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '52500000'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   720.58ms  157.08ms   1.35s    71.44%
        Req/Sec    87.57     41.59   180.00     61.40%
        Latency Distribution
        50%  704.41ms
        75%  813.32ms
        90%  917.22ms
        99%    1.16s
        1898 requests in 3.02s, 1.25MB read
        Requests/sec:    627.49
        Transfer/sec:    422.21KB
        [run.sh] Speed is 627.49, duration is 127
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d127s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5bfcf6744c-ckvql        1228m        57Mi
        service1-d9df6bdd4-pttwr         835m         16Mi
        service2-b9b68cb9d-4rss2         890m         15Mi
        service3-68847cf48c-5kv6n        454m         14Mi
        ubuntu-client-76886f6bbd-dmzcl   40m          17Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   698.25ms  183.40ms   2.05s    77.54%
        Req/Sec    92.78     43.77   282.00     66.42%
        Latency Distribution
        50%  676.38ms
        75%  785.26ms
        90%  923.02ms
        99%    1.33s
        40001 requests in 2.12m, 26.29MB read
        Requests/sec:    314.97
        Transfer/sec:    211.99KB
        ------------------------------
        stop time: 54.456936
        stop time: 54.747904
        stop time: 54.437980
        stop time: 55.005756
        stop time: 55.197437
        stop time: 55.080612
        stop time: 54.972480
        stop time: 55.185824
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [54.456936, 54.747904, 54.43798, 55.005756, 55.197437, 55.080612, 54.97248, 55.185824]
    [exp] Throughput: 728.7883934636253
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.00105037', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '262.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '26250000', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '262.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '26250000', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '262.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '26250000'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   595.78ms  216.64ms   1.59s    77.86%
        Req/Sec    99.93     47.65   282.00     65.20%
        Latency Distribution
        50%  551.76ms
        75%  674.72ms
        90%  885.68ms
        99%    1.32s
        2302 requests in 3.03s, 1.52MB read
        Requests/sec:    758.53
        Transfer/sec:    511.26KB
        [run.sh] Speed is 758.53, duration is 105
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d105s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-bcfb95945-bfss6         1514m        57Mi
        service1-78ddbd897d-n8gws        1033m        14Mi
        service2-b9b68cb9d-254qd         1097m        14Mi
        service3-f5668fbb9-znl9s         562m         14Mi
        ubuntu-client-76886f6bbd-5nmnw   49m          15Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   563.03ms  163.90ms   1.68s    77.91%
        Req/Sec   113.98     45.05   323.00     69.72%
        Latency Distribution
        50%  538.86ms
        75%  631.38ms
        90%  760.68ms
        99%    1.17s
        40000 requests in 1.75m, 26.29MB read
        Requests/sec:    380.95
        Transfer/sec:    256.43KB
        ------------------------------
        stop time: 43.860489
        stop time: 43.856560
        stop time: 44.339471
        stop time: 44.263712
        stop time: 44.423815
        stop time: 44.536884
        stop time: 44.410758
        stop time: 44.230858
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [43.860489, 43.85656, 44.339471, 44.263712, 44.423815, 44.536884, 44.410758, 44.230858]
    [exp] Throughput: 904.1526252352609
[test.py] Baseline throughput:  1046.10947521928
[test.py] Groundtruth:  [1174.1453832390716, 1171.3764443401005]
[test.py] Slowdown:  [728.7883934636253, 904.1526252352609]
[test.py] Predicted:  [1180.6997113547102, 1185.7853374952767]
[test.py] Error percentage:  [0.5582211716880725, 1.2300822015670212]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1046.10947521928
    Groundtruth: [1174.1453832390716, 1171.3764443401005]
    Slowdown:    [728.7883934636253, 904.1526252352609]
    Predicted:   [1180.6997113547102, 1185.7853374952767]
    Error Perc:  [0.5582211716880725, 1.2300822015670212]
