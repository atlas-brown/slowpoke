[config.py] Random numbers for execution time: [467.7110783366884, 525.184656690112, 990.1754468108787, 1144.090129435625]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : fanout-w3-http-sync
repetitions                      : 1
target_num_exp                   : 2
pre_run                          : False
num_req                          : 40000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 22197
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 1, 'service3': 1}
baseline_service_processing_time : {'service0': 1144.09, 'service1': 990.18, 'service2': 1050.37, 'service3': 467.71}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2}
target_processing_time_range     : [0, 1050.37]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 525]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.00105037', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   482.04ms  117.24ms   1.08s    82.38%
        Req/Sec   137.99     41.81   252.00     69.71%
        Latency Distribution
        50%  449.61ms
        75%  505.31ms
        90%  651.67ms
        99%  884.14ms
        2952 requests in 3.03s, 2.27MB read
        Requests/sec:    974.45
        Transfer/sec:    766.05KB
        [run.sh] Speed is 974.45, duration is 61
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d61s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   461.86ms   93.90ms   1.66s    89.24%
        Req/Sec   138.65     34.99   350.00     69.84%
        Latency Distribution
        50%  441.39ms
        75%  481.01ms
        90%  535.71ms
        99%  858.27ms
        40000 requests in 1.02m, 30.71MB read
        Requests/sec:    655.74
        Transfer/sec:    515.50KB
        ------------------------------
        stop time: 36.060926
        stop time: 36.312447
        stop time: 36.281559
        stop time: 36.490249
        stop time: 36.412807
        stop time: 36.485784
        stop time: 36.276237
        stop time: 36.457700
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [36.060926, 36.312447, 36.281559, 36.490249, 36.412807, 36.485784, 36.276237, 36.4577]
    [exp] Throughput: 1100.4970123070884
[test.py] Baseline throughput: 1100.4970123070884
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.0', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   440.60ms  134.43ms   1.05s    73.40%
        Req/Sec   147.71     54.09   282.00     70.83%
        Latency Distribution
        50%  412.24ms
        75%  498.59ms
        90%  632.09ms
        99%  860.39ms
        3223 requests in 3.04s, 2.47MB read
        Requests/sec:   1061.24
        Transfer/sec:    834.27KB
        [run.sh] Speed is 1061.24, duration is 56
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d56s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   422.55ms  148.83ms   1.73s    77.20%
        Req/Sec   151.79     49.91   330.00     67.64%
        Latency Distribution
        50%  400.83ms
        75%  484.66ms
        90%  591.79ms
        99%  936.95ms
        40000 requests in 0.93m, 30.71MB read
        Requests/sec:    714.28
        Transfer/sec:    561.52KB
        ------------------------------
        stop time: 32.897873
        stop time: 33.189725
        stop time: 32.873590
        stop time: 33.301739
        stop time: 33.361528
        stop time: 33.272454
        stop time: 33.370176
        stop time: 33.307864
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [32.897873, 33.189725, 32.87359, 33.301739, 33.361528, 33.272454, 33.370176, 33.307864]
    [exp] Throughput: 1204.9329246035174
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.000525', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   448.08ms  194.35ms   1.51s    68.35%
        Req/Sec   148.57     53.30   300.00     73.08%
        Latency Distribution
        50%  398.64ms
        75%  575.64ms
        90%  725.35ms
        99%    1.00s
        3114 requests in 3.02s, 2.39MB read
        Requests/sec:   1031.65
        Transfer/sec:    811.01KB
        [run.sh] Speed is 1031.65, duration is 58
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d58s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        ubuntu-client-76886f6bbd-kn75v   15m          0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   419.71ms  150.56ms   1.60s    76.24%
        Req/Sec   152.91     47.18   320.00     69.33%
        Latency Distribution
        50%  394.38ms
        75%  485.29ms
        90%  604.28ms
        99%  924.24ms
        40000 requests in 0.97m, 30.71MB read
        Requests/sec:    689.65
        Transfer/sec:    542.16KB
        ------------------------------
        stop time: 32.622118
        stop time: 33.120715
        stop time: 33.030002
        stop time: 32.972915
        stop time: 32.823473
        stop time: 33.179247
        stop time: 33.063824
        stop time: 33.135917
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [32.622118, 33.120715, 33.030002, 32.972915, 32.823473, 33.179247, 33.063824, 33.135917]
    [exp] Throughput: 1212.3590411453858
[test.py] Running slowdown experiment
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.00105037', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '525.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '525.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '525.0'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   697.36ms  344.25ms   1.86s    65.85%
        Req/Sec    90.78     58.19   240.00     60.00%
        Latency Distribution
        50%  677.51ms
        75%  897.14ms
        90%    1.25s
        99%    1.51s
        1758 requests in 3.03s, 1.35MB read
        Socket errors: connect 0, read 0, write 0, timeout 1
        Requests/sec:    581.00
        Transfer/sec:    456.75KB
        [run.sh] Speed is 581.00, duration is 103
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d103s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-c565df8cd-6gc97         400m         39Mi
        service1-7889b5c78f-l4gk5        254m         12Mi
        service2-69bc9dd878-bks9n        271m         11Mi
        service3-b97dfb9bb-fbzrv         135m         11Mi
        ubuntu-client-76886f6bbd-zm4kv   8m           0Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   676.23ms  383.60ms   3.19s    69.08%
        Req/Sec    97.87     50.04   300.00     65.01%
        Latency Distribution
        50%  628.77ms
        75%  899.82ms
        90%    1.18s
        99%    1.84s
        40000 requests in 1.72m, 30.71MB read
        Requests/sec:    388.35
        Transfer/sec:    305.29KB
        ------------------------------
        stop time: 53.018543
        stop time: 52.889444
        stop time: 53.021009
        stop time: 53.435930
        stop time: 53.131984
        stop time: 53.297956
        stop time: 53.428074
        stop time: 53.487128
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [53.018543, 52.889444, 53.021009, 53.43593, 53.131984, 53.297956, 53.428074, 53.487128]
    [exp] Throughput: 751.6852995828139
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.00105037', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '262.5', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '262.5', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '262.5'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   535.52ms  223.45ms   1.36s    69.26%
        Req/Sec   119.35     46.50   230.00     70.39%
        Latency Distribution
        50%  532.64ms
        75%  679.28ms
        90%  821.84ms
        99%    1.09s
        2482 requests in 3.02s, 1.91MB read
        Requests/sec:    821.30
        Transfer/sec:    645.65KB
        [run.sh] Speed is 821.30, duration is 73
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d73s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5d59d98d45-x7bp2        1491m        56Mi
        service1-f6dd6c6f4-hhnzj         1030m        14Mi
        service2-69bc9dd878-jhhz4        1090m        14Mi
        service3-994d4d6df-qh9tq         536m         12Mi
        ubuntu-client-76886f6bbd-w5xhr   36m          19Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   549.86ms  300.00ms   3.14s    75.69%
        Req/Sec   118.52     49.61   310.00     67.81%
        Latency Distribution
        50%  480.72ms
        75%  691.80ms
        90%  941.77ms
        99%    1.55s
        40000 requests in 1.22m, 30.71MB read
        Requests/sec:    547.94
        Transfer/sec:    430.76KB
        ------------------------------
        stop time: 43.166938
        stop time: 42.882373
        stop time: 42.757162
        stop time: 43.340256
        stop time: 42.769574
        stop time: 42.950215
        stop time: 43.089742
        stop time: 43.363466
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [43.166938, 42.882373, 42.757162, 43.340256, 42.769574, 42.950215, 43.089742, 43.363466]
    [exp] Throughput: 929.3687693048408
[test.py] Baseline throughput:  1100.4970123070884
[test.py] Groundtruth:  [1204.9329246035174, 1212.3590411453858]
[test.py] Slowdown:  [751.6852995828139, 929.3687693048408]
[test.py] Predicted:  [1241.9907702387404, 1229.5372061147682]
[test.py] Error percentage:  [3.075511082695067, 1.4169205974785442]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1100.4970123070884
    Groundtruth: [1204.9329246035174, 1212.3590411453858]
    Slowdown:    [751.6852995828139, 929.3687693048408]
    Predicted:   [1241.9907702387404, 1229.5372061147682]
    Error Perc:  [3.075511082695067, 1.4169205974785442]
