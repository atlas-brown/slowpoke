[config.py] Random numbers for execution time: [467.7110783366884, 525.184656690112, 990.1754468108787, 1144.090129435625]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : fanout-w3-http-sync
repetitions                      : 1
target_num_exp                   : 2
pre_run                          : False
num_req                          : 40000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 22197
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 1, 'service3': 1}
baseline_service_processing_time : {'service0': 1144.09, 'service1': 990.18, 'service2': 1050.37, 'service3': 467.71}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2}
target_processing_time_range     : [0, 1050.37]
baseline_throughputs             : []
poker_batch                      : 30000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 525]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.00105037', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   493.94ms  140.65ms   1.22s    84.76%
        Req/Sec   131.69     44.13   230.00     72.69%
        Latency Distribution
        50%  446.35ms
        75%  517.08ms
        90%  701.96ms
        99%    1.03s
        2854 requests in 3.02s, 2.19MB read
        Requests/sec:    945.43
        Transfer/sec:    743.23KB
        [run.sh] Speed is 945.43, duration is 63
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d63s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   463.38ms   94.60ms   1.32s    90.02%
        Req/Sec   138.06     33.54   280.00     71.03%
        Latency Distribution
        50%  442.14ms
        75%  480.99ms
        90%  533.64ms
        99%  875.25ms
        40000 requests in 1.05m, 30.71MB read
        Requests/sec:    634.92
        Transfer/sec:    499.13KB
        ------------------------------
        stop time: 36.143217
        stop time: 36.408938
        stop time: 36.503057
        stop time: 36.484793
        stop time: 36.294417
        stop time: 36.483102
        stop time: 36.667178
        stop time: 36.581142
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [36.143217, 36.408938, 36.503057, 36.484793, 36.294417, 36.483102, 36.667178, 36.581142]
    [exp] Throughput: 1097.522246124275
[test.py] Baseline throughput: 1097.522246124275
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.0', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   455.88ms  213.46ms   1.46s    80.34%
        Req/Sec   136.76     64.48   330.00     67.53%
        Latency Distribution
        50%  394.22ms
        75%  529.47ms
        90%  723.15ms
        99%    1.26s
        3168 requests in 3.03s, 2.43MB read
        Requests/sec:   1045.21
        Transfer/sec:    821.68KB
        [run.sh] Speed is 1045.21, duration is 57
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d57s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   420.27ms  156.45ms   1.59s    76.41%
        Req/Sec   152.82     49.72   350.00     68.99%
        Latency Distribution
        50%  388.20ms
        75%  486.48ms
        90%  615.84ms
        99%  957.80ms
        40000 requests in 0.95m, 30.71MB read
        Requests/sec:    701.75
        Transfer/sec:    551.67KB
        ------------------------------
        stop time: 33.056930
        stop time: 33.072070
        stop time: 33.024011
        stop time: 33.032125
        stop time: 33.087436
        stop time: 33.164238
        stop time: 33.105560
        stop time: 32.836597
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [33.05693, 33.07207, 33.024011, 33.032125, 33.087436, 33.164238, 33.10556, 32.836597]
    [exp] Throughput: 1210.383729201877
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.000525', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   451.09ms  170.05ms   1.14s    70.80%
        Req/Sec   146.89     50.79   280.00     70.95%
        Latency Distribution
        50%  417.89ms
        75%  540.62ms
        90%  699.93ms
        99%  953.85ms
        3144 requests in 3.04s, 2.41MB read
        Requests/sec:   1035.29
        Transfer/sec:    813.88KB
        [run.sh] Speed is 1035.29, duration is 57
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d57s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-7d7b74c5c9-qngc5        605m         51Mi
        service1-79544bdbfb-v2mqd        410m         11Mi
        service2-5cf74bd689-k55jt        239m         12Mi
        service3-7999f7bb99-w9929        219m         12Mi
        ubuntu-client-76886f6bbd-422h5   19m          0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   420.08ms  155.47ms   1.55s    74.46%
        Req/Sec   153.02     45.40   353.00     68.91%
        Latency Distribution
        50%  390.03ms
        75%  491.48ms
        90%  625.30ms
        99%  918.47ms
        40000 requests in 0.95m, 30.71MB read
        Requests/sec:    701.75
        Transfer/sec:    551.67KB
        ------------------------------
        stop time: 32.660801
        stop time: 33.096597
        stop time: 33.216887
        stop time: 33.147465
        stop time: 32.779638
        stop time: 33.020633
        stop time: 32.997625
        stop time: 33.119182
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [32.660801, 33.096597, 33.216887, 33.147465, 32.779638, 33.020633, 32.997625, 33.119182]
    [exp] Throughput: 1211.9429646915414
[test.py] Running slowdown experiment
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.00105037', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '525.0', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '525.0', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '525.0'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   686.57ms  271.66ms   1.62s    66.09%
        Req/Sec    95.25     51.30   212.00     64.17%
        Latency Distribution
        50%  639.09ms
        75%  868.43ms
        90%    1.08s
        99%    1.31s
        1837 requests in 3.02s, 1.41MB read
        Requests/sec:    607.65
        Transfer/sec:    477.69KB
        [run.sh] Speed is 607.65, duration is 98
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d98s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-5f66c6545c-fdchg        196m         55Mi
        service1-5b56b4b86-w78v2         11m          12Mi
        service2-5cf74bd689-h8mqb        326m         12Mi
        service3-7c7f4786d5-m7l4f        158m         12Mi
        ubuntu-client-76886f6bbd-4m525   6m           16Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   682.20ms  400.61ms   3.66s    72.59%
        Req/Sec    97.39     48.57   410.00     67.56%
        Latency Distribution
        50%  593.16ms
        75%  890.26ms
        90%    1.23s
        99%    1.92s
        40000 requests in 1.63m, 30.71MB read
        Requests/sec:    408.16
        Transfer/sec:    320.87KB
        ------------------------------
        stop time: 53.200813
        stop time: 53.351694
        stop time: 53.435830
        stop time: 53.532967
        stop time: 53.086762
        stop time: 53.960341
        stop time: 53.703057
        stop time: 53.970025
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [53.200813, 53.351694, 53.43583, 53.532967, 53.086762, 53.960341, 53.703057, 53.970025]
    [exp] Throughput: 747.2419375975036
    [exp] Running (pre_run: False) workload synthetic/fanout-w3-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '30000000', 'PROCESSING_TIME_SERVICE0': '0.00114409', 'PROCESSING_TIME_SERVICE1': '0.00099018', 'PROCESSING_TIME_SERVICE2': '0.00105037', 'PROCESSING_TIME_SERVICE3': '0.00046771', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '262.5', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '262.5', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '262.5'}
    [exp] Executing cmd `bash run.sh synthetic fanout-w3-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request fanout-w3-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   576.63ms  227.80ms   1.57s    66.70%
        Req/Sec   111.07     49.28   230.00     64.00%
        Latency Distribution
        50%  558.05ms
        75%  717.32ms
        90%  888.12ms
        99%    1.24s
        2275 requests in 3.03s, 1.75MB read
        Requests/sec:    752.04
        Transfer/sec:    591.21KB
        [run.sh] Speed is 752.04, duration is 79
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d79s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   553.70ms  297.82ms   2.81s    76.05%
        Req/Sec   116.84     50.08   313.00     66.98%
        Latency Distribution
        50%  481.35ms
        75%  678.21ms
        90%  961.16ms
        99%    1.51s
        40000 requests in 1.32m, 30.71MB read
        Requests/sec:    506.33
        Transfer/sec:    398.04KB
        ------------------------------
        stop time: 43.776956
        stop time: 43.483939
        stop time: 43.775176
        stop time: 43.602559
        stop time: 43.196716
        stop time: 43.091941
        stop time: 43.663862
        stop time: 43.451265
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [43.776956, 43.483939, 43.775176, 43.602559, 43.196716, 43.091941, 43.663862, 43.451265]
    [exp] Throughput: 919.4281706137116
[test.py] Baseline throughput:  1097.522246124275
[test.py] Groundtruth:  [1210.383729201877, 1211.9429646915414]
[test.py] Slowdown:  [747.2419375975036, 919.4281706137116]
[test.py] Predicted:  [1229.9069288301941, 1212.1982877290068]
[test.py] Error percentage:  [1.6129760469591448, 0.021067248616798002]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1097.522246124275
    Groundtruth: [1210.383729201877, 1211.9429646915414]
    Slowdown:    [747.2419375975036, 919.4281706137116]
    Predicted:   [1229.9069288301941, 1212.1982877290068]
    Error Perc:  [1.6129760469591448, 0.021067248616798002]
