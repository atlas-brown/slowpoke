[config.py] Random numbers for execution time: [327.1401928188092, 413.64483282972117, 538.4197694084535, 757.768661517463, 1034.1911857738382]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : dynamic-once-http-async
repetitions                      : 1
target_num_exp                   : 10
pre_run                          : False
num_req                          : 40000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 14495
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.8, 'service3': 0.2, 'service4': 0.8}
baseline_service_processing_time : {'service0': 1034.19, 'service1': 757.77, 'service2': 673.02, 'service3': 2068.22, 'service4': 408.93}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2, 'service4': 2}
target_processing_time_range     : [0, 673.02]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 67, 134, 201, 268, 335, 402, 469, 536, 603]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   370.97ms  104.22ms 864.78ms   85.09%
        Req/Sec   173.39     58.88   313.00     73.66%
        Latency Distribution
        50%  340.14ms
        75%  391.98ms
        90%  514.76ms
        99%  769.05ms
        3908 requests in 3.03s, 2.27MB read
        Requests/sec:   1291.22
        Transfer/sec:    768.82KB
        [run.sh] Speed is 1291.22, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   349.38ms  110.95ms   1.82s    91.32%
        Req/Sec   183.87     49.35   606.00     70.33%
        Latency Distribution
        50%  334.21ms
        75%  372.17ms
        90%  421.46ms
        99%  771.58ms
        40000 requests in 46.00s, 23.20MB read
        Requests/sec:    869.56
        Transfer/sec:    516.52KB
        ------------------------------
        stop time: 26.663442
        stop time: 27.246658
        stop time: 27.238829
        stop time: 27.397443
        stop time: 27.363352
        stop time: 27.579597
        stop time: 27.514781
        stop time: 27.408228
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [26.663442, 27.246658, 27.238829, 27.397443, 27.363352, 27.579597, 27.514781, 27.408228]
    [exp] Throughput: 1465.1187503928923
[test.py] Baseline throughput: 1465.1187503928923
[test.py] Running 0th optmization experiment
[test.py] Running 0th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.0', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   374.13ms  107.20ms   1.18s    83.11%
        Req/Sec   175.71     57.73   390.00     75.80%
        Latency Distribution
        50%  343.56ms
        75%  402.92ms
        90%  511.48ms
        99%  742.79ms
        3876 requests in 3.03s, 2.25MB read
        Requests/sec:   1279.11
        Transfer/sec:    759.77KB
        [run.sh] Speed is 1279.11, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-bc779         600m         52Mi
        service2-66888cb84d-f69l6        3m           12Mi
        service3-67b8d48975-m2sff        200m         8Mi
        service4-dcdcc9fc4-dgmsj         221m         9Mi
        ubuntu-client-76886f6bbd-p6tpg   31m          0Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   345.27ms  127.54ms   1.97s    89.99%
        Req/Sec   187.60     53.04   535.00     73.68%
        Latency Distribution
        50%  330.24ms
        75%  370.65ms
        90%  424.13ms
        99%  802.19ms
        40001 requests in 46.00s, 23.21MB read
        Requests/sec:    869.58
        Transfer/sec:    516.63KB
        ------------------------------
        stop time: 26.186457
        stop time: 26.551117
        stop time: 26.586710
        stop time: 26.830398
        stop time: 27.013542
        stop time: 27.223345
        stop time: 27.263214
        stop time: 27.303680
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.186457, 26.551117, 26.58671, 26.830398, 27.013542, 27.223345, 27.263214, 27.30368]
    [exp] Throughput: 1488.6596951523607
[test.py] Running 0th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '269.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '26899990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '269.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '26899990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1346.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '26919990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '336.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '26919990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-57bdd7df56-vwv99 cannot connect to service4
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   507.27ms  115.94ms   1.01s    78.95%
        Req/Sec   129.55     48.91   270.00     68.40%
        Latency Distribution
        50%  469.40ms
        75%  539.98ms
        90%  708.01ms
        99%  845.13ms
        2779 requests in 3.03s, 1.61MB read
        Requests/sec:    916.29
        Transfer/sec:    544.03KB
        [run.sh] Speed is 916.29, duration is 65
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d65s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-57bdd7df56-vwv99        1050m        55Mi
        service1-757d89b8c5-vzd94        65m          19Mi
        service2-66888cb84d-zgbxh        53m          15Mi
        service3-55fc5c66c-d82mk         333m         8Mi
        service4-86df9775f9-7n5bw        290m         10Mi
        ubuntu-client-76886f6bbd-xhrrf   33m          13Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   480.19ms   82.03ms   1.82s    81.78%
        Req/Sec   133.43     41.92   390.00     68.49%
        Latency Distribution
        50%  470.73ms
        75%  511.00ms
        90%  563.35ms
        99%  725.11ms
        40000 requests in 1.08m, 23.21MB read
        Requests/sec:    615.38
        Transfer/sec:    365.72KB
        ------------------------------
        stop time: 37.065310
        stop time: 37.507506
        stop time: 37.693673
        stop time: 37.756218
        stop time: 37.818431
        stop time: 37.991401
        stop time: 38.003879
        stop time: 37.981830
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [37.06531, 37.507506, 37.693673, 37.756218, 37.818431, 37.991401, 38.003879, 37.98183]
    [exp] Throughput: 1060.2407313689
[test.py] Finished running 0th optmization experiment: groundtruth->1488.6596951523607, slowdown->1060.2407313689, predicted->1483.7367063218799, err->-0.33069941011447446
[test.py] Running 1th optmization experiment
[test.py] Running 1th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '6.7e-05', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   365.99ms  115.70ms   1.19s    86.74%
        Req/Sec   170.33     58.94   323.00     72.61%
        Latency Distribution
        50%  336.44ms
        75%  385.18ms
        90%  488.59ms
        99%  885.84ms
        3917 requests in 3.03s, 2.27MB read
        Requests/sec:   1292.72
        Transfer/sec:    767.20KB
        [run.sh] Speed is 1292.72, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-29ccc         740m         55Mi
        service1-5c544b6b9c-nzsv9        500m         18Mi
        service2-66888cb84d-824pr        225m         11Mi
        service3-67b8d48975-nq29b        227m         8Mi
        service4-dcdcc9fc4-d6lhm         157m         9Mi
        ubuntu-client-76886f6bbd-sjm58   12m          12Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   349.04ms   77.30ms   1.14s    83.89%
        Req/Sec   183.36     46.86   343.00     68.42%
        Latency Distribution
        50%  335.87ms
        75%  374.60ms
        90%  425.47ms
        99%  637.65ms
        40000 requests in 46.00s, 23.21MB read
        Requests/sec:    869.56
        Transfer/sec:    516.61KB
        ------------------------------
        stop time: 27.319430
        stop time: 27.484907
        stop time: 27.373013
        stop time: 27.516090
        stop time: 27.566513
        stop time: 27.522527
        stop time: 27.452996
        stop time: 27.275275
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.31943, 27.484907, 27.373013, 27.51609, 27.566513, 27.522527, 27.452996, 27.275275]
    [exp] Throughput: 1457.7873682369207
[test.py] Running 1th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '242.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '24199990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '242.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '24199990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1212.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '24239990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '303.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '24239990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   487.69ms   93.01ms 844.63ms   77.30%
        Req/Sec   132.59     43.14   290.00     75.46%
        Latency Distribution
        50%  463.05ms
        75%  513.16ms
        90%  627.86ms
        99%  789.43ms
        2899 requests in 3.03s, 1.68MB read
        Requests/sec:    956.52
        Transfer/sec:    567.45KB
        [run.sh] Speed is 956.52, duration is 62
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d62s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-688c6bfc4d-fqjnh        1467m        56Mi
        service1-77db5cb8cf-nmjvs        1203m        20Mi
        service2-66888cb84d-27lcq        1032m        13Mi
        service3-869ff9444d-s6fjh        507m         9Mi
        service4-5cdd489855-rv7hb        535m         10Mi
        ubuntu-client-76886f6bbd-cf5fb   57m          14Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   469.28ms   88.90ms   1.67s    82.64%
        Req/Sec   136.63     44.95   440.00     70.57%
        Latency Distribution
        50%  458.59ms
        75%  501.84ms
        90%  557.36ms
        99%  767.16ms
        40001 requests in 1.03m, 23.22MB read
        Requests/sec:    645.18
        Transfer/sec:    383.52KB
        ------------------------------
        stop time: 36.335128
        stop time: 36.335148
        stop time: 36.692737
        stop time: 37.059000
        stop time: 37.151231
        stop time: 37.042631
        stop time: 37.035332
        stop time: 37.120696
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [36.335128, 36.335148, 36.692737, 37.059, 37.151231, 37.042631, 37.035332, 37.120696]
    [exp] Throughput: 1085.5851481882926
[test.py] Finished running 1th optmization experiment: groundtruth->1457.7873682369207, slowdown->1085.5851481882926, predicted->1473.2873912294365, err->1.06325677737638
[test.py] Running 2th optmization experiment
[test.py] Running 2th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.000134', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   391.70ms  251.81ms   1.73s    88.49%
        Req/Sec   165.51     60.39   373.00     67.51%
        Latency Distribution
        50%  328.60ms
        75%  388.89ms
        90%  626.81ms
        99%    1.58s
        3931 requests in 3.03s, 2.28MB read
        Requests/sec:   1296.40
        Transfer/sec:    768.75KB
        [run.sh] Speed is 1296.40, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-bkt5m         1943m        55Mi
        service1-5c544b6b9c-gd645        1639m        17Mi
        service2-66888cb84d-mnql4        880m         11Mi
        service3-67b8d48975-q5cxw        669m         8Mi
        service4-dcdcc9fc4-s2flm         736m         9Mi
        ubuntu-client-76886f6bbd-h6qnb   73m          14Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   349.11ms  111.38ms   1.92s    90.19%
        Req/Sec   184.36     48.02   414.00     71.56%
        Latency Distribution
        50%  332.31ms
        75%  371.86ms
        90%  427.71ms
        99%  779.93ms
        40000 requests in 46.00s, 23.20MB read
        Requests/sec:    869.56
        Transfer/sec:    516.42KB
        ------------------------------
        stop time: 27.063626
        stop time: 27.046201
        stop time: 27.214495
        stop time: 27.292630
        stop time: 27.358006
        stop time: 27.436815
        stop time: 27.430597
        stop time: 27.462598
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.063626, 27.046201, 27.214495, 27.29263, 27.358006, 27.436815, 27.430597, 27.462598]
    [exp] Throughput: 1465.8392932221316
[test.py] Running 2th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '215.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '21549990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '215.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '21549990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1078.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '21559990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '269.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '21559990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-6945b86b4f-qm29c cannot connect to service4
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   471.78ms  181.65ms   1.39s    81.99%
        Req/Sec   130.64     52.91   292.00     71.43%
        Latency Distribution
        50%  441.68ms
        75%  483.83ms
        90%  653.21ms
        99%    1.25s
        3028 requests in 3.02s, 1.77MB read
        Requests/sec:   1001.23
        Transfer/sec:    599.18KB
        [run.sh] Speed is 1001.23, duration is 59
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d59s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6945b86b4f-qm29c        1512m        56Mi
        service1-77d84d9f4-8gw4v         1259m        19Mi
        service2-66888cb84d-xncb7        1058m        13Mi
        service3-7bf85b79cb-lvkbz        506m         9Mi
        service4-59ccb9bfd9-bkl2t        549m         10Mi
        ubuntu-client-76886f6bbd-hs7tg   59m          14Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   453.53ms   89.35ms   1.83s    84.21%
        Req/Sec   141.56     44.89   380.00     71.99%
        Latency Distribution
        50%  443.82ms
        75%  484.09ms
        90%  539.15ms
        99%  722.53ms
        40000 requests in 0.98m, 23.22MB read
        Requests/sec:    677.96
        Transfer/sec:    403.00KB
        ------------------------------
        stop time: 34.854651
        stop time: 35.327231
        stop time: 35.631247
        stop time: 35.434209
        stop time: 35.769114
        stop time: 35.920202
        stop time: 36.042461
        stop time: 35.981839
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [34.854651, 35.327231, 35.631247, 35.434209, 35.769114, 35.920202, 36.042461, 35.981839]
    [exp] Throughput: 1122.960867122869
[test.py] Finished running 2th optmization experiment: groundtruth->1465.8392932221316, slowdown->1122.960867122869, predicted->1481.7120111752201, err->1.0828416202568827
[test.py] Running 3th optmization experiment
[test.py] Running 3th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.000201', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-8cbfd77d6-5sjlr cannot connect to service4
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   369.66ms  157.27ms   1.57s    90.19%
        Req/Sec   177.06     57.36   333.00     73.21%
        Latency Distribution
        50%  331.21ms
        75%  384.53ms
        90%  489.89ms
        99%    1.10s
        3989 requests in 3.03s, 2.32MB read
        Requests/sec:   1317.65
        Transfer/sec:    784.13KB
        [run.sh] Speed is 1317.65, duration is 45
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d45s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-5sjlr         1942m        55Mi
        service1-5c544b6b9c-cb9dk        1507m        20Mi
        service2-66888cb84d-646c7        787m         14Mi
        service3-67b8d48975-cntvl        672m         9Mi
        service4-dcdcc9fc4-89nqq         748m         9Mi
        ubuntu-client-76886f6bbd-knm89   41m          13Mi
        Running 45s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   346.29ms   80.23ms   1.10s    84.45%
        Req/Sec   184.85     49.46   383.00     69.66%
        Latency Distribution
        50%  332.58ms
        75%  370.90ms
        90%  425.30ms
        99%  645.14ms
        40001 requests in 45.00s, 23.21MB read
        Requests/sec:    888.91
        Transfer/sec:    528.07KB
        ------------------------------
        stop time: 26.908631
        stop time: 27.092060
        stop time: 26.890609
        stop time: 27.310211
        stop time: 27.268841
        stop time: 27.381816
        stop time: 27.389401
        stop time: 27.392397
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [26.908631, 27.09206, 26.890609, 27.310211, 27.268841, 27.381816, 27.389401, 27.392397]
    [exp] Throughput: 1470.3587214874356
[test.py] Running 3th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '188.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '18849990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '188.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '18849990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '944.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '18879990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '236.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '18879990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   465.66ms  206.69ms   1.55s    84.51%
        Req/Sec   136.59     53.30   282.00     66.52%
        Latency Distribution
        50%  411.63ms
        75%  478.25ms
        90%  735.87ms
        99%    1.31s
        3126 requests in 3.03s, 1.82MB read
        Requests/sec:   1030.03
        Transfer/sec:    614.68KB
        [run.sh] Speed is 1030.03, duration is 58
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d58s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service1-76d7458d4d-tvsbr        3m           18Mi
        service2-66888cb84d-cf2f9        3m           13Mi
        ubuntu-client-76886f6bbd-rxlpb   21m          0Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   441.52ms   99.80ms   1.96s    89.07%
        Req/Sec   145.19     43.39   323.00     65.26%
        Latency Distribution
        50%  429.28ms
        75%  467.14ms
        90%  522.67ms
        99%  771.64ms
        40000 requests in 0.97m, 23.21MB read
        Requests/sec:    689.65
        Transfer/sec:    409.71KB
        ------------------------------
        stop time: 34.358647
        stop time: 34.461965
        stop time: 34.535051
        stop time: 34.544144
        stop time: 34.858441
        stop time: 34.770204
        stop time: 34.799715
        stop time: 34.697022
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [34.358647, 34.461965, 34.535051, 34.544144, 34.858441, 34.770204, 34.799715, 34.697022]
    [exp] Throughput: 1155.1296153072924
[test.py] Finished running 3th optmization experiment: groundtruth->1470.3587214874356, slowdown->1155.1296153072924, predicted->1477.332441196894, err->0.47428696191931663
[test.py] Running 4th optmization experiment
[test.py] Running 4th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.000268', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   380.99ms  107.39ms 772.27ms   79.66%
        Req/Sec   177.92     53.50   292.00     72.60%
        Latency Distribution
        50%  345.13ms
        75%  404.98ms
        90%  553.02ms
        99%  715.61ms
        3811 requests in 3.03s, 2.21MB read
        Requests/sec:   1257.97
        Transfer/sec:    747.75KB
        [run.sh] Speed is 1257.97, duration is 47
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d47s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-nl2mb         69m          52Mi
        service1-5c544b6b9c-qhh5v        373m         19Mi
        service2-66888cb84d-x4ppr        299m         12Mi
        service3-67b8d48975-fqjdk        3m           8Mi
        ubuntu-client-76886f6bbd-qmrlt   26m          0Mi
        Running 47s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   346.65ms  103.91ms   1.74s    89.34%
        Req/Sec   185.05     48.47   383.00     71.41%
        Latency Distribution
        50%  330.85ms
        75%  369.26ms
        90%  423.11ms
        99%  700.00ms
        40000 requests in 47.00s, 23.20MB read
        Requests/sec:    851.06
        Transfer/sec:    505.45KB
        ------------------------------
        stop time: 26.677835
        stop time: 26.959297
        stop time: 27.154630
        stop time: 27.295817
        stop time: 27.141883
        stop time: 27.296592
        stop time: 27.339769
        stop time: 27.351240
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.677835, 26.959297, 27.15463, 27.295817, 27.141883, 27.296592, 27.339769, 27.35124]
    [exp] Throughput: 1473.1807694131285
[test.py] Running 4th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '162.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '16199990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '162.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '16199990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '810.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '16199990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '202.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '16199990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-6778c7888b-lbgsj cannot connect to service4
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   431.50ms   86.17ms 841.38ms   78.26%
        Req/Sec   149.48     51.43   300.00     75.00%
        Latency Distribution
        50%  414.39ms
        75%  457.80ms
        90%  545.18ms
        99%  733.91ms
        3294 requests in 3.03s, 1.91MB read
        Requests/sec:   1086.44
        Transfer/sec:    645.11KB
        [run.sh] Speed is 1086.44, duration is 55
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-6778c7888b-lbgsj        203m         57Mi
        service1-84c95d5d89-qm9rl        430m         19Mi
        service2-66888cb84d-m4n48        475m         14Mi
        service3-d59876d5-q6vg6          5m           9Mi
        service4-86b9b4c686-wxq4l        60m          10Mi
        ubuntu-client-76886f6bbd-rdqfr   40m          13Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   423.41ms  117.46ms   1.91s    90.95%
        Req/Sec   151.66     48.32   380.00     67.84%
        Latency Distribution
        50%  409.81ms
        75%  451.10ms
        90%  504.00ms
        99%  832.52ms
        40000 requests in 0.92m, 23.21MB read
        Requests/sec:    727.27
        Transfer/sec:    432.09KB
        ------------------------------
        stop time: 32.748504
        stop time: 32.712535
        stop time: 33.161984
        stop time: 33.098329
        stop time: 33.296065
        stop time: 33.290859
        stop time: 33.270529
        stop time: 33.500627
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [32.748504, 32.712535, 33.161984, 33.098329, 33.296065, 33.290859, 33.270529, 33.500627]
    [exp] Throughput: 1207.1853239824356
[test.py] Finished running 4th optmization experiment: groundtruth->1473.1807694131285, slowdown->1207.1853239824356, predicted->1500.67855056512, err->1.8665585190163665
[test.py] Running 5th optmization experiment
[test.py] Running 5th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.000335', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   367.94ms  111.64ms   1.09s    87.18%
        Req/Sec   173.91     53.06   290.00     72.77%
        Latency Distribution
        50%  334.86ms
        75%  380.52ms
        90%  494.76ms
        99%  874.93ms
        3906 requests in 3.03s, 2.26MB read
        Requests/sec:   1288.67
        Transfer/sec:    764.48KB
        [run.sh] Speed is 1288.67, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-j7rfp         1728m        55Mi
        service1-5c544b6b9c-7hhw5        1640m        17Mi
        service2-66888cb84d-tmgtq        1076m        12Mi
        service3-67b8d48975-nrqsl        505m         8Mi
        service4-dcdcc9fc4-p7vjn         467m         8Mi
        ubuntu-client-76886f6bbd-x9tf6   74m          13Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   348.18ms   88.92ms   1.45s    87.86%
        Req/Sec   184.18     48.81   390.00     71.38%
        Latency Distribution
        50%  333.63ms
        75%  371.67ms
        90%  423.07ms
        99%  652.14ms
        40000 requests in 46.00s, 23.21MB read
        Requests/sec:    869.56
        Transfer/sec:    516.60KB
        ------------------------------
        stop time: 27.180156
        stop time: 27.115462
        stop time: 27.306608
        stop time: 27.304741
        stop time: 27.383563
        stop time: 27.356299
        stop time: 27.430704
        stop time: 27.518138
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.180156, 27.115462, 27.306608, 27.304741, 27.383563, 27.356299, 27.430704, 27.518138]
    [exp] Throughput: 1463.8899230534166
[test.py] Running 5th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '135.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '13499990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '135.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '13499990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '676.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '13519990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '169.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '13519990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   439.05ms  191.87ms   1.60s    82.97%
        Req/Sec   137.85     49.88   270.00     65.42%
        Latency Distribution
        50%  400.61ms
        75%  466.90ms
        90%  640.35ms
        99%    1.22s
        3299 requests in 3.03s, 1.93MB read
        Requests/sec:   1088.03
        Transfer/sec:    651.15KB
        [run.sh] Speed is 1088.03, duration is 55
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d55s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-65c7d99f84-nt5bm        1658m        56Mi
        service1-8648975b79-7szbv        1374m        18Mi
        service2-66888cb84d-bx9wz        1155m        13Mi
        service3-6c95986bf4-kz2kr        587m         9Mi
        service4-7d84995f88-jmgvt        615m         10Mi
        ubuntu-client-76886f6bbd-47868   65m          14Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   411.36ms   93.63ms   1.77s    85.71%
        Req/Sec   156.01     52.00   470.00     68.32%
        Latency Distribution
        50%  399.40ms
        75%  440.57ms
        90%  496.77ms
        99%  739.84ms
        40000 requests in 0.92m, 23.19MB read
        Requests/sec:    727.27
        Transfer/sec:    431.79KB
        ------------------------------
        stop time: 31.609253
        stop time: 31.900998
        stop time: 32.140545
        stop time: 32.450188
        stop time: 32.478663
        stop time: 32.558005
        stop time: 32.583657
        stop time: 32.505919
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [31.609253, 31.900998, 32.140545, 32.450188, 32.478663, 32.558005, 32.583657, 32.505919]
    [exp] Throughput: 1239.2186621001874
[test.py] Finished running 5th optmization experiment: groundtruth->1463.8899230534166, slowdown->1239.2186621001874, predicted->1488.6444249419621, err->1.69100842206168
[test.py] Running 6th optmization experiment
[test.py] Running 6th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.000402', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   367.50ms   98.20ms 757.31ms   80.52%
        Req/Sec   172.70     60.26   333.00     74.34%
        Latency Distribution
        50%  337.54ms
        75%  390.80ms
        90%  516.18ms
        99%  694.31ms
        3912 requests in 3.03s, 2.27MB read
        Requests/sec:   1293.05
        Transfer/sec:    768.84KB
        [run.sh] Speed is 1293.05, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   348.17ms   97.04ms   1.94s    89.66%
        Req/Sec   184.42     47.50   360.00     70.28%
        Latency Distribution
        50%  332.94ms
        75%  372.32ms
        90%  424.41ms
        99%  640.80ms
        40000 requests in 46.00s, 23.20MB read
        Requests/sec:    869.56
        Transfer/sec:    516.45KB
        ------------------------------
        stop time: 26.924707
        stop time: 26.950171
        stop time: 27.240797
        stop time: 27.147934
        stop time: 27.376614
        stop time: 27.445945
        stop time: 27.384777
        stop time: 27.465942
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [26.924707, 26.950171, 27.240797, 27.147934, 27.376614, 27.445945, 27.384777, 27.465942]
    [exp] Throughput: 1468.3149989198482
[test.py] Running 6th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '108.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10799990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '108.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10799990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '542.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10839990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '135.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10839990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   423.13ms   99.82ms 968.21ms   79.09%
        Req/Sec   151.95     59.16   290.00     69.41%
        Latency Distribution
        50%  400.38ms
        75%  463.25ms
        90%  563.46ms
        99%  804.36ms
        3390 requests in 3.03s, 1.96MB read
        Requests/sec:   1117.09
        Transfer/sec:    662.83KB
        [run.sh] Speed is 1117.09, duration is 53
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d53s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service0-6b494fb974-mp55q   286m         52Mi
        service1-767568b45-xk8cg    445m         19Mi
        service3-7d9b877654-5tqsq   3m           8Mi
        service4-6d598f4f4d-mtxkp   3m           9Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   395.21ms   81.35ms   1.30s    80.56%
        Req/Sec   162.09     50.99   400.00     68.40%
        Latency Distribution
        50%  381.94ms
        75%  426.44ms
        90%  479.52ms
        99%  681.29ms
        40000 requests in 0.88m, 23.21MB read
        Requests/sec:    754.71
        Transfer/sec:    448.37KB
        ------------------------------
        stop time: 30.846812
        stop time: 30.702823
        stop time: 30.944165
        stop time: 30.979930
        stop time: 31.100139
        stop time: 31.244003
        stop time: 31.283830
        stop time: 31.281037
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [30.846812, 30.702823, 30.944165, 30.97993, 31.100139, 31.244003, 31.28383, 31.281037]
    [exp] Throughput: 1288.334291216589
[test.py] Finished running 6th optmization experiment: groundtruth->1468.3149989198482, slowdown->1288.334291216589, predicted->1497.4811034146458, err->1.9863656310977753
[test.py] Running 7th optmization experiment
[test.py] Running 7th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.000469', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   374.62ms  135.31ms   1.37s    86.96%
        Req/Sec   165.77     62.64   333.00     68.22%
        Latency Distribution
        50%  342.72ms
        75%  402.10ms
        90%  499.54ms
        99%    1.01s
        3913 requests in 3.03s, 2.27MB read
        Requests/sec:   1291.97
        Transfer/sec:    768.50KB
        [run.sh] Speed is 1291.97, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-cs6ng         370m         39Mi
        service1-5c544b6b9c-l2vfd        505m         18Mi
        service2-66888cb84d-97sbk        370m         13Mi
        service3-67b8d48975-826zl        198m         8Mi
        service4-dcdcc9fc4-vnfgm         224m         9Mi
        ubuntu-client-76886f6bbd-p42tf   31m          0Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   345.73ms   79.60ms   1.35s    85.33%
        Req/Sec   185.01     48.86   373.00     70.89%
        Latency Distribution
        50%  332.62ms
        75%  370.49ms
        90%  422.44ms
        99%  647.65ms
        40000 requests in 46.00s, 23.21MB read
        Requests/sec:    869.56
        Transfer/sec:    516.65KB
        ------------------------------
        stop time: 26.837051
        stop time: 26.971170
        stop time: 27.153582
        stop time: 27.060054
        stop time: 27.327728
        stop time: 27.339423
        stop time: 27.323152
        stop time: 27.254979
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.837051, 26.97117, 27.153582, 27.060054, 27.327728, 27.339423, 27.323152, 27.254979]
    [exp] Throughput: 1472.8412288799918
[test.py] Running 7th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '81.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '8149990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '81.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '8149990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '408.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '8159990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '102.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '8159990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   411.06ms  188.61ms   1.53s    90.15%
        Req/Sec   158.84     55.66   320.00     68.28%
        Latency Distribution
        50%  360.13ms
        75%  426.82ms
        90%  558.73ms
        99%    1.31s
        3635 requests in 3.03s, 2.12MB read
        Requests/sec:   1199.97
        Transfer/sec:    716.38KB
        [run.sh] Speed is 1199.97, duration is 50
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d50s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-795b48bb97-8fctf        1778m        56Mi
        service1-7d4cbfc8d6-94dj5        799m         19Mi
        service2-66888cb84d-sqt88        811m         15Mi
        service3-577bc54975-2qgq9        628m         9Mi
        service4-76b696d755-j9w6m        663m         10Mi
        ubuntu-client-76886f6bbd-sb28n   42m          14Mi
        Running 50s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   382.49ms   97.38ms   1.36s    85.41%
        Req/Sec   167.73     55.81   434.00     67.74%
        Latency Distribution
        50%  368.58ms
        75%  415.31ms
        90%  471.95ms
        99%  771.76ms
        40000 requests in 50.00s, 23.20MB read
        Requests/sec:    800.00
        Transfer/sec:    475.18KB
        ------------------------------
        stop time: 29.553326
        stop time: 29.526222
        stop time: 30.051198
        stop time: 29.985242
        stop time: 30.244000
        stop time: 30.302176
        stop time: 30.349806
        stop time: 30.291301
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [29.553326, 29.526222, 30.051198, 29.985242, 30.244, 30.302176, 30.349806, 30.291301]
    [exp] Throughput: 1331.6506207691198
[test.py] Finished running 7th optmization experiment: groundtruth->1472.8412288799918, slowdown->1331.6506207691198, predicted->1494.0096446072737, err->1.437250350696604
[test.py] Running 8th optmization experiment
[test.py] Running 8th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.000536', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   368.05ms   99.40ms 917.20ms   80.29%
        Req/Sec   182.19     59.93   350.00     74.77%
        Latency Distribution
        50%  336.99ms
        75%  393.26ms
        90%  512.81ms
        99%  691.89ms
        3941 requests in 3.03s, 2.29MB read
        Requests/sec:   1300.55
        Transfer/sec:    772.70KB
        [run.sh] Speed is 1300.55, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-h2dl4         1942m        55Mi
        service1-5c544b6b9c-4kk7x        1634m        19Mi
        service2-66888cb84d-znvl8        1236m        12Mi
        service3-67b8d48975-bkf78        683m         9Mi
        service4-dcdcc9fc4-jxmsp         730m         9Mi
        ubuntu-client-76886f6bbd-8z8b2   72m          13Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   350.65ms   85.91ms   1.67s    86.62%
        Req/Sec   182.61     47.45   360.00     68.34%
        Latency Distribution
        50%  336.64ms
        75%  374.80ms
        90%  429.35ms
        99%  634.86ms
        40000 requests in 46.00s, 23.19MB read
        Requests/sec:    869.56
        Transfer/sec:    516.24KB
        ------------------------------
        stop time: 27.250609
        stop time: 27.601027
        stop time: 27.513829
        stop time: 27.528565
        stop time: 27.573071
        stop time: 27.659485
        stop time: 27.532112
        stop time: 27.628803
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.250609, 27.601027, 27.513829, 27.528565, 27.573071, 27.659485, 27.532112, 27.628803]
    [exp] Throughput: 1452.6471022974652
[test.py] Running 8th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '54.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '5449990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '54.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '5449990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '274.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '5479990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '68.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '5479990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   385.88ms  127.31ms   1.33s    86.02%
        Req/Sec   165.43     63.50   360.00     67.41%
        Latency Distribution
        50%  348.98ms
        75%  404.09ms
        90%  537.71ms
        99%  894.17ms
        3736 requests in 3.03s, 2.18MB read
        Requests/sec:   1231.51
        Transfer/sec:    736.58KB
        [run.sh] Speed is 1231.51, duration is 48
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d48s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 48s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   367.59ms   84.70ms   1.63s    82.31%
        Req/Sec   174.01     54.08   450.00     68.80%
        Latency Distribution
        50%  352.52ms
        75%  397.22ms
        90%  456.72ms
        99%  666.60ms
        40000 requests in 48.00s, 23.21MB read
        Requests/sec:    833.33
        Transfer/sec:    495.12KB
        ------------------------------
        stop time: 28.511387
        stop time: 28.537038
        stop time: 28.943039
        stop time: 28.944146
        stop time: 28.942923
        stop time: 29.006560
        stop time: 29.071356
        stop time: 29.112295
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [28.511387, 28.537038, 28.943039, 28.944146, 28.942923, 29.00656, 29.071356, 29.112295]
    [exp] Throughput: 1384.8692577824372
[test.py] Finished running 8th optmization experiment: groundtruth->1452.6471022974652, slowdown->1384.8692577824372, predicted->1498.6171697393377, err->3.1645722742411126
[test.py] Running 9th optmization experiment
[test.py] Running 9th groundtruth exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.000603', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   372.29ms  135.45ms   1.36s    88.82%
        Req/Sec   171.56     57.73   320.00     70.43%
        Latency Distribution
        50%  341.93ms
        75%  385.68ms
        90%  466.77ms
        99%  972.02ms
        3951 requests in 3.03s, 2.29MB read
        Requests/sec:   1302.69
        Transfer/sec:    773.40KB
        [run.sh] Speed is 1302.69, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-vcn8j         3m           51Mi
        service1-5c544b6b9c-2cftg        163m         18Mi
        service2-66888cb84d-l24qc        279m         12Mi
        service3-67b8d48975-s8h6r        207m         8Mi
        service4-dcdcc9fc4-m2684         223m         9Mi
        ubuntu-client-76886f6bbd-2hxss   10m          0Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   346.52ms  112.57ms   2.06s    90.16%
        Req/Sec   185.48     50.10   560.00     71.34%
        Latency Distribution
        50%  333.26ms
        75%  371.72ms
        90%  420.50ms
        99%  736.96ms
        40000 requests in 46.00s, 23.21MB read
        Requests/sec:    869.56
        Transfer/sec:    516.77KB
        ------------------------------
        stop time: 26.687777
        stop time: 26.529063
        stop time: 26.997363
        stop time: 27.004504
        stop time: 27.119348
        stop time: 27.204226
        stop time: 27.323823
        stop time: 27.392549
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [26.687777, 26.529063, 26.997363, 27.004504, 27.119348, 27.204226, 27.323823, 27.392549]
    [exp] Throughput: 1479.709577216316
[test.py] Running 9th slowdown exp
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-async request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00103419', 'PROCESSING_TIME_SERVICE1': '0.00075777', 'PROCESSING_TIME_SERVICE2': '0.00067302', 'PROCESSING_TIME_SERVICE3': '0.00206822', 'PROCESSING_TIME_SERVICE4': '0.00040893', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '28.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '2799990', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '28.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '2799990', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '140.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '2799990', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '35.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '2799990'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-async 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-async, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   372.38ms  120.75ms 965.32ms   84.21%
        Req/Sec   167.72     65.47   330.00     70.26%
        Latency Distribution
        50%  338.43ms
        75%  391.01ms
        90%  534.57ms
        99%  807.21ms
        3899 requests in 3.03s, 2.27MB read
        Requests/sec:   1285.22
        Transfer/sec:    767.60KB
        [run.sh] Speed is 1285.22, duration is 46
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d46s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-746bdd7cdb-55bqt        271m         55Mi
        service1-bbbb9fdb9-r2fcs         513m         17Mi
        service2-66888cb84d-npbpv        582m         11Mi
        service3-67c75dfb7b-q6tsc        586m         8Mi
        service4-7fb574c664-fw5pv        576m         9Mi
        ubuntu-client-76886f6bbd-7n9ll   18m          14Mi
        Running 46s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   359.94ms  116.68ms   2.09s    89.29%
        Req/Sec   178.79     53.51   363.00     69.69%
        Latency Distribution
        50%  342.29ms
        75%  386.24ms
        90%  445.07ms
        99%  837.87ms
        40000 requests in 46.00s, 23.20MB read
        Requests/sec:    869.56
        Transfer/sec:    516.46KB
        ------------------------------
        stop time: 27.899421
        stop time: 28.008742
        stop time: 27.984796
        stop time: 28.117912
        stop time: 28.192317
        stop time: 28.403157
        stop time: 28.298133
        stop time: 28.367753
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [27.899421, 28.008742, 27.984796, 28.117912, 28.192317, 28.403157, 28.298133, 28.367753]
    [exp] Throughput: 1420.5035329010436
[test.py] Finished running 9th optmization experiment: groundtruth->1479.709577216316, slowdown->1420.5035329010436, predicted->1479.3605783811674, err->-0.02358563062117901
[test.py] Baseline throughput:  1465.1187503928923
[test.py] Groundtruth:  [1488.6596951523607, 1457.7873682369207, 1465.8392932221316, 1470.3587214874356, 1473.1807694131285, 1463.8899230534166, 1468.3149989198482, 1472.8412288799918, 1452.6471022974652, 1479.709577216316]
[test.py] Slowdown:  [1060.2407313689, 1085.5851481882926, 1122.960867122869, 1155.1296153072924, 1207.1853239824356, 1239.2186621001874, 1288.334291216589, 1331.6506207691198, 1384.8692577824372, 1420.5035329010436]
[test.py] Predicted:  [1483.7367063218799, 1473.2873912294365, 1481.7120111752201, 1477.332441196894, 1500.67855056512, 1488.6444249419621, 1497.4811034146458, 1494.0096446072737, 1498.6171697393377, 1479.3605783811674]
[test.py] Error percentage:  [-0.33069941011447446, 1.06325677737638, 1.0828416202568827, 0.47428696191931663, 1.8665585190163665, 1.69100842206168, 1.9863656310977753, 1.437250350696604, 3.1645722742411126, -0.02358563062117901]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1465.1187503928923
    Groundtruth: [1488.6596951523607, 1457.7873682369207, 1465.8392932221316, 1470.3587214874356, 1473.1807694131285, 1463.8899230534166, 1468.3149989198482, 1472.8412288799918, 1452.6471022974652, 1479.709577216316]
    Slowdown:    [1060.2407313689, 1085.5851481882926, 1122.960867122869, 1155.1296153072924, 1207.1853239824356, 1239.2186621001874, 1288.334291216589, 1331.6506207691198, 1384.8692577824372, 1420.5035329010436]
    Predicted:   [1483.7367063218799, 1473.2873912294365, 1481.7120111752201, 1477.332441196894, 1500.67855056512, 1488.6444249419621, 1497.4811034146458, 1494.0096446072737, 1498.6171697393377, 1479.3605783811674]
    Error Perc:  [-0.33069941011447446, 1.06325677737638, 1.0828416202568827, 0.47428696191931663, 1.8665585190163665, 1.69100842206168, 1.9863656310977753, 1.437250350696604, 3.1645722742411126, -0.02358563062117901]
