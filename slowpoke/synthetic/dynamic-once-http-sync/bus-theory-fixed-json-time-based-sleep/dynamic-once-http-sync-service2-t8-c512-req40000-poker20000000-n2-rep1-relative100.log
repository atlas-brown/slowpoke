[config.py] Random numbers for execution time: [330.4282305589177, 926.2147791423245, 969.3195440411856, 1018.5674974891101, 1315.2072117922453]
benchmark                        : synthetic
num_threads                      : 8
num_conns                        : 512
target_service                   : service2
request_type                     : dynamic-once-http-sync
repetitions                      : 1
target_num_exp                   : 2
pre_run                          : False
num_req                          : 40000
groundtruths                     : []
slowdowns                        : []
predicteds                       : []
errs                             : []
client_cpu_quota                 : 2
random_seed                      : 32383
request_ratio                    : {'service0': 1, 'service1': 1, 'service2': 0.8, 'service3': 0.2, 'service4': 0.8}
baseline_service_processing_time : {'service0': 1315.21, 'service1': 1018.57, 'service2': 1211.65, 'service3': 4631.07, 'service4': 413.04}
cpu_quota                        : {'service0': 2, 'service1': 2, 'service2': 2, 'service3': 2, 'service4': 2}
target_processing_time_range     : [0, 1211.65]
baseline_throughputs             : []
poker_batch                      : 20000000
[test.py] Starting experiment...
[test.py] >>>>>>>>>>>>>>>>>>>>>>>>>>>>> Running experiment 0...
[test.py] Actual processing time range: [0, 605]
[test.py] Running baseline experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00131521', 'PROCESSING_TIME_SERVICE1': '0.00101857', 'PROCESSING_TIME_SERVICE2': '0.00121165', 'PROCESSING_TIME_SERVICE3': '0.00463107', 'PROCESSING_TIME_SERVICE4': '0.00041304', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   447.33ms  138.60ms   1.37s    87.43%
        Req/Sec   142.36     48.04   280.00     69.12%
        Latency Distribution
        50%  402.66ms
        75%  464.75ms
        90%  623.64ms
        99%  984.52ms
        3159 requests in 3.03s, 1.83MB read
        Requests/sec:   1043.43
        Transfer/sec:    618.88KB
        [run.sh] Speed is 1043.43, duration is 76
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d76s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   415.49ms  123.92ms   2.31s    89.27%
        Req/Sec   154.44     45.48   440.00     69.01%
        Latency Distribution
        50%  397.61ms
        75%  441.02ms
        90%  507.28ms
        99%  798.74ms
        40000 requests in 1.27m, 23.21MB read
        Requests/sec:    526.31
        Transfer/sec:    312.66KB
        ------------------------------
        stop time: 31.767000
        stop time: 32.355219
        stop time: 32.525381
        stop time: 32.418679
        stop time: 32.811589
        stop time: 32.761596
        stop time: 32.912471
        stop time: 32.991722
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > error: metrics not available yet
    [exp] Times: [31.767, 32.355219, 32.525381, 32.418679, 32.811589, 32.761596, 32.912471, 32.991722]
    [exp] Throughput: 1228.2010764898414
[test.py] Baseline throughput: 1228.2010764898414
[test.py] Running groundtruth experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00131521', 'PROCESSING_TIME_SERVICE1': '0.00101857', 'PROCESSING_TIME_SERVICE2': '0.0', 'PROCESSING_TIME_SERVICE3': '0.00463107', 'PROCESSING_TIME_SERVICE4': '0.00041304', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-8cbfd77d6-hhxt6 cannot connect to service4
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   449.37ms  186.46ms   1.54s    90.18%
        Req/Sec   147.26     44.12   252.00     73.61%
        Latency Distribution
        50%  399.47ms
        75%  467.97ms
        90%  608.98ms
        99%    1.37s
        3256 requests in 3.03s, 1.89MB read
        Requests/sec:   1075.26
        Transfer/sec:    639.23KB
        [run.sh] Speed is 1075.26, duration is 74
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d74s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-hhxt6         1950m        50Mi
        service1-5c544b6b9c-2j766        1662m        17Mi
        service2-66888cb84d-56ws4        635m         9Mi
        service3-67b8d48975-kf4zh        1156m        11Mi
        service4-dcdcc9fc4-4s9t9         639m         9Mi
        ubuntu-client-76886f6bbd-xjs5x   61m          14Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   416.32ms  106.00ms   1.89s    88.03%
        Req/Sec   153.86     45.51   414.00     69.96%
        Latency Distribution
        50%  400.56ms
        75%  444.99ms
        90%  505.45ms
        99%  798.80ms
        40002 requests in 1.23m, 23.20MB read
        Requests/sec:    540.57
        Transfer/sec:    321.08KB
        ------------------------------
        stop time: 32.301264
        stop time: 32.240693
        stop time: 32.455549
        stop time: 32.795727
        stop time: 32.856799
        stop time: 33.009836
        stop time: 32.966642
        stop time: 33.014263
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [32.301264, 32.240693, 32.455549, 32.795727, 32.856799, 33.009836, 32.966642, 33.014263]
    [exp] Throughput: 1223.050965378397
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00131521', 'PROCESSING_TIME_SERVICE1': '0.00101857', 'PROCESSING_TIME_SERVICE2': '0.000605', 'PROCESSING_TIME_SERVICE3': '0.00463107', 'PROCESSING_TIME_SERVICE4': '0.00041304', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '10'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] service0-8cbfd77d6-2kprm cannot connect to service4
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   476.21ms  304.25ms   1.99s    82.53%
        Req/Sec   135.50     49.33   303.00     70.26%
        Latency Distribution
        50%  384.85ms
        75%  466.08ms
        90%  902.98ms
        99%    1.78s
        3166 requests in 3.03s, 1.83MB read
        Socket errors: connect 0, read 0, write 0, timeout 9
        Requests/sec:   1044.86
        Transfer/sec:    619.17KB
        [run.sh] Speed is 1044.86, duration is 76
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d76s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-8cbfd77d6-2kprm         1550m        49Mi
        service1-5c544b6b9c-f7qbj        1140m        18Mi
        service2-66888cb84d-f6gwr        877m         10Mi
        service3-67b8d48975-t2vk5        720m         8Mi
        service4-dcdcc9fc4-rq65t         409m         10Mi
        ubuntu-client-76886f6bbd-k5qh7   11m          14Mi
        Running 1m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   416.10ms  157.29ms   2.95s    89.95%
        Req/Sec   154.40     45.32   404.00     70.66%
        Latency Distribution
        50%  396.66ms
        75%  441.14ms
        90%  505.93ms
        99%  866.20ms
        40000 requests in 1.27m, 23.22MB read
        Requests/sec:    526.31
        Transfer/sec:    312.82KB
        ------------------------------
        stop time: 31.888655
        stop time: 31.835408
        stop time: 32.279682
        stop time: 32.871470
        stop time: 32.968206
        stop time: 32.918916
        stop time: 32.871992
        stop time: 32.676100
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
        > command terminated with exit code 1
    [exp] Times: [31.888655, 31.835408, 32.279682, 32.87147, 32.968206, 32.918916, 32.871992, 32.6761]
    [exp] Throughput: 1229.3014967909717
[test.py] Running slowdown experiment
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00131521', 'PROCESSING_TIME_SERVICE1': '0.00101857', 'PROCESSING_TIME_SERVICE2': '0.00121165', 'PROCESSING_TIME_SERVICE3': '0.00463107', 'PROCESSING_TIME_SERVICE4': '0.00041304', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '484.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '48450000', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '484.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '48450000', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '2423.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '242300000', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '605.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '60550000'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   672.19ms  283.90ms   1.99s    79.19%
        Req/Sec    86.42     38.64   202.00     66.38%
        Latency Distribution
        50%  645.12ms
        75%  730.47ms
        90%  962.82ms
        99%    1.73s
        2019 requests in 3.03s, 1.18MB read
        Socket errors: connect 0, read 0, write 0, timeout 1
        Requests/sec:    666.06
        Transfer/sec:    398.09KB
        [run.sh] Speed is 666.06, duration is 120
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d120s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                        CPU(cores)   MEMORY(bytes)
        service1-6d57ff68b6-p5269   352m         20Mi
        service3-d66b68c6b-8t5br    250m         10Mi
        service4-584c995d7f-j9btf   125m         11Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   671.45ms  121.86ms   2.34s    86.06%
        Req/Sec    95.26     40.20   292.00     65.92%
        Latency Distribution
        50%  657.93ms
        75%  704.30ms
        90%  787.18ms
        99%  993.08ms
        40000 requests in 2.00m, 23.20MB read
        Requests/sec:    333.33
        Transfer/sec:    198.00KB
        ------------------------------
        stop time: 52.240487
        stop time: 52.407329
        stop time: 52.949102
        stop time: 52.885521
        stop time: 53.077868
        stop time: 52.846074
        stop time: 52.949095
        stop time: 52.749308
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [52.240487, 52.407329, 52.949102, 52.885521, 53.077868, 52.846074, 52.949095, 52.749308]
    [exp] Throughput: 758.105598727353
    [exp] Running (pre_run: False) workload synthetic/dynamic-once-http-sync request with the following configuration: {'CLIENT_CPU_QUOTA': '2', 'SLOWPOKE_POKER_BATCH_THRESHOLD': '20000000', 'PROCESSING_TIME_SERVICE0': '0.00131521', 'PROCESSING_TIME_SERVICE1': '0.00101857', 'PROCESSING_TIME_SERVICE2': '0.00121165', 'PROCESSING_TIME_SERVICE3': '0.00463107', 'PROCESSING_TIME_SERVICE4': '0.00041304', 'SLOWPOKE_DELAY_MICROS_SERVICE0': '242.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE0': '24250000', 'SLOWPOKE_DELAY_MICROS_SERVICE1': '242.5', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE1': '24250000', 'SLOWPOKE_DELAY_MICROS_SERVICE2': '0.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE2': '10', 'SLOWPOKE_DELAY_MICROS_SERVICE3': '1213.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE3': '121300000', 'SLOWPOKE_DELAY_MICROS_SERVICE4': '303.0', 'SLOWPOKE_POKER_BATCH_THRESHOLD_SERVICE4': '30300000'}
    [exp] Executing cmd `bash run.sh synthetic dynamic-once-http-sync 8 512 40000`:
        [run.sh] Running benchmark synthetic with request dynamic-once-http-sync, thread 8, conn 512, duration 60
        [run.sh] Deleting all services
        configmap "config-service0" deleted
        deployment.apps "service0" deleted
        service "service0" deleted
        configmap "config-service1" deleted
        deployment.apps "service1" deleted
        service "service1" deleted
        configmap "config-service2" deleted
        deployment.apps "service2" deleted
        service "service2" deleted
        configmap "config-service3" deleted
        deployment.apps "service3" deleted
        service "service3" deleted
        configmap "config-service4" deleted
        deployment.apps "service4" deleted
        service "service4" deleted
        deployment.apps "ubuntu-client" deleted
        [run.sh] Waiting for all pods to be deleted
        [run.sh] Deploying all services
        configmap/config-service0 created
        deployment.apps/service0 created
        service/service0 created
        configmap/config-service1 created
        deployment.apps/service1 created
        service/service1 created
        configmap/config-service2 created
        deployment.apps/service2 created
        service/service2 created
        configmap/config-service3 created
        deployment.apps/service3 created
        service/service3 created
        configmap/config-service4 created
        deployment.apps/service4 created
        service/service4 created
        [run.sh] Client pod not found, deploying client
        deployment.apps/ubuntu-client created
        [run.sh] Waiting for all pods to be running
        [run.sh] All pods are running
        [run.sh] Checking heartbeat for all services
        [run.sh] All pods can connect to all services
        [run.sh] Running warmup test
        [run.sh] /wrk/wrk -t8 -c512 -d3s -L http://service0:80/endpoint1
        Running 3s test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   563.35ms  255.27ms   1.63s    81.53%
        Req/Sec   103.59     44.65   222.00     68.51%
        Latency Distribution
        50%  523.42ms
        75%  581.29ms
        90%  789.45ms
        99%    1.45s
        2452 requests in 3.03s, 1.42MB read
        Requests/sec:    809.55
        Transfer/sec:    480.70KB
        [run.sh] Speed is 809.55, duration is 98
        [run.sh] Fix the request number.
        [run.sh] Running the actual test
        [run.sh] /wrk/wrk --timeout 20s -t8 -c512 -d98s -L -s /wrk/fix_req_n.lua http://service0:80/endpoint1
        [run.sh] Checking the resource usage
        NAME                             CPU(cores)   MEMORY(bytes)
        service0-56664ffc97-56lrw        3m           46Mi
        service1-758468fb7d-kdcxc        3m           19Mi
        service2-66888cb84d-g6pf9        3m           14Mi
        ubuntu-client-76886f6bbd-5hsqt   5m           0Mi
        Running 2m test @ http://service0:80/endpoint1
        8 threads and 512 connections
        Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency   533.60ms  114.32ms   2.39s    88.00%
        Req/Sec   120.15     42.31   313.00     73.83%
        Latency Distribution
        50%  521.21ms
        75%  563.84ms
        90%  630.12ms
        99%  862.53ms
        40000 requests in 1.63m, 23.21MB read
        Requests/sec:    408.16
        Transfer/sec:    242.52KB
        ------------------------------
        stop time: 41.356910
        stop time: 41.356940
        stop time: 41.685423
        stop time: 41.991020
        stop time: 42.229564
        stop time: 42.235964
        stop time: 42.146505
        stop time: 42.093971
        [run.sh] Test finished with status 0
        > STDERR
        > No resources found in default namespace.
    [exp] Times: [41.35691, 41.35694, 41.685423, 41.99102, 42.229564, 42.235964, 42.146505, 42.093971]
    [exp] Throughput: 954.9493768353994
[test.py] Baseline throughput:  1228.2010764898414
[test.py] Groundtruth:  [1223.050965378397, 1229.3014967909717]
[test.py] Slowdown:  [758.105598727353, 954.9493768353994]
[test.py] Predicted:  [1198.4409002951702, 1242.9834699862238]
[test.py] Error percentage:  [-2.012186391236178, 1.1129875975070558]
[test.py] ++++++++++++++++++++++++++++++++ Summary: 
[test.py] Result for the experiment 0: 
    Baseline throughput: 1228.2010764898414
    Groundtruth: [1223.050965378397, 1229.3014967909717]
    Slowdown:    [758.105598727353, 954.9493768353994]
    Predicted:   [1198.4409002951702, 1242.9834699862238]
    Error Perc:  [-2.012186391236178, 1.1129875975070558]
